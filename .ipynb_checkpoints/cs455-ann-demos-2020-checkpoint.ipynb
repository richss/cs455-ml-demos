{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CS 455/595a: Artificial Neural Network Demonstrations - 2020</center></h1>\n",
    "<center>Richard S. Stansbury</center>\n",
    "\n",
    "This notebook applies the ANN techniques for the Titanic Survivors and Boston Housing Prediction models covered in [1] with the [Titanic](https://www.kaggle.com/c/titanic/) and [Boston Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) data sets.\n",
    "\n",
    "This demonstration focuses upon showcasing the Keras API to implement an ANN classifier and an ANN regressor for each.\n",
    "\n",
    "Reference:\n",
    "\n",
    "[1] Aurelen Geron. *Hands on Machine Learning with Scikit-Learn & TensorFlow* O'Reilley Media Inc, 2017.\n",
    "\n",
    "[2] Aurelen Geron. \"ageron/handson-ml: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\" Github.com, online at: https://github.com/ageron/handson-ml [last accessed 2019-03-01]\n",
    "\n",
    "[2] Aurelen Geron. *Hands on Machine Learning with Scikit-Learn, Keras, & TensorFlow* 2nd Edition, O'Reilley Media Inc, 2019.\n",
    "\n",
    "[3] Aurelen Geron. \"ageron/handson-ml: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\" Github.com, online at: https://github.com/ageron/handson-ml2 [last accessed 2020-04-01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. [Titanic Survivor ANN Classifiers](#Titanic-Survivor-Classifier)\n",
    " \n",
    "2. [Boston Housing Cost Ensemble ANN Regressor](#Boston-Housing-Cost-Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# TensorFlow â‰¥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "assert keras.__version__ >= \"2.0\"\n",
    "\n",
    "\n",
    "#From Ageron demo if running under Collaboratory this will remind you to turn on your GPU.\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and apply pipelines to pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data from input files into Pandas data frames\n",
    "data_path = os.path.join(\"datasets\",\"titanic\")\n",
    "train_filename = \"train.csv\"\n",
    "test_filename = \"test.csv\"\n",
    "\n",
    "def read_csv(data_path, filename):\n",
    "    joined_path = os.path.join(data_path, filename)\n",
    "    return pd.read_csv(joined_path)\n",
    "\n",
    "# Read CSV file into Pandas Dataframes\n",
    "train_df = read_csv(data_path, train_filename)\n",
    "\n",
    "# Defining Data Pre-Processing Pipelines\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attributes):\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributes]\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent = pd.Series([X[c].value_counts().index[0] for c in X], \n",
    "                                       index = X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.most_frequent)\n",
    "\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Age\", \"Fare\", \"SibSp\", \"Parch\"])), # Selects Fields from dataframe\n",
    "        (\"Imputer\", SimpleImputer(strategy=\"median\")),   # Fills in NaN w/ median value for its column\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "categories_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Pclass\", \"Sex\"])), # Selects Fields from dataframe\n",
    "        (\"MostFreqImp\", MostFrequentImputer()), # Fill in NaN with most frequent\n",
    "        (\"OneHot\", OneHotEncoder(sparse=False, categories='auto')), # Onehot encode\n",
    "    ])\n",
    "\n",
    "preprocessing_pipe = FeatureUnion(transformer_list = [\n",
    "        (\"numeric pipeline\", numeric_pipe), \n",
    "        (\"categories pipeline\", categories_pipe)\n",
    "     ]) \n",
    "\n",
    "# Process Input Data Using Pipleines\n",
    "X_data = preprocessing_pipe.fit_transform(train_df)\n",
    "y_data = train_df[\"Survived\"].values.reshape(-1,1)\n",
    "\n",
    "# Process the output data.\n",
    "feature_names = [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Class0\", \"class1\",\"Sex0\", \"Sex1\"]\n",
    "\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 9)\n",
      "(179, 9)\n",
      "(235, 9)\n",
      "(477, 1)\n",
      "(179, 1)\n",
      "(235, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(50, activation='relu'),    \n",
    "    keras.layers.Dense(50, activation='relu'),   \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x22fbadc8148>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22fc5fe4dc8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22fc606f0c8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,101\n",
      "Trainable params: 3,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image as PImage\n",
    "import pydot\n",
    "\n",
    "keras.utils.plot_model(model, \"Titanic survivor classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lr = 0.1\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477 samples, validate on 235 samples\n",
      "Epoch 1/20\n",
      "477/477 [==============================] - 1s 1ms/sample - loss: 0.6528 - accuracy: 0.5870 - val_loss: 0.6110 - val_accuracy: 0.7064\n",
      "Epoch 2/20\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.5645 - accuracy: 0.7358 - val_loss: 0.5623 - val_accuracy: 0.7532\n",
      "Epoch 3/20\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.5055 - accuracy: 0.8008 - val_loss: 0.5325 - val_accuracy: 0.7702\n",
      "Epoch 4/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.4635 - accuracy: 0.8176 - val_loss: 0.5204 - val_accuracy: 0.7532\n",
      "Epoch 5/20\n",
      "477/477 [==============================] - 0s 79us/sample - loss: 0.4408 - accuracy: 0.8176 - val_loss: 0.5074 - val_accuracy: 0.7660\n",
      "Epoch 6/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.4240 - accuracy: 0.8281 - val_loss: 0.5047 - val_accuracy: 0.7617\n",
      "Epoch 7/20\n",
      "477/477 [==============================] - 0s 79us/sample - loss: 0.4165 - accuracy: 0.8281 - val_loss: 0.4990 - val_accuracy: 0.7617\n",
      "Epoch 8/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.4107 - accuracy: 0.8323 - val_loss: 0.5036 - val_accuracy: 0.7489\n",
      "Epoch 9/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.4053 - accuracy: 0.8365 - val_loss: 0.4967 - val_accuracy: 0.7617\n",
      "Epoch 10/20\n",
      "477/477 [==============================] - 0s 86us/sample - loss: 0.4009 - accuracy: 0.8302 - val_loss: 0.4999 - val_accuracy: 0.7532\n",
      "Epoch 11/20\n",
      "477/477 [==============================] - 0s 79us/sample - loss: 0.3966 - accuracy: 0.8428 - val_loss: 0.4918 - val_accuracy: 0.7660\n",
      "Epoch 12/20\n",
      "477/477 [==============================] - 0s 77us/sample - loss: 0.3924 - accuracy: 0.8470 - val_loss: 0.4920 - val_accuracy: 0.7745\n",
      "Epoch 13/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.3903 - accuracy: 0.8428 - val_loss: 0.4848 - val_accuracy: 0.7830\n",
      "Epoch 14/20\n",
      "477/477 [==============================] - 0s 77us/sample - loss: 0.3906 - accuracy: 0.8386 - val_loss: 0.4863 - val_accuracy: 0.7702\n",
      "Epoch 15/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.3880 - accuracy: 0.8407 - val_loss: 0.4844 - val_accuracy: 0.7660\n",
      "Epoch 16/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.3830 - accuracy: 0.8428 - val_loss: 0.4869 - val_accuracy: 0.7617\n",
      "Epoch 17/20\n",
      "477/477 [==============================] - 0s 88us/sample - loss: 0.3825 - accuracy: 0.8512 - val_loss: 0.4828 - val_accuracy: 0.7745\n",
      "Epoch 18/20\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.3814 - accuracy: 0.8470 - val_loss: 0.4788 - val_accuracy: 0.7702\n",
      "Epoch 19/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.3777 - accuracy: 0.8491 - val_loss: 0.4878 - val_accuracy: 0.7745\n",
      "Epoch 20/20\n",
      "477/477 [==============================] - 0s 82us/sample - loss: 0.3779 - accuracy: 0.8449 - val_loss: 0.4822 - val_accuracy: 0.7787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val,y_val))\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y, y_score):\n",
    "    \"\"\"\n",
    "    Prints a precision vs. recall curve.\n",
    "    \"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_score)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_roc(y, y_score):\n",
    "    \"\"\"\n",
    "    Prints a Receiver Operating Characteristic (ROC) Curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.show()\n",
    "    \n",
    "def evaluate_classifier(y, y_pred):\n",
    "    \"\"\"\n",
    "    Prints the confusion matrix, precision score, recall score, and f1 score\n",
    "    \"\"\"\n",
    "  \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(\"Pecision Score = \" + str(precision_score(y, y_pred)))\n",
    "    print(\"Recall Score = \" + str(recall_score(y,y_pred)))\n",
    "    print(\"F1 Score = \" + str(f1_score(y,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[98 18]\n",
      " [15 48]]\n",
      "Pecision Score = 0.7272727272727273\n",
      "Recall Score = 0.7619047619047619\n",
      "F1 Score = 0.7441860465116279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "plot_precision_recall_curve(y_test, y_pred_prob)\n",
    "plot_roc(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "y_pred = [1 if y > 0.5 else 0 for y in y_pred_prob]\n",
    "evaluate_classifier(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Cost Estimator\n",
    "\n",
    "Building off the classifier examples above, this section demonstrates an implementation of a simple ANN regressor for boston housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 13)\n",
      "(102, 13)\n",
      "(134, 13)\n",
      "(270,)\n",
      "(102,)\n",
      "(134,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data Set\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "boston_housing_data = datasets.load_boston()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "bouston_housing_data_instances = scaler.fit_transform(boston_housing_data.data)\n",
    "bouston_housing_data_instances.shape\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bouston_housing_data_instances,\n",
    "                                                   boston_housing_data.target,\n",
    "                                                   test_size=0.20)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 581.2902 - mae: 22.1225 - val_loss: 498.6561 - val_mae: 20.4487\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 440.5283 - mae: 18.4713 - val_loss: 197.8446 - val_mae: 11.0970\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 133.0751 - mae: 8.8043 - val_loss: 86.3624 - val_mae: 7.0326\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 95.2673 - mae: 7.2937 - val_loss: 68.4452 - val_mae: 6.0221\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 77.6364 - mae: 6.4566 - val_loss: 56.4140 - val_mae: 5.4097\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 64.3009 - mae: 5.7806 - val_loss: 48.5572 - val_mae: 4.9600\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 55.6785 - mae: 5.3420 - val_loss: 44.2438 - val_mae: 4.6734\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 51.0455 - mae: 5.1531 - val_loss: 41.0107 - val_mae: 4.8142\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 46.9312 - mae: 4.8164 - val_loss: 43.0516 - val_mae: 5.2066\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 43.7695 - mae: 4.7717 - val_loss: 47.0813 - val_mae: 5.6191\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 42.2083 - mae: 4.7076 - val_loss: 42.1446 - val_mae: 5.2359\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 0s 159us/sample - loss: 39.5844 - mae: 4.4963 - val_loss: 33.7122 - val_mae: 4.3498\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 36.8184 - mae: 4.2874 - val_loss: 31.6892 - val_mae: 4.0858\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 36.4737 - mae: 4.1846 - val_loss: 30.2738 - val_mae: 3.9418\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 33.3656 - mae: 4.0338 - val_loss: 33.2130 - val_mae: 4.5201\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 33.3844 - mae: 4.1426 - val_loss: 27.8101 - val_mae: 3.8321\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 30.8594 - mae: 3.9265 - val_loss: 28.9956 - val_mae: 4.1361\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 30.1841 - mae: 3.9334 - val_loss: 25.9115 - val_mae: 3.7032\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 29.5955 - mae: 3.7784 - val_loss: 24.3426 - val_mae: 3.5132\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 28.5363 - mae: 3.7756 - val_loss: 23.4928 - val_mae: 3.2900\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 0s 135us/sample - loss: 26.6204 - mae: 3.5233 - val_loss: 24.3312 - val_mae: 3.6755\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 26.2588 - mae: 3.5976 - val_loss: 23.5898 - val_mae: 3.1958\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 26.4431 - mae: 3.4910 - val_loss: 21.3605 - val_mae: 3.0544\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 25.1783 - mae: 3.4128 - val_loss: 24.9067 - val_mae: 3.8280\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 0s 151us/sample - loss: 24.3937 - mae: 3.4929 - val_loss: 19.6044 - val_mae: 2.9608\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 23.4472 - mae: 3.3574 - val_loss: 21.0249 - val_mae: 2.9585\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 23.5036 - mae: 3.3132 - val_loss: 19.1210 - val_mae: 2.8217\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 21.7266 - mae: 3.1833 - val_loss: 21.3051 - val_mae: 3.4155\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 21.6003 - mae: 3.1848 - val_loss: 18.2758 - val_mae: 2.9677\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 0s 148us/sample - loss: 21.4614 - mae: 3.1997 - val_loss: 19.0493 - val_mae: 2.7544\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 20.7326 - mae: 3.1550 - val_loss: 17.2455 - val_mae: 2.6934\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 21.5864 - mae: 3.2761 - val_loss: 17.0216 - val_mae: 2.6159\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 21.2054 - mae: 3.0808 - val_loss: 21.0535 - val_mae: 3.4321\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 22.3880 - mae: 3.3807 - val_loss: 17.8376 - val_mae: 2.9549\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 0s 144us/sample - loss: 19.3367 - mae: 3.0049 - val_loss: 16.3350 - val_mae: 2.5763\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 19.0868 - mae: 2.9986 - val_loss: 16.1339 - val_mae: 2.5463\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 19.7170 - mae: 3.1281 - val_loss: 16.5625 - val_mae: 2.6920\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 19.9751 - mae: 3.1304 - val_loss: 17.7007 - val_mae: 2.9247\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 20.5289 - mae: 3.1804 - val_loss: 16.7430 - val_mae: 2.7579\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 18.6904 - mae: 2.9929 - val_loss: 16.0663 - val_mae: 2.6412\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 19.5575 - mae: 3.1520 - val_loss: 15.5695 - val_mae: 2.5151\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 18.7196 - mae: 2.9888 - val_loss: 15.7763 - val_mae: 2.5654\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 18.7446 - mae: 3.0337 - val_loss: 16.1682 - val_mae: 2.6704\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 18.4613 - mae: 2.9509 - val_loss: 17.3306 - val_mae: 2.5491\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 18.6547 - mae: 2.9496 - val_loss: 15.4045 - val_mae: 2.4848\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 18.5866 - mae: 2.9219 - val_loss: 15.2246 - val_mae: 2.4087\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 17.9932 - mae: 2.9369 - val_loss: 15.2566 - val_mae: 2.4918\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 0s 170us/sample - loss: 18.0429 - mae: 2.8833 - val_loss: 16.5481 - val_mae: 2.4528\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 17.4647 - mae: 2.8813 - val_loss: 17.0875 - val_mae: 2.5039\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 18.7898 - mae: 2.9057 - val_loss: 14.9558 - val_mae: 2.4299\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 17.3821 - mae: 2.9275 - val_loss: 15.3943 - val_mae: 2.5723\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 18.0385 - mae: 2.9625 - val_loss: 18.6679 - val_mae: 2.6834\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 18.3056 - mae: 3.0152 - val_loss: 15.0171 - val_mae: 2.3684\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 17.8421 - mae: 2.9060 - val_loss: 17.4151 - val_mae: 2.9746\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 17.5622 - mae: 2.9601 - val_loss: 18.4662 - val_mae: 2.6362\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 21.9516 - mae: 3.3155 - val_loss: 16.0091 - val_mae: 2.3780\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 16.9586 - mae: 2.8565 - val_loss: 26.1479 - val_mae: 4.2312\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 19.5257 - mae: 3.1253 - val_loss: 15.2835 - val_mae: 2.6191\n",
      "Epoch 59/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 19.1506 - mae: 3.1527 - val_loss: 22.5926 - val_mae: 3.7496\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 17.0733 - mae: 2.8496 - val_loss: 14.3123 - val_mae: 2.2895\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 16.8293 - mae: 2.8514 - val_loss: 14.3669 - val_mae: 2.2884\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 17.3996 - mae: 2.9104 - val_loss: 15.9620 - val_mae: 2.3751\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 17.0027 - mae: 2.8690 - val_loss: 14.6348 - val_mae: 2.2790\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 17.5782 - mae: 2.9211 - val_loss: 14.4404 - val_mae: 2.4555\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 15.8611 - mae: 2.7270 - val_loss: 56.4183 - val_mae: 6.8356\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 24.5977 - mae: 3.6184 - val_loss: 20.0425 - val_mae: 3.4690\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 19.0852 - mae: 3.0402 - val_loss: 13.9170 - val_mae: 2.2422\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 16.0875 - mae: 2.7555 - val_loss: 13.8637 - val_mae: 2.2584\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 16.7691 - mae: 2.8683 - val_loss: 16.6365 - val_mae: 2.4597\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 15.8193 - mae: 2.7255 - val_loss: 14.1020 - val_mae: 2.4177\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 18.9528 - mae: 3.0443 - val_loss: 13.9723 - val_mae: 2.2053\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 19.6666 - mae: 3.1122 - val_loss: 14.5929 - val_mae: 2.5858\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 15.8554 - mae: 2.7386 - val_loss: 13.6168 - val_mae: 2.2640\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 15.7583 - mae: 2.7133 - val_loss: 15.6949 - val_mae: 2.7780\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 17.1797 - mae: 2.9799 - val_loss: 16.4769 - val_mae: 2.4427\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 17.7904 - mae: 2.9600 - val_loss: 13.5734 - val_mae: 2.3207\n",
      "Epoch 77/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 16.8629 - mae: 2.8895 - val_loss: 17.9817 - val_mae: 2.6209\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 17.0322 - mae: 2.8784 - val_loss: 13.8882 - val_mae: 2.4293\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 15.2613 - mae: 2.7221 - val_loss: 13.9140 - val_mae: 2.2214\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 15.6829 - mae: 2.6963 - val_loss: 14.0128 - val_mae: 2.1880\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 15.0053 - mae: 2.6263 - val_loss: 13.6589 - val_mae: 2.1867\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 15.8037 - mae: 2.7592 - val_loss: 13.8050 - val_mae: 2.1644\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 15.8613 - mae: 2.7405 - val_loss: 15.2762 - val_mae: 2.2965\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 16.4203 - mae: 2.6966 - val_loss: 13.4527 - val_mae: 2.2842\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 16.0841 - mae: 2.7031 - val_loss: 14.2264 - val_mae: 2.5635\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 16.1371 - mae: 2.8519 - val_loss: 15.0676 - val_mae: 2.7068\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 15.5606 - mae: 2.7046 - val_loss: 14.7037 - val_mae: 2.6567\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 15.1415 - mae: 2.7167 - val_loss: 13.3208 - val_mae: 2.2329\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 15.7295 - mae: 2.7341 - val_loss: 13.5604 - val_mae: 2.1958\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 15.5271 - mae: 2.7134 - val_loss: 14.2183 - val_mae: 2.5837\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 15.9764 - mae: 2.7811 - val_loss: 13.5507 - val_mae: 2.1558\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 15.4632 - mae: 2.7093 - val_loss: 13.5258 - val_mae: 2.1576\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 15.2463 - mae: 2.7053 - val_loss: 12.9803 - val_mae: 2.2853\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 16.6317 - mae: 2.9008 - val_loss: 12.9760 - val_mae: 2.2975\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 14.8751 - mae: 2.6583 - val_loss: 13.2824 - val_mae: 2.4058\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 19.0476 - mae: 3.1406 - val_loss: 15.9706 - val_mae: 2.4367\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 15.1444 - mae: 2.6899 - val_loss: 12.9471 - val_mae: 2.1893\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 16.1068 - mae: 2.8050 - val_loss: 39.1685 - val_mae: 5.5613\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 20.7217 - mae: 3.2317 - val_loss: 13.2731 - val_mae: 2.3891\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 16.9970 - mae: 2.8154 - val_loss: 13.2427 - val_mae: 2.3861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(97, activation='relu'),             \n",
    "    keras.layers.Dense(97, activation='relu'),            \n",
    "    keras.layers.Dense(97, activation='relu'),  \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "lr = 0.00059\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (X_val, y_val),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of Hyperparameter Tuning using RandomSearch from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.42423481e-02 0.00000000e+00 7.00879765e-01 ... 2.23404255e-01\n",
      "  8.53799990e-01 1.04028698e-01]\n",
      " [2.42284243e-03 2.00000000e-01 2.38269795e-01 ... 6.38297872e-01\n",
      "  9.84542841e-01 1.33830022e-01]\n",
      " [3.00551153e-04 0.00000000e+00 1.73387097e-01 ... 8.08510638e-01\n",
      "  9.98083615e-01 1.87086093e-01]\n",
      " ...\n",
      " [9.58976229e-04 0.00000000e+00 3.79398827e-01 ... 7.02127660e-01\n",
      "  9.84895860e-01 1.04580574e-01]\n",
      " [2.74290580e-02 0.00000000e+00 7.00879765e-01 ... 2.23404255e-01\n",
      "  2.22678905e-01 3.97626932e-01]\n",
      " [8.50512555e-04 0.00000000e+00 4.93401760e-01 ... 3.61702128e-01\n",
      "  1.00000000e+00 2.39238411e-01]]\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 3ms/sample - loss: 1196.1835 - val_loss: 489.9852\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: inf - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard.stansbury\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1261: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   0.9s\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 3ms/sample - loss: 4071.7594 - val_loss: 593.7357\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 487.3055 - val_loss: 490.7452\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 394.8050 - val_loss: 83.0642\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 89.6556 - val_loss: 97.9206\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 85.1595 - val_loss: 441.2018\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 283.8864 - val_loss: 78.8014\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 87.7674 - val_loss: 94.3075\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.9689 - val_loss: 74.8846\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.0846 - val_loss: 76.4636\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 72.3035 - val_loss: 54.6272\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 232.5817 - val_loss: 140.4757\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 102.7994 - val_loss: 79.8646\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 86.9339 - val_loss: 81.4896\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 88.0677 - val_loss: 79.2212\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 88.7332 - val_loss: 86.8970\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 97.3773 - val_loss: 83.1989\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 86.8318 - val_loss: 80.3226\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 87.9985 - val_loss: 80.7258\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.6698 - val_loss: 79.3532\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 88.2716 - val_loss: 79.8297\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 102.6887\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   1.1s\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 4ms/sample - loss: 445.1516 - val_loss: 603.5752\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 572.1633 - val_loss: 433.8413\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 392.6016 - val_loss: 182.0408\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 268.3226 - val_loss: 93.2009\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 104.3659 - val_loss: 78.6911\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 97.9434 - val_loss: 167.1330\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 119.5082 - val_loss: 79.6405\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.7117 - val_loss: 84.6010\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 97.1188 - val_loss: 79.4042\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 93.0963 - val_loss: 84.2841\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 107.5139 - val_loss: 82.2481\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 94.8907 - val_loss: 65.9487\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.7086 - val_loss: 79.7591\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.0909 - val_loss: 80.2913\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 98.2528 - val_loss: 79.4545\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.2774 - val_loss: 79.8716\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 99.4910 - val_loss: 82.1039\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.6333 - val_loss: 79.6359\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.7536 - val_loss: 82.8442\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.5619 - val_loss: 79.9266\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 100.4783 - val_loss: 80.0640\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 96.8592 - val_loss: 79.6793\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 80.2155\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   1.4s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 583.7797 - val_loss: 531.9726\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 542.3634 - val_loss: 479.8772\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 476.8269 - val_loss: 390.2941\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 363.6850 - val_loss: 247.4429\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 210.4651 - val_loss: 117.4014\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 117.8568 - val_loss: 89.2351\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 98.7440 - val_loss: 81.9199\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 92.3410 - val_loss: 77.4409\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 86.5298 - val_loss: 75.2877\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 81.7997 - val_loss: 69.4355\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 77.3199 - val_loss: 66.6722\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.0878 - val_loss: 63.0074\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 70.1127 - val_loss: 60.3570\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 66.3542 - val_loss: 59.0198\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 63.4994 - val_loss: 56.3629\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 61.2649 - val_loss: 54.5337\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 58.9995 - val_loss: 53.1199\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 56.9271 - val_loss: 52.1059\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.3916 - val_loss: 51.2411\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.3790 - val_loss: 50.9837\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.8235 - val_loss: 51.2184\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.5640 - val_loss: 48.4566\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 49.5062 - val_loss: 47.9393\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 48.7413 - val_loss: 48.4681\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.6695 - val_loss: 47.0423\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 47.2045 - val_loss: 46.3419\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.1516 - val_loss: 46.2292\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 45.5682 - val_loss: 48.0000\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 44.3782 - val_loss: 45.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 43.4297 - val_loss: 44.5995\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.9528 - val_loss: 45.3071\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 42.2126 - val_loss: 44.5272\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 41.7152 - val_loss: 43.8896\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.0549 - val_loss: 43.6886\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.6928 - val_loss: 42.4251\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 39.7930 - val_loss: 44.8592\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 39.6122 - val_loss: 42.5034\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 38.7819 - val_loss: 42.0296\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2211 - val_loss: 41.3100\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.3489 - val_loss: 41.7248\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.3499 - val_loss: 43.6875\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 37.1641 - val_loss: 39.7794\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 36.8252 - val_loss: 38.9335\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 35.7526 - val_loss: 40.5145\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.5235 - val_loss: 38.7475\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.5412 - val_loss: 38.3194\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.2125 - val_loss: 38.3593\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.4591 - val_loss: 36.2904\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 33.2107 - val_loss: 36.1480\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.0645 - val_loss: 35.5697\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.7351 - val_loss: 35.1328\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 31.6435 - val_loss: 35.5708\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 31.1512 - val_loss: 34.9283\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.7651 - val_loss: 33.8636\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 30.9626 - val_loss: 33.9390\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 29.9562 - val_loss: 32.9494\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.7586 - val_loss: 33.0179\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.4059 - val_loss: 32.2688\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.8181 - val_loss: 32.0267\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 28.8011 - val_loss: 31.1387\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 28.4366 - val_loss: 30.9332\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.2684 - val_loss: 30.5029\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 27.2297 - val_loss: 30.0515\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.9857 - val_loss: 29.6176\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.1226 - val_loss: 29.3570\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 26.7261 - val_loss: 29.0925\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 25.8580 - val_loss: 28.6573\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.7459 - val_loss: 28.2816\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 25.2322 - val_loss: 27.8930\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.3190 - val_loss: 27.6857\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 24.6308 - val_loss: 27.3695\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 25.0803 - val_loss: 27.2393\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 24.5136 - val_loss: 26.9386\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 23.7843 - val_loss: 26.4403\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 23.5526 - val_loss: 26.2370\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 23.4551 - val_loss: 25.8713\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.2806 - val_loss: 25.6833\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.0706 - val_loss: 25.3069\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.6972 - val_loss: 25.1458\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.6965 - val_loss: 24.9145\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.2301 - val_loss: 24.7607\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 22.1495 - val_loss: 24.6766\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.7828 - val_loss: 24.5127\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 21.5901 - val_loss: 24.1974\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 21.9919 - val_loss: 24.1201\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2171 - val_loss: 23.9164\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 21.4234 - val_loss: 23.6494\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 21.1594 - val_loss: 23.6787\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 20.8313 - val_loss: 23.8310\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.1506 - val_loss: 23.0953\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 20.5405 - val_loss: 23.0980\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 20.7230 - val_loss: 22.7319\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 20.3362 - val_loss: 22.6780\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 14.32 - 0s 94us/sample - loss: 20.0572 - val_loss: 22.5184\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 20.1867 - val_loss: 22.2978\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 19.9761 - val_loss: 23.6290\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 19.9756 - val_loss: 22.4233\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 19.4255 - val_loss: 21.9657\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 19.4505 - val_loss: 21.9158\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.2382 - val_loss: 21.7045\n",
      "90/90 [==============================] - 0s 78us/sample - loss: 31.3270\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.7s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 602.7485 - val_loss: 557.2624\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 575.3454 - val_loss: 530.4937\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 545.2088 - val_loss: 493.4432\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 498.9029 - val_loss: 430.6394\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 416.7989 - val_loss: 318.2644\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 281.3849 - val_loss: 168.4011\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 149.0092 - val_loss: 95.2874\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 100.3981 - val_loss: 81.3638\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.3743 - val_loss: 76.5434\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 87.7582 - val_loss: 72.8280\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 81.9500 - val_loss: 67.9846\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 77.1646 - val_loss: 64.2875\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 73.5502 - val_loss: 61.2137\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 69.8475 - val_loss: 58.0457\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 67.4297 - val_loss: 55.4899\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 64.4646 - val_loss: 53.3532\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.6790 - val_loss: 52.0856\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 59.0744 - val_loss: 51.2324\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 57.1451 - val_loss: 48.8714\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.3552 - val_loss: 48.3929\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 54.9375 - val_loss: 45.7128\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 52.3582 - val_loss: 44.1756\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 51.5947 - val_loss: 43.5074\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.6124 - val_loss: 45.3071\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 48.6673 - val_loss: 41.7514\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.5484 - val_loss: 42.2001\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 46.5655 - val_loss: 41.0079\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 46.1942 - val_loss: 39.9473\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.9663 - val_loss: 40.4982\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 44.8533 - val_loss: 39.6646\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 43.5024 - val_loss: 38.7414\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 42.9852 - val_loss: 38.0160\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.0815 - val_loss: 38.3334\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.5584 - val_loss: 37.8924\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 40.9878 - val_loss: 39.4592\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 40.4170 - val_loss: 37.2954\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 39.6981 - val_loss: 35.5659\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 39.4808 - val_loss: 34.8061\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.8596 - val_loss: 34.4328\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2799 - val_loss: 35.1436\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.4214 - val_loss: 33.4548\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.0093 - val_loss: 34.1194\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 36.3131 - val_loss: 33.7965\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.9952 - val_loss: 34.0139\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.5563 - val_loss: 32.0245\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 34.8933 - val_loss: 31.7303\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 34.2444 - val_loss: 31.9557\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.7479 - val_loss: 30.9528\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.4016 - val_loss: 29.9012\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 33.4603 - val_loss: 29.5483\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 32.4278 - val_loss: 32.1541\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 32.4625 - val_loss: 29.0811\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 31.6642 - val_loss: 28.3505\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.6325 - val_loss: 28.3835\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 31.3313 - val_loss: 27.8748\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.6947 - val_loss: 28.5230\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.4120 - val_loss: 27.3228\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.6085 - val_loss: 26.8152\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.0630 - val_loss: 26.7440\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.8790 - val_loss: 26.3719\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.6517 - val_loss: 26.1003\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.3352 - val_loss: 26.2219\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.0684 - val_loss: 25.2522\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.8335 - val_loss: 24.8601\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 27.5862 - val_loss: 24.6445\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.9959 - val_loss: 24.1916\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.1329 - val_loss: 24.1483\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.3906 - val_loss: 24.1205\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 26.5925 - val_loss: 23.9581\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.3013 - val_loss: 23.4974\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 25.7826 - val_loss: 23.0591\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 25.5006 - val_loss: 23.1012\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.3523 - val_loss: 22.6246\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 25.3340 - val_loss: 22.6888\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 25.2873 - val_loss: 22.4420\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 24.9116 - val_loss: 22.5231\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 24.7654 - val_loss: 22.6870\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 24.4640 - val_loss: 22.0619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 24.1087 - val_loss: 21.6599\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 23.9778 - val_loss: 21.5151\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.3527 - val_loss: 21.3341\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.6168 - val_loss: 21.2123\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.4092 - val_loss: 21.5334\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 23.3348 - val_loss: 21.1635\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 23.2385 - val_loss: 21.0390\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 23.5192 - val_loss: 21.2083\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.7264 - val_loss: 20.7094\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.0864 - val_loss: 20.5214\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 22.6088 - val_loss: 20.5623\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.5704 - val_loss: 20.5847\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.7278 - val_loss: 20.2171\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.4643 - val_loss: 20.1014\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 22.2456 - val_loss: 20.0581\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.8001 - val_loss: 19.9486\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.9356 - val_loss: 20.7049\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.1638 - val_loss: 19.8749\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.9830 - val_loss: 20.5769\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.0278 - val_loss: 20.0015\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.3245 - val_loss: 21.1010\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 22.0682 - val_loss: 19.5279\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 23.9843\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.9s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 594.2191 - val_loss: 521.9863\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 552.5587 - val_loss: 469.6328\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 481.0902 - val_loss: 372.9343\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 355.0832 - val_loss: 227.8407\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 205.1798 - val_loss: 123.8707\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 130.4755 - val_loss: 103.5755\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 116.2079 - val_loss: 97.7259\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 109.6279 - val_loss: 91.5179\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 104.0866 - val_loss: 86.2834\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.7701 - val_loss: 81.7999\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 92.6158 - val_loss: 78.0110\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 87.6263 - val_loss: 74.2585\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 84.6423 - val_loss: 68.8091\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.0250 - val_loss: 65.7680\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 75.8686 - val_loss: 64.8568\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 72.4448 - val_loss: 61.4633\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 69.8068 - val_loss: 59.0015\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 66.6695 - val_loss: 55.5106\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 64.6097 - val_loss: 58.2178\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 62.4907 - val_loss: 52.1103\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.9262 - val_loss: 50.6431\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 58.7433 - val_loss: 49.9030\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.1293 - val_loss: 49.0560\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.9205 - val_loss: 51.3842\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.3495 - val_loss: 46.8961\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.2129 - val_loss: 46.0986\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.8444 - val_loss: 45.6739\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.4180 - val_loss: 44.3884\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.5452 - val_loss: 44.4663\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.3983 - val_loss: 42.9069\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 49.4880 - val_loss: 41.8672\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 48.5004 - val_loss: 42.7324\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.5068 - val_loss: 42.0412\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.8687 - val_loss: 40.5045\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.4408 - val_loss: 40.0545\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.4599 - val_loss: 40.6602\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 44.7967 - val_loss: 39.5589\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.3931 - val_loss: 39.6587\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 43.4559 - val_loss: 37.5374\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.9518 - val_loss: 36.7054\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.6200 - val_loss: 35.9171\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 41.9205 - val_loss: 36.0189\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.3589 - val_loss: 35.7409\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 40.6214 - val_loss: 34.7031\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.1226 - val_loss: 34.1748\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 39.4465 - val_loss: 34.8993\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.0009 - val_loss: 32.7476\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.6736 - val_loss: 33.1886\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 38.1987 - val_loss: 32.9842\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.6065 - val_loss: 32.0609\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.9757 - val_loss: 31.4996\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.5130 - val_loss: 30.3694\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.2646 - val_loss: 30.4014\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.7933 - val_loss: 29.2214\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.2785 - val_loss: 29.0749\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.8152 - val_loss: 28.9475\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 34.5357 - val_loss: 28.7314\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 123us/sample - loss: 34.5498 - val_loss: 28.0452\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 33.7645 - val_loss: 27.8877\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 33.7796 - val_loss: 26.5854\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 33.2838 - val_loss: 26.1687\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 33.0180 - val_loss: 26.6295\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 32.6119 - val_loss: 25.3303\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 32.2002 - val_loss: 25.8042\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 31.6578 - val_loss: 24.6502\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.4290 - val_loss: 24.9805\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.7875 - val_loss: 24.7579\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.5079 - val_loss: 23.5232\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4887 - val_loss: 24.7319\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.7654 - val_loss: 26.1937\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.1495 - val_loss: 23.6390\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 29.3300 - val_loss: 22.3526\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 29.2948 - val_loss: 22.6499\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.6737 - val_loss: 22.0141\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.5511 - val_loss: 21.6818\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.7586 - val_loss: 21.4342\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 28.6753 - val_loss: 21.1175\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.1275 - val_loss: 20.9829\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.9250 - val_loss: 20.8198\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 27.9438 - val_loss: 20.9198\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.4647 - val_loss: 20.8637\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.3668 - val_loss: 20.5703\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 27.1873 - val_loss: 19.9309\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0727 - val_loss: 19.8688\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 26.8623 - val_loss: 19.6935\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.7492 - val_loss: 19.5442\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.3724 - val_loss: 19.4766\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.3581 - val_loss: 19.3633\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.5194 - val_loss: 19.1501\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.9850 - val_loss: 19.5126\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.5581 - val_loss: 18.9605\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.7239 - val_loss: 19.0745\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.3954 - val_loss: 19.1324\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 25.6107 - val_loss: 19.2892\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.2960 - val_loss: 18.6340\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.5362 - val_loss: 18.4546\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 25.0642 - val_loss: 18.2786\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.0723 - val_loss: 18.1228\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 24.6865 - val_loss: 18.1514\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.5527 - val_loss: 18.8076\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 16.7894\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.7s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 610.6600 - val_loss: 404.5937\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 209.8927 - val_loss: 301.3063\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 399.0133 - val_loss: 228.9976\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 153.2370 - val_loss: 79.7621\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.3701 - val_loss: 91.2239\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.1526 - val_loss: 80.4193\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.9559 - val_loss: 83.2246\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 98.3185 - val_loss: 84.6922\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 81.8317 - val_loss: 826.5580\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 321.4719 - val_loss: 173.8261\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 173.2118 - val_loss: 130.4395\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 136.6235 - val_loss: 107.1841\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 116.4706 - val_loss: 93.8274\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 104.6383 - val_loss: 86.8330\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 105.2870\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.0s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 4439.8046 - val_loss: 922.3849\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 755.7691 - val_loss: 633.6982\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 402.1666 - val_loss: 105.4683\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 133.2059 - val_loss: 170.3268\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 129.8231 - val_loss: 117.1512\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 97.5021 - val_loss: 84.0153\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 112.9258 - val_loss: 83.2723\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.4448 - val_loss: 102.6894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 90.4947 - val_loss: 79.2227\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 91.3755 - val_loss: 139.3293\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 128.0515 - val_loss: 278.6838\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 177.3534 - val_loss: 79.3570\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 104.2123 - val_loss: 80.0164\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 91.1814 - val_loss: 141.2271\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 115.6222 - val_loss: 83.7780\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 90.9751 - val_loss: 82.2361\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 85.9124 - val_loss: 83.9539\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 112.2447 - val_loss: 85.5812\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 102.4606 - val_loss: 79.5650\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 100.4243\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.3s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 14311.1967 - val_loss: 7649.3546\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 3353.1078 - val_loss: 1166.1938\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 1010.4317 - val_loss: 396.0609\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 1000.4827 - val_loss: 536.1684\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 494.1543 - val_loss: 329.3832\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 320.2677 - val_loss: 216.2705\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 222.9120 - val_loss: 153.2327\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 168.1145 - val_loss: 118.5135\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 137.1067 - val_loss: 100.3391\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 119.7802 - val_loss: 89.7200\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 109.6846 - val_loss: 84.3199\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 103.9451 - val_loss: 81.5928\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 101.0271 - val_loss: 80.2373\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.9809 - val_loss: 79.5133\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 97.8668 - val_loss: 79.2208\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 97.1606 - val_loss: 79.1877\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.9428 - val_loss: 79.2169\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.5891 - val_loss: 79.2802\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.5444 - val_loss: 79.3956\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 96.4285 - val_loss: 79.4509\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.4371 - val_loss: 79.4542\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.3503 - val_loss: 79.5917\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.3669 - val_loss: 79.6458\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.3260 - val_loss: 79.6538\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 96.3462 - val_loss: 79.6824\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 96.3044 - val_loss: 79.6591\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 80.1973\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.3s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 525.7688 - val_loss: 400.5583\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 379.6618 - val_loss: 291.9819\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 285.5802 - val_loss: 223.5341\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 225.3918 - val_loss: 178.6345\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 185.9342 - val_loss: 149.7741\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 160.0115 - val_loss: 130.3720\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 142.4004 - val_loss: 117.5924\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 130.4601 - val_loss: 108.5663\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 122.0868 - val_loss: 102.4651\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 116.0314 - val_loss: 97.9478\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 111.6606 - val_loss: 94.2560\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 107.7598 - val_loss: 91.3314\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 104.6483 - val_loss: 88.9372\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 102.0132 - val_loss: 86.7641\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 99.8319 - val_loss: 84.8653\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 97.5845 - val_loss: 83.0614\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 115.300 - 0s 105us/sample - loss: 95.5822 - val_loss: 81.3773\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 93.7602 - val_loss: 79.7791\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 91.9041 - val_loss: 78.2413\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.2187 - val_loss: 76.7499\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 88.5688 - val_loss: 75.3713\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 87.0426 - val_loss: 73.9917\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 85.3546 - val_loss: 72.6614\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 83.9077 - val_loss: 71.4355\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 82.4446 - val_loss: 70.1945\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 81.0451 - val_loss: 69.0841\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 79.8559 - val_loss: 67.9932\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 78.4819 - val_loss: 66.9350\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 77.2764 - val_loss: 65.9402\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 76.0970 - val_loss: 64.9693\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.0922 - val_loss: 64.0186\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 73.9144 - val_loss: 63.1308\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 72.8883 - val_loss: 62.2945\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 71.8083 - val_loss: 61.5227\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 71.0152 - val_loss: 60.7779\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.9314 - val_loss: 60.0351\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 69.0798 - val_loss: 59.2839\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 68.1913 - val_loss: 58.5629\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 67.2579 - val_loss: 57.8993\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 66.4400 - val_loss: 57.2313\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 65.6277 - val_loss: 56.6088\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 64.7941 - val_loss: 56.0195\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 64.0982 - val_loss: 55.4896\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 63.3942 - val_loss: 54.9825\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 62.8017 - val_loss: 54.4561\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 62.1182 - val_loss: 53.9283\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.3189 - val_loss: 53.4300\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 60.6612 - val_loss: 52.9468\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.0272 - val_loss: 52.4903\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.4558 - val_loss: 52.0529\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 59.0115 - val_loss: 51.6421\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.3648 - val_loss: 51.2507\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.8101 - val_loss: 50.9452\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 57.3160 - val_loss: 50.5975\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.8213 - val_loss: 50.2526\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 56.2589 - val_loss: 49.9586\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.7978 - val_loss: 49.6720\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 55.3143 - val_loss: 49.3060\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 54.8607 - val_loss: 49.0608\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.4512 - val_loss: 48.7867\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 53.9951 - val_loss: 48.5397\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.6099 - val_loss: 48.2485\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 53.2685 - val_loss: 48.0874\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 52.8069 - val_loss: 47.8304\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.3908 - val_loss: 47.5419\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 52.0560 - val_loss: 47.3082\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 51.7454 - val_loss: 47.0221\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 77us/sample - loss: 51.3453 - val_loss: 46.7839\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 50.9967 - val_loss: 46.5859\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.6877 - val_loss: 46.3882\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.3649 - val_loss: 46.2014\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 50.0292 - val_loss: 46.0120\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 49.7788 - val_loss: 45.8006\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.4814 - val_loss: 45.6087\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 49.2056 - val_loss: 45.4818\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 48.9004 - val_loss: 45.3189\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.7378 - val_loss: 45.2429\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 48.4465 - val_loss: 45.1042\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 48.1276 - val_loss: 44.9855\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.8604 - val_loss: 44.8168\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.6769 - val_loss: 44.7127\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.3541 - val_loss: 44.5505\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.1745 - val_loss: 44.4249\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.9776 - val_loss: 44.3046\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.7049 - val_loss: 44.1472\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.4856 - val_loss: 44.0279\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 46.2266 - val_loss: 43.8780\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.0415 - val_loss: 43.7705\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.8272 - val_loss: 43.6385\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 45.6594 - val_loss: 43.4608\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.4312 - val_loss: 43.3782\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.2127 - val_loss: 43.2755\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 45.0241 - val_loss: 43.1879\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.8545 - val_loss: 43.1223\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 44.6382 - val_loss: 43.0125\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.4672 - val_loss: 42.9674\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.3391 - val_loss: 42.8760\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 44.1013 - val_loss: 42.7885\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 43.9630 - val_loss: 42.7187\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 43.7721 - val_loss: 42.6302\n",
      "90/90 [==============================] - 0s 44us/sample - loss: 55.2019\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.5s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 528.2889 - val_loss: 406.7119\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 378.9616 - val_loss: 296.7624\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 282.9333 - val_loss: 227.6561\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 222.6929 - val_loss: 183.8853\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 184.4613 - val_loss: 156.4904\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 159.5979 - val_loss: 136.2819\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/sample - loss: 141.7907 - val_loss: 123.5227\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 130.1258 - val_loss: 114.6833\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 122.1616 - val_loss: 108.3150\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 116.1314 - val_loss: 103.5973\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 111.5833 - val_loss: 99.9667\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 108.1346 - val_loss: 96.9019\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 105.1211 - val_loss: 94.2317\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 102.3965 - val_loss: 92.0104\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 100.2853 - val_loss: 89.9146\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 98.0775 - val_loss: 88.1076\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.2115 - val_loss: 86.3020\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 94.3945 - val_loss: 84.6624\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.7506 - val_loss: 83.1050\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.1419 - val_loss: 81.5914\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 89.5416 - val_loss: 80.1673\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 88.1342 - val_loss: 78.7701\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.7117 - val_loss: 77.4378\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 85.3002 - val_loss: 76.1554\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 84.0564 - val_loss: 74.9224\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 82.7917 - val_loss: 73.7264\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 81.5867 - val_loss: 72.6115\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 80.4451 - val_loss: 71.5363\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 79.3643 - val_loss: 70.5682\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 78.3156 - val_loss: 69.5961\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.2394 - val_loss: 68.6249\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 76.2149 - val_loss: 67.6318\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.3438 - val_loss: 66.7383\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 74.4548 - val_loss: 65.9123\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 73.5164 - val_loss: 65.1234\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 72.5809 - val_loss: 64.3209\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 71.7328 - val_loss: 63.5971\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 70.9147 - val_loss: 62.7902\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 70.1393 - val_loss: 62.0768\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.3212 - val_loss: 61.3683\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 68.6171 - val_loss: 60.7248\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 67.8993 - val_loss: 60.1295\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 67.2741 - val_loss: 59.4650\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 66.5527 - val_loss: 58.8966\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 65.9508 - val_loss: 58.3094\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 65.5484 - val_loss: 57.7913\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 64.7719 - val_loss: 57.2613\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 64.2016 - val_loss: 56.8023\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 63.5951 - val_loss: 56.3028\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 63.1268 - val_loss: 55.8519\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 62.5845 - val_loss: 55.3338\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 62.0359 - val_loss: 54.8821\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.5417 - val_loss: 54.4636\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.0708 - val_loss: 54.0671\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 60.6659 - val_loss: 53.5889\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 60.1641 - val_loss: 53.2403\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 59.7913 - val_loss: 52.8735\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 59.3692 - val_loss: 52.5821\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.9851 - val_loss: 52.2866\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.5680 - val_loss: 51.9749\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.1735 - val_loss: 51.6046\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.8723 - val_loss: 51.2903\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 57.4683 - val_loss: 50.9791\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.1418 - val_loss: 50.7159\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 56.7571 - val_loss: 50.4303\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 56.4468 - val_loss: 50.2453\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 56.1014 - val_loss: 49.9362\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 126us/sample - loss: 55.7997 - val_loss: 49.6641\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.5855 - val_loss: 49.4035\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 55.1855 - val_loss: 49.1402\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.8948 - val_loss: 48.8922\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 54.5903 - val_loss: 48.6774\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 54.3156 - val_loss: 48.3966\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 54.0290 - val_loss: 48.1705\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.8496 - val_loss: 47.9613\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.5378 - val_loss: 47.6822\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 53.2436 - val_loss: 47.5082\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.0222 - val_loss: 47.3677\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 52.8473 - val_loss: 47.1698\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.6468 - val_loss: 46.9121\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 52.3541 - val_loss: 46.8344\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 52.0662 - val_loss: 46.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 51.8723 - val_loss: 46.4510\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.6482 - val_loss: 46.2719\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 51.5660 - val_loss: 46.0483\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 51.2983 - val_loss: 45.8767\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 51.0613 - val_loss: 45.7235\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.8892 - val_loss: 45.5241\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.6711 - val_loss: 45.3926\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 50.4710 - val_loss: 45.3194\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.3085 - val_loss: 45.1962\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.0475 - val_loss: 45.0367\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.9259 - val_loss: 44.8086\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.7396 - val_loss: 44.5987\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.5369 - val_loss: 44.4830\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.4010 - val_loss: 44.3806\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.2604 - val_loss: 44.2295\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 49.0509 - val_loss: 44.1212\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 48.8922 - val_loss: 43.9530\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.7526 - val_loss: 43.8595\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 52.3163\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.5s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 542.3533 - val_loss: 392.0698\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 389.5951 - val_loss: 281.0448\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 290.4840 - val_loss: 212.2117\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 228.1418 - val_loss: 168.2484\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 187.3720 - val_loss: 140.3590\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 161.0592 - val_loss: 122.1371\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 143.5358 - val_loss: 110.6617\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 132.0153 - val_loss: 102.7960\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 123.9175 - val_loss: 97.2802\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 117.8847 - val_loss: 93.0346\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 113.1794 - val_loss: 89.9556\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 109.7832 - val_loss: 87.5802\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.6840 - val_loss: 85.5003\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 104.2214 - val_loss: 83.6263\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 102.0859 - val_loss: 81.9446\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 99.9252 - val_loss: 80.3800\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 98.0011 - val_loss: 78.9467\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.2942 - val_loss: 77.6053\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 94.6614 - val_loss: 76.2126\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 93.0867 - val_loss: 74.9343\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.5666 - val_loss: 73.7788\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.2104 - val_loss: 72.6676\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 88.8879 - val_loss: 71.5768\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 87.4832 - val_loss: 70.5135\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 86.3481 - val_loss: 69.4497\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 85.1507 - val_loss: 68.3995\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 84.1497 - val_loss: 67.5103\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 82.7769 - val_loss: 66.5556\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 81.6175 - val_loss: 65.6493\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 80.5973 - val_loss: 64.8244\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 79.5817 - val_loss: 63.9626\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 78.5978 - val_loss: 63.1391\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 77.6674 - val_loss: 62.4028\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 76.8722 - val_loss: 61.7431\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 76.0274 - val_loss: 61.0711\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 75.2003 - val_loss: 60.4802\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 74.3657 - val_loss: 59.7651\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 97us/sample - loss: 73.5829 - val_loss: 59.1296\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 72.9124 - val_loss: 58.4737\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 72.0960 - val_loss: 57.8461\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 71.4726 - val_loss: 57.3027\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 70.7988 - val_loss: 56.8274\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 70.1403 - val_loss: 56.4382\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 69.5068 - val_loss: 55.9501\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 68.9216 - val_loss: 55.3885\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 68.4201 - val_loss: 54.9852\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 67.7892 - val_loss: 54.6032\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 67.2092 - val_loss: 54.1386\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 66.6822 - val_loss: 53.6897\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 66.1639 - val_loss: 53.3602\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 65.6271 - val_loss: 53.0271\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 65.1919 - val_loss: 52.6680\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 64.8082 - val_loss: 52.2385\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 64.3632 - val_loss: 51.8138\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 63.8643 - val_loss: 51.5740\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 63.4321 - val_loss: 51.2414\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 62.9777 - val_loss: 50.9833\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 62.5809 - val_loss: 50.6511\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 62.2004 - val_loss: 50.4315\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 61.8611 - val_loss: 50.2842\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 61.4529 - val_loss: 50.0034\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 61.1156 - val_loss: 49.7573\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.8847 - val_loss: 49.5653\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.3963 - val_loss: 49.3344\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.0501 - val_loss: 49.0921\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 59.8195 - val_loss: 48.8030\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 59.4798 - val_loss: 48.6576\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.1901 - val_loss: 48.3912\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.8727 - val_loss: 48.1406\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 58.6104 - val_loss: 48.0350\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.4628 - val_loss: 47.8963\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 58.0796 - val_loss: 47.7538\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 57.7921 - val_loss: 47.6104\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 57.5480 - val_loss: 47.3280\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 57.3196 - val_loss: 47.1869\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.1024 - val_loss: 46.9941\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 56.8806 - val_loss: 46.8760\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.6187 - val_loss: 46.6163\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 56.3681 - val_loss: 46.4170\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.1493 - val_loss: 46.3737\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 55.9271 - val_loss: 46.1949\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.7228 - val_loss: 46.0747\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 55.5379 - val_loss: 46.0332\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 55.3032 - val_loss: 45.7998\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.1055 - val_loss: 45.6307\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.9551 - val_loss: 45.4462\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 54.7209 - val_loss: 45.4056\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 54.5831 - val_loss: 45.3195\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 54.3896 - val_loss: 45.1232\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 54.2135 - val_loss: 45.0458\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 53.9997 - val_loss: 44.9004\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.8300 - val_loss: 44.7714\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.7160 - val_loss: 44.7024\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.5283 - val_loss: 44.5870\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.3290 - val_loss: 44.4778\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 53.2170 - val_loss: 44.4078\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.1287 - val_loss: 44.2448\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 52.9631 - val_loss: 44.0491\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7575 - val_loss: 43.9876\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 52.5804 - val_loss: 43.8560\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 41.6843\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.4s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 4ms/sample - loss: 607.6163 - val_loss: 568.1834\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 591.0724 - val_loss: 553.9462\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 576.2385 - val_loss: 538.4478\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 558.5792 - val_loss: 517.4774\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 532.9808 - val_loss: 484.6780\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 490.0720 - val_loss: 424.7034\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 408.6617 - val_loss: 309.3816\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 267.5840 - val_loss: 158.9773\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 146.1976 - val_loss: 106.2526\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 118.0285 - val_loss: 98.2595\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 110.1847 - val_loss: 91.0195\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 102.4682 - val_loss: 85.2935\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 96.6771 - val_loss: 79.4117\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 89.4858 - val_loss: 73.6567\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 83.4402 - val_loss: 69.4642\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 78.0293 - val_loss: 64.4239\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 73.1097 - val_loss: 60.1089\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 69.1954 - val_loss: 56.6942\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 63.1917 - val_loss: 54.2578\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 59.7897 - val_loss: 50.7500\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 57.5697 - val_loss: 48.0807\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 53.2066 - val_loss: 45.9944\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 50.5294 - val_loss: 44.5004\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 47.8748 - val_loss: 43.3853\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 46.5976 - val_loss: 42.5578\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.1830 - val_loss: 41.5521\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.5321 - val_loss: 43.7113\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 41.2803 - val_loss: 40.6166\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 161us/sample - loss: 40.2021 - val_loss: 39.7264\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 39.2853 - val_loss: 39.5705\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.9969 - val_loss: 39.1921\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.4670 - val_loss: 38.8147\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.0423 - val_loss: 38.8581\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 35.7608 - val_loss: 37.6312\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.2284 - val_loss: 38.6807\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.7451 - val_loss: 37.1923\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 33.8927 - val_loss: 36.8175\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 32.8654 - val_loss: 41.9142\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 33.9945 - val_loss: 37.2031\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 32.4226 - val_loss: 34.9425\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.7648 - val_loss: 35.4725\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 31.1745 - val_loss: 34.2155\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 30.1693 - val_loss: 33.3834\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 29.5588 - val_loss: 33.1723\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 29.2700 - val_loss: 32.7749\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 29.7199 - val_loss: 33.6107\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 28.1348 - val_loss: 33.6416\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 28.2829 - val_loss: 30.9817\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.1386 - val_loss: 31.7888\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 26.7433 - val_loss: 30.6001\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 26.5252 - val_loss: 30.8884\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 25.8136 - val_loss: 28.9599\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.2234 - val_loss: 28.4693\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 24.9440 - val_loss: 28.5278\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.3125 - val_loss: 28.6353\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.2326 - val_loss: 27.7643\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.1803 - val_loss: 27.0702\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 23.4938 - val_loss: 27.5737\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 23.2320 - val_loss: 26.2813\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 22.8057 - val_loss: 26.3048\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 21.9169 - val_loss: 25.4870\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 22.1316 - val_loss: 25.3615\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 177us/sample - loss: 21.7923 - val_loss: 26.1917\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 21.7242 - val_loss: 24.3309\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 20.8055 - val_loss: 24.2308\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 169us/sample - loss: 20.6712 - val_loss: 23.8096\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 177us/sample - loss: 20.6829 - val_loss: 23.7743\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 20.2548 - val_loss: 23.8885\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.8805 - val_loss: 23.0403\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.6156 - val_loss: 22.8144\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.8865 - val_loss: 22.6985\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9847 - val_loss: 22.4072\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.7122 - val_loss: 23.8761\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 18.9643 - val_loss: 22.1882\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 19.4355 - val_loss: 21.7965\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.1141 - val_loss: 23.3148\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.3613 - val_loss: 21.4480\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 18.1819 - val_loss: 21.2559\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.5945 - val_loss: 20.9970\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 17.7345 - val_loss: 20.9839\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 17.9046 - val_loss: 20.6746\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.1598 - val_loss: 20.7913\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 17.9015 - val_loss: 20.8575\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 17.8569 - val_loss: 20.6757\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 17.1751 - val_loss: 20.3565\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 17.4267 - val_loss: 20.3389\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 17.7064 - val_loss: 20.4884\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 17.0656 - val_loss: 20.1164\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.6237 - val_loss: 19.8468\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 16.6949 - val_loss: 19.7272\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.5440 - val_loss: 19.5957\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 16.3087 - val_loss: 19.9320\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.3013 - val_loss: 19.5038\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.3678 - val_loss: 19.3590\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 16.4630 - val_loss: 19.4309\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 15.9353 - val_loss: 19.3590\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.0186 - val_loss: 19.2058\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 15.9591 - val_loss: 21.6124\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 16.4845 - val_loss: 19.2571\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 16.0006 - val_loss: 19.1574\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 28.0789\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.7s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 591.3251 - val_loss: 552.9586\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 571.9180 - val_loss: 530.9104\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 544.7608 - val_loss: 495.9012\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 498.5259 - val_loss: 431.3949\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 409.3816 - val_loss: 302.8565\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 253.2303 - val_loss: 147.0416\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 135.4197 - val_loss: 109.8441\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 114.2382 - val_loss: 99.8815\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 105.7058 - val_loss: 92.4394\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 99.1502 - val_loss: 87.4847\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 93.1126 - val_loss: 80.3130\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 85.8618 - val_loss: 75.2218\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 81.3600 - val_loss: 70.4064\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 75.6884 - val_loss: 65.7261\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 71.9132 - val_loss: 62.1106\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 67.5774 - val_loss: 58.9308\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 64.4241 - val_loss: 55.9864\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 61.7617 - val_loss: 53.7326\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 58.1131 - val_loss: 52.9528\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 56.3864 - val_loss: 50.2870\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 53.6545 - val_loss: 52.7831\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 52.6955 - val_loss: 47.6296\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 51.6207 - val_loss: 46.1927\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 49.2750 - val_loss: 44.8574\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 49.6569 - val_loss: 43.8103\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 46.8888 - val_loss: 45.9339\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 47.2544 - val_loss: 41.9786\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.8985 - val_loss: 40.8073\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 44.3825 - val_loss: 41.6792\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 42.8937 - val_loss: 39.4497\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 42.8302 - val_loss: 38.5274\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 41.3984 - val_loss: 40.3417\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 40.8811 - val_loss: 37.9493\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 39.3392 - val_loss: 36.7039\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 38.8186 - val_loss: 36.6216\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.9487 - val_loss: 34.5280\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 37.5527 - val_loss: 36.9032\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.1239 - val_loss: 33.7194\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.4379 - val_loss: 33.7431\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 34.8727 - val_loss: 31.9968\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.3391 - val_loss: 33.1634\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 33.6878 - val_loss: 30.4876\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.8682 - val_loss: 31.0998\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 32.0611 - val_loss: 29.1725\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.8533 - val_loss: 29.6083\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.7566 - val_loss: 28.0070\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 30.5172 - val_loss: 27.4157\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.0629 - val_loss: 27.0504\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 29.1973 - val_loss: 26.2713\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 29.1493 - val_loss: 26.2232\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 28.4105 - val_loss: 25.5266\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.7017 - val_loss: 26.4279\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.2233 - val_loss: 24.4730\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.8967 - val_loss: 24.1370\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 26.3131 - val_loss: 24.2202\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.4191 - val_loss: 25.9028\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.9428 - val_loss: 22.9571\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.2274 - val_loss: 24.7618\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.8880 - val_loss: 23.9360\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 24.8565 - val_loss: 23.3938\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.0360 - val_loss: 24.7910\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.5086 - val_loss: 22.7062\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 24.1097 - val_loss: 21.2291\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.4553 - val_loss: 21.0903\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.2949 - val_loss: 20.7989\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 23.5690 - val_loss: 21.6023\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.9142 - val_loss: 22.9214\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.5929 - val_loss: 20.3317\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.8756 - val_loss: 20.0293\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.7054 - val_loss: 20.6524\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 21.9820 - val_loss: 19.7043\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.2839 - val_loss: 19.5976\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 21.5768 - val_loss: 19.4302\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.9598 - val_loss: 19.2889\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.2645 - val_loss: 19.2276\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.4315 - val_loss: 21.6596\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.0274 - val_loss: 18.7499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 20.8723 - val_loss: 18.7402\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.2806 - val_loss: 18.5253\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.3637 - val_loss: 18.8502\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.9587 - val_loss: 18.3616\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.4930 - val_loss: 18.6234\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 20.4069 - val_loss: 19.0064\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 20.5167 - val_loss: 17.9761\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9304 - val_loss: 17.8402\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.3702 - val_loss: 18.1544\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.2131 - val_loss: 17.6503\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9840 - val_loss: 18.1051\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.0228 - val_loss: 17.6722\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 19.8508 - val_loss: 17.4335\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.2384 - val_loss: 17.3744\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 19.8703 - val_loss: 17.3191\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.1980 - val_loss: 17.3958\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.2400 - val_loss: 17.1773\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 19.1576 - val_loss: 17.4490\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 19.1623 - val_loss: 18.3253\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 18.9979 - val_loss: 17.0018\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 18.8154 - val_loss: 17.3380\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.3341 - val_loss: 18.3425\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 18.8931 - val_loss: 17.2795\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 20.8547\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.4s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 627.1999 - val_loss: 565.5895\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 611.5902 - val_loss: 549.4668\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 593.5261 - val_loss: 528.4976\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 568.2365 - val_loss: 496.7654\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 527.1144 - val_loss: 441.2921\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 451.2816 - val_loss: 333.5417\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 308.6633 - val_loss: 165.0809\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 155.1866 - val_loss: 96.0191\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 114.0606 - val_loss: 86.6093\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 104.8299 - val_loss: 80.8416\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 98.5604 - val_loss: 75.3000\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 91.8093 - val_loss: 69.3902\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 86.4497 - val_loss: 65.9301\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 79.4918 - val_loss: 61.0978\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 75.0707 - val_loss: 58.0077\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 70.9535 - val_loss: 53.9424\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 66.9655 - val_loss: 53.1327\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 64.8191 - val_loss: 52.2101\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 61.9223 - val_loss: 47.2198\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 59.2939 - val_loss: 48.8405\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 56.8491 - val_loss: 45.0578\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 55.1274 - val_loss: 43.6622\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 53.7450 - val_loss: 42.5151\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 51.8197 - val_loss: 44.2883\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 51.6114 - val_loss: 40.5661\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 50.3236 - val_loss: 41.3313\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 48.7961 - val_loss: 40.9448\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 48.2694 - val_loss: 39.5790\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.7368 - val_loss: 38.2465\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 46.8281 - val_loss: 38.0484\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 45.6549 - val_loss: 38.6547\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 44.8910 - val_loss: 37.4347\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.4274 - val_loss: 38.1359\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 43.4540 - val_loss: 37.0402\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 42.6717 - val_loss: 35.9230\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 42.7545 - val_loss: 35.9409\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 42.1421 - val_loss: 38.7916\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 41.6687 - val_loss: 34.7484\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 40.4855 - val_loss: 36.9202\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 40.2734 - val_loss: 35.2219\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 39.2116 - val_loss: 32.5263\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 39.1228 - val_loss: 31.9536\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 38.3377 - val_loss: 31.0201\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.8550 - val_loss: 34.4287\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 37.5283 - val_loss: 30.1705\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 36.6988 - val_loss: 30.3210\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 37.1279 - val_loss: 30.6794\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.9500 - val_loss: 29.1870\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 35.8874 - val_loss: 30.0798\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.0521 - val_loss: 27.8809\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.3794 - val_loss: 28.0022\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 34.0395 - val_loss: 27.0907\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 33.5570 - val_loss: 26.6993\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 34.2495 - val_loss: 26.1841\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 32.8034 - val_loss: 27.5623\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 33.2275 - val_loss: 25.5248\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 32.0157 - val_loss: 25.6495\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 32.0524 - val_loss: 26.9062\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.5567 - val_loss: 25.5028\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 31.3049 - val_loss: 23.7925\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 31.2111 - val_loss: 23.6322\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.6136 - val_loss: 23.2305\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 30.0632 - val_loss: 24.3587\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.2327 - val_loss: 22.9136\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 29.0140 - val_loss: 23.8880\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 28.8477 - val_loss: 22.0596\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 29.0109 - val_loss: 22.3506\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.8674 - val_loss: 21.8171\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.6274 - val_loss: 21.7252\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.0097 - val_loss: 21.1103\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.4954 - val_loss: 20.8300\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.2643 - val_loss: 20.7175\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.3428 - val_loss: 20.7561\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.2945 - val_loss: 21.0610\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.1814 - val_loss: 19.7647\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 25.9541 - val_loss: 20.3223\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.5354 - val_loss: 20.2145\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.8444 - val_loss: 19.3253\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.1955 - val_loss: 19.3440\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 24.7736 - val_loss: 18.9820\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.0397 - val_loss: 18.9762\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.6332 - val_loss: 18.7016\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.0796 - val_loss: 20.8399\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.9974 - val_loss: 18.7315\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.7958 - val_loss: 19.2262\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.0893 - val_loss: 19.3084\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.7155 - val_loss: 17.9746\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.5798 - val_loss: 17.8177\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.9727 - val_loss: 17.7241\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.8279 - val_loss: 18.0103\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.9352 - val_loss: 18.0104\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.3251 - val_loss: 17.7891\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.1504 - val_loss: 17.2392\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.3088 - val_loss: 17.5511\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.7584 - val_loss: 17.2097\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.1475 - val_loss: 17.7259\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.5218 - val_loss: 16.9863\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.8195 - val_loss: 18.9613\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.6184 - val_loss: 16.9178\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.1845 - val_loss: 16.8099\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 14.1986\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.4s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 416.9764 - val_loss: 215.8233\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 180.5233 - val_loss: 62.2413\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 72.6323 - val_loss: 170.6845\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 123.0773 - val_loss: 96.8774\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.7662 - val_loss: 43.8455\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 98.3084 - val_loss: 41.7299\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.4279 - val_loss: 119.2476\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 112.4265 - val_loss: 51.9273\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 99.7454 - val_loss: 203.0290\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 110.7026 - val_loss: 31.9753\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.4457 - val_loss: 44.2968\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.6352 - val_loss: 89.6619\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 52.0178 - val_loss: 30.0090\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.3301 - val_loss: 24.9550\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 33.7967 - val_loss: 29.1734\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.0394 - val_loss: 76.6121\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 33.0626 - val_loss: 43.6603\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 46.0603 - val_loss: 21.8060\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.4927 - val_loss: 38.6081\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.6426 - val_loss: 26.8088\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.3138 - val_loss: 21.8955\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.1235 - val_loss: 20.3407\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 21.8224 - val_loss: 41.3642\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/sample - loss: 30.3901 - val_loss: 88.2973\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 45.4769 - val_loss: 21.7680\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 18.3134 - val_loss: 19.4928\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0234 - val_loss: 45.1553\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.7848 - val_loss: 30.3373\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.4112 - val_loss: 23.5503\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 16.3015 - val_loss: 24.3554\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 19.9543 - val_loss: 38.4057\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.7563 - val_loss: 18.1166\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.4293 - val_loss: 26.8983\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 24.2852 - val_loss: 20.5685\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 38.4054 - val_loss: 36.5160\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 20.2934 - val_loss: 26.7602\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 30.7795 - val_loss: 18.4387\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 29.2564 - val_loss: 16.9120\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 16.9587 - val_loss: 25.7582\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 37.7561 - val_loss: 31.6676\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.1497 - val_loss: 35.2783\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 24.4491 - val_loss: 16.7764\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.7059 - val_loss: 17.7345\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 14.0291 - val_loss: 18.6260\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.9418 - val_loss: 27.4769\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 14.4841 - val_loss: 16.1991\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 14.9937 - val_loss: 20.3807\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 13.4932 - val_loss: 17.7372\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 13.4474 - val_loss: 19.7147\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.9447 - val_loss: 27.0007\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.6068 - val_loss: 15.5034\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.0080 - val_loss: 16.9317\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 15.9408 - val_loss: 15.4154\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.0151 - val_loss: 18.3162\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.0307 - val_loss: 17.3151\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 17.7709 - val_loss: 24.3279\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 16.5283 - val_loss: 15.9697\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 11.5943 - val_loss: 17.9647\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 20.4185 - val_loss: 15.0466\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 13.1998 - val_loss: 21.3925\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 13.5435 - val_loss: 20.2768\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 21.5040 - val_loss: 15.7348\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 11.5297 - val_loss: 20.5755\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 14.1738 - val_loss: 15.7221\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 15.5893 - val_loss: 17.6743\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 16.9077 - val_loss: 15.4158\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 14.1375 - val_loss: 44.0930\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.0100 - val_loss: 16.1174\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 12.5086 - val_loss: 14.7633\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.9799 - val_loss: 15.1035\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 16.6776 - val_loss: 21.8484\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 13.3210 - val_loss: 27.4394\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 13.7652 - val_loss: 14.6895\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 10.8897 - val_loss: 15.3865\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 11.2344 - val_loss: 19.3209\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 11.5518 - val_loss: 14.6169\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 10.3264 - val_loss: 15.8505\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 24.1590 - val_loss: 23.4610\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 19.7003 - val_loss: 14.6715\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 11.0791 - val_loss: 15.5680\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 12.1551 - val_loss: 15.7712\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 13.3233 - val_loss: 14.5539\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 11.2976 - val_loss: 24.9073\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 16.7018 - val_loss: 16.7513\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 11.5310 - val_loss: 15.6141\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 10.8127 - val_loss: 19.1148\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 11.2587 - val_loss: 18.3201\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.7281 - val_loss: 17.3076\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 14.6158 - val_loss: 14.5571\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 11.4520 - val_loss: 24.8249\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 13.1044 - val_loss: 18.6836\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 11.1502 - val_loss: 18.5739\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 26.9460\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   2.6s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 346.3227 - val_loss: 231.2678\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 188.0277 - val_loss: 147.1319\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 180.2637 - val_loss: 45.0602\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 69.0386 - val_loss: 336.6258\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 127.8046 - val_loss: 133.9302\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 93.0111 - val_loss: 33.3082\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 53.6454 - val_loss: 175.5648\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 62.6118 - val_loss: 37.5231\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 60.9865 - val_loss: 30.2308\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.1821 - val_loss: 27.5342\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.5778 - val_loss: 250.1388\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 98.9868 - val_loss: 27.0119\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.9054 - val_loss: 67.9924\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 42.0926 - val_loss: 33.0371\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 26.9643 - val_loss: 23.5522\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 39.5553 - val_loss: 23.9716\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 35.1569 - val_loss: 119.5428\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.3338 - val_loss: 65.7121\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.3198 - val_loss: 23.2518\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.1684 - val_loss: 33.9488\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 45.0822 - val_loss: 33.3379\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.3891 - val_loss: 22.8125\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 29.0480 - val_loss: 19.1000\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 21.7855 - val_loss: 19.1820\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 24.8362 - val_loss: 34.7543\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.5203 - val_loss: 19.5251\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 20.0122 - val_loss: 18.7050\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.7267 - val_loss: 23.6556\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.5393 - val_loss: 17.3303\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 21.8375 - val_loss: 18.4328\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 24.1023 - val_loss: 31.2533\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.2052 - val_loss: 17.9908\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 18.4793 - val_loss: 27.7141\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.1164 - val_loss: 16.3662\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.3745 - val_loss: 25.1037\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 106us/sample - loss: 23.1320 - val_loss: 19.1185\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.7348 - val_loss: 44.1542\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.3734 - val_loss: 20.9734\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.9847 - val_loss: 20.9745\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.1684 - val_loss: 35.1423\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 24.5450 - val_loss: 17.2789\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 21.2419 - val_loss: 16.5852\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.0109 - val_loss: 17.5163\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 18.2043 - val_loss: 24.2648\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 30.5339\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   1.5s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 432.7643 - val_loss: 93.2372\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 163.6381 - val_loss: 120.3915\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 118.8667 - val_loss: 296.6670\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 399.6561 - val_loss: 105.3164\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 58.5972 - val_loss: 41.6874\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.9730 - val_loss: 170.7400\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.5028 - val_loss: 49.5470\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 40.6517 - val_loss: 37.6921\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.4698 - val_loss: 30.8859\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.2656 - val_loss: 62.5567\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.9614 - val_loss: 33.3312\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.2472 - val_loss: 28.2856\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.2218 - val_loss: 43.4284\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 95.1074 - val_loss: 23.9647\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.2709 - val_loss: 93.8931\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 59.6511 - val_loss: 87.6154\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 58.1805 - val_loss: 40.9635\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 40.3304 - val_loss: 26.2555\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0690 - val_loss: 49.1013\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 60.2191 - val_loss: 20.1399\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 38.8166 - val_loss: 21.4576\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.2471 - val_loss: 23.1737\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 31.9175 - val_loss: 22.8579\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 34.0806 - val_loss: 19.5297\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.7926 - val_loss: 18.5872\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.7497 - val_loss: 27.1700\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.0120 - val_loss: 24.1765\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 73.8704 - val_loss: 21.3104\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.5388 - val_loss: 17.9634\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 23.6307 - val_loss: 42.0183\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.6408 - val_loss: 17.2087\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 22.2633 - val_loss: 15.6067\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 22.9249 - val_loss: 14.9963\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/sample - loss: 20.9548 - val_loss: 14.9118\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 33.0493 - val_loss: 46.5557\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.5350 - val_loss: 14.4745\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.5460 - val_loss: 16.2668\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.6752 - val_loss: 20.1559\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.3779 - val_loss: 14.6114\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.8150 - val_loss: 56.6781\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.8866 - val_loss: 45.5416\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.5656 - val_loss: 65.9133\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.2996 - val_loss: 17.4183\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.1611 - val_loss: 16.8994\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.9485 - val_loss: 13.8405\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 32.5585 - val_loss: 24.2824\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.1457 - val_loss: 13.4858\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.6828 - val_loss: 51.3454\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4724 - val_loss: 38.1481\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 37.8832 - val_loss: 44.4929\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.9190 - val_loss: 13.1485\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.1989 - val_loss: 16.9056\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.3614 - val_loss: 17.2227\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.9321 - val_loss: 48.8349\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 26.5503 - val_loss: 12.8037\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.8913 - val_loss: 12.6165\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 25.4978 - val_loss: 39.0859\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 31.7207 - val_loss: 12.3616\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 26.1311 - val_loss: 13.0945\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.0691 - val_loss: 17.0362\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.5668 - val_loss: 59.2500\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 52.7778 - val_loss: 33.2119\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 35.2971 - val_loss: 13.2070\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.7063 - val_loss: 12.2682\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 23.6043 - val_loss: 42.7843\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.2734 - val_loss: 14.1308\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.0480 - val_loss: 11.9868\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 19.7992 - val_loss: 28.9757\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.0298 - val_loss: 13.6720\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 17.3548 - val_loss: 11.2185\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.0914 - val_loss: 11.6156\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.5238 - val_loss: 18.6347\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.4528 - val_loss: 15.0221\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 19.1753 - val_loss: 18.7201\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 18.2143 - val_loss: 13.7574\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 15.9942 - val_loss: 11.7456\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 23.8554 - val_loss: 15.0163\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 18.7004 - val_loss: 14.5111\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.1205 - val_loss: 10.7480\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.3147 - val_loss: 50.0438\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 32.4828 - val_loss: 31.2692\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2085 - val_loss: 31.8198\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.8412 - val_loss: 14.6728\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.9644 - val_loss: 12.4047\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.5669 - val_loss: 19.0741\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 19.5422 - val_loss: 12.7891\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 17.7907 - val_loss: 10.6801\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.5481 - val_loss: 11.5863\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.0290 - val_loss: 20.2338\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.9043 - val_loss: 11.2140\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.5909 - val_loss: 14.0238\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 17.2718 - val_loss: 12.8778\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.0508 - val_loss: 13.7606\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.6996 - val_loss: 30.9698\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.6490 - val_loss: 11.2629\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.4942 - val_loss: 10.7327\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.3418 - val_loss: 10.8867\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 11.0095\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   2.8s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 93673272186005684232716367691776.0000 - val_loss: inf\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   1.0s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: inf - val_loss: nan\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 67us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   1.0s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 495447616299288678629376.0000 - val_loss: inf\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   0.9s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 5602.7596 - val_loss: 3775503.3134\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 673868.3168 - val_loss: 2406.5233\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 1932.4003 - val_loss: 1373.7660\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 1108.9102 - val_loss: 799.2755\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 652.3206 - val_loss: 479.0129\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 399.4668 - val_loss: 304.1972\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 262.0329 - val_loss: 205.9980\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 185.3709 - val_loss: 151.1539\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 142.9753 - val_loss: 120.1448\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 119.4573 - val_loss: 103.5699\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.7803 - val_loss: 93.0079\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 99.3596 - val_loss: 87.9918\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 95.6889 - val_loss: 84.4736\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 93.2194 - val_loss: 82.5243\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 91.9392 - val_loss: 81.1381\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 91.1134 - val_loss: 80.5507\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.7677 - val_loss: 79.9886\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.4915 - val_loss: 79.7786\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3808 - val_loss: 79.6011\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.3890 - val_loss: 79.5497\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.2839 - val_loss: 79.4288\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 90.4482 - val_loss: 79.4025\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.3627 - val_loss: 79.3776\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2904 - val_loss: 79.4340\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 90.3384 - val_loss: 79.4069\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3732 - val_loss: 79.4413\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2691 - val_loss: 79.4779\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 90.3472 - val_loss: 79.3666\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 90.2445 - val_loss: 79.3807\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3391 - val_loss: 79.3647\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2506 - val_loss: 79.3759\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3596 - val_loss: 79.3348\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3475 - val_loss: 79.3591\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.2715 - val_loss: 79.4129\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.3046 - val_loss: 79.3983\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.3099 - val_loss: 79.3316\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3048 - val_loss: 79.3038\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.2900 - val_loss: 79.2923\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3171 - val_loss: 79.3656\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.3427 - val_loss: 79.2890\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 90.3061 - val_loss: 79.2742\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.2343 - val_loss: 79.3056\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.3106 - val_loss: 79.3763\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 90.2376 - val_loss: 79.3783\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 90.2565 - val_loss: 79.3679\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3453 - val_loss: 79.4050\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 90.3289 - val_loss: 79.4331\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3576 - val_loss: 79.3438\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 90.2701 - val_loss: 79.3631\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3221 - val_loss: 79.3853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.2400 - val_loss: 79.3363\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 92.3742\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.7s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 424.1770 - val_loss: 1424.9258\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 565.7866 - val_loss: 129.1448\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 103.8966 - val_loss: 71.6629\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 100.0820 - val_loss: 86.8151\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 87.9412 - val_loss: 86.9664\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 95.6688 - val_loss: 100.6473\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 92.5963 - val_loss: 83.5309\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.7026 - val_loss: 80.0017\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 101.4225 - val_loss: 102.3710\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 92.4501 - val_loss: 89.8063\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 94.5100 - val_loss: 147.5924\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 101.3110 - val_loss: 81.1870\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 87.3318 - val_loss: 106.8812\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 120.6674\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.0s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 5426.0371 - val_loss: 685.2263\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 616.1946 - val_loss: 409.3563\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 385.5592 - val_loss: 256.2172\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 256.5754 - val_loss: 174.3019\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 185.8148 - val_loss: 129.4701\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 146.4004 - val_loss: 104.8119\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 123.8078 - val_loss: 91.9050\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 111.5546 - val_loss: 85.0155\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 104.6207 - val_loss: 81.8314\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 100.9618 - val_loss: 80.1412\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 98.9269 - val_loss: 79.3331\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 97.5006 - val_loss: 79.2057\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 97.1562 - val_loss: 79.1885\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.7631 - val_loss: 79.2579\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 96.5994 - val_loss: 79.3584\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.4312 - val_loss: 79.4655\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 96.4226 - val_loss: 79.5520\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 96.4775 - val_loss: 79.4939\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.3487 - val_loss: 79.6180\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 96.3289 - val_loss: 79.6783\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 96.3985 - val_loss: 79.6849\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.3671 - val_loss: 79.6680\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.4522 - val_loss: 79.6755\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 80.2120\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.0s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 571.8534 - val_loss: 504.6908\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 498.9862 - val_loss: 423.3043\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 406.4291 - val_loss: 320.7082\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 299.1494 - val_loss: 221.9892\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 207.2815 - val_loss: 149.0317\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 149.9752 - val_loss: 119.0017\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 126.9423 - val_loss: 107.2033\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 116.8159 - val_loss: 99.8152\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 110.4116 - val_loss: 94.8927\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 105.2483 - val_loss: 90.3992\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 108us/sample - loss: 100.2128 - val_loss: 86.2177\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.4084 - val_loss: 82.3851\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.0097 - val_loss: 79.2612\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 88.0137 - val_loss: 75.6200\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 84.2707 - val_loss: 72.6480\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 80.8575 - val_loss: 69.7217\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.7278 - val_loss: 66.7589\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 74.4459 - val_loss: 64.3750\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 71.4892 - val_loss: 61.5267\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 68.3823 - val_loss: 59.2807\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 66.0013 - val_loss: 57.8586\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 63.5239 - val_loss: 55.8948\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.3490 - val_loss: 54.3114\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 59.3878 - val_loss: 52.5792\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.9291 - val_loss: 51.2504\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 55.7315 - val_loss: 50.2070\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.1725 - val_loss: 49.1033\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7075 - val_loss: 48.3759\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 51.2353 - val_loss: 47.2250\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.1425 - val_loss: 46.6675\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 48.9409 - val_loss: 46.1281\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 47.7725 - val_loss: 45.1955\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.9812 - val_loss: 44.6650\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 46.1312 - val_loss: 43.9973\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.1124 - val_loss: 43.6132\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.5162 - val_loss: 43.3470\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.5881 - val_loss: 43.0087\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 42.9814 - val_loss: 42.5331\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 42.4301 - val_loss: 42.3536\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 41.7523 - val_loss: 42.2510\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 41.1923 - val_loss: 42.0600\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.6675 - val_loss: 41.5021\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.2395 - val_loss: 41.4486\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.8219 - val_loss: 41.1009\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 39.4637 - val_loss: 41.2497\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 39.3074 - val_loss: 40.7422\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 38.5731 - val_loss: 40.8495\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2235 - val_loss: 40.6047\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 37.7310 - val_loss: 40.1726\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 37.3532 - val_loss: 39.7625\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 37.0876 - val_loss: 39.4629\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.7661 - val_loss: 39.5260\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.4999 - val_loss: 39.0507\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.1026 - val_loss: 38.7721\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.7528 - val_loss: 38.8402\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 35.4612 - val_loss: 38.5696\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 35.2652 - val_loss: 38.3185\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.9893 - val_loss: 38.3203\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 34.5138 - val_loss: 37.7459\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 34.4360 - val_loss: 37.7583\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 34.0039 - val_loss: 37.3704\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 33.6429 - val_loss: 37.2506\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.5787 - val_loss: 37.0614\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.0899 - val_loss: 36.8020\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 32.8420 - val_loss: 36.5641\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.7364 - val_loss: 36.4460\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 32.3633 - val_loss: 36.0470\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 32.2913 - val_loss: 35.6931\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 32.1434 - val_loss: 35.5310\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.8269 - val_loss: 35.1528\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 31.5457 - val_loss: 34.9611\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 31.3333 - val_loss: 34.9193\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.9726 - val_loss: 35.0449\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.7498 - val_loss: 34.4833\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 30.6521 - val_loss: 34.4956\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.2870 - val_loss: 34.3766\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.0610 - val_loss: 34.1944\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.8935 - val_loss: 33.4899\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 29.6473 - val_loss: 33.3201\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.5667 - val_loss: 33.1011\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.3451 - val_loss: 33.0068\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 29.2026 - val_loss: 32.7636\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.9182 - val_loss: 32.5248\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.6340 - val_loss: 32.4012\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 28.5077 - val_loss: 32.4413\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.2467 - val_loss: 31.9734\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.1951 - val_loss: 32.0927\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 27.9979 - val_loss: 31.9263\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 27.8391 - val_loss: 31.6041\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 27.5074 - val_loss: 31.3838\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.3570 - val_loss: 31.2926\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 27.1844 - val_loss: 30.9698\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 27.0431 - val_loss: 30.9106\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.8593 - val_loss: 30.5606\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 26.7542 - val_loss: 30.3774\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.4343 - val_loss: 30.3164\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 26.2308 - val_loss: 30.0802\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 26.2162 - val_loss: 29.9559\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 25.8995 - val_loss: 29.8861\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.9957 - val_loss: 29.5787\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 40.8671\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.6s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 601.0300 - val_loss: 543.9716\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 551.1588 - val_loss: 490.7246\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 489.2354 - val_loss: 417.9571\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 403.8156 - val_loss: 321.2414\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/sample - loss: 299.4022 - val_loss: 219.5985\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 203.0182 - val_loss: 147.2800\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 143.9796 - val_loss: 113.2914\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 118.2880 - val_loss: 100.3576\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 107.9825 - val_loss: 94.4724\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 102.7802 - val_loss: 90.4203\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.6381 - val_loss: 87.0540\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 95.1821 - val_loss: 83.8089\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 91.9516 - val_loss: 80.7091\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 88.9259 - val_loss: 77.9654\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 86.1148 - val_loss: 75.3156\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 83.3093 - val_loss: 72.9090\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 80.8398 - val_loss: 70.2720\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 78.3403 - val_loss: 68.4429\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 76.0941 - val_loss: 66.2572\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.9730 - val_loss: 64.1917\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 72.4458 - val_loss: 62.3248\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 70.0284 - val_loss: 60.6015\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 68.3812 - val_loss: 59.1537\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 66.6244 - val_loss: 58.0177\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 65.0505 - val_loss: 57.0025\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 63.5990 - val_loss: 55.4453\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 62.4018 - val_loss: 53.5631\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.8655 - val_loss: 52.8176\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 59.5336 - val_loss: 52.0833\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.6665 - val_loss: 51.2228\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.5989 - val_loss: 50.0884\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 56.3967 - val_loss: 49.4671\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 55.6032 - val_loss: 48.7317\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.6730 - val_loss: 48.0525\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.0034 - val_loss: 47.4059\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 53.3878 - val_loss: 47.0987\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 70.81 - 0s 94us/sample - loss: 52.8640 - val_loss: 46.8532\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 51.9563 - val_loss: 46.0292\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.3088 - val_loss: 45.1580\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.6825 - val_loss: 44.8002\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 50.1589 - val_loss: 44.5146\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 49.6865 - val_loss: 43.6615\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.1927 - val_loss: 43.4507\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 48.6877 - val_loss: 43.2815\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.2595 - val_loss: 42.8741\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 47.7049 - val_loss: 42.4540\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 47.6261 - val_loss: 42.1682\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.0126 - val_loss: 41.8557\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.6709 - val_loss: 41.9118\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.2687 - val_loss: 41.4211\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.6946 - val_loss: 41.4101\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.4240 - val_loss: 40.7003\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.8910 - val_loss: 40.6676\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.7224 - val_loss: 39.8514\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.3390 - val_loss: 39.9398\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 43.8249 - val_loss: 39.2981\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 43.5150 - val_loss: 38.6912\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 43.2460 - val_loss: 38.7720\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.8035 - val_loss: 38.7603\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.5555 - val_loss: 38.3668\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.3878 - val_loss: 37.9038\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 41.9440 - val_loss: 37.7885\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.5780 - val_loss: 37.8606\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.4201 - val_loss: 37.4089\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 41.2099 - val_loss: 36.6635\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 40.8685 - val_loss: 36.2593\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 40.4583 - val_loss: 36.2826\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.0981 - val_loss: 35.9317\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 40.1949 - val_loss: 35.4944\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.5953 - val_loss: 35.3115\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.3571 - val_loss: 35.2162\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.9690 - val_loss: 35.5998\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 38.8693 - val_loss: 34.8816\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 38.3828 - val_loss: 34.4112\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.3022 - val_loss: 34.1255\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.8641 - val_loss: 33.9728\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.6816 - val_loss: 33.7468\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 37.3525 - val_loss: 33.6110\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.1365 - val_loss: 33.2748\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.8810 - val_loss: 33.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.5255 - val_loss: 33.2145\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.3618 - val_loss: 32.6618\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.1229 - val_loss: 32.6888\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.0483 - val_loss: 32.6651\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 35.5724 - val_loss: 31.8900\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 35.3182 - val_loss: 31.6267\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 35.3379 - val_loss: 31.7616\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.8867 - val_loss: 31.5495\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.7502 - val_loss: 31.4409\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.5196 - val_loss: 30.9545\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.3166 - val_loss: 30.4063\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.0721 - val_loss: 30.3288\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 33.9407 - val_loss: 30.0319\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.6822 - val_loss: 30.0748\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 33.7988 - val_loss: 29.7539\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 33.1523 - val_loss: 30.0122\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 33.0373 - val_loss: 30.2412\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 32.9538 - val_loss: 29.7899\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 32.6954 - val_loss: 29.6517\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.3663 - val_loss: 28.9108\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 34.7723\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.7s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 592.3980 - val_loss: 502.7538\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 520.7194 - val_loss: 422.5028\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 426.7979 - val_loss: 320.6958\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 315.8472 - val_loss: 217.5816\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 217.7549 - val_loss: 148.4863\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 159.6042 - val_loss: 117.6967\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 134.1750 - val_loss: 104.7813\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 122.3172 - val_loss: 99.3039\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 116.9869 - val_loss: 94.9855\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 111.8501 - val_loss: 90.8191\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 107.0285 - val_loss: 87.0291\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 102.8492 - val_loss: 83.2904\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 98.9340 - val_loss: 80.3157\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 95.2451 - val_loss: 77.3326\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.6857 - val_loss: 73.8591\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 88.2855 - val_loss: 71.2421\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 85.2300 - val_loss: 68.6448\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 82.7137 - val_loss: 66.6809\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.6978 - val_loss: 63.7376\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 77.0511 - val_loss: 62.7007\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 74.7016 - val_loss: 60.4597\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 72.5019 - val_loss: 59.0114\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 70.6229 - val_loss: 57.0770\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 68.8026 - val_loss: 55.5087\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 66.9397 - val_loss: 54.5621\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 65.3263 - val_loss: 53.0945\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 63.8019 - val_loss: 52.2230\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 62.5385 - val_loss: 50.8901\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.1953 - val_loss: 50.1358\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 60.1739 - val_loss: 49.5983\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 59.0757 - val_loss: 49.1731\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 58.3125 - val_loss: 49.8441\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 57.4274 - val_loss: 48.1610\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 56.5183 - val_loss: 46.9851\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.7230 - val_loss: 46.7654\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.8349 - val_loss: 46.6892\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 54.3240 - val_loss: 46.2058\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 53.6867 - val_loss: 45.9429\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 53.2238 - val_loss: 45.5532\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7977 - val_loss: 44.5325\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.1157 - val_loss: 44.3886\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.6099 - val_loss: 44.1929\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 51.1239 - val_loss: 43.7862\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.7520 - val_loss: 43.1587\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 50.5781 - val_loss: 42.7215\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 49.9792 - val_loss: 43.1508\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 49.4537 - val_loss: 42.9638\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.2697 - val_loss: 42.3150\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 110us/sample - loss: 48.8872 - val_loss: 42.2597\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.8059 - val_loss: 41.8723\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 48.1909 - val_loss: 41.2834\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 47.7596 - val_loss: 41.0031\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.4513 - val_loss: 41.1771\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 47.0716 - val_loss: 40.5460\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.8193 - val_loss: 40.9620\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.3940 - val_loss: 40.8505\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.1132 - val_loss: 40.3715\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.3010 - val_loss: 39.8946\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 45.5159 - val_loss: 39.8641\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.3833 - val_loss: 38.8915\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 44.8276 - val_loss: 39.1387\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.5285 - val_loss: 39.5547\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 44.3117 - val_loss: 38.8557\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 43.9806 - val_loss: 38.9496\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.8261 - val_loss: 38.1568\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.5871 - val_loss: 37.2188\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.2441 - val_loss: 37.2589\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.0059 - val_loss: 36.9588\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.6985 - val_loss: 36.7150\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.5666 - val_loss: 36.6747\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 42.0295 - val_loss: 36.8503\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.8416 - val_loss: 36.6233\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.5380 - val_loss: 36.3267\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 66.09 - 0s 105us/sample - loss: 41.1656 - val_loss: 35.7474\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.9222 - val_loss: 35.5857\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 40.7067 - val_loss: 35.4437\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 40.6098 - val_loss: 34.9655\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.2814 - val_loss: 34.6066\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 40.4127 - val_loss: 34.1257\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 39.8476 - val_loss: 34.1356\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 39.7857 - val_loss: 33.9402\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 39.3051 - val_loss: 34.2141\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 38.9839 - val_loss: 33.4963\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.6919 - val_loss: 33.6197\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 38.6699 - val_loss: 33.2009\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.4709 - val_loss: 32.7415\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.2044 - val_loss: 32.7561\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 38.0442 - val_loss: 32.1823\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 37.6384 - val_loss: 32.3605\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.5341 - val_loss: 32.1018\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.2916 - val_loss: 31.6647\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.1610 - val_loss: 31.4526\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.0860 - val_loss: 31.3318\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.6709 - val_loss: 31.1511\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 36.3698 - val_loss: 30.8379\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.3253 - val_loss: 30.8661\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.2129 - val_loss: 30.3945\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.8963 - val_loss: 30.1982\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 35.7549 - val_loss: 29.8075\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 35.5262 - val_loss: 29.7970\n",
      "90/90 [==============================] - 0s 44us/sample - loss: 24.9830\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.6s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 401.3324 - val_loss: 152.8101\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 149us/sample - loss: 316.1091 - val_loss: 350.0138\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 232.2919 - val_loss: 300.3606\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 274.6873 - val_loss: 116.6808\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 83.5501 - val_loss: 74.0282\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 70.9639 - val_loss: 47.8970\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 81.8420 - val_loss: 61.3508\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.4513 - val_loss: 49.7415\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.2526 - val_loss: 53.6481\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 74.4715 - val_loss: 34.6974\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.5069 - val_loss: 32.3495\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.2120 - val_loss: 29.7955\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.3899 - val_loss: 26.6992\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.3802 - val_loss: 23.8857\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.9800 - val_loss: 50.6364\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 43.8013 - val_loss: 23.5134\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2418 - val_loss: 51.4313\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.5168 - val_loss: 20.1384\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.6578 - val_loss: 31.1802\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 24.0956 - val_loss: 35.2813\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 68.2964 - val_loss: 21.0141\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.3392 - val_loss: 22.8068\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.8527 - val_loss: 71.7404\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 30.6391 - val_loss: 21.7389\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.9430 - val_loss: 23.5060\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 18.3821 - val_loss: 25.7458\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/sample - loss: 23.7420 - val_loss: 20.3766\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 15.0562 - val_loss: 17.8905\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 18.0561 - val_loss: 17.0210\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 19.3781 - val_loss: 22.2817\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 14.8058 - val_loss: 29.4034\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.5927 - val_loss: 18.0460\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 18.2248 - val_loss: 33.9865\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.1798 - val_loss: 39.1959\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.4611 - val_loss: 17.8562\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 13.3882 - val_loss: 16.1960\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 12.1941 - val_loss: 23.7435\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.0953 - val_loss: 20.8620\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 28.5734 - val_loss: 15.3677\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 19.3983 - val_loss: 42.3627\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 17.7948 - val_loss: 24.2534\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 23.4587 - val_loss: 28.7936\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 14.5013 - val_loss: 18.8072\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 12.2576 - val_loss: 14.7037\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 17.3926 - val_loss: 52.3591\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 36.2494 - val_loss: 15.2251\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 14.5282 - val_loss: 15.1863\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 16.3266 - val_loss: 19.0651\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.9983 - val_loss: 59.5998\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4807 - val_loss: 73.4764\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 34.2226 - val_loss: 16.3665\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 11.9245 - val_loss: 15.7083\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.2946 - val_loss: 44.6941\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.6206 - val_loss: 21.0747\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 32.1550\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.7s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 292.9857 - val_loss: 150.5109\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 141.1087 - val_loss: 225.8679\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 223.5075 - val_loss: 310.6685\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 208.9495 - val_loss: 230.4313\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 230.9520 - val_loss: 92.7066\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.1258 - val_loss: 56.0980\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 65.1219 - val_loss: 89.4350\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 75.0332 - val_loss: 67.0958\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.2168 - val_loss: 122.5726\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 57.7645 - val_loss: 83.6184\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.5102 - val_loss: 23.8598\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.1159 - val_loss: 57.5041\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 44.7079 - val_loss: 34.7924\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 54.1820 - val_loss: 27.9629\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 24.5912 - val_loss: 21.1775\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.0180 - val_loss: 37.5408\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 95.8966 - val_loss: 33.0566\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 30.0557 - val_loss: 26.3700\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.2242 - val_loss: 20.4725\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 22.6578 - val_loss: 37.0840\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.6007 - val_loss: 66.5033\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.4159 - val_loss: 32.0167\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 40.5256 - val_loss: 18.6017\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.3432 - val_loss: 21.4179\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 21.6221 - val_loss: 18.5820\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.6314 - val_loss: 16.6313\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 17.5511 - val_loss: 16.2510\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.0236 - val_loss: 35.5965\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.3859 - val_loss: 81.9903\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.8771 - val_loss: 18.8130\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 18.3361 - val_loss: 16.5186\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 23.2030 - val_loss: 15.9708\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.5765 - val_loss: 18.7029\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 21.6315 - val_loss: 54.7517\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.1208 - val_loss: 32.7003\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 22.2022 - val_loss: 16.1456\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 56.3112 - val_loss: 20.7513\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.7969 - val_loss: 37.9338\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.4628 - val_loss: 31.2747\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.9086 - val_loss: 17.8938\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.2838 - val_loss: 19.0050\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 20.6641 - val_loss: 30.5466\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 35.1924\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.6s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 466.2099 - val_loss: 353.2231\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 203.8177 - val_loss: 386.2215\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 344.2270 - val_loss: 94.5998\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 228.4950 - val_loss: 213.3386\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 167.1251 - val_loss: 80.7292\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 85.4755 - val_loss: 51.4002\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.0761 - val_loss: 44.7171\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 81.3973 - val_loss: 45.8911\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.2117 - val_loss: 43.2586\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 56.8398 - val_loss: 37.0028\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 135.4252 - val_loss: 38.1035\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.0301 - val_loss: 35.9797\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 49.9429 - val_loss: 29.3376\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.2621 - val_loss: 33.6070\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.8622 - val_loss: 35.0535\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.3775 - val_loss: 31.8466\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 50.6726 - val_loss: 24.3019\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.8747 - val_loss: 31.7110\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.6826 - val_loss: 25.4972\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.6633 - val_loss: 29.1782\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 26.0553 - val_loss: 21.0221\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 31.1049 - val_loss: 20.7500\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 36.4823 - val_loss: 20.3649\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 31.6510 - val_loss: 20.7281\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 24.3760 - val_loss: 23.0579\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.7480 - val_loss: 26.4147\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 46.0535 - val_loss: 108.8371\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 61.6098 - val_loss: 27.1616\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.4466 - val_loss: 21.0188\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 30.7879 - val_loss: 20.4835\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.4040 - val_loss: 36.1873\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 41.2496 - val_loss: 40.1566\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 34.7782 - val_loss: 35.5394\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 32.0864\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.2s\n",
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   59.1s finished\n",
      "C:\\Users\\richard.stansbury\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 1s 2ms/sample - loss: 583.8328 - val_loss: 523.5317\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 0s 96us/sample - loss: 528.9890 - val_loss: 438.3452\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 0s 100us/sample - loss: 389.1581 - val_loss: 218.2884\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 0s 100us/sample - loss: 163.0669 - val_loss: 108.1025\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 116.8943 - val_loss: 100.6449\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 105.3471 - val_loss: 84.6953\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 94.8330 - val_loss: 76.5121\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 86.7094 - val_loss: 69.2287\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 78.3921 - val_loss: 62.6716\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 71.4048 - val_loss: 57.4610\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 66.3688 - val_loss: 57.6062\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 61.9316 - val_loss: 51.3060\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 57.6299 - val_loss: 47.7231\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 53.6423 - val_loss: 45.9876\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 50.9503 - val_loss: 50.3333\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 49.9339 - val_loss: 41.9181\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 47.0548 - val_loss: 40.9085\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 45.7341 - val_loss: 39.7258\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 44.2892 - val_loss: 38.9552\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 42.5633 - val_loss: 37.8126\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 41.6202 - val_loss: 36.8565\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 40.0614 - val_loss: 36.5405\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 39.0148 - val_loss: 49.3174\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 39.2908 - val_loss: 34.1498\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 36.8674 - val_loss: 33.2054\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 36.0461 - val_loss: 32.6074\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 34.7237 - val_loss: 32.2217\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 34.1929 - val_loss: 30.7640\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 34.0165 - val_loss: 30.7008\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 32.6834 - val_loss: 30.4055\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 31.3121 - val_loss: 29.9757\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 30.6342 - val_loss: 27.7685\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 30.1653 - val_loss: 27.0044\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 29.1440 - val_loss: 26.7361\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 29.1482 - val_loss: 25.8612\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 0s 114us/sample - loss: 27.9134 - val_loss: 25.6054\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 27.0945 - val_loss: 24.7323\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 26.9274 - val_loss: 24.1887\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 26.2959 - val_loss: 23.7360\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 25.5603 - val_loss: 23.6031\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 25.3374 - val_loss: 24.5273\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 24.6759 - val_loss: 23.8642\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 24.2926 - val_loss: 23.0048\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 24.1109 - val_loss: 21.9097\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 23.8854 - val_loss: 21.2632\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 23.1595 - val_loss: 22.3246\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 23.5614 - val_loss: 21.9164\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 22.8337 - val_loss: 20.9294\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 22.8185 - val_loss: 19.9112\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 22.8430 - val_loss: 20.0842\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 21.9388 - val_loss: 19.5658\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 22.1661 - val_loss: 19.1478\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 21.9118 - val_loss: 19.9509\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 21.4996 - val_loss: 19.0666\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 21.2490 - val_loss: 18.5016\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 20.7037 - val_loss: 19.1956\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 21.2502 - val_loss: 21.5835\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 20.6418 - val_loss: 18.4912\n",
      "Epoch 59/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 20.4283 - val_loss: 17.8705\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 19.7412 - val_loss: 17.7490\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 20.1408 - val_loss: 17.5890\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 19.8389 - val_loss: 19.1225\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.0202 - val_loss: 17.6508\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 0s 116us/sample - loss: 19.6784 - val_loss: 18.7106\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.1093 - val_loss: 17.1595\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.0598 - val_loss: 17.2840\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.9796 - val_loss: 18.1601\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.3309 - val_loss: 17.1377\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2896 - val_loss: 16.7315\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 18.4427 - val_loss: 16.7119\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.8293 - val_loss: 17.4678\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.7546 - val_loss: 16.6315\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 18.2095 - val_loss: 16.4738\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 18.0889 - val_loss: 16.6038\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2867 - val_loss: 16.3512\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.0259 - val_loss: 16.6975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.7973 - val_loss: 16.2581\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 17.7507 - val_loss: 24.1572\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.7235 - val_loss: 17.0640\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 17.7068 - val_loss: 18.8588\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.7348 - val_loss: 16.3200\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 17.5287 - val_loss: 15.8408\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.4712 - val_loss: 15.7981\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.5123 - val_loss: 16.0019\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.1369 - val_loss: 16.0562\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.0689 - val_loss: 15.9726\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.3819 - val_loss: 15.8501\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 17.2237 - val_loss: 16.3386\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.2427 - val_loss: 15.7244\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.0856 - val_loss: 16.0268\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.1649 - val_loss: 15.8056\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 16.8764 - val_loss: 15.6320\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.5414 - val_loss: 15.4881\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.7811 - val_loss: 15.2772\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 16.5557 - val_loss: 15.8493\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.6232 - val_loss: 15.9881\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.4985 - val_loss: 15.3283\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 0s 96us/sample - loss: 16.6098 - val_loss: 15.2057\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.2506 - val_loss: 19.8862\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.6560 - val_loss: 15.5610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00031819783764683556, 'n_hidden': 3, 'n_neurons': 64}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=13):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_hidden': [0,1,2,3],\n",
    "    'n_neurons': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4,3e-2),\n",
    "}\n",
    "\n",
    "\n",
    "lr = 1e-2\n",
    "model = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "rnd_search = RandomizedSearchCV(model, \n",
    "                                param_dist, \n",
    "                                n_iter=10, \n",
    "                                cv=3, verbose=2, \n",
    "                                error_score='raise-deprecating')\n",
    "print(X_train)\n",
    "\n",
    "rnd_search.fit(X_train, \n",
    "               y_train, \n",
    "               epochs=100,\n",
    "               validation_data=(X_val, y_val),\n",
    "               callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "rnd_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN Demonstration\n",
    "\n",
    "Our final demonstration will use the MNIST image set to demonstrate a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(X_train_full.shape)\n",
    "\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "33344/55000 [=================>............] - ETA: 3:07 - loss: 0.8670 - accuracy: 0.6855"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "score = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:10] # pretend we have new images\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
