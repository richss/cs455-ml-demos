{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CS 455/595a: MLP Demo using TensorFlow</center></h1>\n",
    "<center>Richard S. Stansbury</center>\n",
    "\n",
    "This notebook applies the ANN techniques for the Titanic Survivors and Boston Housing Prediction models covered in [1] with the [Titanic](https://www.kaggle.com/c/titanic/) and [Boston Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) data sets for DT-based classification and regression, respectively.\n",
    "\n",
    "Several different approaches to model construction are shown ihe demos below\n",
    "\n",
    "Reference:\n",
    "\n",
    "[1] Aurelen Geron. *Hands on Machine Learning with Scikit-Learn & TensorFlow* O'Reilley Media Inc, 2017.\n",
    "\n",
    "[2] Aurelen Geron. \"ageron/handson-ml: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\" Github.com, online at: https://github.com/ageron/handson-ml [last accessed 2019-03-01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. [Titanic Survivor ANN Classifiers](#Titanic-Survivor-Classifier)\n",
    " \n",
    "2. [Boston Housing Cost Ensemble ANN Regressor](#Boston-Housing-Cost-Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survivor Classifier\n",
    "\n",
    "## Set up - Imports of libraries and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# From: https://github.com/ageron/handson-ml/blob/master/09_up_and_running_with_tensorflow.ipynb    \n",
    "def reset_graph():\n",
    "    tf.reset_default_graph() \n",
    "    \n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"titanic-logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and apply pipelines to pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data from input files into Pandas data frames\n",
    "data_path = os.path.join(\"datasets\",\"titanic\")\n",
    "train_filename = \"train.csv\"\n",
    "test_filename = \"test.csv\"\n",
    "\n",
    "def read_csv(data_path, filename):\n",
    "    joined_path = os.path.join(data_path, filename)\n",
    "    return pd.read_csv(joined_path)\n",
    "\n",
    "# Read CSV file into Pandas Dataframes\n",
    "train_df = read_csv(data_path, train_filename)\n",
    "\n",
    "# Defining Data Pre-Processing Pipelines\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attributes):\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributes]\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent = pd.Series([X[c].value_counts().index[0] for c in X], \n",
    "                                       index = X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.most_frequent)\n",
    "\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Age\", \"Fare\", \"SibSp\", \"Parch\"])), # Selects Fields from dataframe\n",
    "        (\"Imputer\", SimpleImputer(strategy=\"median\")),   # Fills in NaN w/ median value for its column\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "categories_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Pclass\", \"Sex\"])), # Selects Fields from dataframe\n",
    "        (\"MostFreqImp\", MostFrequentImputer()), # Fill in NaN with most frequent\n",
    "        (\"OneHot\", OneHotEncoder(sparse=False, categories='auto')), # Onehot encode\n",
    "    ])\n",
    "\n",
    "preprocessing_pipe = FeatureUnion(transformer_list = [\n",
    "        (\"numeric pipeline\", numeric_pipe), \n",
    "        (\"categories pipeline\", categories_pipe)\n",
    "     ]) \n",
    "\n",
    "# Process Input Data Using Pipleines\n",
    "X_data = preprocessing_pipe.fit_transform(train_df)\n",
    "y_data = train_df[\"Survived\"].values.reshape(-1,1)\n",
    "\n",
    "# Process the output data.\n",
    "feature_names = [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Class0\", \"class1\",\"Sex0\", \"Sex1\"]\n",
    "\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(596, 9) (596, 1) (295, 9) (295, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.33)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the TF.Estimator.DNNClassifier (formerly of TFLearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\richa\\AppData\\Local\\Temp\\tmp4izoed8g\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\richa\\\\AppData\\\\Local\\\\Temp\\\\tmp4izoed8g', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000138A18A2978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\richa\\AppData\\Local\\Temp\\tmp4izoed8g\\model.ckpt.\n",
      "INFO:tensorflow:loss = 34.74399, step = 1\n",
      "INFO:tensorflow:global_step/sec: 187.654\n",
      "INFO:tensorflow:loss = 16.228445, step = 101 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.492\n",
      "INFO:tensorflow:loss = 18.341307, step = 201 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.222\n",
      "INFO:tensorflow:loss = 21.915796, step = 301 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.426\n",
      "INFO:tensorflow:loss = 19.758213, step = 401 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.13\n",
      "INFO:tensorflow:loss = 14.491086, step = 501 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.62\n",
      "INFO:tensorflow:loss = 23.44286, step = 601 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.749\n",
      "INFO:tensorflow:loss = 17.026653, step = 701 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.831\n",
      "INFO:tensorflow:loss = 15.444432, step = 801 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.248\n",
      "INFO:tensorflow:loss = 22.440725, step = 901 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 381.281\n",
      "INFO:tensorflow:loss = 21.03134, step = 1001 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.909\n",
      "INFO:tensorflow:loss = 11.449336, step = 1101 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.474\n",
      "INFO:tensorflow:loss = 13.691645, step = 1201 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.795\n",
      "INFO:tensorflow:loss = 18.442833, step = 1301 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.756\n",
      "INFO:tensorflow:loss = 23.222626, step = 1401 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.039\n",
      "INFO:tensorflow:loss = 18.748005, step = 1501 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.73\n",
      "INFO:tensorflow:loss = 24.716835, step = 1601 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.275\n",
      "INFO:tensorflow:loss = 15.565292, step = 1701 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.496\n",
      "INFO:tensorflow:loss = 14.189315, step = 1801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.671\n",
      "INFO:tensorflow:loss = 11.628001, step = 1901 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.891\n",
      "INFO:tensorflow:loss = 11.646231, step = 2001 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.005\n",
      "INFO:tensorflow:loss = 16.366295, step = 2101 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.032\n",
      "INFO:tensorflow:loss = 13.825056, step = 2201 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.515\n",
      "INFO:tensorflow:loss = 16.111677, step = 2301 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.107\n",
      "INFO:tensorflow:loss = 15.113697, step = 2401 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.447\n",
      "INFO:tensorflow:loss = 17.8179, step = 2501 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.909\n",
      "INFO:tensorflow:loss = 13.547301, step = 2601 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.355\n",
      "INFO:tensorflow:loss = 11.167451, step = 2701 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.087\n",
      "INFO:tensorflow:loss = 15.114304, step = 2801 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.478\n",
      "INFO:tensorflow:loss = 14.253019, step = 2901 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.794\n",
      "INFO:tensorflow:loss = 19.68377, step = 3001 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.395\n",
      "INFO:tensorflow:loss = 16.126736, step = 3101 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.466\n",
      "INFO:tensorflow:loss = 18.106968, step = 3201 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.957\n",
      "INFO:tensorflow:loss = 18.440763, step = 3301 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.889\n",
      "INFO:tensorflow:loss = 20.47282, step = 3401 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.803\n",
      "INFO:tensorflow:loss = 18.63028, step = 3501 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.739\n",
      "INFO:tensorflow:loss = 14.605592, step = 3601 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.721\n",
      "INFO:tensorflow:loss = 21.73963, step = 3701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.15\n",
      "INFO:tensorflow:loss = 18.1314, step = 3801 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.598\n",
      "INFO:tensorflow:loss = 12.375155, step = 3901 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.348\n",
      "INFO:tensorflow:loss = 14.808523, step = 4001 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.836\n",
      "INFO:tensorflow:loss = 19.303349, step = 4101 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.81\n",
      "INFO:tensorflow:loss = 15.089264, step = 4201 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.109\n",
      "INFO:tensorflow:loss = 16.019909, step = 4301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.065\n",
      "INFO:tensorflow:loss = 15.491533, step = 4401 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.678\n",
      "INFO:tensorflow:loss = 16.873522, step = 4501 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.265\n",
      "INFO:tensorflow:loss = 13.311244, step = 4601 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.02\n",
      "INFO:tensorflow:loss = 21.095108, step = 4701 (0.256 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4768 into C:\\Users\\richa\\AppData\\Local\\Temp\\tmp4izoed8g\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 17.124784.\n",
      "(596, 9)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-09T20:31:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\richa\\AppData\\Local\\Temp\\tmp4izoed8g\\model.ckpt-4768\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-09-20:31:13\n",
      "INFO:tensorflow:Saving dict for global step 4768: accuracy = 0.82033896, accuracy_baseline = 0.6, auc = 0.8530833, auc_precision_recall = 0.83617675, average_loss = 0.5096449, global_step = 4768, label/mean = 0.4, loss = 50.11508, precision = 0.7826087, prediction/mean = 0.40462694, recall = 0.7627119\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4768: C:\\Users\\richa\\AppData\\Local\\Temp\\tmp4izoed8g\\model.ckpt-4768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.82033896,\n",
       " 'accuracy_baseline': 0.6,\n",
       " 'auc': 0.8530833,\n",
       " 'auc_precision_recall': 0.83617675,\n",
       " 'average_loss': 0.5096449,\n",
       " 'label/mean': 0.4,\n",
       " 'loss': 50.11508,\n",
       " 'precision': 0.7826087,\n",
       " 'prediction/mean': 0.40462694,\n",
       " 'recall': 0.7627119,\n",
       " 'global_step': 4768}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction Phase\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "feature_cols = [tf.feature_column.numeric_column(\"X\", shape=[X_data.shape[1]])]\n",
    "\n",
    "dnn_clf = tf.estimator.DNNClassifier(hidden_units=[20,20], n_classes=2,\n",
    "                                     feature_columns=feature_cols)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_train}, y=y_train, batch_size=50, num_epochs=400, shuffle=True)\n",
    "dnn_clf.train(input_fn=train_input_fn)\n",
    "\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"X\": X_test}, y=y_test, shuffle=False)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "eval_results = dnn_clf.evaluate(input_fn=test_input_fn)\n",
    "                                \n",
    "eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use plain TensorFlow to implement a neural network using the tf.layers.dense class to define fully-connected (dense) layers of RELU and a softmax of the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-59fa78d8d48e>:17: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "0-Train: 0.6304348111152649 Test:0.6000000238418579\n",
      "1-Train: 0.6304348111152649 Test:0.6000000238418579\n",
      "2-Train: 0.739130437374115 Test:0.7762711644172668\n",
      "3-Train: 0.739130437374115 Test:0.7864406704902649\n",
      "4-Train: 0.739130437374115 Test:0.7932203412055969\n",
      "5-Train: 0.739130437374115 Test:0.800000011920929\n",
      "6-Train: 0.739130437374115 Test:0.806779682636261\n",
      "7-Train: 0.739130437374115 Test:0.7966101765632629\n",
      "8-Train: 0.782608687877655 Test:0.800000011920929\n",
      "9-Train: 0.782608687877655 Test:0.803389847278595\n",
      "10-Train: 0.782608687877655 Test:0.800000011920929\n",
      "11-Train: 0.782608687877655 Test:0.803389847278595\n",
      "12-Train: 0.804347813129425 Test:0.810169517993927\n",
      "13-Train: 0.782608687877655 Test:0.8169491291046143\n",
      "14-Train: 0.804347813129425 Test:0.8135592937469482\n",
      "15-Train: 0.804347813129425 Test:0.8203389644622803\n",
      "16-Train: 0.804347813129425 Test:0.8169491291046143\n",
      "17-Train: 0.804347813129425 Test:0.8237287998199463\n",
      "18-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "19-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "20-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "21-Train: 0.8260869383811951 Test:0.8271186351776123\n",
      "22-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "23-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "24-Train: 0.8260869383811951 Test:0.8169491291046143\n",
      "25-Train: 0.8260869383811951 Test:0.8203389644622803\n",
      "26-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "27-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "28-Train: 0.8260869383811951 Test:0.8237287998199463\n",
      "29-Train: 0.8478260636329651 Test:0.8237287998199463\n",
      "30-Train: 0.8478260636329651 Test:0.8237287998199463\n",
      "31-Train: 0.8478260636329651 Test:0.8237287998199463\n",
      "32-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "33-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "34-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "35-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "36-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "37-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "38-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "39-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "40-Train: 0.8478260636329651 Test:0.8237287998199463\n",
      "41-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "42-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "43-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "44-Train: 0.8695651888847351 Test:0.8237287998199463\n",
      "45-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "46-Train: 0.8695651888847351 Test:0.8237287998199463\n",
      "47-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "48-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "49-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "50-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "51-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "52-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "53-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "54-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "55-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "56-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "57-Train: 0.8478260636329651 Test:0.8203389644622803\n",
      "58-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "59-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "60-Train: 0.8478260636329651 Test:0.8237287998199463\n",
      "61-Train: 0.8695651888847351 Test:0.8271186351776123\n",
      "62-Train: 0.8695651888847351 Test:0.8237287998199463\n",
      "63-Train: 0.8695651888847351 Test:0.8237287998199463\n",
      "64-Train: 0.8695651888847351 Test:0.8237287998199463\n",
      "65-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "66-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "67-Train: 0.8260869383811951 Test:0.810169517993927\n",
      "68-Train: 0.8478260636329651 Test:0.8169491291046143\n",
      "69-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "70-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "71-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "72-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "73-Train: 0.8478260636329651 Test:0.810169517993927\n",
      "74-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "75-Train: 0.8478260636329651 Test:0.810169517993927\n",
      "76-Train: 0.8260869383811951 Test:0.803389847278595\n",
      "77-Train: 0.8478260636329651 Test:0.8135592937469482\n",
      "78-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "79-Train: 0.8695651888847351 Test:0.8135592937469482\n",
      "80-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "81-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "82-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "83-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "84-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "85-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "86-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "87-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "88-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "89-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "90-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "91-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "92-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "93-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "94-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "95-Train: 0.8695651888847351 Test:0.8203389644622803\n",
      "96-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "97-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "98-Train: 0.8695651888847351 Test:0.8169491291046143\n",
      "99-Train: 0.8478260636329651 Test:0.8169491291046143\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "def get_batch(X, iter, size):\n",
    "    return X[(iter*batch_size) : ((iter+1)*batch_size)]\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "num_instances = X_train.shape[0]\n",
    "\n",
    "# Construction\n",
    "X = tf.placeholder(tf.float32, shape=(None, num_features), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"Titanic_MLP\"):\n",
    "    hidden1 = tf.layers.dense(X, 20, name=\"Hidden-1\", activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, 10, name=\"Hidden-2\", activation=tf.nn.relu)\n",
    "    hidden3 = tf.layers.dense(hidden2, 5, name=\"Hidden-3\", activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden3, 2, name=\"Survived\")\n",
    "    output = tf.nn.softmax(logits)\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary = tf.summary.scalar('Loss', loss)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "with tf.name_scope(\"train\"): \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "\n",
    "# Execution\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    step=0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for iteration in range(num_instances // batch_size + 1):\n",
    "            step+=1\n",
    "            X_batch = get_batch(X_train, iteration, batch_size)\n",
    "            y_batch = get_batch(y_train, iteration, batch_size)\n",
    "            \n",
    "            sess.run(training_op, feed_dict={X: X_batch,\n",
    "                                            y: y_batch.reshape(y_batch.shape[0])})\n",
    "            \n",
    "        # Save trained model at end of epoch\n",
    "        save_path = saver.save(sess, \"./tf_plain_class.chkp\")\n",
    "        \n",
    "        #Evaluate on final training batch vs. final testing\n",
    "        acc_train, loss_summary_str, acc_summary_str = sess.run([accuracy, loss_summary, accuracy_summary],feed_dict={X: X_batch, y: y_batch.reshape(y_batch.shape[0])})\n",
    "        acc_val = accuracy.eval(feed_dict={X:X_test, y: y_test.reshape(y_test.shape[0])})\n",
    "\n",
    "        # Logging for Tensor Board for each epoch\n",
    "        file_writer.add_summary(loss_summary_str,step)\n",
    "        file_writer.add_summary(acc_summary_str,step)\n",
    "        \n",
    "        # Print progress made\n",
    "        print(\"{}-Train: {} Test:{}\".format(epoch,\n",
    "                                           acc_train,\n",
    "                                           acc_val)) \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_plain_class.chkp\n",
      "Precision: 0.8137254901960784, \n",
      "Recall: 0.7033898305084746, \n",
      "Conf Mat: [[158  19]\n",
      " [ 35  83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, \"./tf_plain_class.chkp\")\n",
    "    y_predict = output.eval(feed_dict={X:X_test, y: y_test.reshape(y_test.shape[0])})\n",
    "    \n",
    "    con_mx = confusion_matrix(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    precision = precision_score(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    recall = recall_score(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    print(\"Precision: {}, \\nRecall: {}, \\nConf Mat: {}\". format(precision, recall, con_mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 596 samples, validate on 295 samples\n",
      "Epoch 1/400\n",
      "100/596 [====>.........................] - ETA: 2s - loss: 0.7856 - acc: 0.6300\n",
      "Epoch 00001: saving model to ./keras_model_class.ckpt\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "596/596 [==============================] - 1s 1ms/sample - loss: 0.7181 - acc: 0.6309 - val_loss: 0.6429 - val_acc: 0.6000\n",
      "Epoch 2/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.6084 - acc: 0.6000\n",
      "Epoch 00002: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.6139 - acc: 0.6510 - val_loss: 0.5838 - val_acc: 0.6915\n",
      "Epoch 3/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5704 - acc: 0.6900\n",
      "Epoch 00003: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 167us/sample - loss: 0.5686 - acc: 0.6997 - val_loss: 0.5570 - val_acc: 0.7220\n",
      "Epoch 4/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5703 - acc: 0.7500\n",
      "Epoch 00004: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 165us/sample - loss: 0.5463 - acc: 0.7349 - val_loss: 0.5376 - val_acc: 0.7729\n",
      "Epoch 5/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5437 - acc: 0.7200\n",
      "Epoch 00005: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.5305 - acc: 0.7718 - val_loss: 0.5220 - val_acc: 0.7898\n",
      "Epoch 6/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5346 - acc: 0.7600\n",
      "Epoch 00006: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 105us/sample - loss: 0.5197 - acc: 0.7869 - val_loss: 0.5099 - val_acc: 0.7966\n",
      "Epoch 7/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5437 - acc: 0.7600\n",
      "Epoch 00007: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 166us/sample - loss: 0.5068 - acc: 0.7987 - val_loss: 0.5045 - val_acc: 0.7864\n",
      "Epoch 8/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5519 - acc: 0.7700\n",
      "Epoch 00008: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.5031 - acc: 0.7953 - val_loss: 0.4913 - val_acc: 0.7966\n",
      "Epoch 9/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4368 - acc: 0.8400\n",
      "Epoch 00009: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.4913 - acc: 0.7886 - val_loss: 0.4838 - val_acc: 0.8136\n",
      "Epoch 10/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4968 - acc: 0.8400\n",
      "Epoch 00010: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.4859 - acc: 0.8188 - val_loss: 0.4761 - val_acc: 0.8000\n",
      "Epoch 11/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4890 - acc: 0.8000\n",
      "Epoch 00011: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 122us/sample - loss: 0.4801 - acc: 0.8121 - val_loss: 0.4710 - val_acc: 0.8203\n",
      "Epoch 12/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4694 - acc: 0.8200\n",
      "Epoch 00012: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 201us/sample - loss: 0.4765 - acc: 0.8087 - val_loss: 0.4660 - val_acc: 0.8203\n",
      "Epoch 13/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4822 - acc: 0.8200\n",
      "Epoch 00013: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.4705 - acc: 0.8221 - val_loss: 0.4617 - val_acc: 0.8203\n",
      "Epoch 14/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4766 - acc: 0.8200\n",
      "Epoch 00014: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.4678 - acc: 0.8138 - val_loss: 0.4578 - val_acc: 0.8305\n",
      "Epoch 15/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4707 - acc: 0.8400\n",
      "Epoch 00015: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 164us/sample - loss: 0.4631 - acc: 0.8138 - val_loss: 0.4575 - val_acc: 0.8169\n",
      "Epoch 16/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4897 - acc: 0.7900\n",
      "Epoch 00016: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.4663 - acc: 0.8121 - val_loss: 0.4520 - val_acc: 0.8237\n",
      "Epoch 17/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4765 - acc: 0.8100\n",
      "Epoch 00017: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.4579 - acc: 0.8205 - val_loss: 0.4506 - val_acc: 0.8203\n",
      "Epoch 18/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4331 - acc: 0.8600\n",
      "Epoch 00018: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.4535 - acc: 0.8205 - val_loss: 0.4529 - val_acc: 0.8102\n",
      "Epoch 19/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5063 - acc: 0.8000\n",
      "Epoch 00019: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.4556 - acc: 0.8205 - val_loss: 0.4503 - val_acc: 0.8136\n",
      "Epoch 20/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4073 - acc: 0.8500\n",
      "Epoch 00020: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 168us/sample - loss: 0.4502 - acc: 0.8188 - val_loss: 0.4443 - val_acc: 0.8237\n",
      "Epoch 21/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4354 - acc: 0.8300\n",
      "Epoch 00021: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 165us/sample - loss: 0.4456 - acc: 0.8171 - val_loss: 0.4423 - val_acc: 0.8237\n",
      "Epoch 22/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4056 - acc: 0.8400\n",
      "Epoch 00022: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.4471 - acc: 0.8221 - val_loss: 0.4389 - val_acc: 0.8169\n",
      "Epoch 23/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4709 - acc: 0.8100\n",
      "Epoch 00023: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 134us/sample - loss: 0.4417 - acc: 0.8255 - val_loss: 0.4374 - val_acc: 0.8203\n",
      "Epoch 24/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4420 - acc: 0.8100\n",
      "Epoch 00024: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.4452 - acc: 0.8171 - val_loss: 0.4379 - val_acc: 0.8169\n",
      "Epoch 25/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3547 - acc: 0.8800\n",
      "Epoch 00025: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 180us/sample - loss: 0.4439 - acc: 0.8238 - val_loss: 0.4426 - val_acc: 0.8203\n",
      "Epoch 26/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4441 - acc: 0.8300\n",
      "Epoch 00026: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 172us/sample - loss: 0.4391 - acc: 0.8238 - val_loss: 0.4324 - val_acc: 0.8169\n",
      "Epoch 27/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5106 - acc: 0.7700\n",
      "Epoch 00027: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.4384 - acc: 0.8121 - val_loss: 0.4358 - val_acc: 0.8169\n",
      "Epoch 28/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4555 - acc: 0.8200\n",
      "Epoch 00028: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 121us/sample - loss: 0.4328 - acc: 0.8238 - val_loss: 0.4291 - val_acc: 0.8203\n",
      "Epoch 29/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4291 - acc: 0.8500\n",
      "Epoch 00029: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.4332 - acc: 0.8238 - val_loss: 0.4272 - val_acc: 0.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3805 - acc: 0.8700\n",
      "Epoch 00030: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 123us/sample - loss: 0.4317 - acc: 0.8255 - val_loss: 0.4281 - val_acc: 0.8271\n",
      "Epoch 31/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4908 - acc: 0.7900\n",
      "Epoch 00031: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 108us/sample - loss: 0.4330 - acc: 0.8188 - val_loss: 0.4267 - val_acc: 0.8169\n",
      "Epoch 32/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4613 - acc: 0.8100\n",
      "Epoch 00032: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 182us/sample - loss: 0.4283 - acc: 0.8205 - val_loss: 0.4237 - val_acc: 0.8271\n",
      "Epoch 33/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3981 - acc: 0.8600\n",
      "Epoch 00033: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 111us/sample - loss: 0.4258 - acc: 0.8171 - val_loss: 0.4337 - val_acc: 0.8000\n",
      "Epoch 34/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3939 - acc: 0.8300\n",
      "Epoch 00034: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 153us/sample - loss: 0.4286 - acc: 0.8221 - val_loss: 0.4238 - val_acc: 0.8203\n",
      "Epoch 35/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4427 - acc: 0.8100\n",
      "Epoch 00035: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 147us/sample - loss: 0.4267 - acc: 0.8188 - val_loss: 0.4274 - val_acc: 0.8169\n",
      "Epoch 36/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4256 - acc: 0.8100\n",
      "Epoch 00036: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 159us/sample - loss: 0.4375 - acc: 0.8121 - val_loss: 0.4251 - val_acc: 0.8237\n",
      "Epoch 37/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3361 - acc: 0.8700\n",
      "Epoch 00037: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.4244 - acc: 0.8188 - val_loss: 0.4205 - val_acc: 0.8271\n",
      "Epoch 38/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4800 - acc: 0.8000\n",
      "Epoch 00038: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.4220 - acc: 0.8305 - val_loss: 0.4235 - val_acc: 0.8203\n",
      "Epoch 39/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3656 - acc: 0.8500\n",
      "Epoch 00039: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.4207 - acc: 0.8289 - val_loss: 0.4194 - val_acc: 0.8271\n",
      "Epoch 40/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4259 - acc: 0.8400\n",
      "Epoch 00040: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.4195 - acc: 0.8221 - val_loss: 0.4175 - val_acc: 0.8271\n",
      "Epoch 41/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3756 - acc: 0.8600\n",
      "Epoch 00041: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 147us/sample - loss: 0.4243 - acc: 0.8205 - val_loss: 0.4169 - val_acc: 0.8271\n",
      "Epoch 42/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4192 - acc: 0.8100\n",
      "Epoch 00042: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.4180 - acc: 0.8305 - val_loss: 0.4182 - val_acc: 0.8237\n",
      "Epoch 43/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4766 - acc: 0.7900\n",
      "Epoch 00043: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.4167 - acc: 0.8171 - val_loss: 0.4164 - val_acc: 0.8305\n",
      "Epoch 44/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4104 - acc: 0.8400\n",
      "Epoch 00044: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.4198 - acc: 0.8289 - val_loss: 0.4219 - val_acc: 0.8034\n",
      "Epoch 45/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3703 - acc: 0.8200\n",
      "Epoch 00045: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.4182 - acc: 0.8255 - val_loss: 0.4145 - val_acc: 0.8339\n",
      "Epoch 46/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3684 - acc: 0.8500\n",
      "Epoch 00046: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.4157 - acc: 0.8272 - val_loss: 0.4422 - val_acc: 0.8136\n",
      "Epoch 47/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4041 - acc: 0.8100\n",
      "Epoch 00047: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.4281 - acc: 0.8322 - val_loss: 0.4177 - val_acc: 0.8068\n",
      "Epoch 48/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3825 - acc: 0.8600\n",
      "Epoch 00048: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.4118 - acc: 0.8322 - val_loss: 0.4156 - val_acc: 0.8237\n",
      "Epoch 49/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3821 - acc: 0.8300\n",
      "Epoch 00049: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 129us/sample - loss: 0.4128 - acc: 0.8356 - val_loss: 0.4188 - val_acc: 0.8000\n",
      "Epoch 50/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3972 - acc: 0.8000\n",
      "Epoch 00050: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.4108 - acc: 0.8289 - val_loss: 0.4155 - val_acc: 0.8237\n",
      "Epoch 51/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4343 - acc: 0.8200\n",
      "Epoch 00051: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.4199 - acc: 0.8272 - val_loss: 0.4149 - val_acc: 0.8203\n",
      "Epoch 52/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4050 - acc: 0.8500\n",
      "Epoch 00052: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.4154 - acc: 0.8305 - val_loss: 0.4209 - val_acc: 0.8203\n",
      "Epoch 53/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4540 - acc: 0.7800\n",
      "Epoch 00053: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 191us/sample - loss: 0.4117 - acc: 0.8305 - val_loss: 0.4287 - val_acc: 0.7966\n",
      "Epoch 54/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4313 - acc: 0.8000\n",
      "Epoch 00054: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.4140 - acc: 0.8238 - val_loss: 0.4122 - val_acc: 0.8373\n",
      "Epoch 55/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3153 - acc: 0.9000\n",
      "Epoch 00055: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.4147 - acc: 0.8289 - val_loss: 0.4217 - val_acc: 0.8034\n",
      "Epoch 56/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4916 - acc: 0.7700\n",
      "Epoch 00056: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 161us/sample - loss: 0.4163 - acc: 0.8238 - val_loss: 0.4403 - val_acc: 0.8034\n",
      "Epoch 57/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4927 - acc: 0.7800\n",
      "Epoch 00057: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 127us/sample - loss: 0.4332 - acc: 0.8305 - val_loss: 0.4206 - val_acc: 0.8271\n",
      "Epoch 58/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3071 - acc: 0.9100\n",
      "Epoch 00058: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.4112 - acc: 0.8289 - val_loss: 0.4137 - val_acc: 0.8305\n",
      "Epoch 59/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4541 - acc: 0.8000\n",
      "Epoch 00059: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.4084 - acc: 0.8389 - val_loss: 0.4206 - val_acc: 0.8271\n",
      "Epoch 60/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4417 - acc: 0.8000\n",
      "Epoch 00060: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.4043 - acc: 0.8238 - val_loss: 0.4165 - val_acc: 0.8102\n",
      "Epoch 61/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4101 - acc: 0.8500\n",
      "Epoch 00061: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 177us/sample - loss: 0.4051 - acc: 0.8305 - val_loss: 0.4114 - val_acc: 0.8373\n",
      "Epoch 62/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2929 - acc: 0.8900\n",
      "Epoch 00062: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.4098 - acc: 0.8322 - val_loss: 0.4498 - val_acc: 0.8237\n",
      "Epoch 63/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3912 - acc: 0.8400\n",
      "Epoch 00063: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.4191 - acc: 0.8272 - val_loss: 0.4113 - val_acc: 0.8339\n",
      "Epoch 64/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3543 - acc: 0.8800\n",
      "Epoch 00064: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 122us/sample - loss: 0.4031 - acc: 0.8305 - val_loss: 0.4140 - val_acc: 0.8271\n",
      "Epoch 65/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5044 - acc: 0.7700\n",
      "Epoch 00065: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3985 - acc: 0.8272 - val_loss: 0.4234 - val_acc: 0.8102\n",
      "Epoch 66/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3604 - acc: 0.8200\n",
      "Epoch 00066: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.4022 - acc: 0.8322 - val_loss: 0.4152 - val_acc: 0.8271\n",
      "Epoch 67/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4022 - acc: 0.8300\n",
      "Epoch 00067: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 178us/sample - loss: 0.4051 - acc: 0.8272 - val_loss: 0.4288 - val_acc: 0.8237\n",
      "Epoch 68/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3282 - acc: 0.9000\n",
      "Epoch 00068: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.4069 - acc: 0.8221 - val_loss: 0.4129 - val_acc: 0.8271\n",
      "Epoch 69/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4262 - acc: 0.8200\n",
      "Epoch 00069: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 156us/sample - loss: 0.4029 - acc: 0.8339 - val_loss: 0.4261 - val_acc: 0.8237\n",
      "Epoch 70/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4513 - acc: 0.8100\n",
      "Epoch 00070: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 159us/sample - loss: 0.4139 - acc: 0.8305 - val_loss: 0.4180 - val_acc: 0.8102\n",
      "Epoch 71/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4111 - acc: 0.8500\n",
      "Epoch 00071: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 189us/sample - loss: 0.3998 - acc: 0.8289 - val_loss: 0.4165 - val_acc: 0.8102\n",
      "Epoch 72/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3487 - acc: 0.8900\n",
      "Epoch 00072: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.3993 - acc: 0.8372 - val_loss: 0.4118 - val_acc: 0.8271\n",
      "Epoch 73/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3980 - acc: 0.8300\n",
      "Epoch 00073: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 112us/sample - loss: 0.3990 - acc: 0.8238 - val_loss: 0.4625 - val_acc: 0.8034\n",
      "Epoch 74/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4778 - acc: 0.7900\n",
      "Epoch 00074: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 118us/sample - loss: 0.3955 - acc: 0.8356 - val_loss: 0.4130 - val_acc: 0.8136\n",
      "Epoch 75/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4320 - acc: 0.8300\n",
      "Epoch 00075: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.4066 - acc: 0.8456 - val_loss: 0.4137 - val_acc: 0.8068\n",
      "Epoch 76/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3825 - acc: 0.8600\n",
      "Epoch 00076: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3981 - acc: 0.8289 - val_loss: 0.4121 - val_acc: 0.8169\n",
      "Epoch 77/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3986 - acc: 0.8300\n",
      "Epoch 00077: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 118us/sample - loss: 0.3972 - acc: 0.8322 - val_loss: 0.4688 - val_acc: 0.7932\n",
      "Epoch 78/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4230 - acc: 0.8400\n",
      "Epoch 00078: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 115us/sample - loss: 0.3936 - acc: 0.8339 - val_loss: 0.4309 - val_acc: 0.8305\n",
      "Epoch 79/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3829 - acc: 0.8600\n",
      "Epoch 00079: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.4026 - acc: 0.8490 - val_loss: 0.4151 - val_acc: 0.8237\n",
      "Epoch 80/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3655 - acc: 0.8500\n",
      "Epoch 00080: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.4022 - acc: 0.8238 - val_loss: 0.4136 - val_acc: 0.8169\n",
      "Epoch 81/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4009 - acc: 0.8400\n",
      "Epoch 00081: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 101us/sample - loss: 0.4084 - acc: 0.8356 - val_loss: 0.4105 - val_acc: 0.8339\n",
      "Epoch 82/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3431 - acc: 0.8400\n",
      "Epoch 00082: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 177us/sample - loss: 0.4051 - acc: 0.8305 - val_loss: 0.4207 - val_acc: 0.8068\n",
      "Epoch 83/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3195 - acc: 0.8400\n",
      "Epoch 00083: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3920 - acc: 0.8372 - val_loss: 0.4422 - val_acc: 0.8203\n",
      "Epoch 84/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3863 - acc: 0.8500\n",
      "Epoch 00084: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.4081 - acc: 0.8205 - val_loss: 0.4297 - val_acc: 0.8102\n",
      "Epoch 85/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4235 - acc: 0.8200\n",
      "Epoch 00085: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.4016 - acc: 0.8205 - val_loss: 0.4127 - val_acc: 0.8271\n",
      "Epoch 86/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4869 - acc: 0.8000\n",
      "Epoch 00086: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 179us/sample - loss: 0.3910 - acc: 0.8339 - val_loss: 0.4187 - val_acc: 0.8305\n",
      "Epoch 87/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4092 - acc: 0.8200\n",
      "Epoch 00087: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3880 - acc: 0.8490 - val_loss: 0.4463 - val_acc: 0.8000\n",
      "Epoch 88/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4737 - acc: 0.7900\n",
      "Epoch 00088: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 190us/sample - loss: 0.3886 - acc: 0.8356 - val_loss: 0.4140 - val_acc: 0.8271\n",
      "Epoch 89/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4835 - acc: 0.7900\n",
      "Epoch 00089: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.3964 - acc: 0.8322 - val_loss: 0.4201 - val_acc: 0.8102\n",
      "Epoch 90/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3351 - acc: 0.8300\n",
      "Epoch 00090: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 131us/sample - loss: 0.3955 - acc: 0.8289 - val_loss: 0.4163 - val_acc: 0.8271\n",
      "Epoch 91/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3352 - acc: 0.8900\n",
      "Epoch 00091: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.3937 - acc: 0.8339 - val_loss: 0.4154 - val_acc: 0.8068\n",
      "Epoch 92/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3307 - acc: 0.8700\n",
      "Epoch 00092: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 108us/sample - loss: 0.3945 - acc: 0.8339 - val_loss: 0.4144 - val_acc: 0.8000\n",
      "Epoch 93/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4052 - acc: 0.8200\n",
      "Epoch 00093: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 97us/sample - loss: 0.3951 - acc: 0.8272 - val_loss: 0.4157 - val_acc: 0.8000\n",
      "Epoch 94/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3878 - acc: 0.8300\n",
      "Epoch 00094: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3945 - acc: 0.8389 - val_loss: 0.4475 - val_acc: 0.7898\n",
      "Epoch 95/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4338 - acc: 0.8100\n",
      "Epoch 00095: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3927 - acc: 0.8339 - val_loss: 0.4188 - val_acc: 0.7966\n",
      "Epoch 96/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3543 - acc: 0.8300\n",
      "Epoch 00096: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.4009 - acc: 0.8255 - val_loss: 0.4312 - val_acc: 0.8102\n",
      "Epoch 97/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3414 - acc: 0.8300\n",
      "Epoch 00097: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 149us/sample - loss: 0.4093 - acc: 0.8221 - val_loss: 0.5024 - val_acc: 0.8068\n",
      "Epoch 98/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4458 - acc: 0.8600\n",
      "Epoch 00098: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 169us/sample - loss: 0.3992 - acc: 0.8372 - val_loss: 0.4166 - val_acc: 0.8102\n",
      "Epoch 99/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3658 - acc: 0.8600\n",
      "Epoch 00099: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.4043 - acc: 0.8339 - val_loss: 0.4386 - val_acc: 0.8068\n",
      "Epoch 100/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2754 - acc: 0.9100\n",
      "Epoch 00100: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.4354 - acc: 0.8154 - val_loss: 0.4203 - val_acc: 0.8305\n",
      "Epoch 101/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3187 - acc: 0.8900\n",
      "Epoch 00101: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.4078 - acc: 0.8423 - val_loss: 0.4136 - val_acc: 0.8068\n",
      "Epoch 102/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3490 - acc: 0.8300\n",
      "Epoch 00102: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.4097 - acc: 0.8171 - val_loss: 0.4129 - val_acc: 0.8136\n",
      "Epoch 103/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3849 - acc: 0.8400\n",
      "Epoch 00103: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.4071 - acc: 0.8272 - val_loss: 0.4380 - val_acc: 0.8136\n",
      "Epoch 104/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4363 - acc: 0.7800\n",
      "Epoch 00104: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.4018 - acc: 0.8289 - val_loss: 0.4273 - val_acc: 0.8271\n",
      "Epoch 105/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3512 - acc: 0.8700\n",
      "Epoch 00105: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.3910 - acc: 0.8372 - val_loss: 0.4131 - val_acc: 0.8271\n",
      "Epoch 106/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3844 - acc: 0.8400\n",
      "Epoch 00106: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 156us/sample - loss: 0.3947 - acc: 0.8372 - val_loss: 0.4103 - val_acc: 0.8237\n",
      "Epoch 107/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3382 - acc: 0.9000\n",
      "Epoch 00107: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3900 - acc: 0.8440 - val_loss: 0.4490 - val_acc: 0.7932\n",
      "Epoch 108/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3317 - acc: 0.8400\n",
      "Epoch 00108: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.4302 - acc: 0.8104 - val_loss: 0.4264 - val_acc: 0.8203\n",
      "Epoch 109/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4570 - acc: 0.8000\n",
      "Epoch 00109: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 156us/sample - loss: 0.3906 - acc: 0.8406 - val_loss: 0.4315 - val_acc: 0.8136\n",
      "Epoch 110/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3610 - acc: 0.8800\n",
      "Epoch 00110: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3920 - acc: 0.8406 - val_loss: 0.4164 - val_acc: 0.8102\n",
      "Epoch 111/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3699 - acc: 0.8100\n",
      "Epoch 00111: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.3974 - acc: 0.8305 - val_loss: 0.4134 - val_acc: 0.8169\n",
      "Epoch 112/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2607 - acc: 0.8800\n",
      "Epoch 00112: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3854 - acc: 0.8389 - val_loss: 0.4366 - val_acc: 0.8068\n",
      "Epoch 113/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3862 - acc: 0.8700\n",
      "Epoch 00113: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3937 - acc: 0.8372 - val_loss: 0.4272 - val_acc: 0.8305\n",
      "Epoch 114/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5088 - acc: 0.7900\n",
      "Epoch 00114: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 174us/sample - loss: 0.4078 - acc: 0.8188 - val_loss: 0.4180 - val_acc: 0.8203\n",
      "Epoch 115/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3754 - acc: 0.8400\n",
      "Epoch 00115: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.3849 - acc: 0.8272 - val_loss: 0.4161 - val_acc: 0.8271\n",
      "Epoch 116/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3525 - acc: 0.8500\n",
      "Epoch 00116: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.4254 - acc: 0.8205 - val_loss: 0.4204 - val_acc: 0.8136\n",
      "Epoch 117/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3679 - acc: 0.8200\n",
      "Epoch 00117: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3915 - acc: 0.8305 - val_loss: 0.4453 - val_acc: 0.7898\n",
      "Epoch 118/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3649 - acc: 0.8800\n",
      "Epoch 00118: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 159us/sample - loss: 0.3934 - acc: 0.8339 - val_loss: 0.4159 - val_acc: 0.8271\n",
      "Epoch 119/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3389 - acc: 0.8700\n",
      "Epoch 00119: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.3875 - acc: 0.8272 - val_loss: 0.4164 - val_acc: 0.8203\n",
      "Epoch 120/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3636 - acc: 0.8200\n",
      "Epoch 00120: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 125us/sample - loss: 0.3850 - acc: 0.8389 - val_loss: 0.4275 - val_acc: 0.8102\n",
      "Epoch 121/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4537 - acc: 0.8000\n",
      "Epoch 00121: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3915 - acc: 0.8339 - val_loss: 0.4156 - val_acc: 0.8068\n",
      "Epoch 122/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3205 - acc: 0.8700\n",
      "Epoch 00122: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.3953 - acc: 0.8372 - val_loss: 0.4304 - val_acc: 0.8034\n",
      "Epoch 123/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3983 - acc: 0.7800\n",
      "Epoch 00123: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3886 - acc: 0.8272 - val_loss: 0.4177 - val_acc: 0.8237\n",
      "Epoch 124/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4224 - acc: 0.8200\n",
      "Epoch 00124: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.4060 - acc: 0.8305 - val_loss: 0.4154 - val_acc: 0.8203\n",
      "Epoch 125/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3641 - acc: 0.8500\n",
      "Epoch 00125: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.3970 - acc: 0.8272 - val_loss: 0.4268 - val_acc: 0.8203\n",
      "Epoch 126/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3201 - acc: 0.9000\n",
      "Epoch 00126: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 160us/sample - loss: 0.3851 - acc: 0.8507 - val_loss: 0.4212 - val_acc: 0.8102\n",
      "Epoch 127/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4008 - acc: 0.8100\n",
      "Epoch 00127: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.3888 - acc: 0.8406 - val_loss: 0.4173 - val_acc: 0.8102\n",
      "Epoch 128/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3894 - acc: 0.8300\n",
      "Epoch 00128: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 186us/sample - loss: 0.3832 - acc: 0.8423 - val_loss: 0.4155 - val_acc: 0.8102\n",
      "Epoch 129/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3309 - acc: 0.8300\n",
      "Epoch 00129: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3876 - acc: 0.8272 - val_loss: 0.4198 - val_acc: 0.8203\n",
      "Epoch 130/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3643 - acc: 0.8500\n",
      "Epoch 00130: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3863 - acc: 0.8389 - val_loss: 0.4262 - val_acc: 0.8203\n",
      "Epoch 131/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4066 - acc: 0.8200\n",
      "Epoch 00131: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 162us/sample - loss: 0.3935 - acc: 0.8188 - val_loss: 0.4692 - val_acc: 0.7898\n",
      "Epoch 132/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4331 - acc: 0.8100\n",
      "Epoch 00132: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3993 - acc: 0.8339 - val_loss: 0.4160 - val_acc: 0.8068\n",
      "Epoch 133/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3223 - acc: 0.8800\n",
      "Epoch 00133: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 177us/sample - loss: 0.3816 - acc: 0.8423 - val_loss: 0.4626 - val_acc: 0.7898\n",
      "Epoch 134/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3863 - acc: 0.8500\n",
      "Epoch 00134: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.3885 - acc: 0.8490 - val_loss: 0.4424 - val_acc: 0.8136\n",
      "Epoch 135/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3616 - acc: 0.8500\n",
      "Epoch 00135: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 116us/sample - loss: 0.4045 - acc: 0.8238 - val_loss: 0.4125 - val_acc: 0.8305\n",
      "Epoch 136/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4109 - acc: 0.8000\n",
      "Epoch 00136: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 169us/sample - loss: 0.4021 - acc: 0.8356 - val_loss: 0.4215 - val_acc: 0.8136\n",
      "Epoch 137/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4214 - acc: 0.8200\n",
      "Epoch 00137: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 163us/sample - loss: 0.3817 - acc: 0.8440 - val_loss: 0.4303 - val_acc: 0.8102\n",
      "Epoch 138/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3624 - acc: 0.8700\n",
      "Epoch 00138: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.3846 - acc: 0.8507 - val_loss: 0.4168 - val_acc: 0.8169\n",
      "Epoch 139/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4648 - acc: 0.8100\n",
      "Epoch 00139: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3885 - acc: 0.8389 - val_loss: 0.4282 - val_acc: 0.8169\n",
      "Epoch 140/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4601 - acc: 0.8000\n",
      "Epoch 00140: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 203us/sample - loss: 0.4011 - acc: 0.8272 - val_loss: 0.4182 - val_acc: 0.8034\n",
      "Epoch 141/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3618 - acc: 0.8400\n",
      "Epoch 00141: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.3828 - acc: 0.8456 - val_loss: 0.4410 - val_acc: 0.8136\n",
      "Epoch 142/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4028 - acc: 0.8500\n",
      "Epoch 00142: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3905 - acc: 0.8339 - val_loss: 0.4544 - val_acc: 0.7797\n",
      "Epoch 143/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4382 - acc: 0.7900\n",
      "Epoch 00143: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 170us/sample - loss: 0.3825 - acc: 0.8255 - val_loss: 0.4236 - val_acc: 0.8203\n",
      "Epoch 144/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3314 - acc: 0.8600\n",
      "Epoch 00144: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3919 - acc: 0.8322 - val_loss: 0.4189 - val_acc: 0.8136\n",
      "Epoch 145/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4492 - acc: 0.8000\n",
      "Epoch 00145: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.3905 - acc: 0.8322 - val_loss: 0.4177 - val_acc: 0.7966\n",
      "Epoch 146/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3757 - acc: 0.8300\n",
      "Epoch 00146: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3847 - acc: 0.8456 - val_loss: 0.4204 - val_acc: 0.8136\n",
      "Epoch 147/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4204 - acc: 0.8000\n",
      "Epoch 00147: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3861 - acc: 0.8322 - val_loss: 0.4196 - val_acc: 0.8305\n",
      "Epoch 148/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4685 - acc: 0.7800\n",
      "Epoch 00148: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3966 - acc: 0.8456 - val_loss: 0.4212 - val_acc: 0.8102\n",
      "Epoch 149/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3966 - acc: 0.8300\n",
      "Epoch 00149: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.3973 - acc: 0.8238 - val_loss: 0.4167 - val_acc: 0.8102\n",
      "Epoch 150/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4322 - acc: 0.8300\n",
      "Epoch 00150: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.3899 - acc: 0.8372 - val_loss: 0.4205 - val_acc: 0.8237\n",
      "Epoch 151/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3349 - acc: 0.8800\n",
      "Epoch 00151: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 134us/sample - loss: 0.3866 - acc: 0.8406 - val_loss: 0.4381 - val_acc: 0.8034\n",
      "Epoch 152/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3012 - acc: 0.9000\n",
      "Epoch 00152: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.3995 - acc: 0.8356 - val_loss: 0.4382 - val_acc: 0.8068\n",
      "Epoch 153/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3812 - acc: 0.8200\n",
      "Epoch 00153: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.3877 - acc: 0.8238 - val_loss: 0.4327 - val_acc: 0.8068\n",
      "Epoch 154/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2988 - acc: 0.8900\n",
      "Epoch 00154: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.4041 - acc: 0.8104 - val_loss: 0.4273 - val_acc: 0.8136\n",
      "Epoch 155/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2940 - acc: 0.9000\n",
      "Epoch 00155: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.4273 - acc: 0.8289 - val_loss: 0.4203 - val_acc: 0.8102\n",
      "Epoch 156/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3478 - acc: 0.8500\n",
      "Epoch 00156: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 131us/sample - loss: 0.3787 - acc: 0.8523 - val_loss: 0.4383 - val_acc: 0.7966\n",
      "Epoch 157/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4268 - acc: 0.8300\n",
      "Epoch 00157: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.4092 - acc: 0.8272 - val_loss: 0.4254 - val_acc: 0.7898\n",
      "Epoch 158/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3451 - acc: 0.8800\n",
      "Epoch 00158: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 131us/sample - loss: 0.3918 - acc: 0.8289 - val_loss: 0.4425 - val_acc: 0.7966\n",
      "Epoch 159/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3404 - acc: 0.9100\n",
      "Epoch 00159: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3784 - acc: 0.8507 - val_loss: 0.4171 - val_acc: 0.8000\n",
      "Epoch 160/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3892 - acc: 0.8100\n",
      "Epoch 00160: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 164us/sample - loss: 0.3785 - acc: 0.8339 - val_loss: 0.4275 - val_acc: 0.8203\n",
      "Epoch 161/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3717 - acc: 0.8100\n",
      "Epoch 00161: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 179us/sample - loss: 0.3830 - acc: 0.8406 - val_loss: 0.4185 - val_acc: 0.8203\n",
      "Epoch 162/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3672 - acc: 0.8600\n",
      "Epoch 00162: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 123us/sample - loss: 0.3822 - acc: 0.8356 - val_loss: 0.4189 - val_acc: 0.8237\n",
      "Epoch 163/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4107 - acc: 0.8700\n",
      "Epoch 00163: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3832 - acc: 0.8456 - val_loss: 0.4343 - val_acc: 0.8068\n",
      "Epoch 164/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3501 - acc: 0.8400\n",
      "Epoch 00164: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 167us/sample - loss: 0.3994 - acc: 0.8171 - val_loss: 0.4205 - val_acc: 0.8305\n",
      "Epoch 165/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4432 - acc: 0.8300\n",
      "Epoch 00165: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3817 - acc: 0.8339 - val_loss: 0.4230 - val_acc: 0.8169\n",
      "Epoch 166/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3871 - acc: 0.8500\n",
      "Epoch 00166: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3808 - acc: 0.8372 - val_loss: 0.4184 - val_acc: 0.8102\n",
      "Epoch 167/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3554 - acc: 0.8500\n",
      "Epoch 00167: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3836 - acc: 0.8389 - val_loss: 0.4510 - val_acc: 0.7864\n",
      "Epoch 168/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3141 - acc: 0.8700\n",
      "Epoch 00168: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.4045 - acc: 0.8289 - val_loss: 0.4332 - val_acc: 0.8169\n",
      "Epoch 169/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4131 - acc: 0.8200\n",
      "Epoch 00169: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3786 - acc: 0.8372 - val_loss: 0.4228 - val_acc: 0.8136\n",
      "Epoch 170/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4806 - acc: 0.8000\n",
      "Epoch 00170: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.3823 - acc: 0.8322 - val_loss: 0.4442 - val_acc: 0.8102\n",
      "Epoch 171/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4190 - acc: 0.8100\n",
      "Epoch 00171: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.3968 - acc: 0.8322 - val_loss: 0.5524 - val_acc: 0.7593\n",
      "Epoch 172/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5526 - acc: 0.7900\n",
      "Epoch 00172: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.4289 - acc: 0.8221 - val_loss: 0.4400 - val_acc: 0.8034\n",
      "Epoch 173/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4134 - acc: 0.9000\n",
      "Epoch 00173: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 148us/sample - loss: 0.3807 - acc: 0.8574 - val_loss: 0.4258 - val_acc: 0.8068\n",
      "Epoch 174/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4479 - acc: 0.8300\n",
      "Epoch 00174: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 131us/sample - loss: 0.3919 - acc: 0.8406 - val_loss: 0.4867 - val_acc: 0.7763\n",
      "Epoch 175/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3798 - acc: 0.8500\n",
      "Epoch 00175: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 160us/sample - loss: 0.3881 - acc: 0.8272 - val_loss: 0.4217 - val_acc: 0.8203\n",
      "Epoch 176/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3829 - acc: 0.8500\n",
      "Epoch 00176: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.3835 - acc: 0.8389 - val_loss: 0.4742 - val_acc: 0.7797\n",
      "Epoch 177/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3986 - acc: 0.8200\n",
      "Epoch 00177: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 118us/sample - loss: 0.4088 - acc: 0.8272 - val_loss: 0.4261 - val_acc: 0.8305\n",
      "Epoch 178/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3930 - acc: 0.8400\n",
      "Epoch 00178: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 123us/sample - loss: 0.3817 - acc: 0.8507 - val_loss: 0.4249 - val_acc: 0.8102\n",
      "Epoch 179/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4133 - acc: 0.8000\n",
      "Epoch 00179: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.3756 - acc: 0.8440 - val_loss: 0.4206 - val_acc: 0.8203\n",
      "Epoch 180/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4469 - acc: 0.8200\n",
      "Epoch 00180: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3756 - acc: 0.8473 - val_loss: 0.4314 - val_acc: 0.8102\n",
      "Epoch 181/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4613 - acc: 0.8100\n",
      "Epoch 00181: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 177us/sample - loss: 0.3829 - acc: 0.8389 - val_loss: 0.4293 - val_acc: 0.8136\n",
      "Epoch 182/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3926 - acc: 0.8400\n",
      "Epoch 00182: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.3803 - acc: 0.8305 - val_loss: 0.4357 - val_acc: 0.8102\n",
      "Epoch 183/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4080 - acc: 0.8300\n",
      "Epoch 00183: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.4067 - acc: 0.8272 - val_loss: 0.4242 - val_acc: 0.8136\n",
      "Epoch 184/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3322 - acc: 0.8700\n",
      "Epoch 00184: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 134us/sample - loss: 0.3746 - acc: 0.8305 - val_loss: 0.4319 - val_acc: 0.8203\n",
      "Epoch 185/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3723 - acc: 0.8700\n",
      "Epoch 00185: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3751 - acc: 0.8490 - val_loss: 0.4505 - val_acc: 0.7898\n",
      "Epoch 186/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4339 - acc: 0.8300\n",
      "Epoch 00186: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 111us/sample - loss: 0.3799 - acc: 0.8305 - val_loss: 0.4206 - val_acc: 0.8203\n",
      "Epoch 187/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3552 - acc: 0.8200\n",
      "Epoch 00187: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3753 - acc: 0.8473 - val_loss: 0.4491 - val_acc: 0.8000\n",
      "Epoch 188/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3613 - acc: 0.8600\n",
      "Epoch 00188: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.3821 - acc: 0.8456 - val_loss: 0.4367 - val_acc: 0.8068\n",
      "Epoch 189/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4061 - acc: 0.8200\n",
      "Epoch 00189: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 127us/sample - loss: 0.3894 - acc: 0.8440 - val_loss: 0.4200 - val_acc: 0.8305\n",
      "Epoch 190/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3607 - acc: 0.8300\n",
      "Epoch 00190: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3734 - acc: 0.8389 - val_loss: 0.4479 - val_acc: 0.7864\n",
      "Epoch 191/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3453 - acc: 0.8700\n",
      "Epoch 00191: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3786 - acc: 0.8490 - val_loss: 0.4463 - val_acc: 0.7898\n",
      "Epoch 192/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4190 - acc: 0.8200\n",
      "Epoch 00192: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 155us/sample - loss: 0.3723 - acc: 0.8356 - val_loss: 0.4202 - val_acc: 0.8068\n",
      "Epoch 193/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3267 - acc: 0.8400\n",
      "Epoch 00193: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 160us/sample - loss: 0.3793 - acc: 0.8423 - val_loss: 0.4622 - val_acc: 0.7729\n",
      "Epoch 194/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3752 - acc: 0.8400\n",
      "Epoch 00194: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3776 - acc: 0.8356 - val_loss: 0.4210 - val_acc: 0.8237\n",
      "Epoch 195/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3540 - acc: 0.8600\n",
      "Epoch 00195: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3741 - acc: 0.8490 - val_loss: 0.4255 - val_acc: 0.8305\n",
      "Epoch 196/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3785 - acc: 0.8300\n",
      "Epoch 00196: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3729 - acc: 0.8389 - val_loss: 0.4267 - val_acc: 0.8339\n",
      "Epoch 197/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3039 - acc: 0.8500\n",
      "Epoch 00197: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.4173 - acc: 0.8020 - val_loss: 0.4248 - val_acc: 0.8102\n",
      "Epoch 198/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3569 - acc: 0.8500\n",
      "Epoch 00198: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3869 - acc: 0.8389 - val_loss: 0.4314 - val_acc: 0.8136\n",
      "Epoch 199/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3615 - acc: 0.8700\n",
      "Epoch 00199: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.3827 - acc: 0.8356 - val_loss: 0.4283 - val_acc: 0.8237\n",
      "Epoch 200/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3659 - acc: 0.8400\n",
      "Epoch 00200: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3761 - acc: 0.8423 - val_loss: 0.4236 - val_acc: 0.8271\n",
      "Epoch 201/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4199 - acc: 0.8000\n",
      "Epoch 00201: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 163us/sample - loss: 0.3786 - acc: 0.8490 - val_loss: 0.4293 - val_acc: 0.8169\n",
      "Epoch 202/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3330 - acc: 0.8900\n",
      "Epoch 00202: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 144us/sample - loss: 0.3734 - acc: 0.8406 - val_loss: 0.4310 - val_acc: 0.8102\n",
      "Epoch 203/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3591 - acc: 0.8400\n",
      "Epoch 00203: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.3843 - acc: 0.8356 - val_loss: 0.4314 - val_acc: 0.8203\n",
      "Epoch 204/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3440 - acc: 0.8500\n",
      "Epoch 00204: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 167us/sample - loss: 0.3862 - acc: 0.8305 - val_loss: 0.4263 - val_acc: 0.8034\n",
      "Epoch 205/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4677 - acc: 0.8000\n",
      "Epoch 00205: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3898 - acc: 0.8305 - val_loss: 0.4216 - val_acc: 0.8136\n",
      "Epoch 206/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4181 - acc: 0.8300\n",
      "Epoch 00206: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.3935 - acc: 0.8305 - val_loss: 0.4348 - val_acc: 0.8102\n",
      "Epoch 207/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3729 - acc: 0.8500\n",
      "Epoch 00207: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 118us/sample - loss: 0.3776 - acc: 0.8440 - val_loss: 0.4263 - val_acc: 0.8271\n",
      "Epoch 208/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4550 - acc: 0.8000\n",
      "Epoch 00208: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.3768 - acc: 0.8322 - val_loss: 0.4521 - val_acc: 0.7831\n",
      "Epoch 209/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3477 - acc: 0.8500\n",
      "Epoch 00209: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 124us/sample - loss: 0.3821 - acc: 0.8389 - val_loss: 0.4223 - val_acc: 0.8237\n",
      "Epoch 210/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3804 - acc: 0.8400\n",
      "Epoch 00210: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.3757 - acc: 0.8305 - val_loss: 0.4508 - val_acc: 0.7932\n",
      "Epoch 211/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3060 - acc: 0.9100\n",
      "Epoch 00211: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 174us/sample - loss: 0.3841 - acc: 0.8490 - val_loss: 0.4234 - val_acc: 0.8034\n",
      "Epoch 212/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3619 - acc: 0.8500\n",
      "Epoch 00212: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.3690 - acc: 0.8473 - val_loss: 0.4285 - val_acc: 0.8271\n",
      "Epoch 213/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3003 - acc: 0.9300\n",
      "Epoch 00213: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 148us/sample - loss: 0.3847 - acc: 0.8440 - val_loss: 0.4211 - val_acc: 0.8305\n",
      "Epoch 214/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2504 - acc: 0.9300\n",
      "Epoch 00214: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.4091 - acc: 0.8389 - val_loss: 0.4418 - val_acc: 0.7966\n",
      "Epoch 215/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4475 - acc: 0.7800\n",
      "Epoch 00215: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 149us/sample - loss: 0.3763 - acc: 0.8507 - val_loss: 0.4218 - val_acc: 0.8203\n",
      "Epoch 216/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3261 - acc: 0.9000\n",
      "Epoch 00216: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3833 - acc: 0.8339 - val_loss: 0.4265 - val_acc: 0.7966\n",
      "Epoch 217/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3639 - acc: 0.8800\n",
      "Epoch 00217: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 147us/sample - loss: 0.3806 - acc: 0.8322 - val_loss: 0.4239 - val_acc: 0.8068\n",
      "Epoch 218/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4046 - acc: 0.8200\n",
      "Epoch 00218: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.3739 - acc: 0.8456 - val_loss: 0.4213 - val_acc: 0.8068\n",
      "Epoch 219/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4342 - acc: 0.8000\n",
      "Epoch 00219: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3751 - acc: 0.8372 - val_loss: 0.4231 - val_acc: 0.8102\n",
      "Epoch 220/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2802 - acc: 0.8900\n",
      "Epoch 00220: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.3730 - acc: 0.8507 - val_loss: 0.4301 - val_acc: 0.8068\n",
      "Epoch 221/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2737 - acc: 0.9200\n",
      "Epoch 00221: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 164us/sample - loss: 0.4087 - acc: 0.8339 - val_loss: 0.4264 - val_acc: 0.7864\n",
      "Epoch 222/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3982 - acc: 0.8300\n",
      "Epoch 00222: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 181us/sample - loss: 0.3744 - acc: 0.8372 - val_loss: 0.4324 - val_acc: 0.8068\n",
      "Epoch 223/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3337 - acc: 0.8700\n",
      "Epoch 00223: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 245us/sample - loss: 0.3694 - acc: 0.8473 - val_loss: 0.4525 - val_acc: 0.8000\n",
      "Epoch 224/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3143 - acc: 0.8800\n",
      "Epoch 00224: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 166us/sample - loss: 0.3740 - acc: 0.8423 - val_loss: 0.4321 - val_acc: 0.7966\n",
      "Epoch 225/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4770 - acc: 0.8300\n",
      "Epoch 00225: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 149us/sample - loss: 0.3744 - acc: 0.8423 - val_loss: 0.4262 - val_acc: 0.8237\n",
      "Epoch 226/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3866 - acc: 0.8500\n",
      "Epoch 00226: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.4005 - acc: 0.8289 - val_loss: 0.4395 - val_acc: 0.8136\n",
      "Epoch 227/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4049 - acc: 0.8600\n",
      "Epoch 00227: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.3747 - acc: 0.8473 - val_loss: 0.4239 - val_acc: 0.8102\n",
      "Epoch 228/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4041 - acc: 0.8100\n",
      "Epoch 00228: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 158us/sample - loss: 0.3692 - acc: 0.8423 - val_loss: 0.4270 - val_acc: 0.8102\n",
      "Epoch 229/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3620 - acc: 0.8300\n",
      "Epoch 00229: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 115us/sample - loss: 0.3641 - acc: 0.8440 - val_loss: 0.4478 - val_acc: 0.7966\n",
      "Epoch 230/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2988 - acc: 0.8600\n",
      "Epoch 00230: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.3958 - acc: 0.8322 - val_loss: 0.4252 - val_acc: 0.8305\n",
      "Epoch 231/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3030 - acc: 0.8900\n",
      "Epoch 00231: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3810 - acc: 0.8356 - val_loss: 0.4344 - val_acc: 0.8102\n",
      "Epoch 232/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3111 - acc: 0.8600\n",
      "Epoch 00232: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 174us/sample - loss: 0.3707 - acc: 0.8440 - val_loss: 0.4251 - val_acc: 0.8102\n",
      "Epoch 233/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2844 - acc: 0.8900\n",
      "Epoch 00233: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3679 - acc: 0.8456 - val_loss: 0.4322 - val_acc: 0.8136\n",
      "Epoch 234/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2876 - acc: 0.8800\n",
      "Epoch 00234: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3684 - acc: 0.8406 - val_loss: 0.4264 - val_acc: 0.8237\n",
      "Epoch 235/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3641 - acc: 0.8200\n",
      "Epoch 00235: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 115us/sample - loss: 0.4017 - acc: 0.8188 - val_loss: 0.4273 - val_acc: 0.8136\n",
      "Epoch 236/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3557 - acc: 0.8900\n",
      "Epoch 00236: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.3843 - acc: 0.8423 - val_loss: 0.4212 - val_acc: 0.8102\n",
      "Epoch 237/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2848 - acc: 0.8700\n",
      "Epoch 00237: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3669 - acc: 0.8372 - val_loss: 0.4224 - val_acc: 0.8136\n",
      "Epoch 238/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3251 - acc: 0.8800\n",
      "Epoch 00238: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 115us/sample - loss: 0.3709 - acc: 0.8540 - val_loss: 0.4345 - val_acc: 0.8203\n",
      "Epoch 239/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3495 - acc: 0.8900\n",
      "Epoch 00239: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3642 - acc: 0.8591 - val_loss: 0.4188 - val_acc: 0.8271\n",
      "Epoch 240/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3844 - acc: 0.8700\n",
      "Epoch 00240: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 109us/sample - loss: 0.3752 - acc: 0.8490 - val_loss: 0.4248 - val_acc: 0.8203\n",
      "Epoch 241/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3497 - acc: 0.8500\n",
      "Epoch 00241: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 101us/sample - loss: 0.3650 - acc: 0.8456 - val_loss: 0.4275 - val_acc: 0.8102\n",
      "Epoch 242/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3372 - acc: 0.8500\n",
      "Epoch 00242: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 211us/sample - loss: 0.3865 - acc: 0.8272 - val_loss: 0.4167 - val_acc: 0.8271\n",
      "Epoch 243/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2864 - acc: 0.9100\n",
      "Epoch 00243: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3759 - acc: 0.8456 - val_loss: 0.4269 - val_acc: 0.8102\n",
      "Epoch 244/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4142 - acc: 0.7700\n",
      "Epoch 00244: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.3690 - acc: 0.8423 - val_loss: 0.4207 - val_acc: 0.8271\n",
      "Epoch 245/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4154 - acc: 0.8100\n",
      "Epoch 00245: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 176us/sample - loss: 0.3698 - acc: 0.8440 - val_loss: 0.4187 - val_acc: 0.8237\n",
      "Epoch 246/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3210 - acc: 0.8900\n",
      "Epoch 00246: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 201us/sample - loss: 0.4302 - acc: 0.8188 - val_loss: 0.4303 - val_acc: 0.8102\n",
      "Epoch 247/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4197 - acc: 0.8500\n",
      "Epoch 00247: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3896 - acc: 0.8372 - val_loss: 0.4342 - val_acc: 0.8034\n",
      "Epoch 248/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4562 - acc: 0.7900\n",
      "Epoch 00248: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 168us/sample - loss: 0.3657 - acc: 0.8641 - val_loss: 0.4212 - val_acc: 0.8203\n",
      "Epoch 249/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3218 - acc: 0.8600\n",
      "Epoch 00249: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 171us/sample - loss: 0.3800 - acc: 0.8523 - val_loss: 0.4155 - val_acc: 0.8373\n",
      "Epoch 250/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3262 - acc: 0.8300\n",
      "Epoch 00250: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3655 - acc: 0.8607 - val_loss: 0.4293 - val_acc: 0.8136\n",
      "Epoch 251/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3803 - acc: 0.8600\n",
      "Epoch 00251: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3653 - acc: 0.8490 - val_loss: 0.4201 - val_acc: 0.8136\n",
      "Epoch 252/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3605 - acc: 0.8700\n",
      "Epoch 00252: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 146us/sample - loss: 0.3635 - acc: 0.8607 - val_loss: 0.4235 - val_acc: 0.8102\n",
      "Epoch 253/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3369 - acc: 0.8400\n",
      "Epoch 00253: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 123us/sample - loss: 0.3640 - acc: 0.8540 - val_loss: 0.4246 - val_acc: 0.8271\n",
      "Epoch 254/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4061 - acc: 0.8300\n",
      "Epoch 00254: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 148us/sample - loss: 0.3665 - acc: 0.8490 - val_loss: 0.4213 - val_acc: 0.8271\n",
      "Epoch 255/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3928 - acc: 0.8300\n",
      "Epoch 00255: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 169us/sample - loss: 0.3677 - acc: 0.8389 - val_loss: 0.4229 - val_acc: 0.8102\n",
      "Epoch 256/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3688 - acc: 0.8400\n",
      "Epoch 00256: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 129us/sample - loss: 0.3726 - acc: 0.8473 - val_loss: 0.4216 - val_acc: 0.8339\n",
      "Epoch 257/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3554 - acc: 0.8500\n",
      "Epoch 00257: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3659 - acc: 0.8574 - val_loss: 0.4342 - val_acc: 0.7966\n",
      "Epoch 258/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2845 - acc: 0.9000\n",
      "Epoch 00258: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 194us/sample - loss: 0.3620 - acc: 0.8574 - val_loss: 0.4455 - val_acc: 0.8034\n",
      "Epoch 259/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4027 - acc: 0.8200\n",
      "Epoch 00259: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 193us/sample - loss: 0.3668 - acc: 0.8523 - val_loss: 0.5040 - val_acc: 0.7559\n",
      "Epoch 260/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3946 - acc: 0.8200\n",
      "Epoch 00260: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3831 - acc: 0.8255 - val_loss: 0.4335 - val_acc: 0.8169\n",
      "Epoch 261/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4233 - acc: 0.8300\n",
      "Epoch 00261: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3700 - acc: 0.8523 - val_loss: 0.4183 - val_acc: 0.8203\n",
      "Epoch 262/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3632 - acc: 0.8700\n",
      "Epoch 00262: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.3616 - acc: 0.8523 - val_loss: 0.4279 - val_acc: 0.8000\n",
      "Epoch 263/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3213 - acc: 0.8900\n",
      "Epoch 00263: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 125us/sample - loss: 0.3762 - acc: 0.8372 - val_loss: 0.4373 - val_acc: 0.8102\n",
      "Epoch 264/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3811 - acc: 0.8500\n",
      "Epoch 00264: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3621 - acc: 0.8473 - val_loss: 0.4245 - val_acc: 0.8237\n",
      "Epoch 265/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2885 - acc: 0.8700\n",
      "Epoch 00265: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 99us/sample - loss: 0.3654 - acc: 0.8389 - val_loss: 0.4811 - val_acc: 0.7797\n",
      "Epoch 266/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3977 - acc: 0.8600\n",
      "Epoch 00266: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.4252 - acc: 0.8238 - val_loss: 0.4200 - val_acc: 0.8203\n",
      "Epoch 267/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4060 - acc: 0.8100\n",
      "Epoch 00267: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3641 - acc: 0.8507 - val_loss: 0.4263 - val_acc: 0.8102\n",
      "Epoch 268/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3829 - acc: 0.8600\n",
      "Epoch 00268: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 105us/sample - loss: 0.3774 - acc: 0.8389 - val_loss: 0.4314 - val_acc: 0.8136\n",
      "Epoch 269/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3352 - acc: 0.8600\n",
      "Epoch 00269: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3632 - acc: 0.8507 - val_loss: 0.4334 - val_acc: 0.8102\n",
      "Epoch 270/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3095 - acc: 0.8600\n",
      "Epoch 00270: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 166us/sample - loss: 0.3686 - acc: 0.8490 - val_loss: 0.4350 - val_acc: 0.8136\n",
      "Epoch 271/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4328 - acc: 0.8100\n",
      "Epoch 00271: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3793 - acc: 0.8406 - val_loss: 0.4347 - val_acc: 0.8000\n",
      "Epoch 272/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3417 - acc: 0.8700\n",
      "Epoch 00272: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3584 - acc: 0.8574 - val_loss: 0.4259 - val_acc: 0.8271\n",
      "Epoch 273/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2579 - acc: 0.8800\n",
      "Epoch 00273: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 147us/sample - loss: 0.3872 - acc: 0.8272 - val_loss: 0.4222 - val_acc: 0.8339\n",
      "Epoch 274/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3519 - acc: 0.8500\n",
      "Epoch 00274: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3632 - acc: 0.8557 - val_loss: 0.4320 - val_acc: 0.7898\n",
      "Epoch 275/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2508 - acc: 0.9100\n",
      "Epoch 00275: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3663 - acc: 0.8473 - val_loss: 0.4428 - val_acc: 0.8102\n",
      "Epoch 276/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4538 - acc: 0.7800\n",
      "Epoch 00276: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 168us/sample - loss: 0.3895 - acc: 0.8356 - val_loss: 0.4282 - val_acc: 0.8136\n",
      "Epoch 277/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3894 - acc: 0.8300\n",
      "Epoch 00277: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3660 - acc: 0.8523 - val_loss: 0.4308 - val_acc: 0.8102\n",
      "Epoch 278/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4068 - acc: 0.8400\n",
      "Epoch 00278: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.3838 - acc: 0.8423 - val_loss: 0.4676 - val_acc: 0.8136\n",
      "Epoch 279/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5288 - acc: 0.7800\n",
      "Epoch 00279: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.3949 - acc: 0.8423 - val_loss: 0.4286 - val_acc: 0.8169\n",
      "Epoch 280/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4008 - acc: 0.8400\n",
      "Epoch 00280: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 227us/sample - loss: 0.3598 - acc: 0.8507 - val_loss: 0.4309 - val_acc: 0.8102\n",
      "Epoch 281/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3511 - acc: 0.8900\n",
      "Epoch 00281: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 248us/sample - loss: 0.3586 - acc: 0.8574 - val_loss: 0.4225 - val_acc: 0.8203\n",
      "Epoch 282/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4346 - acc: 0.8000\n",
      "Epoch 00282: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 182us/sample - loss: 0.3625 - acc: 0.8607 - val_loss: 0.4295 - val_acc: 0.8034\n",
      "Epoch 283/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3396 - acc: 0.8500\n",
      "Epoch 00283: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 160us/sample - loss: 0.3725 - acc: 0.8574 - val_loss: 0.4481 - val_acc: 0.8000\n",
      "Epoch 284/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2809 - acc: 0.8800\n",
      "Epoch 00284: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.3786 - acc: 0.8389 - val_loss: 0.4239 - val_acc: 0.8169\n",
      "Epoch 285/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3002 - acc: 0.8800\n",
      "Epoch 00285: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3833 - acc: 0.8406 - val_loss: 0.4200 - val_acc: 0.8237\n",
      "Epoch 286/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4067 - acc: 0.8300\n",
      "Epoch 00286: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 180us/sample - loss: 0.3645 - acc: 0.8440 - val_loss: 0.4269 - val_acc: 0.8237\n",
      "Epoch 287/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3286 - acc: 0.8500\n",
      "Epoch 00287: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 111us/sample - loss: 0.3588 - acc: 0.8540 - val_loss: 0.4308 - val_acc: 0.7966\n",
      "Epoch 288/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3687 - acc: 0.8300\n",
      "Epoch 00288: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.3632 - acc: 0.8540 - val_loss: 0.4312 - val_acc: 0.8136\n",
      "Epoch 289/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3154 - acc: 0.8700\n",
      "Epoch 00289: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3689 - acc: 0.8523 - val_loss: 0.4628 - val_acc: 0.7831\n",
      "Epoch 290/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3404 - acc: 0.8900\n",
      "Epoch 00290: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3666 - acc: 0.8490 - val_loss: 0.4294 - val_acc: 0.8034\n",
      "Epoch 291/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3075 - acc: 0.9000\n",
      "Epoch 00291: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 150us/sample - loss: 0.3566 - acc: 0.8691 - val_loss: 0.4275 - val_acc: 0.8169\n",
      "Epoch 292/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3350 - acc: 0.8800\n",
      "Epoch 00292: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3635 - acc: 0.8591 - val_loss: 0.4468 - val_acc: 0.8034\n",
      "Epoch 293/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3719 - acc: 0.8200\n",
      "Epoch 00293: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 128us/sample - loss: 0.3710 - acc: 0.8490 - val_loss: 0.4289 - val_acc: 0.8203\n",
      "Epoch 294/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2977 - acc: 0.8900\n",
      "Epoch 00294: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3570 - acc: 0.8540 - val_loss: 0.4425 - val_acc: 0.8034\n",
      "Epoch 295/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3910 - acc: 0.8700\n",
      "Epoch 00295: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3759 - acc: 0.8473 - val_loss: 0.4279 - val_acc: 0.8136\n",
      "Epoch 296/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2662 - acc: 0.9000\n",
      "Epoch 00296: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 116us/sample - loss: 0.3685 - acc: 0.8423 - val_loss: 0.4460 - val_acc: 0.7966\n",
      "Epoch 297/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4044 - acc: 0.8000\n",
      "Epoch 00297: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3844 - acc: 0.8272 - val_loss: 0.4389 - val_acc: 0.8034\n",
      "Epoch 298/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2755 - acc: 0.8900\n",
      "Epoch 00298: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 156us/sample - loss: 0.3664 - acc: 0.8389 - val_loss: 0.4410 - val_acc: 0.7932\n",
      "Epoch 299/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3753 - acc: 0.8800\n",
      "Epoch 00299: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3626 - acc: 0.8624 - val_loss: 0.4507 - val_acc: 0.8068\n",
      "Epoch 300/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4811 - acc: 0.8000\n",
      "Epoch 00300: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3645 - acc: 0.8624 - val_loss: 0.4364 - val_acc: 0.7966\n",
      "Epoch 301/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3257 - acc: 0.8500\n",
      "Epoch 00301: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 173us/sample - loss: 0.3572 - acc: 0.8557 - val_loss: 0.4433 - val_acc: 0.8068\n",
      "Epoch 302/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3047 - acc: 0.8900\n",
      "Epoch 00302: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 186us/sample - loss: 0.3625 - acc: 0.8557 - val_loss: 0.4338 - val_acc: 0.8203\n",
      "Epoch 303/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3026 - acc: 0.9100\n",
      "Epoch 00303: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 126us/sample - loss: 0.3607 - acc: 0.8607 - val_loss: 0.4240 - val_acc: 0.8169\n",
      "Epoch 304/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3755 - acc: 0.8600\n",
      "Epoch 00304: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3613 - acc: 0.8507 - val_loss: 0.4764 - val_acc: 0.7831\n",
      "Epoch 305/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3846 - acc: 0.8300\n",
      "Epoch 00305: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 165us/sample - loss: 0.3696 - acc: 0.8557 - val_loss: 0.4337 - val_acc: 0.8068\n",
      "Epoch 306/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3529 - acc: 0.8500\n",
      "Epoch 00306: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 121us/sample - loss: 0.3631 - acc: 0.8574 - val_loss: 0.4824 - val_acc: 0.7763\n",
      "Epoch 307/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4029 - acc: 0.8200\n",
      "Epoch 00307: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 93us/sample - loss: 0.3570 - acc: 0.8591 - val_loss: 0.4436 - val_acc: 0.8034\n",
      "Epoch 308/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3470 - acc: 0.8400\n",
      "Epoch 00308: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 170us/sample - loss: 0.3615 - acc: 0.8540 - val_loss: 0.4366 - val_acc: 0.8102\n",
      "Epoch 309/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2940 - acc: 0.9000\n",
      "Epoch 00309: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 129us/sample - loss: 0.3572 - acc: 0.8507 - val_loss: 0.4307 - val_acc: 0.7966\n",
      "Epoch 310/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3663 - acc: 0.8200\n",
      "Epoch 00310: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3642 - acc: 0.8440 - val_loss: 0.4537 - val_acc: 0.7898\n",
      "Epoch 311/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3774 - acc: 0.8300\n",
      "Epoch 00311: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 110us/sample - loss: 0.3697 - acc: 0.8322 - val_loss: 0.4404 - val_acc: 0.7932\n",
      "Epoch 312/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3061 - acc: 0.8800\n",
      "Epoch 00312: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 120us/sample - loss: 0.3637 - acc: 0.8490 - val_loss: 0.4328 - val_acc: 0.8068\n",
      "Epoch 313/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4076 - acc: 0.8300\n",
      "Epoch 00313: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 192us/sample - loss: 0.3866 - acc: 0.8356 - val_loss: 0.4402 - val_acc: 0.7898\n",
      "Epoch 314/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3481 - acc: 0.8400\n",
      "Epoch 00314: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 113us/sample - loss: 0.3617 - acc: 0.8507 - val_loss: 0.4826 - val_acc: 0.8000\n",
      "Epoch 315/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4500 - acc: 0.8000\n",
      "Epoch 00315: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 149us/sample - loss: 0.4085 - acc: 0.8339 - val_loss: 0.4347 - val_acc: 0.7932\n",
      "Epoch 316/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2881 - acc: 0.8800\n",
      "Epoch 00316: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 98us/sample - loss: 0.3630 - acc: 0.8507 - val_loss: 0.4319 - val_acc: 0.8102\n",
      "Epoch 317/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2808 - acc: 0.8700\n",
      "Epoch 00317: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 168us/sample - loss: 0.3656 - acc: 0.8473 - val_loss: 0.4343 - val_acc: 0.8000\n",
      "Epoch 318/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3910 - acc: 0.8800\n",
      "Epoch 00318: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 194us/sample - loss: 0.3599 - acc: 0.8674 - val_loss: 0.4262 - val_acc: 0.8136\n",
      "Epoch 319/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3111 - acc: 0.8900\n",
      "Epoch 00319: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 183us/sample - loss: 0.3533 - acc: 0.8591 - val_loss: 0.4371 - val_acc: 0.8068\n",
      "Epoch 320/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3867 - acc: 0.8700\n",
      "Epoch 00320: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3682 - acc: 0.8523 - val_loss: 0.4487 - val_acc: 0.7932\n",
      "Epoch 321/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5070 - acc: 0.7900\n",
      "Epoch 00321: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 136us/sample - loss: 0.3773 - acc: 0.8372 - val_loss: 0.4320 - val_acc: 0.8136\n",
      "Epoch 322/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3023 - acc: 0.9100\n",
      "Epoch 00322: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3657 - acc: 0.8540 - val_loss: 0.4515 - val_acc: 0.8068\n",
      "Epoch 323/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3816 - acc: 0.8400\n",
      "Epoch 00323: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 103us/sample - loss: 0.3692 - acc: 0.8406 - val_loss: 0.4774 - val_acc: 0.7898\n",
      "Epoch 324/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2642 - acc: 0.9100\n",
      "Epoch 00324: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 167us/sample - loss: 0.3703 - acc: 0.8591 - val_loss: 0.4351 - val_acc: 0.8237\n",
      "Epoch 325/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3758 - acc: 0.8300\n",
      "Epoch 00325: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 115us/sample - loss: 0.3579 - acc: 0.8591 - val_loss: 0.4687 - val_acc: 0.8102\n",
      "Epoch 326/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3919 - acc: 0.8200\n",
      "Epoch 00326: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 138us/sample - loss: 0.3745 - acc: 0.8372 - val_loss: 0.4304 - val_acc: 0.8102\n",
      "Epoch 327/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3635 - acc: 0.8300\n",
      "Epoch 00327: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 125us/sample - loss: 0.3636 - acc: 0.8507 - val_loss: 0.4446 - val_acc: 0.8102\n",
      "Epoch 328/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3670 - acc: 0.8600\n",
      "Epoch 00328: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 135us/sample - loss: 0.3552 - acc: 0.8658 - val_loss: 0.4491 - val_acc: 0.7797\n",
      "Epoch 329/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3580 - acc: 0.8700\n",
      "Epoch 00329: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 116us/sample - loss: 0.3959 - acc: 0.8305 - val_loss: 0.4288 - val_acc: 0.8237\n",
      "Epoch 330/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3695 - acc: 0.8500\n",
      "Epoch 00330: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 184us/sample - loss: 0.3650 - acc: 0.8523 - val_loss: 0.4485 - val_acc: 0.8068\n",
      "Epoch 331/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3351 - acc: 0.8500\n",
      "Epoch 00331: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3613 - acc: 0.8557 - val_loss: 0.4493 - val_acc: 0.8000\n",
      "Epoch 332/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4528 - acc: 0.8200\n",
      "Epoch 00332: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 108us/sample - loss: 0.3701 - acc: 0.8507 - val_loss: 0.4424 - val_acc: 0.7932\n",
      "Epoch 333/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3910 - acc: 0.8200\n",
      "Epoch 00333: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.3499 - acc: 0.8624 - val_loss: 0.4353 - val_acc: 0.8136\n",
      "Epoch 334/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2432 - acc: 0.9000\n",
      "Epoch 00334: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3566 - acc: 0.8557 - val_loss: 0.4476 - val_acc: 0.7932\n",
      "Epoch 335/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3267 - acc: 0.8700\n",
      "Epoch 00335: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 153us/sample - loss: 0.3466 - acc: 0.8742 - val_loss: 0.4612 - val_acc: 0.8068\n",
      "Epoch 336/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3261 - acc: 0.8700\n",
      "Epoch 00336: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 153us/sample - loss: 0.3632 - acc: 0.8473 - val_loss: 0.4656 - val_acc: 0.8034\n",
      "Epoch 337/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3852 - acc: 0.8300\n",
      "Epoch 00337: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 164us/sample - loss: 0.3718 - acc: 0.8490 - val_loss: 0.4437 - val_acc: 0.7966\n",
      "Epoch 338/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3108 - acc: 0.8900\n",
      "Epoch 00338: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 148us/sample - loss: 0.3553 - acc: 0.8574 - val_loss: 0.4412 - val_acc: 0.7932\n",
      "Epoch 339/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3829 - acc: 0.8600\n",
      "Epoch 00339: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 198us/sample - loss: 0.3615 - acc: 0.8574 - val_loss: 0.4304 - val_acc: 0.8136\n",
      "Epoch 340/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3252 - acc: 0.8700\n",
      "Epoch 00340: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 141us/sample - loss: 0.3604 - acc: 0.8557 - val_loss: 0.4378 - val_acc: 0.8203\n",
      "Epoch 341/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3295 - acc: 0.8900\n",
      "Epoch 00341: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 198us/sample - loss: 0.3788 - acc: 0.8406 - val_loss: 0.4638 - val_acc: 0.8068\n",
      "Epoch 342/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4214 - acc: 0.8500\n",
      "Epoch 00342: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 157us/sample - loss: 0.3869 - acc: 0.8507 - val_loss: 0.4334 - val_acc: 0.8102\n",
      "Epoch 343/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3250 - acc: 0.8900\n",
      "Epoch 00343: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 157us/sample - loss: 0.3882 - acc: 0.8255 - val_loss: 0.4313 - val_acc: 0.8169\n",
      "Epoch 344/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2536 - acc: 0.9200\n",
      "Epoch 00344: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 164us/sample - loss: 0.3564 - acc: 0.8641 - val_loss: 0.4343 - val_acc: 0.8136\n",
      "Epoch 345/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3239 - acc: 0.8700\n",
      "Epoch 00345: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 181us/sample - loss: 0.3509 - acc: 0.8674 - val_loss: 0.4339 - val_acc: 0.8169\n",
      "Epoch 346/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3518 - acc: 0.8200\n",
      "Epoch 00346: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 108us/sample - loss: 0.3502 - acc: 0.8641 - val_loss: 0.4476 - val_acc: 0.8169\n",
      "Epoch 347/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3680 - acc: 0.8300\n",
      "Epoch 00347: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 145us/sample - loss: 0.3880 - acc: 0.8205 - val_loss: 0.4537 - val_acc: 0.7966\n",
      "Epoch 348/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3701 - acc: 0.8300\n",
      "Epoch 00348: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 98us/sample - loss: 0.3896 - acc: 0.8322 - val_loss: 0.4377 - val_acc: 0.8203\n",
      "Epoch 349/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3727 - acc: 0.8300\n",
      "Epoch 00349: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 116us/sample - loss: 0.3477 - acc: 0.8641 - val_loss: 0.4419 - val_acc: 0.8136\n",
      "Epoch 350/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2836 - acc: 0.9000\n",
      "Epoch 00350: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3658 - acc: 0.8523 - val_loss: 0.4550 - val_acc: 0.8136\n",
      "Epoch 351/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4106 - acc: 0.8100\n",
      "Epoch 00351: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 206us/sample - loss: 0.3521 - acc: 0.8557 - val_loss: 0.4336 - val_acc: 0.8203\n",
      "Epoch 352/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4039 - acc: 0.8400\n",
      "Epoch 00352: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 177us/sample - loss: 0.3528 - acc: 0.8574 - val_loss: 0.4459 - val_acc: 0.8000\n",
      "Epoch 353/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4370 - acc: 0.8200\n",
      "Epoch 00353: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 104us/sample - loss: 0.3517 - acc: 0.8540 - val_loss: 0.4723 - val_acc: 0.7831\n",
      "Epoch 354/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3399 - acc: 0.8400\n",
      "Epoch 00354: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 130us/sample - loss: 0.4062 - acc: 0.8154 - val_loss: 0.4336 - val_acc: 0.8034\n",
      "Epoch 355/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3978 - acc: 0.8700\n",
      "Epoch 00355: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 101us/sample - loss: 0.3612 - acc: 0.8607 - val_loss: 0.4397 - val_acc: 0.8068\n",
      "Epoch 356/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3417 - acc: 0.8900\n",
      "Epoch 00356: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 139us/sample - loss: 0.4118 - acc: 0.8305 - val_loss: 0.4300 - val_acc: 0.8136\n",
      "Epoch 357/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2878 - acc: 0.8800\n",
      "Epoch 00357: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 117us/sample - loss: 0.3488 - acc: 0.8607 - val_loss: 0.4314 - val_acc: 0.8136\n",
      "Epoch 358/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3605 - acc: 0.8700\n",
      "Epoch 00358: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 111us/sample - loss: 0.3585 - acc: 0.8641 - val_loss: 0.4308 - val_acc: 0.8034\n",
      "Epoch 359/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3978 - acc: 0.8500\n",
      "Epoch 00359: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 206us/sample - loss: 0.3498 - acc: 0.8607 - val_loss: 0.4421 - val_acc: 0.8034\n",
      "Epoch 360/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2745 - acc: 0.9100\n",
      "Epoch 00360: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3845 - acc: 0.8490 - val_loss: 0.4516 - val_acc: 0.7898\n",
      "Epoch 361/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4029 - acc: 0.8300\n",
      "Epoch 00361: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 114us/sample - loss: 0.3728 - acc: 0.8490 - val_loss: 0.4354 - val_acc: 0.8102\n",
      "Epoch 362/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3972 - acc: 0.8800\n",
      "Epoch 00362: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3559 - acc: 0.8624 - val_loss: 0.4334 - val_acc: 0.8068\n",
      "Epoch 363/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3379 - acc: 0.8800\n",
      "Epoch 00363: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.3493 - acc: 0.8742 - val_loss: 0.4623 - val_acc: 0.8034\n",
      "Epoch 364/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4355 - acc: 0.8000\n",
      "Epoch 00364: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 181us/sample - loss: 0.3542 - acc: 0.8624 - val_loss: 0.4568 - val_acc: 0.7898\n",
      "Epoch 365/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2710 - acc: 0.9000\n",
      "Epoch 00365: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 157us/sample - loss: 0.3646 - acc: 0.8423 - val_loss: 0.4346 - val_acc: 0.8237\n",
      "Epoch 366/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3833 - acc: 0.8700\n",
      "Epoch 00366: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3556 - acc: 0.8574 - val_loss: 0.4389 - val_acc: 0.8068\n",
      "Epoch 367/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3332 - acc: 0.8800\n",
      "Epoch 00367: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 118us/sample - loss: 0.3558 - acc: 0.8674 - val_loss: 0.4629 - val_acc: 0.7898\n",
      "Epoch 368/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3937 - acc: 0.8400\n",
      "Epoch 00368: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 119us/sample - loss: 0.3566 - acc: 0.8523 - val_loss: 0.4546 - val_acc: 0.8102\n",
      "Epoch 369/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3244 - acc: 0.8700\n",
      "Epoch 00369: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 156us/sample - loss: 0.3851 - acc: 0.8339 - val_loss: 0.4306 - val_acc: 0.8169\n",
      "Epoch 370/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3812 - acc: 0.8200\n",
      "Epoch 00370: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3446 - acc: 0.8658 - val_loss: 0.4387 - val_acc: 0.8136\n",
      "Epoch 371/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3397 - acc: 0.8600\n",
      "Epoch 00371: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 123us/sample - loss: 0.3690 - acc: 0.8423 - val_loss: 0.4799 - val_acc: 0.7898\n",
      "Epoch 372/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3225 - acc: 0.9000\n",
      "Epoch 00372: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3517 - acc: 0.8557 - val_loss: 0.4366 - val_acc: 0.8068\n",
      "Epoch 373/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3273 - acc: 0.8800\n",
      "Epoch 00373: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 109us/sample - loss: 0.3492 - acc: 0.8691 - val_loss: 0.4384 - val_acc: 0.8000\n",
      "Epoch 374/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2987 - acc: 0.8900\n",
      "Epoch 00374: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 154us/sample - loss: 0.3455 - acc: 0.8607 - val_loss: 0.4950 - val_acc: 0.7864\n",
      "Epoch 375/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3345 - acc: 0.8400\n",
      "Epoch 00375: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 122us/sample - loss: 0.3563 - acc: 0.8523 - val_loss: 0.4564 - val_acc: 0.7932\n",
      "Epoch 376/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2922 - acc: 0.8800\n",
      "Epoch 00376: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 127us/sample - loss: 0.3625 - acc: 0.8574 - val_loss: 0.4410 - val_acc: 0.8169\n",
      "Epoch 377/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3038 - acc: 0.9000\n",
      "Epoch 00377: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 127us/sample - loss: 0.3485 - acc: 0.8674 - val_loss: 0.4383 - val_acc: 0.8169\n",
      "Epoch 378/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3655 - acc: 0.8600\n",
      "Epoch 00378: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 122us/sample - loss: 0.3488 - acc: 0.8658 - val_loss: 0.4496 - val_acc: 0.8136\n",
      "Epoch 379/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3018 - acc: 0.8600\n",
      "Epoch 00379: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 131us/sample - loss: 0.3451 - acc: 0.8540 - val_loss: 0.4419 - val_acc: 0.8136\n",
      "Epoch 380/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3776 - acc: 0.8500\n",
      "Epoch 00380: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 106us/sample - loss: 0.3548 - acc: 0.8523 - val_loss: 0.4411 - val_acc: 0.8102\n",
      "Epoch 381/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3460 - acc: 0.8600\n",
      "Epoch 00381: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 142us/sample - loss: 0.3587 - acc: 0.8624 - val_loss: 0.4511 - val_acc: 0.8034\n",
      "Epoch 382/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3222 - acc: 0.8400\n",
      "Epoch 00382: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 121us/sample - loss: 0.4060 - acc: 0.8305 - val_loss: 0.4420 - val_acc: 0.7932\n",
      "Epoch 383/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3428 - acc: 0.8300\n",
      "Epoch 00383: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 143us/sample - loss: 0.3944 - acc: 0.8289 - val_loss: 0.4569 - val_acc: 0.7898\n",
      "Epoch 384/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3751 - acc: 0.8200\n",
      "Epoch 00384: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 93us/sample - loss: 0.3575 - acc: 0.8523 - val_loss: 0.4451 - val_acc: 0.8136\n",
      "Epoch 385/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3558 - acc: 0.8500\n",
      "Epoch 00385: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 96us/sample - loss: 0.3481 - acc: 0.8557 - val_loss: 0.4370 - val_acc: 0.8136\n",
      "Epoch 386/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2398 - acc: 0.9300\n",
      "Epoch 00386: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 140us/sample - loss: 0.3529 - acc: 0.8792 - val_loss: 0.4389 - val_acc: 0.8034\n",
      "Epoch 387/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3508 - acc: 0.8500\n",
      "Epoch 00387: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 157us/sample - loss: 0.3485 - acc: 0.8591 - val_loss: 0.4511 - val_acc: 0.8000\n",
      "Epoch 388/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3382 - acc: 0.8800\n",
      "Epoch 00388: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 124us/sample - loss: 0.3597 - acc: 0.8456 - val_loss: 0.4529 - val_acc: 0.7898\n",
      "Epoch 389/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3746 - acc: 0.8600\n",
      "Epoch 00389: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 173us/sample - loss: 0.3574 - acc: 0.8607 - val_loss: 0.4443 - val_acc: 0.7932\n",
      "Epoch 390/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3787 - acc: 0.8400\n",
      "Epoch 00390: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3505 - acc: 0.8574 - val_loss: 0.4572 - val_acc: 0.8000\n",
      "Epoch 391/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2647 - acc: 0.9200\n",
      "Epoch 00391: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 152us/sample - loss: 0.3521 - acc: 0.8725 - val_loss: 0.4487 - val_acc: 0.8136\n",
      "Epoch 392/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2911 - acc: 0.9100\n",
      "Epoch 00392: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 137us/sample - loss: 0.3510 - acc: 0.8641 - val_loss: 0.4501 - val_acc: 0.8169\n",
      "Epoch 393/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3965 - acc: 0.8300\n",
      "Epoch 00393: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 147us/sample - loss: 0.3735 - acc: 0.8372 - val_loss: 0.4560 - val_acc: 0.8136\n",
      "Epoch 394/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3141 - acc: 0.8600\n",
      "Epoch 00394: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 111us/sample - loss: 0.3485 - acc: 0.8591 - val_loss: 0.4533 - val_acc: 0.8136\n",
      "Epoch 395/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4160 - acc: 0.8300\n",
      "Epoch 00395: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 133us/sample - loss: 0.3510 - acc: 0.8540 - val_loss: 0.4518 - val_acc: 0.7966\n",
      "Epoch 396/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.2169 - acc: 0.9400\n",
      "Epoch 00396: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 151us/sample - loss: 0.3437 - acc: 0.8641 - val_loss: 0.4417 - val_acc: 0.8102\n",
      "Epoch 397/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3870 - acc: 0.8600\n",
      "Epoch 00397: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 132us/sample - loss: 0.3956 - acc: 0.8389 - val_loss: 0.6107 - val_acc: 0.7966\n",
      "Epoch 398/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.5594 - acc: 0.8200\n",
      "Epoch 00398: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 98us/sample - loss: 0.4037 - acc: 0.8372 - val_loss: 0.4463 - val_acc: 0.8102\n",
      "Epoch 399/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.3189 - acc: 0.8800\n",
      "Epoch 00399: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 129us/sample - loss: 0.3494 - acc: 0.8624 - val_loss: 0.4487 - val_acc: 0.8136\n",
      "Epoch 400/400\n",
      "100/596 [====>.........................] - ETA: 0s - loss: 0.4445 - acc: 0.8400\n",
      "Epoch 00400: saving model to ./keras_model_class.ckpt\n",
      "596/596 [==============================] - 0s 110us/sample - loss: 0.3411 - acc: 0.8691 - val_loss: 0.4876 - val_acc: 0.7898\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "saver_callback = tf.keras.callbacks.ModelCheckpoint(\"./keras_model_class.ckpt\", \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(20, activation='relu', input_shape=(9,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = tf.train.GradientDescentOptimizer(0.1),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Execution\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    accuracy = model.fit(X_train, y_train, \n",
    "              epochs=400, \n",
    "              batch_size=100, \n",
    "              callbacks = [saver_callback],\n",
    "              validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.85, \n",
      "Recall: 0.576271186440678, \n",
      "Conf Mat: [[165  12]\n",
      " [ 50  68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    model.load_weights(\"./keras_model_class.ckpt\")\n",
    "    y_predict = model.predict(X_test)\n",
    "    \n",
    "    con_mx = confusion_matrix(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    precision = precision_score(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    recall = recall_score(y_test.reshape(1,-1)[0], np.argmax(y_predict, axis=1))\n",
    "    print(\"Precision: {}, \\nRecall: {}, \\nConf Mat: {}\". format(precision, recall, con_mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Cost Estimator\n",
    "\n",
    "Building off the classifier examples above, this section shows ensemble regressors using bagging and random forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data Set\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "boston_housing_data = datasets.load_boston()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "bouston_housing_data_instances = scaler.fit_transform(boston_housing_data.data)\n",
    "bouston_housing_data_instances.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0-Train: 180.46746826171875 Test:381.29278564453125\n",
      "1-Train: 19.795461654663086 Test:89.10183715820312\n",
      "2-Train: 36.182029724121094 Test:51.98948287963867\n",
      "3-Train: 43.61358642578125 Test:41.324745178222656\n",
      "4-Train: 40.9240837097168 Test:35.44710159301758\n",
      "5-Train: 36.229923248291016 Test:31.698347091674805\n",
      "6-Train: 33.054847717285156 Test:29.738649368286133\n",
      "7-Train: 29.91683578491211 Test:28.78458023071289\n",
      "8-Train: 29.410011291503906 Test:28.517553329467773\n",
      "9-Train: 28.944133758544922 Test:27.967615127563477\n",
      "10-Train: 28.62889862060547 Test:27.84853172302246\n",
      "11-Train: 27.477588653564453 Test:26.65339469909668\n",
      "12-Train: 27.347824096679688 Test:26.886777877807617\n",
      "13-Train: 26.630828857421875 Test:26.898841857910156\n",
      "14-Train: 26.088605880737305 Test:27.149477005004883\n",
      "15-Train: 25.62571144104004 Test:27.24494171142578\n",
      "16-Train: 25.195283889770508 Test:27.311918258666992\n",
      "17-Train: 24.3526611328125 Test:27.260770797729492\n",
      "18-Train: 23.937515258789062 Test:27.276498794555664\n",
      "19-Train: 23.417404174804688 Test:27.20175552368164\n",
      "20-Train: 23.276582717895508 Test:27.038360595703125\n",
      "21-Train: 23.16933822631836 Test:26.75007438659668\n",
      "22-Train: 22.82672119140625 Test:26.65128517150879\n",
      "23-Train: 22.187950134277344 Test:26.439050674438477\n",
      "24-Train: 21.386119842529297 Test:26.5059814453125\n",
      "25-Train: 20.838247299194336 Test:26.44220733642578\n",
      "26-Train: 20.310672760009766 Test:26.456567764282227\n",
      "27-Train: 19.89205551147461 Test:26.2589054107666\n",
      "28-Train: 19.38811683654785 Test:25.985794067382812\n",
      "29-Train: 18.92022705078125 Test:25.714086532592773\n",
      "30-Train: 18.430110931396484 Test:25.574941635131836\n",
      "31-Train: 17.873022079467773 Test:25.295915603637695\n",
      "32-Train: 17.26778221130371 Test:25.04679298400879\n",
      "33-Train: 16.72022247314453 Test:25.02791976928711\n",
      "34-Train: 16.39238739013672 Test:24.882734298706055\n",
      "35-Train: 16.10243797302246 Test:24.693689346313477\n",
      "36-Train: 15.56881332397461 Test:24.690616607666016\n",
      "37-Train: 15.27981948852539 Test:24.733030319213867\n",
      "38-Train: 15.276274681091309 Test:24.48801040649414\n",
      "39-Train: 14.870307922363281 Test:24.383930206298828\n",
      "40-Train: 14.488166809082031 Test:24.8912410736084\n",
      "41-Train: 14.048540115356445 Test:24.928115844726562\n",
      "42-Train: 13.608755111694336 Test:24.98000717163086\n",
      "43-Train: 13.21048355102539 Test:24.906944274902344\n",
      "44-Train: 12.490256309509277 Test:25.2131290435791\n",
      "45-Train: 12.017796516418457 Test:25.061382293701172\n",
      "46-Train: 12.063879013061523 Test:24.62900161743164\n",
      "47-Train: 11.62972354888916 Test:24.53776741027832\n",
      "48-Train: 11.134208679199219 Test:24.454973220825195\n",
      "49-Train: 10.799417495727539 Test:24.37912368774414\n",
      "50-Train: 10.43896484375 Test:24.335296630859375\n",
      "51-Train: 10.113102912902832 Test:24.30229949951172\n",
      "52-Train: 9.817652702331543 Test:24.246522903442383\n",
      "53-Train: 9.529369354248047 Test:24.244409561157227\n",
      "54-Train: 9.1122465133667 Test:23.70981216430664\n",
      "55-Train: 8.340614318847656 Test:24.385799407958984\n",
      "56-Train: 8.304158210754395 Test:23.8857479095459\n",
      "57-Train: 7.8734846115112305 Test:23.675281524658203\n",
      "58-Train: 7.568706512451172 Test:23.31435775756836\n",
      "59-Train: 7.157441139221191 Test:23.176538467407227\n",
      "60-Train: 6.760124683380127 Test:22.866439819335938\n",
      "61-Train: 6.559303283691406 Test:23.2999210357666\n",
      "62-Train: 6.330754280090332 Test:23.22293472290039\n",
      "63-Train: 6.032664775848389 Test:23.112319946289062\n",
      "64-Train: 6.219386100769043 Test:22.87708282470703\n",
      "65-Train: 5.959402561187744 Test:22.813596725463867\n",
      "66-Train: 5.705935478210449 Test:22.669435501098633\n",
      "67-Train: 5.505012512207031 Test:22.688663482666016\n",
      "68-Train: 5.303535461425781 Test:22.606388092041016\n",
      "69-Train: 5.408992767333984 Test:21.828168869018555\n",
      "70-Train: 5.282907962799072 Test:21.8592529296875\n",
      "71-Train: 5.08999490737915 Test:21.78247833251953\n",
      "72-Train: 4.843592643737793 Test:21.69099998474121\n",
      "73-Train: 4.649014472961426 Test:21.669458389282227\n",
      "74-Train: 4.3374505043029785 Test:21.740209579467773\n",
      "75-Train: 4.1138410568237305 Test:21.65221405029297\n",
      "76-Train: 3.9131836891174316 Test:21.596385955810547\n",
      "77-Train: 3.6761622428894043 Test:21.543542861938477\n",
      "78-Train: 3.510911464691162 Test:21.557401657104492\n",
      "79-Train: 3.3505735397338867 Test:21.459508895874023\n",
      "80-Train: 3.112807035446167 Test:21.42182159423828\n",
      "81-Train: 3.0375757217407227 Test:21.42078399658203\n",
      "82-Train: 2.9160256385803223 Test:21.304672241210938\n",
      "83-Train: 2.790499687194824 Test:21.272714614868164\n",
      "84-Train: 2.6481432914733887 Test:21.33298110961914\n",
      "85-Train: 2.4908595085144043 Test:21.431137084960938\n",
      "86-Train: 2.491694450378418 Test:21.297250747680664\n",
      "87-Train: 2.4126176834106445 Test:21.215932846069336\n",
      "88-Train: 2.318394899368286 Test:21.350738525390625\n",
      "89-Train: 2.296092987060547 Test:21.24668312072754\n",
      "90-Train: 2.2315480709075928 Test:21.157989501953125\n",
      "91-Train: 2.136838436126709 Test:21.218364715576172\n",
      "92-Train: 2.1505253314971924 Test:21.118175506591797\n",
      "93-Train: 2.0603737831115723 Test:21.15888214111328\n",
      "94-Train: 2.0533266067504883 Test:20.98265838623047\n",
      "95-Train: 2.016066789627075 Test:20.9090633392334\n",
      "96-Train: 1.9437886476516724 Test:20.94635581970215\n",
      "97-Train: 1.9094843864440918 Test:20.88982391357422\n",
      "98-Train: 1.8538788557052612 Test:20.92519760131836\n",
      "99-Train: 1.8672511577606201 Test:20.752628326416016\n",
      "100-Train: 1.8295280933380127 Test:20.730140686035156\n",
      "101-Train: 1.7494083642959595 Test:20.760251998901367\n",
      "102-Train: 1.6858175992965698 Test:20.755918502807617\n",
      "103-Train: 1.6727473735809326 Test:20.764535903930664\n",
      "104-Train: 1.660330057144165 Test:20.730531692504883\n",
      "105-Train: 1.6978318691253662 Test:20.676563262939453\n",
      "106-Train: 1.661038875579834 Test:20.57305145263672\n",
      "107-Train: 1.5653741359710693 Test:20.560762405395508\n",
      "108-Train: 1.6190468072891235 Test:20.5865535736084\n",
      "109-Train: 1.6312005519866943 Test:20.506458282470703\n",
      "110-Train: 1.512052297592163 Test:20.453588485717773\n",
      "111-Train: 1.566746711730957 Test:20.518529891967773\n",
      "112-Train: 1.5670232772827148 Test:20.312280654907227\n",
      "113-Train: 1.5154709815979004 Test:20.404266357421875\n",
      "114-Train: 1.5821118354797363 Test:20.212677001953125\n",
      "115-Train: 1.6018013954162598 Test:20.116716384887695\n",
      "116-Train: 1.5310084819793701 Test:20.340856552124023\n",
      "117-Train: 1.5368106365203857 Test:20.308979034423828\n",
      "118-Train: 1.6248105764389038 Test:20.262508392333984\n",
      "119-Train: 1.6372199058532715 Test:20.291778564453125\n",
      "120-Train: 1.6385732889175415 Test:20.269224166870117\n",
      "121-Train: 1.5533649921417236 Test:20.44487190246582\n",
      "122-Train: 1.5333826541900635 Test:20.431180953979492\n",
      "123-Train: 1.5094876289367676 Test:20.39603614807129\n",
      "124-Train: 1.4790153503417969 Test:20.331466674804688\n",
      "125-Train: 1.4552743434906006 Test:20.283111572265625\n",
      "126-Train: 1.4196282625198364 Test:20.243274688720703\n",
      "127-Train: 1.416386604309082 Test:20.115930557250977\n",
      "128-Train: 1.3694462776184082 Test:20.05190086364746\n",
      "129-Train: 1.3696993589401245 Test:19.975112915039062\n",
      "130-Train: 1.310962438583374 Test:19.90129852294922\n",
      "131-Train: 1.3304506540298462 Test:19.897050857543945\n",
      "132-Train: 1.2665560245513916 Test:19.760787963867188\n",
      "133-Train: 1.2714524269104004 Test:19.761316299438477\n",
      "134-Train: 1.3011375665664673 Test:19.62698745727539\n",
      "135-Train: 1.215561032295227 Test:19.592453002929688\n",
      "136-Train: 1.2663403749465942 Test:19.55533218383789\n",
      "137-Train: 1.2354435920715332 Test:19.5042724609375\n",
      "138-Train: 1.2581672668457031 Test:19.391128540039062\n",
      "139-Train: 1.2581709623336792 Test:19.360231399536133\n",
      "140-Train: 1.2518514394760132 Test:19.153526306152344\n",
      "141-Train: 1.2875064611434937 Test:19.145919799804688\n",
      "142-Train: 1.2647018432617188 Test:19.094552993774414\n",
      "143-Train: 1.2617337703704834 Test:19.044681549072266\n",
      "144-Train: 1.2591222524642944 Test:18.97300148010254\n",
      "145-Train: 1.2493817806243896 Test:18.923795700073242\n",
      "146-Train: 1.2470420598983765 Test:18.85430145263672\n",
      "147-Train: 1.2300350666046143 Test:18.821199417114258\n",
      "148-Train: 1.2715212106704712 Test:18.753799438476562\n",
      "149-Train: 1.2522718906402588 Test:18.692211151123047\n",
      "150-Train: 1.2347817420959473 Test:18.712799072265625\n",
      "151-Train: 1.2879054546356201 Test:18.635414123535156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152-Train: 1.3062238693237305 Test:18.572673797607422\n",
      "153-Train: 1.3004568815231323 Test:18.55205535888672\n",
      "154-Train: 1.303747534751892 Test:18.506303787231445\n",
      "155-Train: 1.3613874912261963 Test:18.502227783203125\n",
      "156-Train: 1.3384037017822266 Test:18.355146408081055\n",
      "157-Train: 1.3421123027801514 Test:18.351213455200195\n",
      "158-Train: 1.3952418565750122 Test:18.32588768005371\n",
      "159-Train: 1.3832318782806396 Test:18.26491355895996\n",
      "160-Train: 1.4068256616592407 Test:18.25588035583496\n",
      "161-Train: 1.3912745714187622 Test:18.202878952026367\n",
      "162-Train: 1.387420892715454 Test:18.22077751159668\n",
      "163-Train: 1.4046244621276855 Test:18.146223068237305\n",
      "164-Train: 1.4452699422836304 Test:18.065431594848633\n",
      "165-Train: 1.4196114540100098 Test:18.051183700561523\n",
      "166-Train: 1.4668424129486084 Test:17.97926902770996\n",
      "167-Train: 1.4019179344177246 Test:17.981801986694336\n",
      "168-Train: 1.4599571228027344 Test:17.921825408935547\n",
      "169-Train: 1.463340401649475 Test:17.878101348876953\n",
      "170-Train: 1.4615634679794312 Test:17.7827205657959\n",
      "171-Train: 1.4438495635986328 Test:17.783849716186523\n",
      "172-Train: 1.4849756956100464 Test:17.778196334838867\n",
      "173-Train: 1.453364372253418 Test:17.759864807128906\n",
      "174-Train: 1.500725269317627 Test:17.748865127563477\n",
      "175-Train: 1.5095824003219604 Test:17.662309646606445\n",
      "176-Train: 1.4534754753112793 Test:17.666261672973633\n",
      "177-Train: 1.523522973060608 Test:17.66045570373535\n",
      "178-Train: 1.4721202850341797 Test:17.68290138244629\n",
      "179-Train: 1.4504741430282593 Test:17.611265182495117\n",
      "180-Train: 1.4268451929092407 Test:17.596708297729492\n",
      "181-Train: 1.468070149421692 Test:17.63639259338379\n",
      "182-Train: 1.522112250328064 Test:17.572608947753906\n",
      "183-Train: 1.5370051860809326 Test:17.469045639038086\n",
      "184-Train: 1.486145257949829 Test:17.52760124206543\n",
      "185-Train: 1.4531147480010986 Test:17.531274795532227\n",
      "186-Train: 1.4882895946502686 Test:17.516210556030273\n",
      "187-Train: 1.4661974906921387 Test:17.35794448852539\n",
      "188-Train: 1.3072055578231812 Test:17.371423721313477\n",
      "189-Train: 1.3524765968322754 Test:17.37065887451172\n",
      "190-Train: 1.3822813034057617 Test:17.386194229125977\n",
      "191-Train: 1.3660805225372314 Test:17.245206832885742\n",
      "192-Train: 1.3739949464797974 Test:17.322341918945312\n",
      "193-Train: 1.4095536470413208 Test:17.343400955200195\n",
      "194-Train: 1.388169288635254 Test:17.36598777770996\n",
      "195-Train: 1.3658868074417114 Test:17.184005737304688\n",
      "196-Train: 1.4561247825622559 Test:17.254886627197266\n",
      "197-Train: 1.3802834749221802 Test:17.13457489013672\n",
      "198-Train: 1.4460725784301758 Test:17.22292709350586\n",
      "199-Train: 1.4154560565948486 Test:17.25240135192871\n",
      "200-Train: 1.4242600202560425 Test:17.065889358520508\n",
      "201-Train: 1.4384723901748657 Test:17.167110443115234\n",
      "202-Train: 1.3942067623138428 Test:17.055465698242188\n",
      "203-Train: 1.4556126594543457 Test:17.144697189331055\n",
      "204-Train: 1.4926209449768066 Test:16.932558059692383\n",
      "205-Train: 1.4527002573013306 Test:17.05704116821289\n",
      "206-Train: 1.4244840145111084 Test:16.996265411376953\n",
      "207-Train: 1.4723803997039795 Test:16.94190788269043\n",
      "208-Train: 1.44886314868927 Test:17.04568862915039\n",
      "209-Train: 1.4992281198501587 Test:16.862335205078125\n",
      "210-Train: 1.394195556640625 Test:16.872814178466797\n",
      "211-Train: 1.4446380138397217 Test:16.86301040649414\n",
      "212-Train: 1.5247994661331177 Test:16.82913589477539\n",
      "213-Train: 1.4072216749191284 Test:16.835838317871094\n",
      "214-Train: 1.4899479150772095 Test:16.84526252746582\n",
      "215-Train: 1.4631091356277466 Test:16.96080780029297\n",
      "216-Train: 1.5118825435638428 Test:16.778167724609375\n",
      "217-Train: 1.401392936706543 Test:16.7882022857666\n",
      "218-Train: 1.511940836906433 Test:16.763246536254883\n",
      "219-Train: 1.4053748846054077 Test:16.771026611328125\n",
      "220-Train: 1.5161261558532715 Test:16.74831199645996\n",
      "221-Train: 1.4668676853179932 Test:16.677026748657227\n",
      "222-Train: 1.5248117446899414 Test:16.65461540222168\n",
      "223-Train: 1.4478795528411865 Test:16.67264175415039\n",
      "224-Train: 1.4129897356033325 Test:16.689550399780273\n",
      "225-Train: 1.5150312185287476 Test:16.64456558227539\n",
      "226-Train: 1.5156363248825073 Test:16.593706130981445\n",
      "227-Train: 1.4586243629455566 Test:16.62921714782715\n",
      "228-Train: 1.4438724517822266 Test:16.608461380004883\n",
      "229-Train: 1.4374735355377197 Test:16.62215232849121\n",
      "230-Train: 1.4505014419555664 Test:16.59950828552246\n",
      "231-Train: 1.4257919788360596 Test:16.60322380065918\n",
      "232-Train: 1.4798486232757568 Test:16.534391403198242\n",
      "233-Train: 1.4367256164550781 Test:16.661849975585938\n",
      "234-Train: 1.486100673675537 Test:16.53940200805664\n",
      "235-Train: 1.4268860816955566 Test:16.631242752075195\n",
      "236-Train: 1.437675952911377 Test:16.538345336914062\n",
      "237-Train: 1.4668610095977783 Test:16.521142959594727\n",
      "238-Train: 1.4528900384902954 Test:16.53291893005371\n",
      "239-Train: 1.4230661392211914 Test:16.622774124145508\n",
      "240-Train: 1.4480934143066406 Test:16.510087966918945\n",
      "241-Train: 1.478786587715149 Test:16.492517471313477\n",
      "242-Train: 1.4160164594650269 Test:16.56726837158203\n",
      "243-Train: 1.3975368738174438 Test:16.546585083007812\n",
      "244-Train: 1.4159139394760132 Test:16.528289794921875\n",
      "245-Train: 1.4304250478744507 Test:16.6187686920166\n",
      "246-Train: 1.4491997957229614 Test:16.538190841674805\n",
      "247-Train: 1.3827435970306396 Test:16.535076141357422\n",
      "248-Train: 1.3775997161865234 Test:16.56017303466797\n",
      "249-Train: 1.3635520935058594 Test:16.561769485473633\n",
      "250-Train: 1.3651202917099 Test:16.585342407226562\n",
      "251-Train: 1.3934533596038818 Test:16.602128982543945\n",
      "252-Train: 1.4182124137878418 Test:16.541873931884766\n",
      "253-Train: 1.3808568716049194 Test:16.525039672851562\n",
      "254-Train: 1.3368655443191528 Test:16.534467697143555\n",
      "255-Train: 1.3296821117401123 Test:16.537094116210938\n",
      "256-Train: 1.3653956651687622 Test:16.51786231994629\n",
      "257-Train: 1.327541470527649 Test:16.529722213745117\n",
      "258-Train: 1.3100121021270752 Test:16.51790428161621\n",
      "259-Train: 1.3656058311462402 Test:16.561450958251953\n",
      "260-Train: 1.3545516729354858 Test:16.555458068847656\n",
      "261-Train: 1.354020118713379 Test:16.55583381652832\n",
      "262-Train: 1.346061110496521 Test:16.538406372070312\n",
      "263-Train: 1.5075277090072632 Test:16.583629608154297\n",
      "264-Train: 1.3643018007278442 Test:16.537525177001953\n",
      "265-Train: 1.3568997383117676 Test:16.54419708251953\n",
      "266-Train: 1.34244966506958 Test:16.568180084228516\n",
      "267-Train: 1.350401520729065 Test:16.55257797241211\n",
      "268-Train: 1.3491681814193726 Test:16.55339241027832\n",
      "269-Train: 1.3348759412765503 Test:16.535730361938477\n",
      "270-Train: 1.325007677078247 Test:16.527620315551758\n",
      "271-Train: 1.3992443084716797 Test:16.54916763305664\n",
      "272-Train: 1.3448468446731567 Test:16.535886764526367\n",
      "273-Train: 1.359482765197754 Test:16.502033233642578\n",
      "274-Train: 1.3359508514404297 Test:16.52123260498047\n",
      "275-Train: 1.317748785018921 Test:16.5609073638916\n",
      "276-Train: 1.3351802825927734 Test:16.540733337402344\n",
      "277-Train: 1.322545051574707 Test:16.531522750854492\n",
      "278-Train: 1.3402596712112427 Test:16.520891189575195\n",
      "279-Train: 1.33401620388031 Test:16.521442413330078\n",
      "280-Train: 1.3208562135696411 Test:16.516572952270508\n",
      "281-Train: 1.332489252090454 Test:16.511049270629883\n",
      "282-Train: 1.3039276599884033 Test:16.546600341796875\n",
      "283-Train: 1.3106870651245117 Test:16.535287857055664\n",
      "284-Train: 1.3124167919158936 Test:16.529590606689453\n",
      "285-Train: 1.310405969619751 Test:16.528213500976562\n",
      "286-Train: 1.381439208984375 Test:16.49228286743164\n",
      "287-Train: 1.3325568437576294 Test:16.49546241760254\n",
      "288-Train: 1.320241928100586 Test:16.536685943603516\n",
      "289-Train: 1.4865965843200684 Test:16.532121658325195\n",
      "290-Train: 1.3559186458587646 Test:16.52187728881836\n",
      "291-Train: 1.327564001083374 Test:16.521814346313477\n",
      "292-Train: 1.371234655380249 Test:16.51789093017578\n",
      "293-Train: 1.3055111169815063 Test:16.553932189941406\n",
      "294-Train: 1.5006792545318604 Test:16.542051315307617\n",
      "295-Train: 1.328317403793335 Test:16.534208297729492\n",
      "296-Train: 1.3288239240646362 Test:16.536706924438477\n",
      "297-Train: 1.4979965686798096 Test:16.5297908782959\n",
      "298-Train: 1.3216360807418823 Test:16.525999069213867\n",
      "299-Train: 1.323920488357544 Test:16.5280704498291\n",
      "300-Train: 1.3229674100875854 Test:16.533945083618164\n",
      "301-Train: 1.506934404373169 Test:16.527360916137695\n",
      "302-Train: 1.2830067873001099 Test:16.514602661132812\n",
      "303-Train: 1.4973326921463013 Test:16.54233741760254\n",
      "304-Train: 1.3247268199920654 Test:16.54244041442871\n",
      "305-Train: 1.3249644041061401 Test:16.537456512451172\n",
      "306-Train: 1.322801113128662 Test:16.535783767700195\n",
      "307-Train: 1.3291186094284058 Test:16.529563903808594\n",
      "308-Train: 1.3503021001815796 Test:16.53489112854004\n",
      "309-Train: 1.3420462608337402 Test:16.52912139892578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310-Train: 1.3435509204864502 Test:16.530088424682617\n",
      "311-Train: 1.5204696655273438 Test:16.51389503479004\n",
      "312-Train: 1.2946455478668213 Test:16.520626068115234\n",
      "313-Train: 1.526056170463562 Test:16.559907913208008\n",
      "314-Train: 1.3416448831558228 Test:16.545738220214844\n",
      "315-Train: 1.3512108325958252 Test:16.568775177001953\n",
      "316-Train: 1.3545030355453491 Test:16.564041137695312\n",
      "317-Train: 1.3506404161453247 Test:16.567607879638672\n",
      "318-Train: 1.349765658378601 Test:16.560775756835938\n",
      "319-Train: 1.3719980716705322 Test:16.55293083190918\n",
      "320-Train: 1.383283019065857 Test:16.54125213623047\n",
      "321-Train: 1.4283865690231323 Test:16.52013397216797\n",
      "322-Train: 1.5625708103179932 Test:16.554651260375977\n",
      "323-Train: 1.3859975337982178 Test:16.545867919921875\n",
      "324-Train: 1.389974594116211 Test:16.556289672851562\n",
      "325-Train: 1.3769655227661133 Test:16.575355529785156\n",
      "326-Train: 1.3902792930603027 Test:16.55312728881836\n",
      "327-Train: 1.385424017906189 Test:16.557907104492188\n",
      "328-Train: 1.4009052515029907 Test:16.55799102783203\n",
      "329-Train: 1.3991847038269043 Test:16.55748748779297\n",
      "330-Train: 1.2005982398986816 Test:16.57180404663086\n",
      "331-Train: 1.616788387298584 Test:16.552005767822266\n",
      "332-Train: 1.2054624557495117 Test:16.578365325927734\n",
      "333-Train: 1.613038182258606 Test:16.546842575073242\n",
      "334-Train: 1.1873027086257935 Test:16.604379653930664\n",
      "335-Train: 1.2315956354141235 Test:16.56380844116211\n",
      "336-Train: 1.2521028518676758 Test:16.544391632080078\n",
      "337-Train: 1.5489240884780884 Test:16.542926788330078\n",
      "338-Train: 1.6333191394805908 Test:16.586654663085938\n",
      "339-Train: 1.209290623664856 Test:16.583871841430664\n",
      "340-Train: 1.6430702209472656 Test:16.551685333251953\n",
      "341-Train: 1.222241997718811 Test:16.604639053344727\n",
      "342-Train: 1.2467281818389893 Test:16.59318733215332\n",
      "343-Train: 1.5554389953613281 Test:16.553760528564453\n",
      "344-Train: 1.632107138633728 Test:16.565608978271484\n",
      "345-Train: 1.232177972793579 Test:16.576257705688477\n",
      "346-Train: 1.2395298480987549 Test:16.558183670043945\n",
      "347-Train: 1.562024712562561 Test:16.550273895263672\n",
      "348-Train: 1.2373549938201904 Test:16.614974975585938\n",
      "349-Train: 1.566976547241211 Test:16.556087493896484\n",
      "350-Train: 1.6483986377716064 Test:16.55510711669922\n",
      "351-Train: 1.3514314889907837 Test:16.546730041503906\n",
      "352-Train: 1.5699306726455688 Test:16.512046813964844\n",
      "353-Train: 1.2019685506820679 Test:16.56313133239746\n",
      "354-Train: 1.5386210680007935 Test:16.550830841064453\n",
      "355-Train: 1.2061491012573242 Test:16.573823928833008\n",
      "356-Train: 1.5579043626785278 Test:16.54520034790039\n",
      "357-Train: 1.2017927169799805 Test:16.573881149291992\n",
      "358-Train: 1.5397741794586182 Test:16.543018341064453\n",
      "359-Train: 1.5102535486221313 Test:16.555049896240234\n",
      "360-Train: 1.1992157697677612 Test:16.610366821289062\n",
      "361-Train: 1.537111520767212 Test:16.55695152282715\n",
      "362-Train: 1.517767071723938 Test:16.543622970581055\n",
      "363-Train: 1.4910613298416138 Test:16.55722999572754\n",
      "364-Train: 1.2110261917114258 Test:16.559825897216797\n",
      "365-Train: 1.5060917139053345 Test:16.547801971435547\n",
      "366-Train: 1.4785157442092896 Test:16.557388305664062\n",
      "367-Train: 1.2198479175567627 Test:16.59198570251465\n",
      "368-Train: 1.4844492673873901 Test:16.554489135742188\n",
      "369-Train: 1.4726078510284424 Test:16.553733825683594\n",
      "370-Train: 1.1369693279266357 Test:16.575027465820312\n",
      "371-Train: 1.4764840602874756 Test:16.528182983398438\n",
      "372-Train: 1.1566187143325806 Test:16.585960388183594\n",
      "373-Train: 1.566709041595459 Test:16.52129364013672\n",
      "374-Train: 1.2701319456100464 Test:16.551795959472656\n",
      "375-Train: 1.4735995531082153 Test:16.530517578125\n",
      "376-Train: 1.1445975303649902 Test:16.577241897583008\n",
      "377-Train: 1.481633186340332 Test:16.529085159301758\n",
      "378-Train: 1.4606270790100098 Test:16.545494079589844\n",
      "379-Train: 1.1363716125488281 Test:16.57794189453125\n",
      "380-Train: 1.4857579469680786 Test:16.5372371673584\n",
      "381-Train: 1.47898268699646 Test:16.5384464263916\n",
      "382-Train: 1.1299999952316284 Test:16.578954696655273\n",
      "383-Train: 1.5498874187469482 Test:16.51392364501953\n",
      "384-Train: 1.4774789810180664 Test:16.528261184692383\n",
      "385-Train: 1.244174599647522 Test:16.546300888061523\n",
      "386-Train: 1.5884873867034912 Test:16.76051902770996\n",
      "387-Train: 1.4244486093521118 Test:16.53400230407715\n",
      "388-Train: 1.0907527208328247 Test:16.583345413208008\n",
      "389-Train: 1.1567976474761963 Test:16.572086334228516\n",
      "390-Train: 1.4570211172103882 Test:16.498706817626953\n",
      "391-Train: 1.5299445390701294 Test:16.53217315673828\n",
      "392-Train: 1.4363439083099365 Test:16.564748764038086\n",
      "393-Train: 1.0965793132781982 Test:16.573270797729492\n",
      "394-Train: 1.5247315168380737 Test:16.528230667114258\n",
      "395-Train: 1.107298731803894 Test:16.552703857421875\n",
      "396-Train: 1.226662039756775 Test:16.51066017150879\n",
      "397-Train: 1.5667856931686401 Test:16.493627548217773\n",
      "398-Train: 1.1655540466308594 Test:16.51595115661621\n",
      "399-Train: 1.5391263961791992 Test:16.478174209594727\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(bouston_housing_data_instances,\n",
    "                                                   boston_housing_data.target,\n",
    "                                                   test_size=0.20)\n",
    "\n",
    "def get_batch(X, iter, size):\n",
    "    return X[(iter*batch_size) : ((iter+1)*batch_size)]\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "num_features = train_X.shape[1]\n",
    "num_instances = train_y.shape[0]\n",
    "\n",
    "# Construction\n",
    "X = tf.placeholder(tf.float32, shape=(None, num_features), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"Boston-MLP\"):\n",
    "    hidden1 = tf.layers.dense(X, 5, name=\"Hidden-1\", activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, 5, name=\"Hidden-2\", activation = tf.nn.relu)\n",
    "    output = tf.transpose(tf.layers.dense(hidden2, 1, name=\"Price\"))\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.square(y-output))\n",
    "    \n",
    "with tf.name_scope(\"train\"): \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 400\n",
    "batch_size = 10\n",
    "\n",
    "# Execution\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        for iteration in range(num_instances // batch_size + 1):\n",
    "            X_batch = get_batch(train_X, iteration, batch_size)\n",
    "            y_batch = get_batch(train_y, iteration, batch_size)   \n",
    " \n",
    "            sess.run(training_op, feed_dict={X: X_batch,\n",
    "                                            y: y_batch})\n",
    "            \n",
    "\n",
    "        mse_train = loss.eval(feed_dict={X: X_batch,\n",
    "                                            y: y_batch})\n",
    "        mse_val = loss.eval(feed_dict={X:test_X, y: test_y})\n",
    "        \n",
    "        print(\"{}-Train: {} Test:{}\".format(epoch,\n",
    "                                           mse_train,\n",
    "                                           mse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, you will see that the model converges early. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 339 samples, validate on 167 samples\n",
      "Epoch 1/4000\n",
      "339/339 [==============================] - 1s 2ms/sample - loss: 555.1749 - mean_squared_error: 555.1749 - val_loss: 592.7541 - val_mean_squared_error: 592.7541\n",
      "Epoch 2/4000\n",
      "339/339 [==============================] - 0s 69us/sample - loss: 529.4108 - mean_squared_error: 529.4108 - val_loss: 558.4852 - val_mean_squared_error: 558.4852\n",
      "Epoch 3/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 494.4642 - mean_squared_error: 494.4642 - val_loss: 509.8567 - val_mean_squared_error: 509.8567\n",
      "Epoch 4/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 444.4292 - mean_squared_error: 444.4292 - val_loss: 438.8393 - val_mean_squared_error: 438.8393\n",
      "Epoch 5/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 372.4542 - mean_squared_error: 372.4542 - val_loss: 339.9891 - val_mean_squared_error: 339.9891\n",
      "Epoch 6/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 278.5689 - mean_squared_error: 278.5689 - val_loss: 231.5223 - val_mean_squared_error: 231.5223\n",
      "Epoch 7/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 187.9042 - mean_squared_error: 187.9042 - val_loss: 155.9785 - val_mean_squared_error: 155.9785\n",
      "Epoch 8/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 137.0118 - mean_squared_error: 137.0118 - val_loss: 127.0466 - val_mean_squared_error: 127.0466\n",
      "Epoch 9/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 121.3756 - mean_squared_error: 121.3756 - val_loss: 117.9718 - val_mean_squared_error: 117.9718\n",
      "Epoch 10/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 115.2716 - mean_squared_error: 115.2716 - val_loss: 112.8405 - val_mean_squared_error: 112.8405\n",
      "Epoch 11/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 98.8655 - mean_squared_error: 98.86 - 0s 44us/sample - loss: 110.3123 - mean_squared_error: 110.3123 - val_loss: 107.5644 - val_mean_squared_error: 107.5644\n",
      "Epoch 12/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 105.6943 - mean_squared_error: 105.6943 - val_loss: 104.6307 - val_mean_squared_error: 104.6307\n",
      "Epoch 13/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 101.3831 - mean_squared_error: 101.3831 - val_loss: 101.2117 - val_mean_squared_error: 101.2117\n",
      "Epoch 14/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 97.1217 - mean_squared_error: 97.1217 - val_loss: 97.1916 - val_mean_squared_error: 97.1916\n",
      "Epoch 15/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 93.0756 - mean_squared_error: 93.0756 - val_loss: 93.8576 - val_mean_squared_error: 93.8576\n",
      "Epoch 16/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 89.3747 - mean_squared_error: 89.3747 - val_loss: 90.2333 - val_mean_squared_error: 90.2333\n",
      "Epoch 17/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 85.6840 - mean_squared_error: 85.6840 - val_loss: 88.1368 - val_mean_squared_error: 88.1368\n",
      "Epoch 18/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 82.4508 - mean_squared_error: 82.4508 - val_loss: 86.0691 - val_mean_squared_error: 86.0691\n",
      "Epoch 19/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 79.1151 - mean_squared_error: 79.1151 - val_loss: 82.6154 - val_mean_squared_error: 82.6154\n",
      "Epoch 20/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 76.0699 - mean_squared_error: 76.0699 - val_loss: 80.8443 - val_mean_squared_error: 80.8443\n",
      "Epoch 21/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 73.0887 - mean_squared_error: 73.0887 - val_loss: 78.4784 - val_mean_squared_error: 78.4784\n",
      "Epoch 22/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 71.1477 - mean_squared_error: 71.1477 - val_loss: 75.2418 - val_mean_squared_error: 75.2418\n",
      "Epoch 23/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 72.6106 - mean_squared_error: 72.61 - 0s 36us/sample - loss: 68.0154 - mean_squared_error: 68.0154 - val_loss: 74.2149 - val_mean_squared_error: 74.2149\n",
      "Epoch 24/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 65.5925 - mean_squared_error: 65.5925 - val_loss: 72.5242 - val_mean_squared_error: 72.5242\n",
      "Epoch 25/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 63.5745 - mean_squared_error: 63.5744 - val_loss: 70.7943 - val_mean_squared_error: 70.7943\n",
      "Epoch 26/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 61.8863 - mean_squared_error: 61.8863 - val_loss: 69.2017 - val_mean_squared_error: 69.2017\n",
      "Epoch 27/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 60.0372 - mean_squared_error: 60.0372 - val_loss: 68.7880 - val_mean_squared_error: 68.7880\n",
      "Epoch 28/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 58.4014 - mean_squared_error: 58.4014 - val_loss: 67.4098 - val_mean_squared_error: 67.4098\n",
      "Epoch 29/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 57.0055 - mean_squared_error: 57.0055 - val_loss: 66.5085 - val_mean_squared_error: 66.5085\n",
      "Epoch 30/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 55.8911 - mean_squared_error: 55.8911 - val_loss: 65.8319 - val_mean_squared_error: 65.8319\n",
      "Epoch 31/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 54.7011 - mean_squared_error: 54.7011 - val_loss: 64.2262 - val_mean_squared_error: 64.2262\n",
      "Epoch 32/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 53.6002 - mean_squared_error: 53.6002 - val_loss: 63.8790 - val_mean_squared_error: 63.8790\n",
      "Epoch 33/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 52.6890 - mean_squared_error: 52.6890 - val_loss: 62.8090 - val_mean_squared_error: 62.8090\n",
      "Epoch 34/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 52.5389 - mean_squared_error: 52.5389 - val_loss: 61.9870 - val_mean_squared_error: 61.9870\n",
      "Epoch 35/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 51.3028 - mean_squared_error: 51.3028 - val_loss: 61.5095 - val_mean_squared_error: 61.5095\n",
      "Epoch 36/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 50.4154 - mean_squared_error: 50.4154 - val_loss: 60.8882 - val_mean_squared_error: 60.8882\n",
      "Epoch 37/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 49.5694 - mean_squared_error: 49.5694 - val_loss: 60.8011 - val_mean_squared_error: 60.8011\n",
      "Epoch 38/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 48.9926 - mean_squared_error: 48.9926 - val_loss: 59.8542 - val_mean_squared_error: 59.8542\n",
      "Epoch 39/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 48.6684 - mean_squared_error: 48.6684 - val_loss: 59.3251 - val_mean_squared_error: 59.3251\n",
      "Epoch 40/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 47.7853 - mean_squared_error: 47.7853 - val_loss: 59.2140 - val_mean_squared_error: 59.2140\n",
      "Epoch 41/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 47.2049 - mean_squared_error: 47.2049 - val_loss: 58.7220 - val_mean_squared_error: 58.7220\n",
      "Epoch 42/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 47.0638 - mean_squared_error: 47.0638 - val_loss: 58.8105 - val_mean_squared_error: 58.8105\n",
      "Epoch 43/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 46.4423 - mean_squared_error: 46.4423 - val_loss: 57.4973 - val_mean_squared_error: 57.4973\n",
      "Epoch 44/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 45.8988 - mean_squared_error: 45.8988 - val_loss: 57.0999 - val_mean_squared_error: 57.0999\n",
      "Epoch 45/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 45.4000 - mean_squared_error: 45.4000 - val_loss: 57.2051 - val_mean_squared_error: 57.2051\n",
      "Epoch 46/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 44.8549 - mean_squared_error: 44.8549 - val_loss: 56.2993 - val_mean_squared_error: 56.2993\n",
      "Epoch 47/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 53us/sample - loss: 44.3739 - mean_squared_error: 44.3739 - val_loss: 55.8101 - val_mean_squared_error: 55.8101\n",
      "Epoch 48/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 43.9380 - mean_squared_error: 43.9380 - val_loss: 55.4463 - val_mean_squared_error: 55.4463\n",
      "Epoch 49/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 43.4833 - mean_squared_error: 43.4833 - val_loss: 54.9197 - val_mean_squared_error: 54.9197\n",
      "Epoch 50/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 43.2679 - mean_squared_error: 43.2679 - val_loss: 54.9824 - val_mean_squared_error: 54.9824\n",
      "Epoch 51/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 42.7372 - mean_squared_error: 42.7372 - val_loss: 54.1578 - val_mean_squared_error: 54.1578\n",
      "Epoch 52/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 42.2665 - mean_squared_error: 42.2665 - val_loss: 53.7982 - val_mean_squared_error: 53.7982\n",
      "Epoch 53/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 41.8026 - mean_squared_error: 41.8026 - val_loss: 53.1624 - val_mean_squared_error: 53.1624\n",
      "Epoch 54/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 41.7903 - mean_squared_error: 41.7903 - val_loss: 52.6378 - val_mean_squared_error: 52.6378\n",
      "Epoch 55/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 41.2420 - mean_squared_error: 41.2420 - val_loss: 52.2364 - val_mean_squared_error: 52.2364\n",
      "Epoch 56/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 40.6409 - mean_squared_error: 40.6409 - val_loss: 51.8243 - val_mean_squared_error: 51.8243\n",
      "Epoch 57/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 40.2530 - mean_squared_error: 40.2530 - val_loss: 51.3607 - val_mean_squared_error: 51.3607\n",
      "Epoch 58/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 39.8018 - mean_squared_error: 39.8018 - val_loss: 51.3988 - val_mean_squared_error: 51.3988\n",
      "Epoch 59/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 39.4562 - mean_squared_error: 39.4562 - val_loss: 50.8874 - val_mean_squared_error: 50.8874\n",
      "Epoch 60/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 38.9193 - mean_squared_error: 38.9193 - val_loss: 50.2689 - val_mean_squared_error: 50.2689\n",
      "Epoch 61/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 38.5256 - mean_squared_error: 38.5256 - val_loss: 49.7087 - val_mean_squared_error: 49.7087\n",
      "Epoch 62/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 38.0687 - mean_squared_error: 38.0687 - val_loss: 49.3725 - val_mean_squared_error: 49.3725\n",
      "Epoch 63/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 38.5865 - mean_squared_error: 38.5865 - val_loss: 48.9832 - val_mean_squared_error: 48.9832\n",
      "Epoch 64/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 37.5396 - mean_squared_error: 37.5396 - val_loss: 48.6775 - val_mean_squared_error: 48.6775\n",
      "Epoch 65/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 36.8989 - mean_squared_error: 36.8989 - val_loss: 48.0603 - val_mean_squared_error: 48.0603\n",
      "Epoch 66/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 36.6259 - mean_squared_error: 36.6259 - val_loss: 48.4815 - val_mean_squared_error: 48.4815\n",
      "Epoch 67/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 36.3856 - mean_squared_error: 36.3856 - val_loss: 47.2850 - val_mean_squared_error: 47.2850\n",
      "Epoch 68/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 36.3416 - mean_squared_error: 36.3416 - val_loss: 46.8865 - val_mean_squared_error: 46.8865\n",
      "Epoch 69/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 35.3565 - mean_squared_error: 35.3565 - val_loss: 47.0683 - val_mean_squared_error: 47.0683\n",
      "Epoch 70/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 34.9661 - mean_squared_error: 34.9661 - val_loss: 46.5385 - val_mean_squared_error: 46.5385\n",
      "Epoch 71/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 35.0692 - mean_squared_error: 35.0692 - val_loss: 45.9058 - val_mean_squared_error: 45.9058\n",
      "Epoch 72/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 34.4050 - mean_squared_error: 34.4050 - val_loss: 45.8709 - val_mean_squared_error: 45.8709\n",
      "Epoch 73/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 34.0176 - mean_squared_error: 34.0176 - val_loss: 45.6838 - val_mean_squared_error: 45.6838\n",
      "Epoch 74/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 28.2479 - mean_squared_error: 28.24 - 0s 32us/sample - loss: 33.5666 - mean_squared_error: 33.5666 - val_loss: 44.9421 - val_mean_squared_error: 44.9421\n",
      "Epoch 75/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 33.2372 - mean_squared_error: 33.2372 - val_loss: 44.8314 - val_mean_squared_error: 44.8314\n",
      "Epoch 76/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 33.0282 - mean_squared_error: 33.0282 - val_loss: 44.5859 - val_mean_squared_error: 44.5859\n",
      "Epoch 77/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 32.7346 - mean_squared_error: 32.7346 - val_loss: 43.7846 - val_mean_squared_error: 43.7846\n",
      "Epoch 78/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 32.3528 - mean_squared_error: 32.3528 - val_loss: 43.5989 - val_mean_squared_error: 43.5989\n",
      "Epoch 79/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 32.2979 - mean_squared_error: 32.2979 - val_loss: 43.9463 - val_mean_squared_error: 43.9463\n",
      "Epoch 80/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 31.8866 - mean_squared_error: 31.8866 - val_loss: 42.8199 - val_mean_squared_error: 42.8199\n",
      "Epoch 81/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 31.6289 - mean_squared_error: 31.6289 - val_loss: 42.5371 - val_mean_squared_error: 42.5371\n",
      "Epoch 82/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 31.2064 - mean_squared_error: 31.2064 - val_loss: 42.5635 - val_mean_squared_error: 42.5635\n",
      "Epoch 83/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 31.0044 - mean_squared_error: 31.0044 - val_loss: 41.8728 - val_mean_squared_error: 41.8728\n",
      "Epoch 84/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 30.8970 - mean_squared_error: 30.8970 - val_loss: 41.5580 - val_mean_squared_error: 41.5580\n",
      "Epoch 85/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 30.5991 - mean_squared_error: 30.5991 - val_loss: 41.2518 - val_mean_squared_error: 41.2518\n",
      "Epoch 86/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 30.4627 - mean_squared_error: 30.4627 - val_loss: 40.9176 - val_mean_squared_error: 40.9176\n",
      "Epoch 87/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 29.9341 - mean_squared_error: 29.9341 - val_loss: 40.8000 - val_mean_squared_error: 40.8000\n",
      "Epoch 88/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 29.5777 - mean_squared_error: 29.5777 - val_loss: 40.4714 - val_mean_squared_error: 40.4714\n",
      "Epoch 89/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 29.3504 - mean_squared_error: 29.3504 - val_loss: 40.1853 - val_mean_squared_error: 40.1853\n",
      "Epoch 90/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 29.2676 - mean_squared_error: 29.2676 - val_loss: 39.7659 - val_mean_squared_error: 39.7659\n",
      "Epoch 91/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 29.1071 - mean_squared_error: 29.1071 - val_loss: 39.4873 - val_mean_squared_error: 39.4873\n",
      "Epoch 92/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 28.6834 - mean_squared_error: 28.6834 - val_loss: 39.3193 - val_mean_squared_error: 39.3193\n",
      "Epoch 93/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 28.6027 - mean_squared_error: 28.6027 - val_loss: 38.9212 - val_mean_squared_error: 38.9212\n",
      "Epoch 94/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 32us/sample - loss: 28.2346 - mean_squared_error: 28.2346 - val_loss: 38.8246 - val_mean_squared_error: 38.8246\n",
      "Epoch 95/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 27.9781 - mean_squared_error: 27.9781 - val_loss: 38.8021 - val_mean_squared_error: 38.8021\n",
      "Epoch 96/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 27.8494 - mean_squared_error: 27.8494 - val_loss: 38.5640 - val_mean_squared_error: 38.5640\n",
      "Epoch 97/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 27.5631 - mean_squared_error: 27.5631 - val_loss: 37.8880 - val_mean_squared_error: 37.8880\n",
      "Epoch 98/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 27.7513 - mean_squared_error: 27.7513 - val_loss: 37.6320 - val_mean_squared_error: 37.6320\n",
      "Epoch 99/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 27.3008 - mean_squared_error: 27.3008 - val_loss: 37.4427 - val_mean_squared_error: 37.4427\n",
      "Epoch 100/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 26.8594 - mean_squared_error: 26.8594 - val_loss: 37.4123 - val_mean_squared_error: 37.4123\n",
      "Epoch 101/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 27.0266 - mean_squared_error: 27.0266 - val_loss: 37.8443 - val_mean_squared_error: 37.8443\n",
      "Epoch 102/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 26.6511 - mean_squared_error: 26.6511 - val_loss: 36.6248 - val_mean_squared_error: 36.6248\n",
      "Epoch 103/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 26.3483 - mean_squared_error: 26.3483 - val_loss: 36.7040 - val_mean_squared_error: 36.7040\n",
      "Epoch 104/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 26.4046 - mean_squared_error: 26.4046 - val_loss: 37.0614 - val_mean_squared_error: 37.0614\n",
      "Epoch 105/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 26.0148 - mean_squared_error: 26.0148 - val_loss: 35.9683 - val_mean_squared_error: 35.9683\n",
      "Epoch 106/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 25.8202 - mean_squared_error: 25.8202 - val_loss: 35.7562 - val_mean_squared_error: 35.7562\n",
      "Epoch 107/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 25.5206 - mean_squared_error: 25.5206 - val_loss: 35.9012 - val_mean_squared_error: 35.9012\n",
      "Epoch 108/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 25.3384 - mean_squared_error: 25.3384 - val_loss: 35.4168 - val_mean_squared_error: 35.4168\n",
      "Epoch 109/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 25.1629 - mean_squared_error: 25.1629 - val_loss: 35.3677 - val_mean_squared_error: 35.3677\n",
      "Epoch 110/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 22.7610 - mean_squared_error: 22.76 - 0s 28us/sample - loss: 25.0242 - mean_squared_error: 25.0242 - val_loss: 34.9239 - val_mean_squared_error: 34.9239\n",
      "Epoch 111/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 24.9216 - mean_squared_error: 24.9216 - val_loss: 34.7372 - val_mean_squared_error: 34.7372\n",
      "Epoch 112/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 25.5351 - mean_squared_error: 25.5351 - val_loss: 34.6575 - val_mean_squared_error: 34.6575\n",
      "Epoch 113/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 24.7750 - mean_squared_error: 24.7750 - val_loss: 34.8123 - val_mean_squared_error: 34.8123\n",
      "Epoch 114/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 24.3959 - mean_squared_error: 24.3959 - val_loss: 34.4150 - val_mean_squared_error: 34.4150\n",
      "Epoch 115/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 24.1870 - mean_squared_error: 24.1870 - val_loss: 33.9820 - val_mean_squared_error: 33.9820\n",
      "Epoch 116/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 24.1599 - mean_squared_error: 24.1599 - val_loss: 33.7697 - val_mean_squared_error: 33.7697\n",
      "Epoch 117/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 24.2588 - mean_squared_error: 24.2588 - val_loss: 35.1997 - val_mean_squared_error: 35.1997\n",
      "Epoch 118/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 24.0316 - mean_squared_error: 24.0316 - val_loss: 33.4281 - val_mean_squared_error: 33.4281\n",
      "Epoch 119/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 23.7264 - mean_squared_error: 23.7264 - val_loss: 33.9027 - val_mean_squared_error: 33.9027\n",
      "Epoch 120/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 23.7568 - mean_squared_error: 23.7568 - val_loss: 33.9149 - val_mean_squared_error: 33.9149\n",
      "Epoch 121/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 23.8825 - mean_squared_error: 23.8825 - val_loss: 33.9789 - val_mean_squared_error: 33.9789\n",
      "Epoch 122/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 23.3839 - mean_squared_error: 23.3839 - val_loss: 32.7405 - val_mean_squared_error: 32.7405\n",
      "Epoch 123/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 23.2347 - mean_squared_error: 23.2347 - val_loss: 33.7252 - val_mean_squared_error: 33.7252\n",
      "Epoch 124/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 23.0480 - mean_squared_error: 23.0480 - val_loss: 32.4770 - val_mean_squared_error: 32.4770\n",
      "Epoch 125/4000\n",
      "339/339 [==============================] - 0s 15us/sample - loss: 23.1559 - mean_squared_error: 23.1559 - val_loss: 32.2798 - val_mean_squared_error: 32.2798\n",
      "Epoch 126/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 23.0078 - mean_squared_error: 23.0078 - val_loss: 32.1631 - val_mean_squared_error: 32.1631\n",
      "Epoch 127/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 22.6893 - mean_squared_error: 22.6893 - val_loss: 32.9234 - val_mean_squared_error: 32.9234\n",
      "Epoch 128/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 22.7399 - mean_squared_error: 22.7399 - val_loss: 31.9394 - val_mean_squared_error: 31.9394\n",
      "Epoch 129/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 22.6317 - mean_squared_error: 22.6317 - val_loss: 32.0535 - val_mean_squared_error: 32.0535\n",
      "Epoch 130/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 22.2704 - mean_squared_error: 22.2704 - val_loss: 31.9477 - val_mean_squared_error: 31.9477\n",
      "Epoch 131/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 22.4323 - mean_squared_error: 22.4323 - val_loss: 31.5036 - val_mean_squared_error: 31.5036\n",
      "Epoch 132/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 22.2203 - mean_squared_error: 22.2203 - val_loss: 32.0771 - val_mean_squared_error: 32.0771\n",
      "Epoch 133/4000\n",
      "339/339 [==============================] - 0s 20us/sample - loss: 21.9936 - mean_squared_error: 21.9936 - val_loss: 31.3915 - val_mean_squared_error: 31.3915\n",
      "Epoch 134/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 21.8729 - mean_squared_error: 21.8729 - val_loss: 31.6184 - val_mean_squared_error: 31.6184\n",
      "Epoch 135/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 21.8740 - mean_squared_error: 21.8740 - val_loss: 31.0072 - val_mean_squared_error: 31.0072\n",
      "Epoch 136/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 21.7464 - mean_squared_error: 21.7464 - val_loss: 31.5095 - val_mean_squared_error: 31.5095\n",
      "Epoch 137/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 21.6712 - mean_squared_error: 21.6712 - val_loss: 30.7702 - val_mean_squared_error: 30.7702\n",
      "Epoch 138/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 21.6850 - mean_squared_error: 21.6850 - val_loss: 31.9964 - val_mean_squared_error: 31.9964\n",
      "Epoch 139/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 21.6089 - mean_squared_error: 21.6089 - val_loss: 30.6737 - val_mean_squared_error: 30.6737\n",
      "Epoch 140/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 21.3592 - mean_squared_error: 21.3592 - val_loss: 30.8151 - val_mean_squared_error: 30.8151\n",
      "Epoch 141/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 27us/sample - loss: 21.4549 - mean_squared_error: 21.4549 - val_loss: 30.3805 - val_mean_squared_error: 30.3805\n",
      "Epoch 142/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 22.2479 - mean_squared_error: 22.2479 - val_loss: 30.3658 - val_mean_squared_error: 30.3658\n",
      "Epoch 143/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 21.3957 - mean_squared_error: 21.3957 - val_loss: 30.5610 - val_mean_squared_error: 30.5610\n",
      "Epoch 144/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 21.2403 - mean_squared_error: 21.2403 - val_loss: 30.9435 - val_mean_squared_error: 30.9435\n",
      "Epoch 145/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 21.1160 - mean_squared_error: 21.1160 - val_loss: 30.3253 - val_mean_squared_error: 30.3253\n",
      "Epoch 146/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 21.0197 - mean_squared_error: 21.0197 - val_loss: 30.7168 - val_mean_squared_error: 30.7168\n",
      "Epoch 147/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 20.8786 - mean_squared_error: 20.8786 - val_loss: 29.8228 - val_mean_squared_error: 29.8228\n",
      "Epoch 148/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 20.8655 - mean_squared_error: 20.8655 - val_loss: 29.8573 - val_mean_squared_error: 29.8573\n",
      "Epoch 149/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 20.7293 - mean_squared_error: 20.7293 - val_loss: 29.7360 - val_mean_squared_error: 29.7360\n",
      "Epoch 150/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 20.6290 - mean_squared_error: 20.6290 - val_loss: 29.8436 - val_mean_squared_error: 29.8436\n",
      "Epoch 151/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 20.6877 - mean_squared_error: 20.6877 - val_loss: 29.4400 - val_mean_squared_error: 29.4400\n",
      "Epoch 152/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 20.5998 - mean_squared_error: 20.5998 - val_loss: 29.6856 - val_mean_squared_error: 29.6856\n",
      "Epoch 153/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 20.5709 - mean_squared_error: 20.5709 - val_loss: 29.2927 - val_mean_squared_error: 29.2927\n",
      "Epoch 154/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 20.5244 - mean_squared_error: 20.5244 - val_loss: 29.4060 - val_mean_squared_error: 29.4060\n",
      "Epoch 155/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 20.3927 - mean_squared_error: 20.3927 - val_loss: 29.8509 - val_mean_squared_error: 29.8509\n",
      "Epoch 156/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 20.3810 - mean_squared_error: 20.3810 - val_loss: 29.4526 - val_mean_squared_error: 29.4526\n",
      "Epoch 157/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 20.6005 - mean_squared_error: 20.6005 - val_loss: 29.1272 - val_mean_squared_error: 29.1272\n",
      "Epoch 158/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 20.4824 - mean_squared_error: 20.4824 - val_loss: 29.3447 - val_mean_squared_error: 29.3447\n",
      "Epoch 159/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 20.1965 - mean_squared_error: 20.1965 - val_loss: 29.4929 - val_mean_squared_error: 29.4929\n",
      "Epoch 160/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 20.0714 - mean_squared_error: 20.0714 - val_loss: 28.8819 - val_mean_squared_error: 28.8819\n",
      "Epoch 161/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 20.0352 - mean_squared_error: 20.0352 - val_loss: 28.8749 - val_mean_squared_error: 28.8749\n",
      "Epoch 162/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.9540 - mean_squared_error: 19.9540 - val_loss: 28.8074 - val_mean_squared_error: 28.8074\n",
      "Epoch 163/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 19.9041 - mean_squared_error: 19.9041 - val_loss: 28.9326 - val_mean_squared_error: 28.9326\n",
      "Epoch 164/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.9244 - mean_squared_error: 19.9244 - val_loss: 28.5289 - val_mean_squared_error: 28.5289\n",
      "Epoch 165/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 19.8499 - mean_squared_error: 19.8499 - val_loss: 29.1102 - val_mean_squared_error: 29.1102\n",
      "Epoch 166/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 19.8884 - mean_squared_error: 19.8884 - val_loss: 28.9188 - val_mean_squared_error: 28.9188\n",
      "Epoch 167/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.7845 - mean_squared_error: 19.7845 - val_loss: 28.8241 - val_mean_squared_error: 28.8241\n",
      "Epoch 168/4000\n",
      "339/339 [==============================] - 0s 17us/sample - loss: 19.7071 - mean_squared_error: 19.7071 - val_loss: 28.6740 - val_mean_squared_error: 28.6740\n",
      "Epoch 169/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 19.6212 - mean_squared_error: 19.6212 - val_loss: 28.3989 - val_mean_squared_error: 28.3989\n",
      "Epoch 170/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 19.5925 - mean_squared_error: 19.5925 - val_loss: 28.6625 - val_mean_squared_error: 28.6625\n",
      "Epoch 171/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 19.6621 - mean_squared_error: 19.6621 - val_loss: 28.1387 - val_mean_squared_error: 28.1387\n",
      "Epoch 172/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 20.1501 - mean_squared_error: 20.1501 - val_loss: 28.0951 - val_mean_squared_error: 28.0951\n",
      "Epoch 173/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 19.8679 - mean_squared_error: 19.8679 - val_loss: 28.0955 - val_mean_squared_error: 28.0955\n",
      "Epoch 174/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 19.8677 - mean_squared_error: 19.8677 - val_loss: 27.9956 - val_mean_squared_error: 27.9956\n",
      "Epoch 175/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.5230 - mean_squared_error: 19.5230 - val_loss: 28.7357 - val_mean_squared_error: 28.7357\n",
      "Epoch 176/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 19.4231 - mean_squared_error: 19.4231 - val_loss: 27.8550 - val_mean_squared_error: 27.8550\n",
      "Epoch 177/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 19.5014 - mean_squared_error: 19.5014 - val_loss: 29.3492 - val_mean_squared_error: 29.3492\n",
      "Epoch 178/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.5143 - mean_squared_error: 19.5143 - val_loss: 27.8536 - val_mean_squared_error: 27.8536\n",
      "Epoch 179/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 19.2667 - mean_squared_error: 19.2667 - val_loss: 28.1651 - val_mean_squared_error: 28.1651\n",
      "Epoch 180/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 19.3942 - mean_squared_error: 19.3942 - val_loss: 28.5340 - val_mean_squared_error: 28.5340\n",
      "Epoch 181/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 19.3112 - mean_squared_error: 19.3112 - val_loss: 27.6157 - val_mean_squared_error: 27.6157\n",
      "Epoch 182/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 19.3476 - mean_squared_error: 19.3476 - val_loss: 27.7847 - val_mean_squared_error: 27.7847\n",
      "Epoch 183/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 19.1636 - mean_squared_error: 19.1636 - val_loss: 28.0264 - val_mean_squared_error: 28.0264\n",
      "Epoch 184/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 19.3373 - mean_squared_error: 19.3373 - val_loss: 28.5077 - val_mean_squared_error: 28.5077\n",
      "Epoch 185/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 19.2384 - mean_squared_error: 19.2384 - val_loss: 27.6905 - val_mean_squared_error: 27.6905\n",
      "Epoch 186/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 19.0723 - mean_squared_error: 19.0723 - val_loss: 27.7809 - val_mean_squared_error: 27.7809\n",
      "Epoch 187/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 19.0389 - mean_squared_error: 19.0389 - val_loss: 27.4956 - val_mean_squared_error: 27.4956\n",
      "Epoch 188/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 23us/sample - loss: 19.0083 - mean_squared_error: 19.0083 - val_loss: 27.8215 - val_mean_squared_error: 27.8215\n",
      "Epoch 189/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 19.1876 - mean_squared_error: 19.1876 - val_loss: 28.1846 - val_mean_squared_error: 28.1846\n",
      "Epoch 190/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 19.0297 - mean_squared_error: 19.0297 - val_loss: 27.2400 - val_mean_squared_error: 27.2400\n",
      "Epoch 191/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 19.1127 - mean_squared_error: 19.1127 - val_loss: 27.3504 - val_mean_squared_error: 27.3504\n",
      "Epoch 192/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 18.9763 - mean_squared_error: 18.9763 - val_loss: 28.0549 - val_mean_squared_error: 28.0549\n",
      "Epoch 193/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 19.0815 - mean_squared_error: 19.0815 - val_loss: 27.6060 - val_mean_squared_error: 27.6060\n",
      "Epoch 194/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 18.9023 - mean_squared_error: 18.9023 - val_loss: 27.1732 - val_mean_squared_error: 27.1732\n",
      "Epoch 195/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 19.1326 - mean_squared_error: 19.1326 - val_loss: 27.1198 - val_mean_squared_error: 27.1198\n",
      "Epoch 196/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 18.8786 - mean_squared_error: 18.8786 - val_loss: 27.8231 - val_mean_squared_error: 27.8231\n",
      "Epoch 197/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 19.1597 - mean_squared_error: 19.1597 - val_loss: 28.1078 - val_mean_squared_error: 28.1078\n",
      "Epoch 198/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 19.4234 - mean_squared_error: 19.4234 - val_loss: 28.3270 - val_mean_squared_error: 28.3270\n",
      "Epoch 199/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.9269 - mean_squared_error: 18.9269 - val_loss: 27.1454 - val_mean_squared_error: 27.1454\n",
      "Epoch 200/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 18.9183 - mean_squared_error: 18.9183 - val_loss: 28.2236 - val_mean_squared_error: 28.2236\n",
      "Epoch 201/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 19.0758 - mean_squared_error: 19.0758 - val_loss: 27.4874 - val_mean_squared_error: 27.4874\n",
      "Epoch 202/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 18.7115 - mean_squared_error: 18.7115 - val_loss: 27.0610 - val_mean_squared_error: 27.0610\n",
      "Epoch 203/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 18.6782 - mean_squared_error: 18.6782 - val_loss: 27.3540 - val_mean_squared_error: 27.3540\n",
      "Epoch 204/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 18.7483 - mean_squared_error: 18.7483 - val_loss: 27.4795 - val_mean_squared_error: 27.4795\n",
      "Epoch 205/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 18.6791 - mean_squared_error: 18.6791 - val_loss: 26.8396 - val_mean_squared_error: 26.8396\n",
      "Epoch 206/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 19.2220 - mean_squared_error: 19.2220 - val_loss: 26.8341 - val_mean_squared_error: 26.8341\n",
      "Epoch 207/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 19.0798 - mean_squared_error: 19.0798 - val_loss: 26.8155 - val_mean_squared_error: 26.8155\n",
      "Epoch 208/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 18.6259 - mean_squared_error: 18.6259 - val_loss: 27.1897 - val_mean_squared_error: 27.1897\n",
      "Epoch 209/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 18.8195 - mean_squared_error: 18.8195 - val_loss: 27.8397 - val_mean_squared_error: 27.8397\n",
      "Epoch 210/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 19.2975 - mean_squared_error: 19.2975 - val_loss: 28.1741 - val_mean_squared_error: 28.1741\n",
      "Epoch 211/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 19.2509 - mean_squared_error: 19.2509 - val_loss: 27.7159 - val_mean_squared_error: 27.7159\n",
      "Epoch 212/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.6574 - mean_squared_error: 18.6574 - val_loss: 26.8721 - val_mean_squared_error: 26.8721\n",
      "Epoch 213/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 18.5703 - mean_squared_error: 18.5703 - val_loss: 27.4089 - val_mean_squared_error: 27.4089\n",
      "Epoch 214/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 18.6912 - mean_squared_error: 18.6912 - val_loss: 27.2572 - val_mean_squared_error: 27.2572\n",
      "Epoch 215/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 18.5339 - mean_squared_error: 18.5339 - val_loss: 26.6477 - val_mean_squared_error: 26.6477\n",
      "Epoch 216/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 18.8542 - mean_squared_error: 18.8542 - val_loss: 26.6004 - val_mean_squared_error: 26.6004\n",
      "Epoch 217/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 18.8779 - mean_squared_error: 18.8779 - val_loss: 26.5449 - val_mean_squared_error: 26.5449\n",
      "Epoch 218/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 18.8057 - mean_squared_error: 18.8057 - val_loss: 26.5135 - val_mean_squared_error: 26.5135\n",
      "Epoch 219/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.6760 - mean_squared_error: 18.6760 - val_loss: 26.4801 - val_mean_squared_error: 26.4801\n",
      "Epoch 220/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 18.4287 - mean_squared_error: 18.4287 - val_loss: 27.1016 - val_mean_squared_error: 27.1016\n",
      "Epoch 221/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 18.4245 - mean_squared_error: 18.4245 - val_loss: 26.6505 - val_mean_squared_error: 26.6505\n",
      "Epoch 222/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 18.6459 - mean_squared_error: 18.6459 - val_loss: 27.9191 - val_mean_squared_error: 27.9191\n",
      "Epoch 223/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 18.6723 - mean_squared_error: 18.6723 - val_loss: 26.6583 - val_mean_squared_error: 26.6583\n",
      "Epoch 224/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 18.4243 - mean_squared_error: 18.4243 - val_loss: 26.3834 - val_mean_squared_error: 26.3834\n",
      "Epoch 225/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 18.6058 - mean_squared_error: 18.6058 - val_loss: 26.3804 - val_mean_squared_error: 26.3804\n",
      "Epoch 226/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 18.4120 - mean_squared_error: 18.4120 - val_loss: 26.5605 - val_mean_squared_error: 26.5605\n",
      "Epoch 227/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 18.3323 - mean_squared_error: 18.3323 - val_loss: 26.3940 - val_mean_squared_error: 26.3940\n",
      "Epoch 228/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 18.6767 - mean_squared_error: 18.6767 - val_loss: 26.2945 - val_mean_squared_error: 26.2945\n",
      "Epoch 229/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 18.5988 - mean_squared_error: 18.5988 - val_loss: 26.3815 - val_mean_squared_error: 26.3815\n",
      "Epoch 230/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 18.3025 - mean_squared_error: 18.3025 - val_loss: 26.3950 - val_mean_squared_error: 26.3950\n",
      "Epoch 231/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 18.3521 - mean_squared_error: 18.3521 - val_loss: 26.2226 - val_mean_squared_error: 26.2226\n",
      "Epoch 232/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 18.4292 - mean_squared_error: 18.4292 - val_loss: 26.1999 - val_mean_squared_error: 26.1999\n",
      "Epoch 233/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 18.3045 - mean_squared_error: 18.3045 - val_loss: 26.2916 - val_mean_squared_error: 26.2916\n",
      "Epoch 234/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 18.2168 - mean_squared_error: 18.2168 - val_loss: 26.4561 - val_mean_squared_error: 26.4561\n",
      "Epoch 235/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 51us/sample - loss: 18.5101 - mean_squared_error: 18.5101 - val_loss: 27.5932 - val_mean_squared_error: 27.5932\n",
      "Epoch 236/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 18.4421 - mean_squared_error: 18.4421 - val_loss: 26.3025 - val_mean_squared_error: 26.3025\n",
      "Epoch 237/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 18.1805 - mean_squared_error: 18.1805 - val_loss: 26.4089 - val_mean_squared_error: 26.4089\n",
      "Epoch 238/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 18.3013 - mean_squared_error: 18.3013 - val_loss: 26.0617 - val_mean_squared_error: 26.0617\n",
      "Epoch 239/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 18.6051 - mean_squared_error: 18.6051 - val_loss: 26.0647 - val_mean_squared_error: 26.0647\n",
      "Epoch 240/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 17.6129 - mean_squared_error: 17.61 - 0s 53us/sample - loss: 18.2009 - mean_squared_error: 18.2009 - val_loss: 26.9488 - val_mean_squared_error: 26.9488\n",
      "Epoch 241/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 18.7342 - mean_squared_error: 18.7342 - val_loss: 27.4642 - val_mean_squared_error: 27.4642\n",
      "Epoch 242/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 18.2775 - mean_squared_error: 18.2775 - val_loss: 26.0296 - val_mean_squared_error: 26.0296\n",
      "Epoch 243/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 18.3417 - mean_squared_error: 18.3417 - val_loss: 26.2375 - val_mean_squared_error: 26.2375\n",
      "Epoch 244/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 18.1539 - mean_squared_error: 18.1539 - val_loss: 26.0685 - val_mean_squared_error: 26.0685\n",
      "Epoch 245/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 18.3849 - mean_squared_error: 18.3849 - val_loss: 25.9181 - val_mean_squared_error: 25.9181\n",
      "Epoch 246/4000\n",
      "339/339 [==============================] - 0s 65us/sample - loss: 18.3830 - mean_squared_error: 18.3830 - val_loss: 25.9760 - val_mean_squared_error: 25.9760\n",
      "Epoch 247/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 18.1808 - mean_squared_error: 18.1808 - val_loss: 27.0557 - val_mean_squared_error: 27.0557\n",
      "Epoch 248/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 18.1805 - mean_squared_error: 18.1805 - val_loss: 25.9173 - val_mean_squared_error: 25.9173\n",
      "Epoch 249/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 18.1170 - mean_squared_error: 18.1170 - val_loss: 26.6737 - val_mean_squared_error: 26.6737\n",
      "Epoch 250/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 18.1507 - mean_squared_error: 18.1507 - val_loss: 26.0243 - val_mean_squared_error: 26.0243\n",
      "Epoch 251/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 18.0700 - mean_squared_error: 18.0700 - val_loss: 26.3388 - val_mean_squared_error: 26.3388\n",
      "Epoch 252/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.1611 - mean_squared_error: 18.1611 - val_loss: 25.7912 - val_mean_squared_error: 25.7912\n",
      "Epoch 253/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 18.2295 - mean_squared_error: 18.2295 - val_loss: 26.0723 - val_mean_squared_error: 26.0723\n",
      "Epoch 254/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 18.3105 - mean_squared_error: 18.3105 - val_loss: 27.3267 - val_mean_squared_error: 27.3267\n",
      "Epoch 255/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 18.7288 - mean_squared_error: 18.7288 - val_loss: 26.8116 - val_mean_squared_error: 26.8116\n",
      "Epoch 256/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 18.1369 - mean_squared_error: 18.1369 - val_loss: 25.9765 - val_mean_squared_error: 25.9765\n",
      "Epoch 257/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 18.2425 - mean_squared_error: 18.2425 - val_loss: 25.7117 - val_mean_squared_error: 25.7117\n",
      "Epoch 258/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 18.1692 - mean_squared_error: 18.1692 - val_loss: 26.0272 - val_mean_squared_error: 26.0272\n",
      "Epoch 259/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 18.4116 - mean_squared_error: 18.4116 - val_loss: 27.4894 - val_mean_squared_error: 27.4894\n",
      "Epoch 260/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.3629 - mean_squared_error: 18.3629 - val_loss: 25.9248 - val_mean_squared_error: 25.9248\n",
      "Epoch 261/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.9643 - mean_squared_error: 17.9643 - val_loss: 25.7612 - val_mean_squared_error: 25.7612\n",
      "Epoch 262/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 18.2538 - mean_squared_error: 18.2538 - val_loss: 25.6490 - val_mean_squared_error: 25.6490\n",
      "Epoch 263/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 19.0336 - mean_squared_error: 19.0336 - val_loss: 25.7257 - val_mean_squared_error: 25.7257\n",
      "Epoch 264/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 18.1215 - mean_squared_error: 18.1215 - val_loss: 26.7441 - val_mean_squared_error: 26.7441\n",
      "Epoch 265/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 18.0893 - mean_squared_error: 18.0893 - val_loss: 25.8003 - val_mean_squared_error: 25.8003\n",
      "Epoch 266/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 17.9312 - mean_squared_error: 17.9312 - val_loss: 26.0533 - val_mean_squared_error: 26.0533\n",
      "Epoch 267/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 18.4534 - mean_squared_error: 18.4534 - val_loss: 27.4798 - val_mean_squared_error: 27.4798\n",
      "Epoch 268/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 18.2255 - mean_squared_error: 18.2255 - val_loss: 25.6834 - val_mean_squared_error: 25.6834\n",
      "Epoch 269/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 18.1888 - mean_squared_error: 18.1888 - val_loss: 25.5761 - val_mean_squared_error: 25.5761\n",
      "Epoch 270/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 18.5994 - mean_squared_error: 18.5994 - val_loss: 25.5640 - val_mean_squared_error: 25.5640\n",
      "Epoch 271/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 18.1132 - mean_squared_error: 18.1132 - val_loss: 25.8151 - val_mean_squared_error: 25.8151\n",
      "Epoch 272/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.8732 - mean_squared_error: 17.8732 - val_loss: 25.6675 - val_mean_squared_error: 25.6675\n",
      "Epoch 273/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.8588 - mean_squared_error: 17.8589 - val_loss: 25.8703 - val_mean_squared_error: 25.8703\n",
      "Epoch 274/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 18.1144 - mean_squared_error: 18.1144 - val_loss: 26.7869 - val_mean_squared_error: 26.7869\n",
      "Epoch 275/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.9610 - mean_squared_error: 17.9610 - val_loss: 25.4874 - val_mean_squared_error: 25.4874\n",
      "Epoch 276/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 18.3042 - mean_squared_error: 18.3042 - val_loss: 28.6066 - val_mean_squared_error: 28.6066\n",
      "Epoch 277/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 18.8034 - mean_squared_error: 18.8034 - val_loss: 25.7377 - val_mean_squared_error: 25.7377\n",
      "Epoch 278/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.8236 - mean_squared_error: 17.8236 - val_loss: 25.8365 - val_mean_squared_error: 25.8365\n",
      "Epoch 279/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.9098 - mean_squared_error: 17.9098 - val_loss: 26.0299 - val_mean_squared_error: 26.0299\n",
      "Epoch 280/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 17.9085 - mean_squared_error: 17.9085 - val_loss: 25.9579 - val_mean_squared_error: 25.9579\n",
      "Epoch 281/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 17.8413 - mean_squared_error: 17.8413 - val_loss: 25.4166 - val_mean_squared_error: 25.4166\n",
      "Epoch 282/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 29us/sample - loss: 17.8447 - mean_squared_error: 17.8447 - val_loss: 26.4179 - val_mean_squared_error: 26.4179\n",
      "Epoch 283/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 18.7192 - mean_squared_error: 18.7192 - val_loss: 27.4239 - val_mean_squared_error: 27.4239\n",
      "Epoch 284/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 18.2217 - mean_squared_error: 18.2217 - val_loss: 25.5497 - val_mean_squared_error: 25.5497\n",
      "Epoch 285/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.7840 - mean_squared_error: 17.7840 - val_loss: 25.9801 - val_mean_squared_error: 25.9801\n",
      "Epoch 286/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.8372 - mean_squared_error: 17.8372 - val_loss: 25.3082 - val_mean_squared_error: 25.3082\n",
      "Epoch 287/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.9076 - mean_squared_error: 17.9076 - val_loss: 27.0180 - val_mean_squared_error: 27.0180\n",
      "Epoch 288/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 19.1818 - mean_squared_error: 19.1818 - val_loss: 27.4560 - val_mean_squared_error: 27.4560\n",
      "Epoch 289/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 18.1355 - mean_squared_error: 18.1355 - val_loss: 25.3737 - val_mean_squared_error: 25.3737\n",
      "Epoch 290/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.7651 - mean_squared_error: 17.7651 - val_loss: 26.0680 - val_mean_squared_error: 26.0680\n",
      "Epoch 291/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.7939 - mean_squared_error: 17.7939 - val_loss: 25.4789 - val_mean_squared_error: 25.4789\n",
      "Epoch 292/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.9717 - mean_squared_error: 17.9717 - val_loss: 25.2580 - val_mean_squared_error: 25.2580\n",
      "Epoch 293/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.9658 - mean_squared_error: 17.9658 - val_loss: 25.4110 - val_mean_squared_error: 25.4110\n",
      "Epoch 294/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.8159 - mean_squared_error: 17.8159 - val_loss: 25.1665 - val_mean_squared_error: 25.1665\n",
      "Epoch 295/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.8490 - mean_squared_error: 17.8490 - val_loss: 25.2495 - val_mean_squared_error: 25.2495\n",
      "Epoch 296/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 17.8336 - mean_squared_error: 17.8336 - val_loss: 25.1349 - val_mean_squared_error: 25.1349\n",
      "Epoch 297/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.9930 - mean_squared_error: 17.9930 - val_loss: 25.1304 - val_mean_squared_error: 25.1304\n",
      "Epoch 298/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.7855 - mean_squared_error: 17.7855 - val_loss: 25.2588 - val_mean_squared_error: 25.2588\n",
      "Epoch 299/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 17.6852 - mean_squared_error: 17.6852 - val_loss: 25.6505 - val_mean_squared_error: 25.6505\n",
      "Epoch 300/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.7027 - mean_squared_error: 17.7027 - val_loss: 25.0782 - val_mean_squared_error: 25.0782\n",
      "Epoch 301/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.7189 - mean_squared_error: 17.7189 - val_loss: 25.3081 - val_mean_squared_error: 25.3081\n",
      "Epoch 302/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.7065 - mean_squared_error: 17.7065 - val_loss: 25.0698 - val_mean_squared_error: 25.0698\n",
      "Epoch 303/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 17.7108 - mean_squared_error: 17.7108 - val_loss: 25.7611 - val_mean_squared_error: 25.7611\n",
      "Epoch 304/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.6634 - mean_squared_error: 17.6634 - val_loss: 25.0677 - val_mean_squared_error: 25.0677\n",
      "Epoch 305/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.7048 - mean_squared_error: 17.7048 - val_loss: 25.9476 - val_mean_squared_error: 25.9476\n",
      "Epoch 306/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.9128 - mean_squared_error: 17.9128 - val_loss: 25.6992 - val_mean_squared_error: 25.6992\n",
      "Epoch 307/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.6539 - mean_squared_error: 17.6539 - val_loss: 25.2505 - val_mean_squared_error: 25.2505\n",
      "Epoch 308/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.6035 - mean_squared_error: 17.6035 - val_loss: 25.2502 - val_mean_squared_error: 25.2502\n",
      "Epoch 309/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.8396 - mean_squared_error: 17.8396 - val_loss: 25.0091 - val_mean_squared_error: 25.0091\n",
      "Epoch 310/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.8232 - mean_squared_error: 17.8232 - val_loss: 25.3028 - val_mean_squared_error: 25.3028\n",
      "Epoch 311/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.6455 - mean_squared_error: 17.6455 - val_loss: 24.9854 - val_mean_squared_error: 24.9854\n",
      "Epoch 312/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.6398 - mean_squared_error: 17.6398 - val_loss: 25.3016 - val_mean_squared_error: 25.3016\n",
      "Epoch 313/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.5916 - mean_squared_error: 17.5916 - val_loss: 25.1517 - val_mean_squared_error: 25.1517\n",
      "Epoch 314/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.6831 - mean_squared_error: 17.6831 - val_loss: 24.8931 - val_mean_squared_error: 24.8931\n",
      "Epoch 315/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.8372 - mean_squared_error: 17.8372 - val_loss: 24.9078 - val_mean_squared_error: 24.9078\n",
      "Epoch 316/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 17.6616 - mean_squared_error: 17.6616 - val_loss: 24.9709 - val_mean_squared_error: 24.9709\n",
      "Epoch 317/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.5526 - mean_squared_error: 17.5526 - val_loss: 25.2600 - val_mean_squared_error: 25.2600\n",
      "Epoch 318/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.5364 - mean_squared_error: 17.5364 - val_loss: 25.0331 - val_mean_squared_error: 25.0331\n",
      "Epoch 319/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 18.9446 - mean_squared_error: 18.94 - 0s 39us/sample - loss: 17.5588 - mean_squared_error: 17.5588 - val_loss: 24.9279 - val_mean_squared_error: 24.9279\n",
      "Epoch 320/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 17.5942 - mean_squared_error: 17.5942 - val_loss: 24.8946 - val_mean_squared_error: 24.8946\n",
      "Epoch 321/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 17.5383 - mean_squared_error: 17.5383 - val_loss: 25.0784 - val_mean_squared_error: 25.0784\n",
      "Epoch 322/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.6299 - mean_squared_error: 17.6299 - val_loss: 24.8257 - val_mean_squared_error: 24.8257\n",
      "Epoch 323/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 17.5605 - mean_squared_error: 17.5605 - val_loss: 25.5795 - val_mean_squared_error: 25.5795\n",
      "Epoch 324/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.5614 - mean_squared_error: 17.5614 - val_loss: 25.0118 - val_mean_squared_error: 25.0118\n",
      "Epoch 325/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.5112 - mean_squared_error: 17.5112 - val_loss: 24.9668 - val_mean_squared_error: 24.9668\n",
      "Epoch 326/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.5403 - mean_squared_error: 17.5403 - val_loss: 24.8992 - val_mean_squared_error: 24.8992\n",
      "Epoch 327/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.8803 - mean_squared_error: 17.8803 - val_loss: 24.8021 - val_mean_squared_error: 24.8021\n",
      "Epoch 328/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.7203 - mean_squared_error: 17.7203 - val_loss: 25.0086 - val_mean_squared_error: 25.0086\n",
      "Epoch 329/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 48us/sample - loss: 17.4718 - mean_squared_error: 17.4718 - val_loss: 25.1443 - val_mean_squared_error: 25.1443\n",
      "Epoch 330/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 17.4534 - mean_squared_error: 17.4534 - val_loss: 24.8996 - val_mean_squared_error: 24.8996\n",
      "Epoch 331/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 17.4602 - mean_squared_error: 17.4602 - val_loss: 24.8594 - val_mean_squared_error: 24.8594\n",
      "Epoch 332/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.5652 - mean_squared_error: 17.5652 - val_loss: 24.6576 - val_mean_squared_error: 24.6576\n",
      "Epoch 333/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 17.4933 - mean_squared_error: 17.4933 - val_loss: 25.0548 - val_mean_squared_error: 25.0548\n",
      "Epoch 334/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 17.4368 - mean_squared_error: 17.4368 - val_loss: 24.6899 - val_mean_squared_error: 24.6899\n",
      "Epoch 335/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.6916 - mean_squared_error: 17.6916 - val_loss: 24.6177 - val_mean_squared_error: 24.6177\n",
      "Epoch 336/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.5402 - mean_squared_error: 17.5402 - val_loss: 24.9196 - val_mean_squared_error: 24.9196\n",
      "Epoch 337/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.4061 - mean_squared_error: 17.4061 - val_loss: 24.8213 - val_mean_squared_error: 24.8213\n",
      "Epoch 338/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.4393 - mean_squared_error: 17.4393 - val_loss: 24.6605 - val_mean_squared_error: 24.6605\n",
      "Epoch 339/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 17.5510 - mean_squared_error: 17.5510 - val_loss: 24.5810 - val_mean_squared_error: 24.5810\n",
      "Epoch 340/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 17.9760 - mean_squared_error: 17.9760 - val_loss: 24.6088 - val_mean_squared_error: 24.6088\n",
      "Epoch 341/4000\n",
      "339/339 [==============================] - 0s 58us/sample - loss: 17.5804 - mean_squared_error: 17.5804 - val_loss: 25.2320 - val_mean_squared_error: 25.2320\n",
      "Epoch 342/4000\n",
      "339/339 [==============================] - 0s 118us/sample - loss: 17.4149 - mean_squared_error: 17.4149 - val_loss: 24.5952 - val_mean_squared_error: 24.5952\n",
      "Epoch 343/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 17.4188 - mean_squared_error: 17.4188 - val_loss: 24.7143 - val_mean_squared_error: 24.7143\n",
      "Epoch 344/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 17.4300 - mean_squared_error: 17.4300 - val_loss: 24.6005 - val_mean_squared_error: 24.6005\n",
      "Epoch 345/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.4360 - mean_squared_error: 17.4360 - val_loss: 25.5009 - val_mean_squared_error: 25.5009\n",
      "Epoch 346/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.4493 - mean_squared_error: 17.4493 - val_loss: 24.5151 - val_mean_squared_error: 24.5151\n",
      "Epoch 347/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.3627 - mean_squared_error: 17.3627 - val_loss: 24.7381 - val_mean_squared_error: 24.7381\n",
      "Epoch 348/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.4361 - mean_squared_error: 17.4361 - val_loss: 24.3956 - val_mean_squared_error: 24.3956\n",
      "Epoch 349/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.6682 - mean_squared_error: 17.6682 - val_loss: 26.9884 - val_mean_squared_error: 26.9884\n",
      "Epoch 350/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.7667 - mean_squared_error: 17.7667 - val_loss: 24.4257 - val_mean_squared_error: 24.4257\n",
      "Epoch 351/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.3728 - mean_squared_error: 17.3728 - val_loss: 24.8549 - val_mean_squared_error: 24.8549\n",
      "Epoch 352/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.4732 - mean_squared_error: 17.4732 - val_loss: 24.4198 - val_mean_squared_error: 24.4198\n",
      "Epoch 353/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.9883 - mean_squared_error: 17.9883 - val_loss: 24.3857 - val_mean_squared_error: 24.3857\n",
      "Epoch 354/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.9840 - mean_squared_error: 17.9840 - val_loss: 24.4290 - val_mean_squared_error: 24.4290\n",
      "Epoch 355/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.4263 - mean_squared_error: 17.4263 - val_loss: 25.0810 - val_mean_squared_error: 25.0810\n",
      "Epoch 356/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 17.3952 - mean_squared_error: 17.3952 - val_loss: 24.7718 - val_mean_squared_error: 24.7718\n",
      "Epoch 357/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.2760 - mean_squared_error: 17.2760 - val_loss: 24.4564 - val_mean_squared_error: 24.4564\n",
      "Epoch 358/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 17.9288 - mean_squared_error: 17.9288 - val_loss: 24.5662 - val_mean_squared_error: 24.5662\n",
      "Epoch 359/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 18.7657 - mean_squared_error: 18.7657 - val_loss: 24.4180 - val_mean_squared_error: 24.4180\n",
      "Epoch 360/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 18.3613 - mean_squared_error: 18.3613 - val_loss: 24.4089 - val_mean_squared_error: 24.4089\n",
      "Epoch 361/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.4286 - mean_squared_error: 17.4286 - val_loss: 25.2988 - val_mean_squared_error: 25.2988\n",
      "Epoch 362/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.3189 - mean_squared_error: 17.3189 - val_loss: 24.4016 - val_mean_squared_error: 24.4016\n",
      "Epoch 363/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.4252 - mean_squared_error: 17.4252 - val_loss: 24.2974 - val_mean_squared_error: 24.2974\n",
      "Epoch 364/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.6533 - mean_squared_error: 17.6533 - val_loss: 24.2780 - val_mean_squared_error: 24.2780\n",
      "Epoch 365/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.3148 - mean_squared_error: 17.3148 - val_loss: 24.9933 - val_mean_squared_error: 24.9933\n",
      "Epoch 366/4000\n",
      "339/339 [==============================] - 0s 17us/sample - loss: 17.2608 - mean_squared_error: 17.2608 - val_loss: 24.4074 - val_mean_squared_error: 24.4074\n",
      "Epoch 367/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.4434 - mean_squared_error: 17.4434 - val_loss: 24.2667 - val_mean_squared_error: 24.2667\n",
      "Epoch 368/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.3448 - mean_squared_error: 17.3448 - val_loss: 24.7441 - val_mean_squared_error: 24.7441\n",
      "Epoch 369/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.3339 - mean_squared_error: 17.3339 - val_loss: 24.2194 - val_mean_squared_error: 24.2194\n",
      "Epoch 370/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.3242 - mean_squared_error: 17.3242 - val_loss: 24.8474 - val_mean_squared_error: 24.8474\n",
      "Epoch 371/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.2210 - mean_squared_error: 17.2210 - val_loss: 24.2723 - val_mean_squared_error: 24.2723\n",
      "Epoch 372/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.2763 - mean_squared_error: 17.2763 - val_loss: 24.2136 - val_mean_squared_error: 24.2136\n",
      "Epoch 373/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.3303 - mean_squared_error: 17.3303 - val_loss: 25.7087 - val_mean_squared_error: 25.7087\n",
      "Epoch 374/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.4400 - mean_squared_error: 17.4400 - val_loss: 24.3504 - val_mean_squared_error: 24.3504\n",
      "Epoch 375/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.3945 - mean_squared_error: 17.3945 - val_loss: 24.1955 - val_mean_squared_error: 24.1955\n",
      "Epoch 376/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 34us/sample - loss: 17.3197 - mean_squared_error: 17.3197 - val_loss: 24.5461 - val_mean_squared_error: 24.5461\n",
      "Epoch 377/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.2345 - mean_squared_error: 17.2345 - val_loss: 24.1195 - val_mean_squared_error: 24.1195\n",
      "Epoch 378/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.2362 - mean_squared_error: 17.2362 - val_loss: 24.3299 - val_mean_squared_error: 24.3299\n",
      "Epoch 379/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 17.2052 - mean_squared_error: 17.2052 - val_loss: 24.8081 - val_mean_squared_error: 24.8081\n",
      "Epoch 380/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.4214 - mean_squared_error: 17.4214 - val_loss: 24.9333 - val_mean_squared_error: 24.9333\n",
      "Epoch 381/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 17.3795 - mean_squared_error: 17.3795 - val_loss: 24.7005 - val_mean_squared_error: 24.7005\n",
      "Epoch 382/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.1721 - mean_squared_error: 17.1721 - val_loss: 24.0935 - val_mean_squared_error: 24.0935\n",
      "Epoch 383/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 17.1672 - mean_squared_error: 17.1672 - val_loss: 24.4440 - val_mean_squared_error: 24.4440\n",
      "Epoch 384/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 17.1841 - mean_squared_error: 17.1841 - val_loss: 24.5110 - val_mean_squared_error: 24.5110\n",
      "Epoch 385/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 17.1686 - mean_squared_error: 17.1686 - val_loss: 24.0707 - val_mean_squared_error: 24.0707\n",
      "Epoch 386/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 17.1607 - mean_squared_error: 17.1607 - val_loss: 24.5291 - val_mean_squared_error: 24.5291\n",
      "Epoch 387/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 17.1091 - mean_squared_error: 17.1091 - val_loss: 24.1102 - val_mean_squared_error: 24.1102\n",
      "Epoch 388/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 17.1952 - mean_squared_error: 17.1952 - val_loss: 25.1580 - val_mean_squared_error: 25.1580\n",
      "Epoch 389/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 18.0424 - mean_squared_error: 18.0424 - val_loss: 25.9827 - val_mean_squared_error: 25.9827\n",
      "Epoch 390/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 17.3777 - mean_squared_error: 17.3777 - val_loss: 24.0472 - val_mean_squared_error: 24.0472\n",
      "Epoch 391/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 17.1906 - mean_squared_error: 17.1906 - val_loss: 25.3849 - val_mean_squared_error: 25.3849\n",
      "Epoch 392/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 17.6465 - mean_squared_error: 17.6465 - val_loss: 24.8271 - val_mean_squared_error: 24.8271\n",
      "Epoch 393/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 17.2623 - mean_squared_error: 17.2623 - val_loss: 24.4732 - val_mean_squared_error: 24.4732\n",
      "Epoch 394/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 17.6483 - mean_squared_error: 17.6483 - val_loss: 26.0579 - val_mean_squared_error: 26.0579\n",
      "Epoch 395/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 17.6231 - mean_squared_error: 17.6231 - val_loss: 24.2308 - val_mean_squared_error: 24.2308\n",
      "Epoch 396/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.0719 - mean_squared_error: 17.0719 - val_loss: 24.0390 - val_mean_squared_error: 24.0390\n",
      "Epoch 397/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 17.3024 - mean_squared_error: 17.3024 - val_loss: 23.9411 - val_mean_squared_error: 23.9411\n",
      "Epoch 398/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 17.1244 - mean_squared_error: 17.1244 - val_loss: 24.9450 - val_mean_squared_error: 24.9450\n",
      "Epoch 399/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.1474 - mean_squared_error: 17.1474 - val_loss: 23.9784 - val_mean_squared_error: 23.9784\n",
      "Epoch 400/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 17.1233 - mean_squared_error: 17.1233 - val_loss: 23.9750 - val_mean_squared_error: 23.9750\n",
      "Epoch 401/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.3186 - mean_squared_error: 17.3186 - val_loss: 23.8874 - val_mean_squared_error: 23.8874\n",
      "Epoch 402/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.6344 - mean_squared_error: 17.6344 - val_loss: 23.8608 - val_mean_squared_error: 23.8608\n",
      "Epoch 403/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.1221 - mean_squared_error: 17.1221 - val_loss: 24.3064 - val_mean_squared_error: 24.3064\n",
      "Epoch 404/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.0295 - mean_squared_error: 17.0295 - val_loss: 23.9939 - val_mean_squared_error: 23.9939\n",
      "Epoch 405/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 17.1408 - mean_squared_error: 17.1408 - val_loss: 24.9254 - val_mean_squared_error: 24.9254\n",
      "Epoch 406/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 17.3827 - mean_squared_error: 17.3827 - val_loss: 24.5271 - val_mean_squared_error: 24.5271\n",
      "Epoch 407/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.0590 - mean_squared_error: 17.0590 - val_loss: 23.9636 - val_mean_squared_error: 23.9636\n",
      "Epoch 408/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.0329 - mean_squared_error: 17.0329 - val_loss: 24.4972 - val_mean_squared_error: 24.4972\n",
      "Epoch 409/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 17.1099 - mean_squared_error: 17.1098 - val_loss: 24.1705 - val_mean_squared_error: 24.1705\n",
      "Epoch 410/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.1615 - mean_squared_error: 17.1615 - val_loss: 24.6718 - val_mean_squared_error: 24.6718\n",
      "Epoch 411/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.0470 - mean_squared_error: 17.0470 - val_loss: 23.8033 - val_mean_squared_error: 23.8033\n",
      "Epoch 412/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.0709 - mean_squared_error: 17.0709 - val_loss: 24.9909 - val_mean_squared_error: 24.9909\n",
      "Epoch 413/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 17.0953 - mean_squared_error: 17.0953 - val_loss: 23.8180 - val_mean_squared_error: 23.8180\n",
      "Epoch 414/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.1703 - mean_squared_error: 17.1703 - val_loss: 24.1368 - val_mean_squared_error: 24.1368\n",
      "Epoch 415/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.0234 - mean_squared_error: 17.0234 - val_loss: 24.3136 - val_mean_squared_error: 24.3136\n",
      "Epoch 416/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.2185 - mean_squared_error: 17.2185 - val_loss: 24.8111 - val_mean_squared_error: 24.8111\n",
      "Epoch 417/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.1230 - mean_squared_error: 17.1230 - val_loss: 24.0389 - val_mean_squared_error: 24.0389\n",
      "Epoch 418/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.0302 - mean_squared_error: 17.0302 - val_loss: 23.8048 - val_mean_squared_error: 23.8048\n",
      "Epoch 419/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.9827 - mean_squared_error: 16.9827 - val_loss: 24.5282 - val_mean_squared_error: 24.5282\n",
      "Epoch 420/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.0081 - mean_squared_error: 17.0081 - val_loss: 23.7720 - val_mean_squared_error: 23.7720\n",
      "Epoch 421/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.0741 - mean_squared_error: 17.0741 - val_loss: 24.0334 - val_mean_squared_error: 24.0334\n",
      "Epoch 422/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 17.0396 - mean_squared_error: 17.0396 - val_loss: 23.7676 - val_mean_squared_error: 23.7676\n",
      "Epoch 423/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 30us/sample - loss: 17.0632 - mean_squared_error: 17.0632 - val_loss: 23.9585 - val_mean_squared_error: 23.9585\n",
      "Epoch 424/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.9298 - mean_squared_error: 16.9298 - val_loss: 23.9649 - val_mean_squared_error: 23.9649\n",
      "Epoch 425/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.9553 - mean_squared_error: 16.9553 - val_loss: 24.2782 - val_mean_squared_error: 24.2782\n",
      "Epoch 426/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.9760 - mean_squared_error: 16.9760 - val_loss: 23.9674 - val_mean_squared_error: 23.9674\n",
      "Epoch 427/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.9997 - mean_squared_error: 16.9997 - val_loss: 24.5298 - val_mean_squared_error: 24.5298\n",
      "Epoch 428/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.0735 - mean_squared_error: 17.0735 - val_loss: 24.0683 - val_mean_squared_error: 24.0683\n",
      "Epoch 429/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.9075 - mean_squared_error: 16.9075 - val_loss: 23.7836 - val_mean_squared_error: 23.7836\n",
      "Epoch 430/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.2616 - mean_squared_error: 17.2616 - val_loss: 23.7648 - val_mean_squared_error: 23.7648\n",
      "Epoch 431/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 17.0680 - mean_squared_error: 17.0680 - val_loss: 24.2195 - val_mean_squared_error: 24.2195\n",
      "Epoch 432/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.9294 - mean_squared_error: 16.9294 - val_loss: 23.8875 - val_mean_squared_error: 23.8875\n",
      "Epoch 433/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.0432 - mean_squared_error: 17.0432 - val_loss: 24.7007 - val_mean_squared_error: 24.7007\n",
      "Epoch 434/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.2248 - mean_squared_error: 17.2248 - val_loss: 24.2801 - val_mean_squared_error: 24.2801\n",
      "Epoch 435/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.0377 - mean_squared_error: 17.0377 - val_loss: 24.2248 - val_mean_squared_error: 24.2248\n",
      "Epoch 436/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.3235 - mean_squared_error: 17.3235 - val_loss: 25.0693 - val_mean_squared_error: 25.0693\n",
      "Epoch 437/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.3277 - mean_squared_error: 17.3277 - val_loss: 24.2331 - val_mean_squared_error: 24.2331\n",
      "Epoch 438/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.9497 - mean_squared_error: 16.9497 - val_loss: 23.6604 - val_mean_squared_error: 23.6604\n",
      "Epoch 439/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 17.6139 - mean_squared_error: 17.6139 - val_loss: 23.6488 - val_mean_squared_error: 23.6488\n",
      "Epoch 440/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 17.0076 - mean_squared_error: 17.0076 - val_loss: 24.1190 - val_mean_squared_error: 24.1190\n",
      "Epoch 441/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.8802 - mean_squared_error: 16.8802 - val_loss: 23.8088 - val_mean_squared_error: 23.8088\n",
      "Epoch 442/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.8389 - mean_squared_error: 16.8389 - val_loss: 23.7060 - val_mean_squared_error: 23.7060\n",
      "Epoch 443/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.0641 - mean_squared_error: 17.0641 - val_loss: 24.9880 - val_mean_squared_error: 24.9880\n",
      "Epoch 444/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 17.0452 - mean_squared_error: 17.0452 - val_loss: 23.6708 - val_mean_squared_error: 23.6708\n",
      "Epoch 445/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.8588 - mean_squared_error: 16.8587 - val_loss: 23.6941 - val_mean_squared_error: 23.6941\n",
      "Epoch 446/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.1389 - mean_squared_error: 17.1389 - val_loss: 25.3564 - val_mean_squared_error: 25.3564\n",
      "Epoch 447/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 17.1146 - mean_squared_error: 17.1146 - val_loss: 23.5377 - val_mean_squared_error: 23.5377\n",
      "Epoch 448/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.8434 - mean_squared_error: 16.8434 - val_loss: 24.3054 - val_mean_squared_error: 24.3054\n",
      "Epoch 449/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 16.9842 - mean_squared_error: 16.9842 - val_loss: 23.9311 - val_mean_squared_error: 23.9311\n",
      "Epoch 450/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.9891 - mean_squared_error: 16.9891 - val_loss: 24.2229 - val_mean_squared_error: 24.2229\n",
      "Epoch 451/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.8902 - mean_squared_error: 16.8902 - val_loss: 23.6219 - val_mean_squared_error: 23.6219\n",
      "Epoch 452/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.8636 - mean_squared_error: 16.8636 - val_loss: 24.2669 - val_mean_squared_error: 24.2669\n",
      "Epoch 453/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 16.8934 - mean_squared_error: 16.8934 - val_loss: 23.4576 - val_mean_squared_error: 23.4576\n",
      "Epoch 454/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.1162 - mean_squared_error: 17.1162 - val_loss: 23.5532 - val_mean_squared_error: 23.5532\n",
      "Epoch 455/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.7772 - mean_squared_error: 16.7772 - val_loss: 23.7242 - val_mean_squared_error: 23.7242\n",
      "Epoch 456/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.8476 - mean_squared_error: 16.8476 - val_loss: 23.9519 - val_mean_squared_error: 23.9519\n",
      "Epoch 457/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 16.7976 - mean_squared_error: 16.7976 - val_loss: 23.3830 - val_mean_squared_error: 23.3830\n",
      "Epoch 458/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.8231 - mean_squared_error: 16.8231 - val_loss: 23.6711 - val_mean_squared_error: 23.6711\n",
      "Epoch 459/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.8027 - mean_squared_error: 16.8027 - val_loss: 23.8311 - val_mean_squared_error: 23.8311\n",
      "Epoch 460/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.7752 - mean_squared_error: 16.7752 - val_loss: 23.5480 - val_mean_squared_error: 23.5480\n",
      "Epoch 461/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 16.8364 - mean_squared_error: 16.8364 - val_loss: 24.1488 - val_mean_squared_error: 24.1488\n",
      "Epoch 462/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.1922 - mean_squared_error: 17.1922 - val_loss: 24.4458 - val_mean_squared_error: 24.4458\n",
      "Epoch 463/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 17.2627 - mean_squared_error: 17.2627 - val_loss: 24.2972 - val_mean_squared_error: 24.2972\n",
      "Epoch 464/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 16.8759 - mean_squared_error: 16.8759 - val_loss: 23.5990 - val_mean_squared_error: 23.5990\n",
      "Epoch 465/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 16.9388 - mean_squared_error: 16.9388 - val_loss: 24.5597 - val_mean_squared_error: 24.5597\n",
      "Epoch 466/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.1092 - mean_squared_error: 17.1092 - val_loss: 23.8705 - val_mean_squared_error: 23.8705\n",
      "Epoch 467/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.7634 - mean_squared_error: 16.7634 - val_loss: 23.3580 - val_mean_squared_error: 23.3580\n",
      "Epoch 468/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.7703 - mean_squared_error: 16.7703 - val_loss: 23.7804 - val_mean_squared_error: 23.7804\n",
      "Epoch 469/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.0120 - mean_squared_error: 17.0120 - val_loss: 23.4721 - val_mean_squared_error: 23.4721\n",
      "Epoch 470/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 31us/sample - loss: 17.5733 - mean_squared_error: 17.5733 - val_loss: 23.2527 - val_mean_squared_error: 23.2527\n",
      "Epoch 471/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.7813 - mean_squared_error: 16.7813 - val_loss: 23.5498 - val_mean_squared_error: 23.5498\n",
      "Epoch 472/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.7496 - mean_squared_error: 16.7496 - val_loss: 23.2105 - val_mean_squared_error: 23.2105\n",
      "Epoch 473/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.7387 - mean_squared_error: 16.7387 - val_loss: 23.8878 - val_mean_squared_error: 23.8878\n",
      "Epoch 474/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.8461 - mean_squared_error: 16.8461 - val_loss: 23.6143 - val_mean_squared_error: 23.6143\n",
      "Epoch 475/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.7614 - mean_squared_error: 16.7614 - val_loss: 23.1731 - val_mean_squared_error: 23.1731\n",
      "Epoch 476/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 16.7758 - mean_squared_error: 16.7758 - val_loss: 23.4264 - val_mean_squared_error: 23.4264\n",
      "Epoch 477/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.9208 - mean_squared_error: 16.9208 - val_loss: 23.2362 - val_mean_squared_error: 23.2362\n",
      "Epoch 478/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 17.1336 - mean_squared_error: 17.1336 - val_loss: 23.2374 - val_mean_squared_error: 23.2374\n",
      "Epoch 479/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.6923 - mean_squared_error: 16.6923 - val_loss: 23.3718 - val_mean_squared_error: 23.3718\n",
      "Epoch 480/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.8115 - mean_squared_error: 16.8115 - val_loss: 24.1975 - val_mean_squared_error: 24.1975\n",
      "Epoch 481/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 16.9247 - mean_squared_error: 16.9247 - val_loss: 23.6154 - val_mean_squared_error: 23.6154\n",
      "Epoch 482/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.7601 - mean_squared_error: 16.7601 - val_loss: 23.1403 - val_mean_squared_error: 23.1403\n",
      "Epoch 483/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 17.2588 - mean_squared_error: 17.2588 - val_loss: 23.1326 - val_mean_squared_error: 23.1326\n",
      "Epoch 484/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.0181 - mean_squared_error: 17.0181 - val_loss: 23.1899 - val_mean_squared_error: 23.1899\n",
      "Epoch 485/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.8452 - mean_squared_error: 16.8452 - val_loss: 23.1261 - val_mean_squared_error: 23.1261\n",
      "Epoch 486/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 17.1281 - mean_squared_error: 17.1281 - val_loss: 23.0869 - val_mean_squared_error: 23.0869\n",
      "Epoch 487/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 17.1106 - mean_squared_error: 17.1106 - val_loss: 23.0633 - val_mean_squared_error: 23.0633\n",
      "Epoch 488/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.7814 - mean_squared_error: 16.7814 - val_loss: 24.6528 - val_mean_squared_error: 24.6528\n",
      "Epoch 489/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.0715 - mean_squared_error: 17.0715 - val_loss: 23.3696 - val_mean_squared_error: 23.3696\n",
      "Epoch 490/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.8704 - mean_squared_error: 16.8704 - val_loss: 23.1391 - val_mean_squared_error: 23.1391\n",
      "Epoch 491/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.8596 - mean_squared_error: 16.8596 - val_loss: 23.4999 - val_mean_squared_error: 23.4999\n",
      "Epoch 492/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 17.0125 - mean_squared_error: 17.0125 - val_loss: 24.5107 - val_mean_squared_error: 24.5107\n",
      "Epoch 493/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 17.0022 - mean_squared_error: 17.0022 - val_loss: 23.3413 - val_mean_squared_error: 23.3413\n",
      "Epoch 494/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 20.1372 - mean_squared_error: 20.13 - 0s 27us/sample - loss: 16.6270 - mean_squared_error: 16.6270 - val_loss: 23.1233 - val_mean_squared_error: 23.1233\n",
      "Epoch 495/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.6310 - mean_squared_error: 16.6310 - val_loss: 23.3189 - val_mean_squared_error: 23.3189\n",
      "Epoch 496/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.6551 - mean_squared_error: 16.6551 - val_loss: 23.6277 - val_mean_squared_error: 23.6277\n",
      "Epoch 497/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.8082 - mean_squared_error: 16.8082 - val_loss: 23.8074 - val_mean_squared_error: 23.8074\n",
      "Epoch 498/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.9427 - mean_squared_error: 16.9427 - val_loss: 23.9466 - val_mean_squared_error: 23.9466\n",
      "Epoch 499/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.6819 - mean_squared_error: 16.6819 - val_loss: 23.0631 - val_mean_squared_error: 23.0631\n",
      "Epoch 500/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.8304 - mean_squared_error: 16.8304 - val_loss: 23.2488 - val_mean_squared_error: 23.2488\n",
      "Epoch 501/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.6186 - mean_squared_error: 16.6186 - val_loss: 23.5782 - val_mean_squared_error: 23.5782\n",
      "Epoch 502/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.7105 - mean_squared_error: 16.7105 - val_loss: 23.5556 - val_mean_squared_error: 23.5556\n",
      "Epoch 503/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.6483 - mean_squared_error: 16.6483 - val_loss: 22.9827 - val_mean_squared_error: 22.9827\n",
      "Epoch 504/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.7343 - mean_squared_error: 16.7343 - val_loss: 23.1608 - val_mean_squared_error: 23.1608\n",
      "Epoch 505/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 16.7673 - mean_squared_error: 16.7673 - val_loss: 24.2081 - val_mean_squared_error: 24.2081\n",
      "Epoch 506/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.7700 - mean_squared_error: 16.7700 - val_loss: 23.1137 - val_mean_squared_error: 23.1137\n",
      "Epoch 507/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.9217 - mean_squared_error: 16.9217 - val_loss: 23.0716 - val_mean_squared_error: 23.0716\n",
      "Epoch 508/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.7955 - mean_squared_error: 16.7955 - val_loss: 23.5331 - val_mean_squared_error: 23.5331\n",
      "Epoch 509/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.6949 - mean_squared_error: 16.6949 - val_loss: 22.9550 - val_mean_squared_error: 22.9550\n",
      "Epoch 510/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.7145 - mean_squared_error: 16.7145 - val_loss: 23.3363 - val_mean_squared_error: 23.3363\n",
      "Epoch 511/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.9733 - mean_squared_error: 16.9733 - val_loss: 24.5103 - val_mean_squared_error: 24.5103\n",
      "Epoch 512/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 17.0527 - mean_squared_error: 17.0527 - val_loss: 23.3765 - val_mean_squared_error: 23.3765\n",
      "Epoch 513/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 16.7740 - mean_squared_error: 16.7740 - val_loss: 23.7836 - val_mean_squared_error: 23.7836\n",
      "Epoch 514/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.8747 - mean_squared_error: 16.8747 - val_loss: 23.6581 - val_mean_squared_error: 23.6581\n",
      "Epoch 515/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.6786 - mean_squared_error: 16.6786 - val_loss: 22.9821 - val_mean_squared_error: 22.9821\n",
      "Epoch 516/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.0532 - mean_squared_error: 17.0532 - val_loss: 22.9251 - val_mean_squared_error: 22.9251\n",
      "Epoch 517/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 53us/sample - loss: 16.7111 - mean_squared_error: 16.7111 - val_loss: 22.8672 - val_mean_squared_error: 22.8672\n",
      "Epoch 518/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.8708 - mean_squared_error: 16.8708 - val_loss: 22.8110 - val_mean_squared_error: 22.8110\n",
      "Epoch 519/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.6478 - mean_squared_error: 16.6478 - val_loss: 22.9948 - val_mean_squared_error: 22.9948\n",
      "Epoch 520/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 16.9699 - mean_squared_error: 16.9699 - val_loss: 24.9193 - val_mean_squared_error: 24.9193\n",
      "Epoch 521/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.8036 - mean_squared_error: 16.8036 - val_loss: 22.8021 - val_mean_squared_error: 22.8021\n",
      "Epoch 522/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 16.7246 - mean_squared_error: 16.7246 - val_loss: 22.9613 - val_mean_squared_error: 22.9613\n",
      "Epoch 523/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.5611 - mean_squared_error: 16.5611 - val_loss: 23.5727 - val_mean_squared_error: 23.5727\n",
      "Epoch 524/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.5559 - mean_squared_error: 16.5559 - val_loss: 22.8452 - val_mean_squared_error: 22.8452\n",
      "Epoch 525/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 16.5014 - mean_squared_error: 16.5014 - val_loss: 23.2098 - val_mean_squared_error: 23.2098\n",
      "Epoch 526/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.6577 - mean_squared_error: 16.6577 - val_loss: 23.5265 - val_mean_squared_error: 23.5265\n",
      "Epoch 527/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 16.5471 - mean_squared_error: 16.5471 - val_loss: 22.7060 - val_mean_squared_error: 22.7060\n",
      "Epoch 528/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 16.6690 - mean_squared_error: 16.6690 - val_loss: 22.7831 - val_mean_squared_error: 22.7831\n",
      "Epoch 529/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.5271 - mean_squared_error: 16.5271 - val_loss: 23.4227 - val_mean_squared_error: 23.4227\n",
      "Epoch 530/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 16.5462 - mean_squared_error: 16.5462 - val_loss: 22.8647 - val_mean_squared_error: 22.8647\n",
      "Epoch 531/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.8601 - mean_squared_error: 16.8601 - val_loss: 24.6450 - val_mean_squared_error: 24.6450\n",
      "Epoch 532/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 17.3506 - mean_squared_error: 17.3506 - val_loss: 23.6352 - val_mean_squared_error: 23.6352\n",
      "Epoch 533/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.8463 - mean_squared_error: 16.8463 - val_loss: 23.4527 - val_mean_squared_error: 23.4527\n",
      "Epoch 534/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 16.6096 - mean_squared_error: 16.6096 - val_loss: 22.9616 - val_mean_squared_error: 22.9616\n",
      "Epoch 535/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.5408 - mean_squared_error: 16.5408 - val_loss: 22.6438 - val_mean_squared_error: 22.6438\n",
      "Epoch 536/4000\n",
      "339/339 [==============================] - 0s 71us/sample - loss: 16.8159 - mean_squared_error: 16.8159 - val_loss: 22.6529 - val_mean_squared_error: 22.6529\n",
      "Epoch 537/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 17.8723 - mean_squared_error: 17.8723 - val_loss: 23.3868 - val_mean_squared_error: 23.3868\n",
      "Epoch 538/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 17.9596 - mean_squared_error: 17.9597 - val_loss: 22.6076 - val_mean_squared_error: 22.6076\n",
      "Epoch 539/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 16.7085 - mean_squared_error: 16.7085 - val_loss: 22.5940 - val_mean_squared_error: 22.5940\n",
      "Epoch 540/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.9351 - mean_squared_error: 16.9351 - val_loss: 22.5751 - val_mean_squared_error: 22.5751\n",
      "Epoch 541/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 17.0045 - mean_squared_error: 17.0044 - val_loss: 22.5288 - val_mean_squared_error: 22.5288\n",
      "Epoch 542/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.8013 - mean_squared_error: 16.8013 - val_loss: 22.5051 - val_mean_squared_error: 22.5051\n",
      "Epoch 543/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.5839 - mean_squared_error: 16.5839 - val_loss: 22.5580 - val_mean_squared_error: 22.5580\n",
      "Epoch 544/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 16.5210 - mean_squared_error: 16.5210 - val_loss: 22.5068 - val_mean_squared_error: 22.5068\n",
      "Epoch 545/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 16.7841 - mean_squared_error: 16.7841 - val_loss: 22.4839 - val_mean_squared_error: 22.4839\n",
      "Epoch 546/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.4961 - mean_squared_error: 16.4961 - val_loss: 23.4278 - val_mean_squared_error: 23.4278\n",
      "Epoch 547/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.8019 - mean_squared_error: 16.8019 - val_loss: 23.1821 - val_mean_squared_error: 23.1821\n",
      "Epoch 548/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 16.4762 - mean_squared_error: 16.4762 - val_loss: 22.4119 - val_mean_squared_error: 22.4119\n",
      "Epoch 549/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.5701 - mean_squared_error: 16.5701 - val_loss: 23.9358 - val_mean_squared_error: 23.9358\n",
      "Epoch 550/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.9050 - mean_squared_error: 16.9050 - val_loss: 22.9795 - val_mean_squared_error: 22.9795\n",
      "Epoch 551/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.4454 - mean_squared_error: 16.4454 - val_loss: 22.5405 - val_mean_squared_error: 22.5405\n",
      "Epoch 552/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.4472 - mean_squared_error: 16.4472 - val_loss: 22.5586 - val_mean_squared_error: 22.5586\n",
      "Epoch 553/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.5153 - mean_squared_error: 16.5153 - val_loss: 22.3873 - val_mean_squared_error: 22.3873\n",
      "Epoch 554/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 17.0902 - mean_squared_error: 17.0902 - val_loss: 22.4734 - val_mean_squared_error: 22.4734\n",
      "Epoch 555/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 17.5211 - mean_squared_error: 17.5211 - val_loss: 22.3970 - val_mean_squared_error: 22.3970\n",
      "Epoch 556/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.6589 - mean_squared_error: 16.6589 - val_loss: 22.6079 - val_mean_squared_error: 22.6079\n",
      "Epoch 557/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.3808 - mean_squared_error: 16.3808 - val_loss: 22.4661 - val_mean_squared_error: 22.4661\n",
      "Epoch 558/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.3800 - mean_squared_error: 16.3800 - val_loss: 22.3754 - val_mean_squared_error: 22.3754\n",
      "Epoch 559/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 16.3792 - mean_squared_error: 16.3792 - val_loss: 22.8139 - val_mean_squared_error: 22.8139\n",
      "Epoch 560/4000\n",
      "339/339 [==============================] - 0s 69us/sample - loss: 16.3954 - mean_squared_error: 16.3954 - val_loss: 22.5534 - val_mean_squared_error: 22.5534\n",
      "Epoch 561/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.4130 - mean_squared_error: 16.4130 - val_loss: 22.2946 - val_mean_squared_error: 22.2946\n",
      "Epoch 562/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.5318 - mean_squared_error: 16.5318 - val_loss: 22.3380 - val_mean_squared_error: 22.3380\n",
      "Epoch 563/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.4924 - mean_squared_error: 16.4924 - val_loss: 22.2435 - val_mean_squared_error: 22.2435\n",
      "Epoch 564/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 26us/sample - loss: 16.8744 - mean_squared_error: 16.8744 - val_loss: 22.2539 - val_mean_squared_error: 22.2539\n",
      "Epoch 565/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.4701 - mean_squared_error: 16.4701 - val_loss: 22.8813 - val_mean_squared_error: 22.8813\n",
      "Epoch 566/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.3744 - mean_squared_error: 16.3744 - val_loss: 22.3401 - val_mean_squared_error: 22.3401\n",
      "Epoch 567/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.3969 - mean_squared_error: 16.3969 - val_loss: 23.0832 - val_mean_squared_error: 23.0832\n",
      "Epoch 568/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.9963 - mean_squared_error: 16.9963 - val_loss: 23.8634 - val_mean_squared_error: 23.8634\n",
      "Epoch 569/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.5202 - mean_squared_error: 16.5202 - val_loss: 22.2560 - val_mean_squared_error: 22.2560\n",
      "Epoch 570/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 16.5702 - mean_squared_error: 16.5702 - val_loss: 22.2686 - val_mean_squared_error: 22.2686\n",
      "Epoch 571/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 16.4113 - mean_squared_error: 16.4113 - val_loss: 22.4064 - val_mean_squared_error: 22.4064\n",
      "Epoch 572/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.3189 - mean_squared_error: 16.3189 - val_loss: 22.4163 - val_mean_squared_error: 22.4163\n",
      "Epoch 573/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 16.3013 - mean_squared_error: 16.3013 - val_loss: 22.5915 - val_mean_squared_error: 22.5915\n",
      "Epoch 574/4000\n",
      "339/339 [==============================] - 0s 0s/sample - loss: 16.3403 - mean_squared_error: 16.3403 - val_loss: 22.6605 - val_mean_squared_error: 22.6605\n",
      "Epoch 575/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 16.3208 - mean_squared_error: 16.3208 - val_loss: 22.3028 - val_mean_squared_error: 22.3028\n",
      "Epoch 576/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.2854 - mean_squared_error: 16.2854 - val_loss: 22.6217 - val_mean_squared_error: 22.6217\n",
      "Epoch 577/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.3934 - mean_squared_error: 16.3934 - val_loss: 22.9232 - val_mean_squared_error: 22.9232\n",
      "Epoch 578/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.2999 - mean_squared_error: 16.2999 - val_loss: 22.2346 - val_mean_squared_error: 22.2346\n",
      "Epoch 579/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.4414 - mean_squared_error: 16.4414 - val_loss: 22.2274 - val_mean_squared_error: 22.2274\n",
      "Epoch 580/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.5512 - mean_squared_error: 16.5512 - val_loss: 22.1982 - val_mean_squared_error: 22.1982\n",
      "Epoch 581/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 16.5275 - mean_squared_error: 16.5275 - val_loss: 22.2057 - val_mean_squared_error: 22.2057\n",
      "Epoch 582/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 17.2341 - mean_squared_error: 17.2341 - val_loss: 22.6123 - val_mean_squared_error: 22.6123\n",
      "Epoch 583/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 17.3937 - mean_squared_error: 17.3937 - val_loss: 22.1937 - val_mean_squared_error: 22.1937\n",
      "Epoch 584/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.5362 - mean_squared_error: 16.5362 - val_loss: 22.1790 - val_mean_squared_error: 22.1790\n",
      "Epoch 585/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.3060 - mean_squared_error: 16.3060 - val_loss: 22.5058 - val_mean_squared_error: 22.5058\n",
      "Epoch 586/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.3105 - mean_squared_error: 16.3105 - val_loss: 22.0796 - val_mean_squared_error: 22.0796\n",
      "Epoch 587/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 16.3093 - mean_squared_error: 16.3093 - val_loss: 22.9726 - val_mean_squared_error: 22.9726\n",
      "Epoch 588/4000\n",
      "339/339 [==============================] - 0s 65us/sample - loss: 16.3587 - mean_squared_error: 16.3587 - val_loss: 22.0757 - val_mean_squared_error: 22.0757\n",
      "Epoch 589/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.5732 - mean_squared_error: 16.5732 - val_loss: 22.1869 - val_mean_squared_error: 22.1869\n",
      "Epoch 590/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.2930 - mean_squared_error: 16.2930 - val_loss: 23.0230 - val_mean_squared_error: 23.0230\n",
      "Epoch 591/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.2936 - mean_squared_error: 16.2936 - val_loss: 22.1016 - val_mean_squared_error: 22.1016\n",
      "Epoch 592/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.2888 - mean_squared_error: 16.2888 - val_loss: 23.2199 - val_mean_squared_error: 23.2199\n",
      "Epoch 593/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.5296 - mean_squared_error: 16.5296 - val_loss: 22.5805 - val_mean_squared_error: 22.5805\n",
      "Epoch 594/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 16.2643 - mean_squared_error: 16.2643 - val_loss: 22.0342 - val_mean_squared_error: 22.0342\n",
      "Epoch 595/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 16.5342 - mean_squared_error: 16.5342 - val_loss: 22.0151 - val_mean_squared_error: 22.0151\n",
      "Epoch 596/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.2184 - mean_squared_error: 16.2184 - val_loss: 22.4417 - val_mean_squared_error: 22.4417\n",
      "Epoch 597/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 16.3037 - mean_squared_error: 16.3037 - val_loss: 22.0500 - val_mean_squared_error: 22.0500\n",
      "Epoch 598/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.5651 - mean_squared_error: 16.5651 - val_loss: 22.0694 - val_mean_squared_error: 22.0694\n",
      "Epoch 599/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.1753 - mean_squared_error: 16.1753 - val_loss: 22.3331 - val_mean_squared_error: 22.3331\n",
      "Epoch 600/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.2542 - mean_squared_error: 16.2542 - val_loss: 22.6107 - val_mean_squared_error: 22.6107\n",
      "Epoch 601/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.2783 - mean_squared_error: 16.2783 - val_loss: 22.0463 - val_mean_squared_error: 22.0463\n",
      "Epoch 602/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 17.0265 - mean_squared_error: 17.0265 - val_loss: 21.9874 - val_mean_squared_error: 21.9874\n",
      "Epoch 603/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.3776 - mean_squared_error: 16.3776 - val_loss: 24.3122 - val_mean_squared_error: 24.3122\n",
      "Epoch 604/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.4900 - mean_squared_error: 16.4900 - val_loss: 21.9799 - val_mean_squared_error: 21.9799\n",
      "Epoch 605/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 17.0557 - mean_squared_error: 17.0557 - val_loss: 21.9587 - val_mean_squared_error: 21.9587\n",
      "Epoch 606/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 16.2871 - mean_squared_error: 16.2871 - val_loss: 22.5477 - val_mean_squared_error: 22.5477\n",
      "Epoch 607/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 16.1723 - mean_squared_error: 16.1723 - val_loss: 21.9833 - val_mean_squared_error: 21.9833\n",
      "Epoch 608/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.1818 - mean_squared_error: 16.1818 - val_loss: 21.8493 - val_mean_squared_error: 21.8493\n",
      "Epoch 609/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.2291 - mean_squared_error: 16.2291 - val_loss: 21.8274 - val_mean_squared_error: 21.8274\n",
      "Epoch 610/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.2171 - mean_squared_error: 16.2171 - val_loss: 21.8817 - val_mean_squared_error: 21.8817\n",
      "Epoch 611/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 35us/sample - loss: 16.1712 - mean_squared_error: 16.1712 - val_loss: 22.9243 - val_mean_squared_error: 22.9243\n",
      "Epoch 612/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.2304 - mean_squared_error: 16.2304 - val_loss: 21.8429 - val_mean_squared_error: 21.8429\n",
      "Epoch 613/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.2015 - mean_squared_error: 16.2015 - val_loss: 22.6259 - val_mean_squared_error: 22.6259\n",
      "Epoch 614/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.1518 - mean_squared_error: 16.1518 - val_loss: 21.7832 - val_mean_squared_error: 21.7832\n",
      "Epoch 615/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.3039 - mean_squared_error: 16.3039 - val_loss: 21.8455 - val_mean_squared_error: 21.8455\n",
      "Epoch 616/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.1179 - mean_squared_error: 16.1179 - val_loss: 21.8970 - val_mean_squared_error: 21.8970\n",
      "Epoch 617/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.2967 - mean_squared_error: 16.2967 - val_loss: 23.2075 - val_mean_squared_error: 23.2075\n",
      "Epoch 618/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.2704 - mean_squared_error: 16.2704 - val_loss: 21.7979 - val_mean_squared_error: 21.7979\n",
      "Epoch 619/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.1848 - mean_squared_error: 16.1848 - val_loss: 21.7487 - val_mean_squared_error: 21.7487\n",
      "Epoch 620/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.1781 - mean_squared_error: 16.1781 - val_loss: 21.7912 - val_mean_squared_error: 21.7912\n",
      "Epoch 621/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.4202 - mean_squared_error: 16.4202 - val_loss: 21.6982 - val_mean_squared_error: 21.6982\n",
      "Epoch 622/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.3294 - mean_squared_error: 16.3294 - val_loss: 21.7699 - val_mean_squared_error: 21.7699\n",
      "Epoch 623/4000\n",
      "339/339 [==============================] - 0s 64us/sample - loss: 16.2001 - mean_squared_error: 16.2001 - val_loss: 21.6132 - val_mean_squared_error: 21.6132\n",
      "Epoch 624/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 16.7706 - mean_squared_error: 16.7706 - val_loss: 21.6766 - val_mean_squared_error: 21.6766\n",
      "Epoch 625/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.1915 - mean_squared_error: 16.1915 - val_loss: 23.2058 - val_mean_squared_error: 23.2058\n",
      "Epoch 626/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 16.3182 - mean_squared_error: 16.3182 - val_loss: 21.7386 - val_mean_squared_error: 21.7386\n",
      "Epoch 627/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 16.1234 - mean_squared_error: 16.1234 - val_loss: 21.6415 - val_mean_squared_error: 21.6415\n",
      "Epoch 628/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 16.0517 - mean_squared_error: 16.0517 - val_loss: 21.9656 - val_mean_squared_error: 21.9656\n",
      "Epoch 629/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 16.1111 - mean_squared_error: 16.1111 - val_loss: 22.2407 - val_mean_squared_error: 22.2407\n",
      "Epoch 630/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.2056 - mean_squared_error: 16.2056 - val_loss: 22.2936 - val_mean_squared_error: 22.2936\n",
      "Epoch 631/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 16.0677 - mean_squared_error: 16.0677 - val_loss: 21.6839 - val_mean_squared_error: 21.6839\n",
      "Epoch 632/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.0523 - mean_squared_error: 16.0523 - val_loss: 22.3784 - val_mean_squared_error: 22.3784\n",
      "Epoch 633/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.0517 - mean_squared_error: 16.0517 - val_loss: 21.5537 - val_mean_squared_error: 21.5537\n",
      "Epoch 634/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.1518 - mean_squared_error: 16.1518 - val_loss: 21.5389 - val_mean_squared_error: 21.5389\n",
      "Epoch 635/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.0516 - mean_squared_error: 16.0516 - val_loss: 22.1752 - val_mean_squared_error: 22.1752\n",
      "Epoch 636/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.2884 - mean_squared_error: 16.2884 - val_loss: 22.5568 - val_mean_squared_error: 22.5568\n",
      "Epoch 637/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.0691 - mean_squared_error: 16.0691 - val_loss: 21.5912 - val_mean_squared_error: 21.5912\n",
      "Epoch 638/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 16.1398 - mean_squared_error: 16.1398 - val_loss: 21.4967 - val_mean_squared_error: 21.4967\n",
      "Epoch 639/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.0153 - mean_squared_error: 16.0153 - val_loss: 22.5011 - val_mean_squared_error: 22.5011\n",
      "Epoch 640/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.5888 - mean_squared_error: 16.5888 - val_loss: 22.7739 - val_mean_squared_error: 22.7739\n",
      "Epoch 641/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 16.7711 - mean_squared_error: 16.7711 - val_loss: 22.9844 - val_mean_squared_error: 22.9844\n",
      "Epoch 642/4000\n",
      "339/339 [==============================] - 0s 8us/sample - loss: 16.2735 - mean_squared_error: 16.2735 - val_loss: 21.8694 - val_mean_squared_error: 21.8694\n",
      "Epoch 643/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 16.0448 - mean_squared_error: 16.0448 - val_loss: 21.5676 - val_mean_squared_error: 21.5676\n",
      "Epoch 644/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.0028 - mean_squared_error: 16.0028 - val_loss: 22.1408 - val_mean_squared_error: 22.1408\n",
      "Epoch 645/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 15.9614 - mean_squared_error: 15.9614 - val_loss: 21.5570 - val_mean_squared_error: 21.5570\n",
      "Epoch 646/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.9832 - mean_squared_error: 15.9832 - val_loss: 21.6494 - val_mean_squared_error: 21.6494\n",
      "Epoch 647/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.3766 - mean_squared_error: 16.3766 - val_loss: 21.6518 - val_mean_squared_error: 21.6518\n",
      "Epoch 648/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.4849 - mean_squared_error: 16.4849 - val_loss: 21.6634 - val_mean_squared_error: 21.6634\n",
      "Epoch 649/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.9186 - mean_squared_error: 15.9186 - val_loss: 21.8208 - val_mean_squared_error: 21.8208\n",
      "Epoch 650/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.9728 - mean_squared_error: 15.9728 - val_loss: 21.9752 - val_mean_squared_error: 21.9752\n",
      "Epoch 651/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.9190 - mean_squared_error: 15.9190 - val_loss: 21.5144 - val_mean_squared_error: 21.5144\n",
      "Epoch 652/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.1121 - mean_squared_error: 16.1121 - val_loss: 23.0390 - val_mean_squared_error: 23.0390\n",
      "Epoch 653/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.1838 - mean_squared_error: 16.1838 - val_loss: 21.5033 - val_mean_squared_error: 21.5033\n",
      "Epoch 654/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.9133 - mean_squared_error: 15.9133 - val_loss: 21.6104 - val_mean_squared_error: 21.6104\n",
      "Epoch 655/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.9545 - mean_squared_error: 15.9545 - val_loss: 22.0845 - val_mean_squared_error: 22.0845\n",
      "Epoch 656/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.9486 - mean_squared_error: 15.9486 - val_loss: 21.5793 - val_mean_squared_error: 21.5793\n",
      "Epoch 657/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.9015 - mean_squared_error: 15.9015 - val_loss: 21.8270 - val_mean_squared_error: 21.8270\n",
      "Epoch 658/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 32us/sample - loss: 16.1265 - mean_squared_error: 16.1265 - val_loss: 22.4542 - val_mean_squared_error: 22.4542\n",
      "Epoch 659/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.0168 - mean_squared_error: 16.0168 - val_loss: 21.5030 - val_mean_squared_error: 21.5030\n",
      "Epoch 660/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.9023 - mean_squared_error: 15.9023 - val_loss: 21.7582 - val_mean_squared_error: 21.7582\n",
      "Epoch 661/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.8975 - mean_squared_error: 15.8975 - val_loss: 21.6680 - val_mean_squared_error: 21.6680\n",
      "Epoch 662/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 16.0127 - mean_squared_error: 16.0127 - val_loss: 21.3023 - val_mean_squared_error: 21.3023\n",
      "Epoch 663/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.0146 - mean_squared_error: 16.0146 - val_loss: 21.5971 - val_mean_squared_error: 21.5971\n",
      "Epoch 664/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.8837 - mean_squared_error: 15.8837 - val_loss: 21.8039 - val_mean_squared_error: 21.8039\n",
      "Epoch 665/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.8519 - mean_squared_error: 15.8519 - val_loss: 21.3266 - val_mean_squared_error: 21.3266\n",
      "Epoch 666/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.8609 - mean_squared_error: 15.8609 - val_loss: 21.5746 - val_mean_squared_error: 21.5746\n",
      "Epoch 667/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.0681 - mean_squared_error: 16.0681 - val_loss: 21.3464 - val_mean_squared_error: 21.3464\n",
      "Epoch 668/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.3541 - mean_squared_error: 16.3541 - val_loss: 21.2973 - val_mean_squared_error: 21.2973\n",
      "Epoch 669/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.8441 - mean_squared_error: 15.8441 - val_loss: 21.3764 - val_mean_squared_error: 21.3764\n",
      "Epoch 670/4000\n",
      "339/339 [==============================] - 0s 69us/sample - loss: 15.8652 - mean_squared_error: 15.8652 - val_loss: 21.2123 - val_mean_squared_error: 21.2123\n",
      "Epoch 671/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.8245 - mean_squared_error: 15.8245 - val_loss: 21.5783 - val_mean_squared_error: 21.5783\n",
      "Epoch 672/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 16.3029 - mean_squared_error: 16.3029 - val_loss: 21.6216 - val_mean_squared_error: 21.6216\n",
      "Epoch 673/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.4051 - mean_squared_error: 16.4051 - val_loss: 21.5121 - val_mean_squared_error: 21.5121\n",
      "Epoch 674/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.8557 - mean_squared_error: 15.8557 - val_loss: 21.1309 - val_mean_squared_error: 21.1309\n",
      "Epoch 675/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.0926 - mean_squared_error: 16.0926 - val_loss: 21.1283 - val_mean_squared_error: 21.1283\n",
      "Epoch 676/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.9823 - mean_squared_error: 15.9823 - val_loss: 21.0947 - val_mean_squared_error: 21.0947\n",
      "Epoch 677/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.8169 - mean_squared_error: 15.8169 - val_loss: 21.8861 - val_mean_squared_error: 21.8861\n",
      "Epoch 678/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.3029 - mean_squared_error: 16.3029 - val_loss: 22.5056 - val_mean_squared_error: 22.5056\n",
      "Epoch 679/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 16.1406 - mean_squared_error: 16.1406 - val_loss: 21.4913 - val_mean_squared_error: 21.4913\n",
      "Epoch 680/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.8450 - mean_squared_error: 15.8450 - val_loss: 21.6407 - val_mean_squared_error: 21.6407\n",
      "Epoch 681/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.8044 - mean_squared_error: 15.8044 - val_loss: 21.3115 - val_mean_squared_error: 21.3115\n",
      "Epoch 682/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 15.8445 - mean_squared_error: 15.8445 - val_loss: 21.0378 - val_mean_squared_error: 21.0378\n",
      "Epoch 683/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.8465 - mean_squared_error: 15.8465 - val_loss: 21.2348 - val_mean_squared_error: 21.2348\n",
      "Epoch 684/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.7745 - mean_squared_error: 15.7745 - val_loss: 21.4180 - val_mean_squared_error: 21.4180\n",
      "Epoch 685/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.7638 - mean_squared_error: 15.7638 - val_loss: 21.1483 - val_mean_squared_error: 21.1483\n",
      "Epoch 686/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.0815 - mean_squared_error: 16.0815 - val_loss: 23.0127 - val_mean_squared_error: 23.0127\n",
      "Epoch 687/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.3040 - mean_squared_error: 16.3040 - val_loss: 21.3670 - val_mean_squared_error: 21.3670\n",
      "Epoch 688/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.7537 - mean_squared_error: 15.7537 - val_loss: 21.3107 - val_mean_squared_error: 21.3107\n",
      "Epoch 689/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.7360 - mean_squared_error: 15.7360 - val_loss: 21.0799 - val_mean_squared_error: 21.0799\n",
      "Epoch 690/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.7237 - mean_squared_error: 15.7237 - val_loss: 21.3058 - val_mean_squared_error: 21.3058\n",
      "Epoch 691/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.9733 - mean_squared_error: 15.9733 - val_loss: 22.2006 - val_mean_squared_error: 22.2006\n",
      "Epoch 692/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.2518 - mean_squared_error: 16.2518 - val_loss: 21.7819 - val_mean_squared_error: 21.7819\n",
      "Epoch 693/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.8278 - mean_squared_error: 15.8278 - val_loss: 21.0863 - val_mean_squared_error: 21.0863\n",
      "Epoch 694/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 16.0467 - mean_squared_error: 16.0467 - val_loss: 21.1403 - val_mean_squared_error: 21.1403\n",
      "Epoch 695/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 15.6972 - mean_squared_error: 15.6972 - val_loss: 21.1164 - val_mean_squared_error: 21.1164\n",
      "Epoch 696/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.6914 - mean_squared_error: 15.6914 - val_loss: 21.0257 - val_mean_squared_error: 21.0257\n",
      "Epoch 697/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 15.7537 - mean_squared_error: 15.7537 - val_loss: 21.6513 - val_mean_squared_error: 21.6513\n",
      "Epoch 698/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.0548 - mean_squared_error: 16.0548 - val_loss: 21.7984 - val_mean_squared_error: 21.7984\n",
      "Epoch 699/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 16.3133 - mean_squared_error: 16.3133 - val_loss: 22.5077 - val_mean_squared_error: 22.5077\n",
      "Epoch 700/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.9136 - mean_squared_error: 15.9136 - val_loss: 20.9551 - val_mean_squared_error: 20.9551\n",
      "Epoch 701/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 19.6370 - mean_squared_error: 19.63 - 0s 32us/sample - loss: 15.7451 - mean_squared_error: 15.7451 - val_loss: 21.1213 - val_mean_squared_error: 21.1213\n",
      "Epoch 702/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.6811 - mean_squared_error: 15.6811 - val_loss: 20.9396 - val_mean_squared_error: 20.9396\n",
      "Epoch 703/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.8819 - mean_squared_error: 15.8819 - val_loss: 22.5484 - val_mean_squared_error: 22.5484\n",
      "Epoch 704/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 16.2006 - mean_squared_error: 16.2006 - val_loss: 21.2968 - val_mean_squared_error: 21.2968\n",
      "Epoch 705/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 37us/sample - loss: 15.8602 - mean_squared_error: 15.8602 - val_loss: 21.7182 - val_mean_squared_error: 21.7182\n",
      "Epoch 706/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.9544 - mean_squared_error: 15.9544 - val_loss: 21.4989 - val_mean_squared_error: 21.4989\n",
      "Epoch 707/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.8054 - mean_squared_error: 15.8054 - val_loss: 21.2948 - val_mean_squared_error: 21.2948\n",
      "Epoch 708/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.7142 - mean_squared_error: 15.7142 - val_loss: 20.7648 - val_mean_squared_error: 20.7648\n",
      "Epoch 709/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.7335 - mean_squared_error: 15.7335 - val_loss: 21.0278 - val_mean_squared_error: 21.0278\n",
      "Epoch 710/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.7318 - mean_squared_error: 15.7318 - val_loss: 20.7605 - val_mean_squared_error: 20.7605\n",
      "Epoch 711/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.7070 - mean_squared_error: 15.7070 - val_loss: 21.9211 - val_mean_squared_error: 21.9211\n",
      "Epoch 712/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.0207 - mean_squared_error: 16.0207 - val_loss: 21.3475 - val_mean_squared_error: 21.3475\n",
      "Epoch 713/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.7190 - mean_squared_error: 15.7190 - val_loss: 21.1419 - val_mean_squared_error: 21.1419\n",
      "Epoch 714/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.7191 - mean_squared_error: 15.7191 - val_loss: 21.3082 - val_mean_squared_error: 21.3082\n",
      "Epoch 715/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 19.7561 - mean_squared_error: 19.75 - 0s 33us/sample - loss: 15.6900 - mean_squared_error: 15.6900 - val_loss: 20.9915 - val_mean_squared_error: 20.9915\n",
      "Epoch 716/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.8410 - mean_squared_error: 15.8410 - val_loss: 22.0140 - val_mean_squared_error: 22.0140\n",
      "Epoch 717/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.7649 - mean_squared_error: 15.7649 - val_loss: 20.8685 - val_mean_squared_error: 20.8685\n",
      "Epoch 718/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.9908 - mean_squared_error: 15.9908 - val_loss: 20.8507 - val_mean_squared_error: 20.8507\n",
      "Epoch 719/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.8288 - mean_squared_error: 15.8288 - val_loss: 20.7116 - val_mean_squared_error: 20.7116\n",
      "Epoch 720/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.7957 - mean_squared_error: 15.7957 - val_loss: 20.8349 - val_mean_squared_error: 20.8349\n",
      "Epoch 721/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.6538 - mean_squared_error: 15.6538 - val_loss: 20.7340 - val_mean_squared_error: 20.7340\n",
      "Epoch 722/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.6595 - mean_squared_error: 15.6595 - val_loss: 20.7790 - val_mean_squared_error: 20.7790\n",
      "Epoch 723/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.5752 - mean_squared_error: 15.5752 - val_loss: 20.9392 - val_mean_squared_error: 20.9392\n",
      "Epoch 724/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.6603 - mean_squared_error: 15.6603 - val_loss: 21.1647 - val_mean_squared_error: 21.1647\n",
      "Epoch 725/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 15.8168 - mean_squared_error: 15.8168 - val_loss: 21.2902 - val_mean_squared_error: 21.2902\n",
      "Epoch 726/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.8528 - mean_squared_error: 15.8528 - val_loss: 21.4004 - val_mean_squared_error: 21.4004\n",
      "Epoch 727/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.6229 - mean_squared_error: 15.6229 - val_loss: 20.6016 - val_mean_squared_error: 20.6016\n",
      "Epoch 728/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 16.2028 - mean_squared_error: 16.2028 - val_loss: 20.6927 - val_mean_squared_error: 20.6927\n",
      "Epoch 729/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 16.0077 - mean_squared_error: 16.0077 - val_loss: 20.6802 - val_mean_squared_error: 20.6802\n",
      "Epoch 730/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.8608 - mean_squared_error: 15.8608 - val_loss: 20.5722 - val_mean_squared_error: 20.5722\n",
      "Epoch 731/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.7440 - mean_squared_error: 15.7440 - val_loss: 20.8815 - val_mean_squared_error: 20.8815\n",
      "Epoch 732/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.6202 - mean_squared_error: 15.6202 - val_loss: 21.0243 - val_mean_squared_error: 21.0243\n",
      "Epoch 733/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.5641 - mean_squared_error: 15.5641 - val_loss: 20.5721 - val_mean_squared_error: 20.5721\n",
      "Epoch 734/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.7052 - mean_squared_error: 15.7052 - val_loss: 20.5309 - val_mean_squared_error: 20.5309\n",
      "Epoch 735/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.6096 - mean_squared_error: 15.6096 - val_loss: 20.9343 - val_mean_squared_error: 20.9343\n",
      "Epoch 736/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.5513 - mean_squared_error: 15.5513 - val_loss: 20.5922 - val_mean_squared_error: 20.5922\n",
      "Epoch 737/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.6486 - mean_squared_error: 15.6486 - val_loss: 21.6305 - val_mean_squared_error: 21.6305\n",
      "Epoch 738/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.7747 - mean_squared_error: 15.7747 - val_loss: 20.8111 - val_mean_squared_error: 20.8111\n",
      "Epoch 739/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 15.5604 - mean_squared_error: 15.5604 - val_loss: 20.5944 - val_mean_squared_error: 20.5944\n",
      "Epoch 740/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.5386 - mean_squared_error: 15.5386 - val_loss: 20.7703 - val_mean_squared_error: 20.7703\n",
      "Epoch 741/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.5619 - mean_squared_error: 15.5619 - val_loss: 20.7116 - val_mean_squared_error: 20.7116\n",
      "Epoch 742/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.6273 - mean_squared_error: 15.6273 - val_loss: 20.4510 - val_mean_squared_error: 20.4510\n",
      "Epoch 743/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.7807 - mean_squared_error: 15.7807 - val_loss: 20.4791 - val_mean_squared_error: 20.4791\n",
      "Epoch 744/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.5200 - mean_squared_error: 15.5200 - val_loss: 20.7319 - val_mean_squared_error: 20.7319\n",
      "Epoch 745/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.5495 - mean_squared_error: 15.5495 - val_loss: 20.3535 - val_mean_squared_error: 20.3535\n",
      "Epoch 746/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.7717 - mean_squared_error: 15.7717 - val_loss: 20.3709 - val_mean_squared_error: 20.3709\n",
      "Epoch 747/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.6167 - mean_squared_error: 15.6167 - val_loss: 20.4910 - val_mean_squared_error: 20.4910\n",
      "Epoch 748/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.5335 - mean_squared_error: 15.5335 - val_loss: 21.0372 - val_mean_squared_error: 21.0372\n",
      "Epoch 749/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.6549 - mean_squared_error: 15.6549 - val_loss: 20.4133 - val_mean_squared_error: 20.4133\n",
      "Epoch 750/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.7739 - mean_squared_error: 15.7739 - val_loss: 20.5139 - val_mean_squared_error: 20.5139\n",
      "Epoch 751/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.4920 - mean_squared_error: 15.4920 - val_loss: 20.6490 - val_mean_squared_error: 20.6490\n",
      "Epoch 752/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 31us/sample - loss: 15.5575 - mean_squared_error: 15.5575 - val_loss: 20.3225 - val_mean_squared_error: 20.3225\n",
      "Epoch 753/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.8454 - mean_squared_error: 15.8454 - val_loss: 22.1341 - val_mean_squared_error: 22.1341\n",
      "Epoch 754/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.1587 - mean_squared_error: 16.1587 - val_loss: 20.8138 - val_mean_squared_error: 20.8138\n",
      "Epoch 755/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.5831 - mean_squared_error: 15.5831 - val_loss: 20.8057 - val_mean_squared_error: 20.8057\n",
      "Epoch 756/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.4978 - mean_squared_error: 15.4978 - val_loss: 20.4313 - val_mean_squared_error: 20.4313\n",
      "Epoch 757/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.4898 - mean_squared_error: 15.4898 - val_loss: 20.4326 - val_mean_squared_error: 20.4326\n",
      "Epoch 758/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.9902 - mean_squared_error: 15.9902 - val_loss: 20.5804 - val_mean_squared_error: 20.5804\n",
      "Epoch 759/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.8915 - mean_squared_error: 15.8915 - val_loss: 20.5950 - val_mean_squared_error: 20.5950\n",
      "Epoch 760/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.4888 - mean_squared_error: 15.4888 - val_loss: 20.2595 - val_mean_squared_error: 20.2595\n",
      "Epoch 761/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.4765 - mean_squared_error: 15.4765 - val_loss: 20.5412 - val_mean_squared_error: 20.5412\n",
      "Epoch 762/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.5389 - mean_squared_error: 15.5389 - val_loss: 20.8250 - val_mean_squared_error: 20.8250\n",
      "Epoch 763/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.5436 - mean_squared_error: 15.5436 - val_loss: 20.4643 - val_mean_squared_error: 20.4643\n",
      "Epoch 764/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.4512 - mean_squared_error: 15.4512 - val_loss: 20.2653 - val_mean_squared_error: 20.2653\n",
      "Epoch 765/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.5488 - mean_squared_error: 15.5488 - val_loss: 20.1998 - val_mean_squared_error: 20.1998\n",
      "Epoch 766/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.7233 - mean_squared_error: 15.7233 - val_loss: 20.1809 - val_mean_squared_error: 20.1809\n",
      "Epoch 767/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 15.4905 - mean_squared_error: 15.4905 - val_loss: 20.6866 - val_mean_squared_error: 20.6866\n",
      "Epoch 768/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.5902 - mean_squared_error: 15.5902 - val_loss: 20.7451 - val_mean_squared_error: 20.7451\n",
      "Epoch 769/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.5489 - mean_squared_error: 15.5489 - val_loss: 20.7641 - val_mean_squared_error: 20.7641\n",
      "Epoch 770/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.4844 - mean_squared_error: 15.4844 - val_loss: 20.1998 - val_mean_squared_error: 20.1998\n",
      "Epoch 771/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 16.0003 - mean_squared_error: 16.0003 - val_loss: 20.3455 - val_mean_squared_error: 20.3455\n",
      "Epoch 772/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 16.2865 - mean_squared_error: 16.2865 - val_loss: 20.1482 - val_mean_squared_error: 20.1482\n",
      "Epoch 773/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.7227 - mean_squared_error: 15.7227 - val_loss: 20.1375 - val_mean_squared_error: 20.1375\n",
      "Epoch 774/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.4337 - mean_squared_error: 15.4337 - val_loss: 20.3884 - val_mean_squared_error: 20.3884\n",
      "Epoch 775/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.4267 - mean_squared_error: 15.4267 - val_loss: 20.1504 - val_mean_squared_error: 20.1504\n",
      "Epoch 776/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.4395 - mean_squared_error: 15.4395 - val_loss: 20.2299 - val_mean_squared_error: 20.2299\n",
      "Epoch 777/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.4127 - mean_squared_error: 15.4127 - val_loss: 20.2439 - val_mean_squared_error: 20.2439\n",
      "Epoch 778/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.3920 - mean_squared_error: 15.3920 - val_loss: 20.3206 - val_mean_squared_error: 20.3206\n",
      "Epoch 779/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.5149 - mean_squared_error: 15.5149 - val_loss: 20.8028 - val_mean_squared_error: 20.8028\n",
      "Epoch 780/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.4572 - mean_squared_error: 15.4572 - val_loss: 20.2960 - val_mean_squared_error: 20.2960\n",
      "Epoch 781/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.4715 - mean_squared_error: 15.4715 - val_loss: 20.7893 - val_mean_squared_error: 20.7893\n",
      "Epoch 782/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.4420 - mean_squared_error: 15.4420 - val_loss: 20.1053 - val_mean_squared_error: 20.1053\n",
      "Epoch 783/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.4590 - mean_squared_error: 15.4590 - val_loss: 21.2151 - val_mean_squared_error: 21.2151\n",
      "Epoch 784/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.5286 - mean_squared_error: 15.5286 - val_loss: 20.1496 - val_mean_squared_error: 20.1496\n",
      "Epoch 785/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 15.4064 - mean_squared_error: 15.4064 - val_loss: 20.7212 - val_mean_squared_error: 20.7212\n",
      "Epoch 786/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.5110 - mean_squared_error: 15.5110 - val_loss: 20.4438 - val_mean_squared_error: 20.4438\n",
      "Epoch 787/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.3763 - mean_squared_error: 15.3763 - val_loss: 20.2922 - val_mean_squared_error: 20.2922\n",
      "Epoch 788/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.4976 - mean_squared_error: 15.4976 - val_loss: 20.0597 - val_mean_squared_error: 20.0597\n",
      "Epoch 789/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.6715 - mean_squared_error: 15.6715 - val_loss: 20.0558 - val_mean_squared_error: 20.0558\n",
      "Epoch 790/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.5550 - mean_squared_error: 15.5550 - val_loss: 21.8324 - val_mean_squared_error: 21.8324\n",
      "Epoch 791/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.7831 - mean_squared_error: 16.7831 - val_loss: 22.2386 - val_mean_squared_error: 22.2386\n",
      "Epoch 792/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.1218 - mean_squared_error: 16.1218 - val_loss: 20.5857 - val_mean_squared_error: 20.5857\n",
      "Epoch 793/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.5168 - mean_squared_error: 15.5168 - val_loss: 20.7945 - val_mean_squared_error: 20.7945\n",
      "Epoch 794/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.7391 - mean_squared_error: 15.7391 - val_loss: 21.1240 - val_mean_squared_error: 21.1240\n",
      "Epoch 795/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 15.6737 - mean_squared_error: 15.6737 - val_loss: 20.5621 - val_mean_squared_error: 20.5621\n",
      "Epoch 796/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 15.3726 - mean_squared_error: 15.3726 - val_loss: 20.1895 - val_mean_squared_error: 20.1895\n",
      "Epoch 797/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.4433 - mean_squared_error: 15.4433 - val_loss: 20.6509 - val_mean_squared_error: 20.6509\n",
      "Epoch 798/4000\n",
      "339/339 [==============================] - 0s 65us/sample - loss: 15.3963 - mean_squared_error: 15.3963 - val_loss: 20.1125 - val_mean_squared_error: 20.1125\n",
      "Epoch 799/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 39us/sample - loss: 15.4528 - mean_squared_error: 15.4528 - val_loss: 20.2990 - val_mean_squared_error: 20.2990\n",
      "Epoch 800/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.6540 - mean_squared_error: 15.6540 - val_loss: 21.4920 - val_mean_squared_error: 21.4920\n",
      "Epoch 801/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.4841 - mean_squared_error: 15.4841 - val_loss: 20.1089 - val_mean_squared_error: 20.1089\n",
      "Epoch 802/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.7572 - mean_squared_error: 15.7572 - val_loss: 20.0363 - val_mean_squared_error: 20.0363\n",
      "Epoch 803/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.4333 - mean_squared_error: 15.4333 - val_loss: 20.1047 - val_mean_squared_error: 20.1047\n",
      "Epoch 804/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.5850 - mean_squared_error: 15.5850 - val_loss: 19.9929 - val_mean_squared_error: 19.9929\n",
      "Epoch 805/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.2931 - mean_squared_error: 16.2931 - val_loss: 20.1015 - val_mean_squared_error: 20.1015\n",
      "Epoch 806/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.4949 - mean_squared_error: 15.4949 - val_loss: 21.2383 - val_mean_squared_error: 21.2383\n",
      "Epoch 807/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 15.5770 - mean_squared_error: 15.5770 - val_loss: 20.1066 - val_mean_squared_error: 20.1066\n",
      "Epoch 808/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 15.3792 - mean_squared_error: 15.3792 - val_loss: 19.9241 - val_mean_squared_error: 19.9241\n",
      "Epoch 809/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 16.2129 - mean_squared_error: 16.2129 - val_loss: 20.2909 - val_mean_squared_error: 20.2909\n",
      "Epoch 810/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 17.2933 - mean_squared_error: 17.2933 - val_loss: 20.1953 - val_mean_squared_error: 20.1953\n",
      "Epoch 811/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.5160 - mean_squared_error: 15.5160 - val_loss: 21.7162 - val_mean_squared_error: 21.7162\n",
      "Epoch 812/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 15.5711 - mean_squared_error: 15.5711 - val_loss: 19.9175 - val_mean_squared_error: 19.9175\n",
      "Epoch 813/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 15.7726 - mean_squared_error: 15.7726 - val_loss: 19.8420 - val_mean_squared_error: 19.8420\n",
      "Epoch 814/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.5069 - mean_squared_error: 15.5069 - val_loss: 19.8632 - val_mean_squared_error: 19.8632\n",
      "Epoch 815/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.4019 - mean_squared_error: 15.4019 - val_loss: 21.1879 - val_mean_squared_error: 21.1879\n",
      "Epoch 816/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.7398 - mean_squared_error: 15.7398 - val_loss: 20.4427 - val_mean_squared_error: 20.4427\n",
      "Epoch 817/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.3324 - mean_squared_error: 15.3324 - val_loss: 19.8885 - val_mean_squared_error: 19.8885\n",
      "Epoch 818/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.3493 - mean_squared_error: 15.3493 - val_loss: 19.9516 - val_mean_squared_error: 19.9516\n",
      "Epoch 819/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.5440 - mean_squared_error: 15.5440 - val_loss: 19.9071 - val_mean_squared_error: 19.9071\n",
      "Epoch 820/4000\n",
      "339/339 [==============================] - 0s 64us/sample - loss: 15.4629 - mean_squared_error: 15.4629 - val_loss: 20.2119 - val_mean_squared_error: 20.2119\n",
      "Epoch 821/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.3276 - mean_squared_error: 15.3276 - val_loss: 20.1690 - val_mean_squared_error: 20.1690\n",
      "Epoch 822/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.5375 - mean_squared_error: 15.5375 - val_loss: 20.8697 - val_mean_squared_error: 20.8697\n",
      "Epoch 823/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.3499 - mean_squared_error: 15.3499 - val_loss: 19.8071 - val_mean_squared_error: 19.8071\n",
      "Epoch 824/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 15.5030 - mean_squared_error: 15.5030 - val_loss: 19.7983 - val_mean_squared_error: 19.7983\n",
      "Epoch 825/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 15.4975 - mean_squared_error: 15.4975 - val_loss: 19.7414 - val_mean_squared_error: 19.7414\n",
      "Epoch 826/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.8631 - mean_squared_error: 15.8631 - val_loss: 19.9318 - val_mean_squared_error: 19.9318\n",
      "Epoch 827/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 16.0064 - mean_squared_error: 16.0064 - val_loss: 19.7115 - val_mean_squared_error: 19.7115\n",
      "Epoch 828/4000\n",
      "339/339 [==============================] - 0s 65us/sample - loss: 15.3201 - mean_squared_error: 15.3201 - val_loss: 20.9678 - val_mean_squared_error: 20.9678\n",
      "Epoch 829/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 15.9799 - mean_squared_error: 15.9799 - val_loss: 20.8355 - val_mean_squared_error: 20.8355\n",
      "Epoch 830/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.5513 - mean_squared_error: 15.5513 - val_loss: 20.1075 - val_mean_squared_error: 20.1075\n",
      "Epoch 831/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.2580 - mean_squared_error: 15.2580 - val_loss: 19.7222 - val_mean_squared_error: 19.7222\n",
      "Epoch 832/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.3139 - mean_squared_error: 15.3139 - val_loss: 19.9013 - val_mean_squared_error: 19.9013\n",
      "Epoch 833/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.2006 - mean_squared_error: 15.2006 - val_loss: 19.7005 - val_mean_squared_error: 19.7005\n",
      "Epoch 834/4000\n",
      "339/339 [==============================] - 0s 72us/sample - loss: 15.2119 - mean_squared_error: 15.2119 - val_loss: 20.1527 - val_mean_squared_error: 20.1527\n",
      "Epoch 835/4000\n",
      "339/339 [==============================] - 0s 67us/sample - loss: 15.2376 - mean_squared_error: 15.2376 - val_loss: 19.6764 - val_mean_squared_error: 19.6764\n",
      "Epoch 836/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 15.2934 - mean_squared_error: 15.2934 - val_loss: 20.6456 - val_mean_squared_error: 20.6456\n",
      "Epoch 837/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 15.3042 - mean_squared_error: 15.3042 - val_loss: 19.8511 - val_mean_squared_error: 19.8511\n",
      "Epoch 838/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 15.5965 - mean_squared_error: 15.5965 - val_loss: 19.8097 - val_mean_squared_error: 19.8097\n",
      "Epoch 839/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.2829 - mean_squared_error: 15.2829 - val_loss: 19.6447 - val_mean_squared_error: 19.6447\n",
      "Epoch 840/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.2238 - mean_squared_error: 15.2238 - val_loss: 20.5386 - val_mean_squared_error: 20.5386\n",
      "Epoch 841/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.5523 - mean_squared_error: 15.5523 - val_loss: 20.3040 - val_mean_squared_error: 20.3040\n",
      "Epoch 842/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 15.2029 - mean_squared_error: 15.2029 - val_loss: 19.5971 - val_mean_squared_error: 19.5971\n",
      "Epoch 843/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 15.2348 - mean_squared_error: 15.2348 - val_loss: 20.0315 - val_mean_squared_error: 20.0315\n",
      "Epoch 844/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 14.0567 - mean_squared_error: 14.05 - 0s 57us/sample - loss: 15.3003 - mean_squared_error: 15.3003 - val_loss: 20.2336 - val_mean_squared_error: 20.2336\n",
      "Epoch 845/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.1958 - mean_squared_error: 15.1958 - val_loss: 19.5634 - val_mean_squared_error: 19.5634\n",
      "Epoch 846/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 40us/sample - loss: 15.4373 - mean_squared_error: 15.4373 - val_loss: 21.6312 - val_mean_squared_error: 21.6312\n",
      "Epoch 847/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.7272 - mean_squared_error: 15.7272 - val_loss: 19.7778 - val_mean_squared_error: 19.7778\n",
      "Epoch 848/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.4327 - mean_squared_error: 15.4327 - val_loss: 19.6939 - val_mean_squared_error: 19.6939\n",
      "Epoch 849/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 16.1811 - mean_squared_error: 16.1811 - val_loss: 19.6508 - val_mean_squared_error: 19.6508\n",
      "Epoch 850/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.4756 - mean_squared_error: 15.4756 - val_loss: 19.6478 - val_mean_squared_error: 19.6478\n",
      "Epoch 851/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.1749 - mean_squared_error: 15.1749 - val_loss: 19.5128 - val_mean_squared_error: 19.5128\n",
      "Epoch 852/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.1833 - mean_squared_error: 15.1833 - val_loss: 20.5233 - val_mean_squared_error: 20.5233\n",
      "Epoch 853/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 15.2409 - mean_squared_error: 15.2409 - val_loss: 19.4886 - val_mean_squared_error: 19.4886\n",
      "Epoch 854/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 15.1591 - mean_squared_error: 15.1591 - val_loss: 20.2605 - val_mean_squared_error: 20.2605\n",
      "Epoch 855/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 15.3446 - mean_squared_error: 15.3446 - val_loss: 20.0047 - val_mean_squared_error: 20.0047\n",
      "Epoch 856/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.4788 - mean_squared_error: 15.4788 - val_loss: 20.5931 - val_mean_squared_error: 20.5931\n",
      "Epoch 857/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.2235 - mean_squared_error: 15.2235 - val_loss: 19.5838 - val_mean_squared_error: 19.5838\n",
      "Epoch 858/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.0988 - mean_squared_error: 15.0988 - val_loss: 19.8578 - val_mean_squared_error: 19.8578\n",
      "Epoch 859/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.1539 - mean_squared_error: 15.1539 - val_loss: 19.4920 - val_mean_squared_error: 19.4920\n",
      "Epoch 860/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.4570 - mean_squared_error: 15.4570 - val_loss: 19.4919 - val_mean_squared_error: 19.4919\n",
      "Epoch 861/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.1674 - mean_squared_error: 15.1674 - val_loss: 19.5654 - val_mean_squared_error: 19.5654\n",
      "Epoch 862/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1294 - mean_squared_error: 15.1294 - val_loss: 20.1877 - val_mean_squared_error: 20.1877\n",
      "Epoch 863/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 15.7028 - mean_squared_error: 15.7028 - val_loss: 20.9678 - val_mean_squared_error: 20.9678\n",
      "Epoch 864/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.6898 - mean_squared_error: 15.6898 - val_loss: 20.0954 - val_mean_squared_error: 20.0954\n",
      "Epoch 865/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.1238 - mean_squared_error: 15.1238 - val_loss: 19.4436 - val_mean_squared_error: 19.4436\n",
      "Epoch 866/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.1305 - mean_squared_error: 15.1305 - val_loss: 19.6876 - val_mean_squared_error: 19.6876\n",
      "Epoch 867/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.2951 - mean_squared_error: 15.2951 - val_loss: 20.7119 - val_mean_squared_error: 20.7119\n",
      "Epoch 868/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.5818 - mean_squared_error: 15.5818 - val_loss: 20.0681 - val_mean_squared_error: 20.0681\n",
      "Epoch 869/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.2152 - mean_squared_error: 15.2152 - val_loss: 19.8819 - val_mean_squared_error: 19.8819\n",
      "Epoch 870/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.2602 - mean_squared_error: 15.2602 - val_loss: 20.2064 - val_mean_squared_error: 20.2064\n",
      "Epoch 871/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 15.1738 - mean_squared_error: 15.1738 - val_loss: 19.6791 - val_mean_squared_error: 19.6791\n",
      "Epoch 872/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 15.0864 - mean_squared_error: 15.0864 - val_loss: 19.4121 - val_mean_squared_error: 19.4121\n",
      "Epoch 873/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.0671 - mean_squared_error: 15.0671 - val_loss: 19.7192 - val_mean_squared_error: 19.7192\n",
      "Epoch 874/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.0417 - mean_squared_error: 15.0417 - val_loss: 19.6163 - val_mean_squared_error: 19.6163\n",
      "Epoch 875/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.0888 - mean_squared_error: 15.0888 - val_loss: 19.9839 - val_mean_squared_error: 19.9839\n",
      "Epoch 876/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.5508 - mean_squared_error: 15.5508 - val_loss: 20.8835 - val_mean_squared_error: 20.8835\n",
      "Epoch 877/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.3193 - mean_squared_error: 15.3193 - val_loss: 19.5341 - val_mean_squared_error: 19.5341\n",
      "Epoch 878/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.3728 - mean_squared_error: 15.3728 - val_loss: 21.3949 - val_mean_squared_error: 21.3949\n",
      "Epoch 879/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 16.1279 - mean_squared_error: 16.1279 - val_loss: 20.6108 - val_mean_squared_error: 20.6108\n",
      "Epoch 880/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.1723 - mean_squared_error: 15.1723 - val_loss: 19.4399 - val_mean_squared_error: 19.4399\n",
      "Epoch 881/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.6853 - mean_squared_error: 15.6853 - val_loss: 19.6235 - val_mean_squared_error: 19.6235\n",
      "Epoch 882/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.3381 - mean_squared_error: 15.3381 - val_loss: 19.5778 - val_mean_squared_error: 19.5778\n",
      "Epoch 883/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.0885 - mean_squared_error: 15.0885 - val_loss: 19.3015 - val_mean_squared_error: 19.3015\n",
      "Epoch 884/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.1054 - mean_squared_error: 15.1054 - val_loss: 19.6091 - val_mean_squared_error: 19.6091\n",
      "Epoch 885/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.2142 - mean_squared_error: 15.2142 - val_loss: 20.3786 - val_mean_squared_error: 20.3786\n",
      "Epoch 886/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.8126 - mean_squared_error: 15.8126 - val_loss: 20.9026 - val_mean_squared_error: 20.9026\n",
      "Epoch 887/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.8129 - mean_squared_error: 15.8129 - val_loss: 20.2662 - val_mean_squared_error: 20.2662\n",
      "Epoch 888/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.0447 - mean_squared_error: 15.0447 - val_loss: 19.3610 - val_mean_squared_error: 19.3610\n",
      "Epoch 889/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.0513 - mean_squared_error: 15.0513 - val_loss: 19.6385 - val_mean_squared_error: 19.6385\n",
      "Epoch 890/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.0624 - mean_squared_error: 15.0624 - val_loss: 19.3273 - val_mean_squared_error: 19.3273\n",
      "Epoch 891/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.4207 - mean_squared_error: 15.4207 - val_loss: 19.2896 - val_mean_squared_error: 19.2896\n",
      "Epoch 892/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.0049 - mean_squared_error: 15.0049 - val_loss: 20.3360 - val_mean_squared_error: 20.3360\n",
      "Epoch 893/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1032 - mean_squared_error: 15.1032 - val_loss: 19.3121 - val_mean_squared_error: 19.3121\n",
      "Epoch 894/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 15.0273 - mean_squared_error: 15.0273 - val_loss: 20.2921 - val_mean_squared_error: 20.2921\n",
      "Epoch 895/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.0913 - mean_squared_error: 15.0913 - val_loss: 19.2897 - val_mean_squared_error: 19.2897\n",
      "Epoch 896/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 15.2017 - mean_squared_error: 15.2017 - val_loss: 21.0319 - val_mean_squared_error: 21.0319\n",
      "Epoch 897/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.4588 - mean_squared_error: 15.4588 - val_loss: 19.5993 - val_mean_squared_error: 19.5993\n",
      "Epoch 898/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.9846 - mean_squared_error: 14.9846 - val_loss: 19.6227 - val_mean_squared_error: 19.6227\n",
      "Epoch 899/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.6339 - mean_squared_error: 15.6339 - val_loss: 20.2581 - val_mean_squared_error: 20.2581\n",
      "Epoch 900/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.1046 - mean_squared_error: 16.1046 - val_loss: 19.3557 - val_mean_squared_error: 19.3557\n",
      "Epoch 901/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.9248 - mean_squared_error: 14.9248 - val_loss: 19.4558 - val_mean_squared_error: 19.4558\n",
      "Epoch 902/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 14.9318 - mean_squared_error: 14.9318 - val_loss: 19.4628 - val_mean_squared_error: 19.4628\n",
      "Epoch 903/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 15.0987 - mean_squared_error: 15.0987 - val_loss: 19.2249 - val_mean_squared_error: 19.2249\n",
      "Epoch 904/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.2854 - mean_squared_error: 15.2854 - val_loss: 19.2075 - val_mean_squared_error: 19.2075\n",
      "Epoch 905/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.9356 - mean_squared_error: 14.9356 - val_loss: 19.3264 - val_mean_squared_error: 19.3264\n",
      "Epoch 906/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.9151 - mean_squared_error: 14.9151 - val_loss: 19.2758 - val_mean_squared_error: 19.2758\n",
      "Epoch 907/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.9608 - mean_squared_error: 14.9608 - val_loss: 19.8898 - val_mean_squared_error: 19.8898\n",
      "Epoch 908/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.0464 - mean_squared_error: 15.0464 - val_loss: 19.3799 - val_mean_squared_error: 19.3799\n",
      "Epoch 909/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.9012 - mean_squared_error: 14.9012 - val_loss: 19.2489 - val_mean_squared_error: 19.2489\n",
      "Epoch 910/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.9756 - mean_squared_error: 14.9756 - val_loss: 20.1385 - val_mean_squared_error: 20.1385\n",
      "Epoch 911/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 15.0775 - mean_squared_error: 15.0775 - val_loss: 19.3491 - val_mean_squared_error: 19.3491\n",
      "Epoch 912/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 15.0551 - mean_squared_error: 15.0551 - val_loss: 20.2595 - val_mean_squared_error: 20.2595\n",
      "Epoch 913/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.0234 - mean_squared_error: 15.0234 - val_loss: 19.1512 - val_mean_squared_error: 19.1512\n",
      "Epoch 914/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.9237 - mean_squared_error: 14.9237 - val_loss: 19.8528 - val_mean_squared_error: 19.8528\n",
      "Epoch 915/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.9490 - mean_squared_error: 14.9490 - val_loss: 19.2175 - val_mean_squared_error: 19.2175\n",
      "Epoch 916/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.0691 - mean_squared_error: 15.0691 - val_loss: 20.5630 - val_mean_squared_error: 20.5630\n",
      "Epoch 917/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.7705 - mean_squared_error: 15.7705 - val_loss: 20.3095 - val_mean_squared_error: 20.3095\n",
      "Epoch 918/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.1900 - mean_squared_error: 15.1900 - val_loss: 19.4798 - val_mean_squared_error: 19.4798\n",
      "Epoch 919/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.0034 - mean_squared_error: 15.0034 - val_loss: 19.2175 - val_mean_squared_error: 19.2175\n",
      "Epoch 920/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1944 - mean_squared_error: 15.1944 - val_loss: 19.2259 - val_mean_squared_error: 19.2259\n",
      "Epoch 921/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.9000 - mean_squared_error: 14.9000 - val_loss: 19.3778 - val_mean_squared_error: 19.3778\n",
      "Epoch 922/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.2451 - mean_squared_error: 15.2451 - val_loss: 20.8693 - val_mean_squared_error: 20.8693\n",
      "Epoch 923/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.4900 - mean_squared_error: 15.4900 - val_loss: 19.8447 - val_mean_squared_error: 19.8447\n",
      "Epoch 924/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.9944 - mean_squared_error: 14.9944 - val_loss: 19.6482 - val_mean_squared_error: 19.6482\n",
      "Epoch 925/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.9067 - mean_squared_error: 14.9067 - val_loss: 19.5174 - val_mean_squared_error: 19.5174\n",
      "Epoch 926/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.1941 - mean_squared_error: 15.1941 - val_loss: 20.6409 - val_mean_squared_error: 20.6409\n",
      "Epoch 927/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.1092 - mean_squared_error: 15.1092 - val_loss: 19.2836 - val_mean_squared_error: 19.2836\n",
      "Epoch 928/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.9510 - mean_squared_error: 14.9510 - val_loss: 20.0788 - val_mean_squared_error: 20.0788\n",
      "Epoch 929/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.0418 - mean_squared_error: 15.0418 - val_loss: 19.4765 - val_mean_squared_error: 19.4765\n",
      "Epoch 930/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.9089 - mean_squared_error: 14.9089 - val_loss: 19.1410 - val_mean_squared_error: 19.1410\n",
      "Epoch 931/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.8700 - mean_squared_error: 14.8700 - val_loss: 19.7225 - val_mean_squared_error: 19.7225\n",
      "Epoch 932/4000\n",
      "339/339 [==============================] - 0s 16us/sample - loss: 14.8816 - mean_squared_error: 14.8816 - val_loss: 19.0845 - val_mean_squared_error: 19.0845\n",
      "Epoch 933/4000\n",
      "339/339 [==============================] - 0s 11us/sample - loss: 14.8665 - mean_squared_error: 14.8665 - val_loss: 19.2397 - val_mean_squared_error: 19.2397\n",
      "Epoch 934/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.0522 - mean_squared_error: 15.0522 - val_loss: 19.1417 - val_mean_squared_error: 19.1417\n",
      "Epoch 935/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.7852 - mean_squared_error: 15.7852 - val_loss: 19.1607 - val_mean_squared_error: 19.1607\n",
      "Epoch 936/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 15.0376 - mean_squared_error: 15.0376 - val_loss: 19.3847 - val_mean_squared_error: 19.3847\n",
      "Epoch 937/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.8810 - mean_squared_error: 14.8810 - val_loss: 19.3291 - val_mean_squared_error: 19.3291\n",
      "Epoch 938/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.8237 - mean_squared_error: 14.8237 - val_loss: 19.1908 - val_mean_squared_error: 19.1908\n",
      "Epoch 939/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 14.8274 - mean_squared_error: 14.8274 - val_loss: 19.1033 - val_mean_squared_error: 19.1033\n",
      "Epoch 940/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 31us/sample - loss: 14.7956 - mean_squared_error: 14.7956 - val_loss: 19.1658 - val_mean_squared_error: 19.1658\n",
      "Epoch 941/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.8685 - mean_squared_error: 14.8685 - val_loss: 19.5298 - val_mean_squared_error: 19.5298\n",
      "Epoch 942/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.2901 - mean_squared_error: 15.2901 - val_loss: 20.2994 - val_mean_squared_error: 20.2994\n",
      "Epoch 943/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.0619 - mean_squared_error: 15.0619 - val_loss: 19.0531 - val_mean_squared_error: 19.0531\n",
      "Epoch 944/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.6005 - mean_squared_error: 15.6005 - val_loss: 18.9249 - val_mean_squared_error: 18.9249\n",
      "Epoch 945/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.8768 - mean_squared_error: 14.8768 - val_loss: 19.7813 - val_mean_squared_error: 19.7813\n",
      "Epoch 946/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.3120 - mean_squared_error: 15.3120 - val_loss: 19.9363 - val_mean_squared_error: 19.9363\n",
      "Epoch 947/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.9238 - mean_squared_error: 14.9238 - val_loss: 18.9945 - val_mean_squared_error: 18.9945\n",
      "Epoch 948/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.6525 - mean_squared_error: 15.6525 - val_loss: 19.6885 - val_mean_squared_error: 19.6885\n",
      "Epoch 949/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 16.4802 - mean_squared_error: 16.4802 - val_loss: 19.0723 - val_mean_squared_error: 19.0723\n",
      "Epoch 950/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.0073 - mean_squared_error: 15.0073 - val_loss: 19.1286 - val_mean_squared_error: 19.1286\n",
      "Epoch 951/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.0472 - mean_squared_error: 15.0472 - val_loss: 19.0285 - val_mean_squared_error: 19.0285\n",
      "Epoch 952/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 15.7500 - mean_squared_error: 15.7500 - val_loss: 19.0244 - val_mean_squared_error: 19.0244\n",
      "Epoch 953/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.2647 - mean_squared_error: 15.2647 - val_loss: 18.8839 - val_mean_squared_error: 18.8839\n",
      "Epoch 954/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.0238 - mean_squared_error: 15.0238 - val_loss: 18.8549 - val_mean_squared_error: 18.8549\n",
      "Epoch 955/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.8310 - mean_squared_error: 14.8310 - val_loss: 19.2542 - val_mean_squared_error: 19.2542\n",
      "Epoch 956/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.9075 - mean_squared_error: 14.9075 - val_loss: 18.8607 - val_mean_squared_error: 18.8607\n",
      "Epoch 957/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 15.6042 - mean_squared_error: 15.6042 - val_loss: 18.8838 - val_mean_squared_error: 18.8838\n",
      "Epoch 958/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.3247 - mean_squared_error: 15.3247 - val_loss: 18.8062 - val_mean_squared_error: 18.8062\n",
      "Epoch 959/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.8256 - mean_squared_error: 14.8256 - val_loss: 18.9339 - val_mean_squared_error: 18.9339\n",
      "Epoch 960/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 14.9060 - mean_squared_error: 14.9060 - val_loss: 18.8046 - val_mean_squared_error: 18.8046\n",
      "Epoch 961/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.8116 - mean_squared_error: 14.8116 - val_loss: 19.3732 - val_mean_squared_error: 19.3732\n",
      "Epoch 962/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.1667 - mean_squared_error: 15.1667 - val_loss: 19.9761 - val_mean_squared_error: 19.9761\n",
      "Epoch 963/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.4309 - mean_squared_error: 15.4309 - val_loss: 19.9591 - val_mean_squared_error: 19.9591\n",
      "Epoch 964/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.0693 - mean_squared_error: 15.0693 - val_loss: 19.2045 - val_mean_squared_error: 19.2045\n",
      "Epoch 965/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.7895 - mean_squared_error: 14.7895 - val_loss: 19.1281 - val_mean_squared_error: 19.1281\n",
      "Epoch 966/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.4604 - mean_squared_error: 15.4604 - val_loss: 21.6377 - val_mean_squared_error: 21.6377\n",
      "Epoch 967/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.4325 - mean_squared_error: 15.4325 - val_loss: 18.9453 - val_mean_squared_error: 18.9453\n",
      "Epoch 968/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.1337 - mean_squared_error: 15.1337 - val_loss: 19.0225 - val_mean_squared_error: 19.0225\n",
      "Epoch 969/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.3635 - mean_squared_error: 15.3636 - val_loss: 18.8239 - val_mean_squared_error: 18.8239\n",
      "Epoch 970/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.8926 - mean_squared_error: 14.8926 - val_loss: 20.3087 - val_mean_squared_error: 20.3087\n",
      "Epoch 971/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.0986 - mean_squared_error: 15.0986 - val_loss: 19.0090 - val_mean_squared_error: 19.0090\n",
      "Epoch 972/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.7501 - mean_squared_error: 14.7501 - val_loss: 18.8796 - val_mean_squared_error: 18.8796\n",
      "Epoch 973/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.7387 - mean_squared_error: 14.7387 - val_loss: 19.0141 - val_mean_squared_error: 19.0141\n",
      "Epoch 974/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.7334 - mean_squared_error: 14.7334 - val_loss: 19.0554 - val_mean_squared_error: 19.0554\n",
      "Epoch 975/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.7451 - mean_squared_error: 14.7451 - val_loss: 18.7965 - val_mean_squared_error: 18.7965\n",
      "Epoch 976/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7884 - mean_squared_error: 14.7883 - val_loss: 19.7184 - val_mean_squared_error: 19.7184\n",
      "Epoch 977/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.3123 - mean_squared_error: 15.3123 - val_loss: 20.0387 - val_mean_squared_error: 20.0387\n",
      "Epoch 978/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.9187 - mean_squared_error: 15.9187 - val_loss: 20.9331 - val_mean_squared_error: 20.9331\n",
      "Epoch 979/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.6597 - mean_squared_error: 15.6597 - val_loss: 19.5156 - val_mean_squared_error: 19.5156\n",
      "Epoch 980/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 19.7400 - mean_squared_error: 19.74 - 0s 45us/sample - loss: 14.9746 - mean_squared_error: 14.9746 - val_loss: 19.4380 - val_mean_squared_error: 19.4380\n",
      "Epoch 981/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.7914 - mean_squared_error: 14.7914 - val_loss: 18.9176 - val_mean_squared_error: 18.9176\n",
      "Epoch 982/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.8390 - mean_squared_error: 14.8390 - val_loss: 19.1784 - val_mean_squared_error: 19.1784\n",
      "Epoch 983/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.9241 - mean_squared_error: 14.9241 - val_loss: 19.5374 - val_mean_squared_error: 19.5374\n",
      "Epoch 984/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.9847 - mean_squared_error: 14.9847 - val_loss: 19.2755 - val_mean_squared_error: 19.2755\n",
      "Epoch 985/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.7268 - mean_squared_error: 14.7268 - val_loss: 18.7647 - val_mean_squared_error: 18.7647\n",
      "Epoch 986/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.7367 - mean_squared_error: 14.7367 - val_loss: 19.3860 - val_mean_squared_error: 19.3860\n",
      "Epoch 987/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 38us/sample - loss: 14.7854 - mean_squared_error: 14.7854 - val_loss: 18.8923 - val_mean_squared_error: 18.8923\n",
      "Epoch 988/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.8336 - mean_squared_error: 14.8336 - val_loss: 18.6610 - val_mean_squared_error: 18.6610\n",
      "Epoch 989/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.7695 - mean_squared_error: 14.7695 - val_loss: 18.9596 - val_mean_squared_error: 18.9596\n",
      "Epoch 990/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.7564 - mean_squared_error: 14.7564 - val_loss: 18.6407 - val_mean_squared_error: 18.6407\n",
      "Epoch 991/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.0750 - mean_squared_error: 15.0750 - val_loss: 18.5908 - val_mean_squared_error: 18.5908\n",
      "Epoch 992/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.3433 - mean_squared_error: 15.3433 - val_loss: 18.8322 - val_mean_squared_error: 18.8322\n",
      "Epoch 993/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 15.3712 - mean_squared_error: 15.3712 - val_loss: 18.6122 - val_mean_squared_error: 18.6122\n",
      "Epoch 994/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.8771 - mean_squared_error: 14.8771 - val_loss: 18.5943 - val_mean_squared_error: 18.5943\n",
      "Epoch 995/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.7805 - mean_squared_error: 14.7805 - val_loss: 18.5884 - val_mean_squared_error: 18.5884\n",
      "Epoch 996/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6776 - mean_squared_error: 14.6776 - val_loss: 19.0854 - val_mean_squared_error: 19.0854\n",
      "Epoch 997/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.8399 - mean_squared_error: 14.8399 - val_loss: 19.0291 - val_mean_squared_error: 19.0291\n",
      "Epoch 998/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6995 - mean_squared_error: 14.6995 - val_loss: 18.6946 - val_mean_squared_error: 18.6946\n",
      "Epoch 999/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6602 - mean_squared_error: 14.6602 - val_loss: 18.7548 - val_mean_squared_error: 18.7548\n",
      "Epoch 1000/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.8930 - mean_squared_error: 14.8930 - val_loss: 19.8799 - val_mean_squared_error: 19.8799\n",
      "Epoch 1001/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.8471 - mean_squared_error: 14.8471 - val_loss: 18.6021 - val_mean_squared_error: 18.6021\n",
      "Epoch 1002/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 14.8725 - mean_squared_error: 14.8725 - val_loss: 18.5812 - val_mean_squared_error: 18.5812\n",
      "Epoch 1003/4000\n",
      "339/339 [==============================] - 0s 19us/sample - loss: 14.9137 - mean_squared_error: 14.9137 - val_loss: 18.6138 - val_mean_squared_error: 18.6138\n",
      "Epoch 1004/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.8035 - mean_squared_error: 14.8035 - val_loss: 20.1396 - val_mean_squared_error: 20.1396\n",
      "Epoch 1005/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.9037 - mean_squared_error: 14.9037 - val_loss: 19.0972 - val_mean_squared_error: 19.0972\n",
      "Epoch 1006/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.0758 - mean_squared_error: 16.0758 - val_loss: 18.6812 - val_mean_squared_error: 18.6812\n",
      "Epoch 1007/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 15.1308 - mean_squared_error: 15.1308 - val_loss: 18.5998 - val_mean_squared_error: 18.5998\n",
      "Epoch 1008/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 14.8404 - mean_squared_error: 14.8404 - val_loss: 18.5486 - val_mean_squared_error: 18.5486\n",
      "Epoch 1009/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.6578 - mean_squared_error: 14.6578 - val_loss: 18.8949 - val_mean_squared_error: 18.8949\n",
      "Epoch 1010/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.7502 - mean_squared_error: 14.7502 - val_loss: 19.1159 - val_mean_squared_error: 19.1159\n",
      "Epoch 1011/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.6673 - mean_squared_error: 14.6673 - val_loss: 18.5393 - val_mean_squared_error: 18.5393\n",
      "Epoch 1012/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.6738 - mean_squared_error: 14.6738 - val_loss: 19.0780 - val_mean_squared_error: 19.0780\n",
      "Epoch 1013/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.7556 - mean_squared_error: 14.7556 - val_loss: 18.8528 - val_mean_squared_error: 18.8528\n",
      "Epoch 1014/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6824 - mean_squared_error: 14.6824 - val_loss: 18.5464 - val_mean_squared_error: 18.5464\n",
      "Epoch 1015/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.7362 - mean_squared_error: 14.7362 - val_loss: 19.4809 - val_mean_squared_error: 19.4809\n",
      "Epoch 1016/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.9861 - mean_squared_error: 14.9861 - val_loss: 19.1715 - val_mean_squared_error: 19.1715\n",
      "Epoch 1017/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.0170 - mean_squared_error: 15.0170 - val_loss: 19.5906 - val_mean_squared_error: 19.5906\n",
      "Epoch 1018/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8814 - mean_squared_error: 14.8814 - val_loss: 19.0797 - val_mean_squared_error: 19.0797\n",
      "Epoch 1019/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.1969 - mean_squared_error: 16.1969 - val_loss: 18.6499 - val_mean_squared_error: 18.6499\n",
      "Epoch 1020/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.8058 - mean_squared_error: 14.8058 - val_loss: 18.8491 - val_mean_squared_error: 18.8491\n",
      "Epoch 1021/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6286 - mean_squared_error: 14.6286 - val_loss: 18.4691 - val_mean_squared_error: 18.4691\n",
      "Epoch 1022/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8205 - mean_squared_error: 14.8205 - val_loss: 18.4663 - val_mean_squared_error: 18.4663\n",
      "Epoch 1023/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6346 - mean_squared_error: 14.6346 - val_loss: 18.7791 - val_mean_squared_error: 18.7791\n",
      "Epoch 1024/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.6193 - mean_squared_error: 14.6193 - val_loss: 18.5495 - val_mean_squared_error: 18.5495\n",
      "Epoch 1025/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.6676 - mean_squared_error: 14.6676 - val_loss: 18.4533 - val_mean_squared_error: 18.4533\n",
      "Epoch 1026/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.9925 - mean_squared_error: 14.9925 - val_loss: 18.5203 - val_mean_squared_error: 18.5203\n",
      "Epoch 1027/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.7973 - mean_squared_error: 14.7973 - val_loss: 18.6931 - val_mean_squared_error: 18.6931\n",
      "Epoch 1028/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.9000 - mean_squared_error: 14.9000 - val_loss: 19.7528 - val_mean_squared_error: 19.7528\n",
      "Epoch 1029/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.7964 - mean_squared_error: 14.7964 - val_loss: 18.8121 - val_mean_squared_error: 18.8121\n",
      "Epoch 1030/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.5943 - mean_squared_error: 15.5943 - val_loss: 18.4936 - val_mean_squared_error: 18.4936\n",
      "Epoch 1031/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.7076 - mean_squared_error: 14.7076 - val_loss: 19.9617 - val_mean_squared_error: 19.9617\n",
      "Epoch 1032/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 10.5597 - mean_squared_error: 10.55 - 0s 31us/sample - loss: 14.8136 - mean_squared_error: 14.8136 - val_loss: 18.4472 - val_mean_squared_error: 18.4472\n",
      "Epoch 1033/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.6628 - mean_squared_error: 14.6628 - val_loss: 18.7134 - val_mean_squared_error: 18.7134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1034/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.9314 - mean_squared_error: 14.9314 - val_loss: 19.7629 - val_mean_squared_error: 19.7629\n",
      "Epoch 1035/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.7542 - mean_squared_error: 14.7542 - val_loss: 18.4798 - val_mean_squared_error: 18.4798\n",
      "Epoch 1036/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.6142 - mean_squared_error: 14.6142 - val_loss: 18.8839 - val_mean_squared_error: 18.8839\n",
      "Epoch 1037/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.0646 - mean_squared_error: 15.0646 - val_loss: 19.8047 - val_mean_squared_error: 19.8047\n",
      "Epoch 1038/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.7327 - mean_squared_error: 15.7327 - val_loss: 19.8164 - val_mean_squared_error: 19.8164\n",
      "Epoch 1039/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.0314 - mean_squared_error: 15.0314 - val_loss: 18.6952 - val_mean_squared_error: 18.6952\n",
      "Epoch 1040/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.7079 - mean_squared_error: 14.7079 - val_loss: 19.0519 - val_mean_squared_error: 19.0519\n",
      "Epoch 1041/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.7467 - mean_squared_error: 14.7467 - val_loss: 18.7547 - val_mean_squared_error: 18.7547\n",
      "Epoch 1042/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.6694 - mean_squared_error: 14.6694 - val_loss: 18.6773 - val_mean_squared_error: 18.6773\n",
      "Epoch 1043/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.0137 - mean_squared_error: 15.0137 - val_loss: 20.0054 - val_mean_squared_error: 20.0054\n",
      "Epoch 1044/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.8893 - mean_squared_error: 14.8893 - val_loss: 18.3745 - val_mean_squared_error: 18.3745\n",
      "Epoch 1045/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.8846 - mean_squared_error: 14.8846 - val_loss: 18.3893 - val_mean_squared_error: 18.3893\n",
      "Epoch 1046/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5981 - mean_squared_error: 14.5981 - val_loss: 19.2471 - val_mean_squared_error: 19.2471\n",
      "Epoch 1047/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.6694 - mean_squared_error: 14.6694 - val_loss: 18.3757 - val_mean_squared_error: 18.3757\n",
      "Epoch 1048/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5960 - mean_squared_error: 14.5960 - val_loss: 18.5804 - val_mean_squared_error: 18.5804\n",
      "Epoch 1049/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.6013 - mean_squared_error: 14.6013 - val_loss: 18.3922 - val_mean_squared_error: 18.3922\n",
      "Epoch 1050/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.6351 - mean_squared_error: 14.6351 - val_loss: 18.4552 - val_mean_squared_error: 18.4552\n",
      "Epoch 1051/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.5914 - mean_squared_error: 14.5914 - val_loss: 18.7170 - val_mean_squared_error: 18.7170\n",
      "Epoch 1052/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6248 - mean_squared_error: 14.6248 - val_loss: 18.3483 - val_mean_squared_error: 18.3483\n",
      "Epoch 1053/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.2664 - mean_squared_error: 15.2664 - val_loss: 18.4491 - val_mean_squared_error: 18.4491\n",
      "Epoch 1054/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7229 - mean_squared_error: 14.7229 - val_loss: 18.9262 - val_mean_squared_error: 18.9262\n",
      "Epoch 1055/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.6310 - mean_squared_error: 14.6310 - val_loss: 18.3283 - val_mean_squared_error: 18.3283\n",
      "Epoch 1056/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.6664 - mean_squared_error: 14.6664 - val_loss: 18.6143 - val_mean_squared_error: 18.6143\n",
      "Epoch 1057/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6322 - mean_squared_error: 14.6322 - val_loss: 18.3641 - val_mean_squared_error: 18.3641\n",
      "Epoch 1058/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7640 - mean_squared_error: 14.7640 - val_loss: 18.3577 - val_mean_squared_error: 18.3577\n",
      "Epoch 1059/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5695 - mean_squared_error: 14.5695 - val_loss: 18.7253 - val_mean_squared_error: 18.7253\n",
      "Epoch 1060/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.4036 - mean_squared_error: 15.4036 - val_loss: 19.7078 - val_mean_squared_error: 19.7078\n",
      "Epoch 1061/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 16.2137 - mean_squared_error: 16.2137 - val_loss: 18.3716 - val_mean_squared_error: 18.3716\n",
      "Epoch 1062/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.8139 - mean_squared_error: 14.8139 - val_loss: 18.3688 - val_mean_squared_error: 18.3688\n",
      "Epoch 1063/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.0342 - mean_squared_error: 15.0342 - val_loss: 18.3038 - val_mean_squared_error: 18.3038\n",
      "Epoch 1064/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6194 - mean_squared_error: 14.6194 - val_loss: 18.5211 - val_mean_squared_error: 18.5211\n",
      "Epoch 1065/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.5518 - mean_squared_error: 14.5518 - val_loss: 18.4620 - val_mean_squared_error: 18.4620\n",
      "Epoch 1066/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5664 - mean_squared_error: 14.5664 - val_loss: 18.6973 - val_mean_squared_error: 18.6973\n",
      "Epoch 1067/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.7341 - mean_squared_error: 14.7341 - val_loss: 18.9203 - val_mean_squared_error: 18.9203\n",
      "Epoch 1068/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.7290 - mean_squared_error: 14.7290 - val_loss: 18.6222 - val_mean_squared_error: 18.6222\n",
      "Epoch 1069/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.8246 - mean_squared_error: 14.8246 - val_loss: 18.5292 - val_mean_squared_error: 18.5292\n",
      "Epoch 1070/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.3173 - mean_squared_error: 15.3173 - val_loss: 18.2478 - val_mean_squared_error: 18.2478\n",
      "Epoch 1071/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.2818 - mean_squared_error: 15.2818 - val_loss: 18.5814 - val_mean_squared_error: 18.5814\n",
      "Epoch 1072/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.6836 - mean_squared_error: 15.6836 - val_loss: 18.3212 - val_mean_squared_error: 18.3212\n",
      "Epoch 1073/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8109 - mean_squared_error: 14.8109 - val_loss: 20.8219 - val_mean_squared_error: 20.8219\n",
      "Epoch 1074/4000\n",
      "339/339 [==============================] - 0s 17us/sample - loss: 15.1825 - mean_squared_error: 15.1825 - val_loss: 18.1851 - val_mean_squared_error: 18.1851\n",
      "Epoch 1075/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.5482 - mean_squared_error: 14.5482 - val_loss: 18.4876 - val_mean_squared_error: 18.4876\n",
      "Epoch 1076/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5206 - mean_squared_error: 14.5206 - val_loss: 18.3076 - val_mean_squared_error: 18.3076\n",
      "Epoch 1077/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.6493 - mean_squared_error: 14.6493 - val_loss: 19.2452 - val_mean_squared_error: 19.2452\n",
      "Epoch 1078/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.7389 - mean_squared_error: 14.7389 - val_loss: 18.2875 - val_mean_squared_error: 18.2875\n",
      "Epoch 1079/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.6083 - mean_squared_error: 14.6083 - val_loss: 18.9770 - val_mean_squared_error: 18.9770\n",
      "Epoch 1080/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.2137 - mean_squared_error: 15.2137 - val_loss: 19.7166 - val_mean_squared_error: 19.7166\n",
      "Epoch 1081/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1149 - mean_squared_error: 15.1149 - val_loss: 18.7400 - val_mean_squared_error: 18.7400\n",
      "Epoch 1082/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.5468 - mean_squared_error: 14.5468 - val_loss: 18.2891 - val_mean_squared_error: 18.2891\n",
      "Epoch 1083/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.6813 - mean_squared_error: 14.6813 - val_loss: 19.1814 - val_mean_squared_error: 19.1814\n",
      "Epoch 1084/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.6795 - mean_squared_error: 14.6795 - val_loss: 18.3174 - val_mean_squared_error: 18.3174\n",
      "Epoch 1085/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.6075 - mean_squared_error: 14.6075 - val_loss: 19.0072 - val_mean_squared_error: 19.0072\n",
      "Epoch 1086/4000\n",
      "339/339 [==============================] - 0s 58us/sample - loss: 14.8445 - mean_squared_error: 14.8445 - val_loss: 18.6035 - val_mean_squared_error: 18.6035\n",
      "Epoch 1087/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.7973 - mean_squared_error: 14.7973 - val_loss: 19.0509 - val_mean_squared_error: 19.0509\n",
      "Epoch 1088/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5855 - mean_squared_error: 14.5855 - val_loss: 18.1731 - val_mean_squared_error: 18.1731\n",
      "Epoch 1089/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.7268 - mean_squared_error: 14.7268 - val_loss: 18.2726 - val_mean_squared_error: 18.2726\n",
      "Epoch 1090/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5063 - mean_squared_error: 14.5063 - val_loss: 18.3050 - val_mean_squared_error: 18.3050\n",
      "Epoch 1091/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4984 - mean_squared_error: 14.4984 - val_loss: 18.2201 - val_mean_squared_error: 18.2201\n",
      "Epoch 1092/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5130 - mean_squared_error: 14.5130 - val_loss: 18.1889 - val_mean_squared_error: 18.1889\n",
      "Epoch 1093/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5888 - mean_squared_error: 14.5888 - val_loss: 18.9688 - val_mean_squared_error: 18.9688\n",
      "Epoch 1094/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.9517 - mean_squared_error: 14.9517 - val_loss: 18.7422 - val_mean_squared_error: 18.7422\n",
      "Epoch 1095/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.6448 - mean_squared_error: 14.6448 - val_loss: 18.3437 - val_mean_squared_error: 18.3437\n",
      "Epoch 1096/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.6436 - mean_squared_error: 14.6436 - val_loss: 18.1778 - val_mean_squared_error: 18.1778\n",
      "Epoch 1097/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.6926 - mean_squared_error: 14.6926 - val_loss: 18.2822 - val_mean_squared_error: 18.2822\n",
      "Epoch 1098/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.5088 - mean_squared_error: 14.5088 - val_loss: 18.2560 - val_mean_squared_error: 18.2560\n",
      "Epoch 1099/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6050 - mean_squared_error: 14.6050 - val_loss: 18.7839 - val_mean_squared_error: 18.7839\n",
      "Epoch 1100/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.4078 - mean_squared_error: 15.4078 - val_loss: 20.1276 - val_mean_squared_error: 20.1276\n",
      "Epoch 1101/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.8378 - mean_squared_error: 14.8378 - val_loss: 18.1273 - val_mean_squared_error: 18.1273\n",
      "Epoch 1102/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.8447 - mean_squared_error: 14.8447 - val_loss: 18.0924 - val_mean_squared_error: 18.0924\n",
      "Epoch 1103/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4908 - mean_squared_error: 14.4908 - val_loss: 18.4783 - val_mean_squared_error: 18.4783\n",
      "Epoch 1104/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.5560 - mean_squared_error: 14.5560 - val_loss: 18.4080 - val_mean_squared_error: 18.4080\n",
      "Epoch 1105/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.6557 - mean_squared_error: 14.6557 - val_loss: 18.1677 - val_mean_squared_error: 18.1677\n",
      "Epoch 1106/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.8781 - mean_squared_error: 14.8781 - val_loss: 18.0930 - val_mean_squared_error: 18.0930\n",
      "Epoch 1107/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5440 - mean_squared_error: 14.5440 - val_loss: 18.9059 - val_mean_squared_error: 18.9059\n",
      "Epoch 1108/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5397 - mean_squared_error: 14.5397 - val_loss: 18.0037 - val_mean_squared_error: 18.0037\n",
      "Epoch 1109/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 14.5174 - mean_squared_error: 14.5174 - val_loss: 18.3001 - val_mean_squared_error: 18.3001\n",
      "Epoch 1110/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4732 - mean_squared_error: 14.4732 - val_loss: 18.1857 - val_mean_squared_error: 18.1857\n",
      "Epoch 1111/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.4696 - mean_squared_error: 14.4696 - val_loss: 18.3141 - val_mean_squared_error: 18.3141\n",
      "Epoch 1112/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.9845 - mean_squared_error: 14.9845 - val_loss: 19.8866 - val_mean_squared_error: 19.8866\n",
      "Epoch 1113/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 15.5290 - mean_squared_error: 15.5290 - val_loss: 18.9734 - val_mean_squared_error: 18.9734\n",
      "Epoch 1114/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 14.5848 - mean_squared_error: 14.5848 - val_loss: 18.0472 - val_mean_squared_error: 18.0472\n",
      "Epoch 1115/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4754 - mean_squared_error: 14.4754 - val_loss: 18.5445 - val_mean_squared_error: 18.5445\n",
      "Epoch 1116/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 15.0104 - mean_squared_error: 15.0104 - val_loss: 19.6937 - val_mean_squared_error: 19.6937\n",
      "Epoch 1117/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.6946 - mean_squared_error: 14.6946 - val_loss: 18.0707 - val_mean_squared_error: 18.0707\n",
      "Epoch 1118/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6002 - mean_squared_error: 14.6002 - val_loss: 18.2537 - val_mean_squared_error: 18.2537\n",
      "Epoch 1119/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.5830 - mean_squared_error: 14.5830 - val_loss: 18.8116 - val_mean_squared_error: 18.8116\n",
      "Epoch 1120/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.7073 - mean_squared_error: 14.7073 - val_loss: 18.4335 - val_mean_squared_error: 18.4335\n",
      "Epoch 1121/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.5723 - mean_squared_error: 14.5723 - val_loss: 18.1815 - val_mean_squared_error: 18.1815\n",
      "Epoch 1122/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 15.2039 - mean_squared_error: 15.2039 - val_loss: 18.0601 - val_mean_squared_error: 18.0601\n",
      "Epoch 1123/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.9506 - mean_squared_error: 14.9506 - val_loss: 18.1165 - val_mean_squared_error: 18.1165\n",
      "Epoch 1124/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.6539 - mean_squared_error: 14.6539 - val_loss: 18.1493 - val_mean_squared_error: 18.1493\n",
      "Epoch 1125/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4495 - mean_squared_error: 14.4495 - val_loss: 17.9957 - val_mean_squared_error: 17.9957\n",
      "Epoch 1126/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5584 - mean_squared_error: 14.5584 - val_loss: 17.9115 - val_mean_squared_error: 17.9115\n",
      "Epoch 1127/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.4992 - mean_squared_error: 14.4992 - val_loss: 18.8052 - val_mean_squared_error: 18.8052\n",
      "Epoch 1128/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 30us/sample - loss: 14.8036 - mean_squared_error: 14.8036 - val_loss: 18.4938 - val_mean_squared_error: 18.4938\n",
      "Epoch 1129/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 15.1295 - mean_squared_error: 15.1295 - val_loss: 19.6991 - val_mean_squared_error: 19.6991\n",
      "Epoch 1130/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.8424 - mean_squared_error: 14.8424 - val_loss: 18.0354 - val_mean_squared_error: 18.0354\n",
      "Epoch 1131/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4424 - mean_squared_error: 14.4424 - val_loss: 18.0621 - val_mean_squared_error: 18.0621\n",
      "Epoch 1132/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.4312 - mean_squared_error: 14.4312 - val_loss: 18.2432 - val_mean_squared_error: 18.2432\n",
      "Epoch 1133/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.5522 - mean_squared_error: 14.5522 - val_loss: 18.0335 - val_mean_squared_error: 18.0335\n",
      "Epoch 1134/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.9694 - mean_squared_error: 15.9694 - val_loss: 18.6130 - val_mean_squared_error: 18.6130\n",
      "Epoch 1135/4000\n",
      "339/339 [==============================] - 0s 69us/sample - loss: 15.0857 - mean_squared_error: 15.0857 - val_loss: 18.3775 - val_mean_squared_error: 18.3775\n",
      "Epoch 1136/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4948 - mean_squared_error: 14.4948 - val_loss: 18.1173 - val_mean_squared_error: 18.1173\n",
      "Epoch 1137/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.4182 - mean_squared_error: 14.4182 - val_loss: 17.9289 - val_mean_squared_error: 17.9289\n",
      "Epoch 1138/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4872 - mean_squared_error: 14.4872 - val_loss: 18.4387 - val_mean_squared_error: 18.4387\n",
      "Epoch 1139/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 14.6532 - mean_squared_error: 14.6532 - val_loss: 18.6673 - val_mean_squared_error: 18.6673\n",
      "Epoch 1140/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.9391 - mean_squared_error: 14.9391 - val_loss: 19.0257 - val_mean_squared_error: 19.0257\n",
      "Epoch 1141/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.7203 - mean_squared_error: 14.7203 - val_loss: 18.1603 - val_mean_squared_error: 18.1603\n",
      "Epoch 1142/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4150 - mean_squared_error: 14.4150 - val_loss: 17.9339 - val_mean_squared_error: 17.9339\n",
      "Epoch 1143/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4637 - mean_squared_error: 14.4637 - val_loss: 18.8077 - val_mean_squared_error: 18.8077\n",
      "Epoch 1144/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.6254 - mean_squared_error: 14.6254 - val_loss: 18.1483 - val_mean_squared_error: 18.1483\n",
      "Epoch 1145/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.5041 - mean_squared_error: 14.5041 - val_loss: 18.5858 - val_mean_squared_error: 18.5858\n",
      "Epoch 1146/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.9743 - mean_squared_error: 14.9743 - val_loss: 19.1824 - val_mean_squared_error: 19.1824\n",
      "Epoch 1147/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.5929 - mean_squared_error: 14.5929 - val_loss: 18.2599 - val_mean_squared_error: 18.2599\n",
      "Epoch 1148/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7706 - mean_squared_error: 14.7706 - val_loss: 18.2979 - val_mean_squared_error: 18.2979\n",
      "Epoch 1149/4000\n",
      "339/339 [==============================] - 0s 18us/sample - loss: 14.4313 - mean_squared_error: 14.4313 - val_loss: 17.9323 - val_mean_squared_error: 17.9323\n",
      "Epoch 1150/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.4514 - mean_squared_error: 14.4514 - val_loss: 18.5150 - val_mean_squared_error: 18.5150\n",
      "Epoch 1151/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4941 - mean_squared_error: 14.4941 - val_loss: 17.7975 - val_mean_squared_error: 17.7975\n",
      "Epoch 1152/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.4739 - mean_squared_error: 14.4739 - val_loss: 18.1476 - val_mean_squared_error: 18.1476\n",
      "Epoch 1153/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.6091 - mean_squared_error: 14.6091 - val_loss: 18.0471 - val_mean_squared_error: 18.0471\n",
      "Epoch 1154/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.1694 - mean_squared_error: 15.1694 - val_loss: 17.8032 - val_mean_squared_error: 17.8032\n",
      "Epoch 1155/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.5072 - mean_squared_error: 14.5072 - val_loss: 17.9548 - val_mean_squared_error: 17.9548\n",
      "Epoch 1156/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.4037 - mean_squared_error: 14.4037 - val_loss: 17.8565 - val_mean_squared_error: 17.8565\n",
      "Epoch 1157/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.4571 - mean_squared_error: 14.4571 - val_loss: 17.9210 - val_mean_squared_error: 17.9210\n",
      "Epoch 1158/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.4037 - mean_squared_error: 14.4037 - val_loss: 18.4099 - val_mean_squared_error: 18.4099\n",
      "Epoch 1159/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.5547 - mean_squared_error: 14.5547 - val_loss: 18.1227 - val_mean_squared_error: 18.1227\n",
      "Epoch 1160/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4001 - mean_squared_error: 14.4001 - val_loss: 17.9167 - val_mean_squared_error: 17.9167\n",
      "Epoch 1161/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.4891 - mean_squared_error: 14.4891 - val_loss: 17.8568 - val_mean_squared_error: 17.8568\n",
      "Epoch 1162/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4416 - mean_squared_error: 14.4416 - val_loss: 18.2921 - val_mean_squared_error: 18.2921\n",
      "Epoch 1163/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5336 - mean_squared_error: 14.5336 - val_loss: 18.3055 - val_mean_squared_error: 18.3055\n",
      "Epoch 1164/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4116 - mean_squared_error: 14.4116 - val_loss: 17.8094 - val_mean_squared_error: 17.8094\n",
      "Epoch 1165/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4145 - mean_squared_error: 14.4145 - val_loss: 18.2344 - val_mean_squared_error: 18.2344\n",
      "Epoch 1166/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5600 - mean_squared_error: 14.5600 - val_loss: 18.0145 - val_mean_squared_error: 18.0145\n",
      "Epoch 1167/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.8476 - mean_squared_error: 14.8476 - val_loss: 17.8617 - val_mean_squared_error: 17.8617\n",
      "Epoch 1168/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3715 - mean_squared_error: 14.3715 - val_loss: 18.0391 - val_mean_squared_error: 18.0391\n",
      "Epoch 1169/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3938 - mean_squared_error: 14.3938 - val_loss: 17.8920 - val_mean_squared_error: 17.8920\n",
      "Epoch 1170/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4449 - mean_squared_error: 14.4449 - val_loss: 17.6633 - val_mean_squared_error: 17.6633\n",
      "Epoch 1171/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.4166 - mean_squared_error: 14.4166 - val_loss: 17.9801 - val_mean_squared_error: 17.9801\n",
      "Epoch 1172/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5312 - mean_squared_error: 14.5312 - val_loss: 18.3646 - val_mean_squared_error: 18.3646\n",
      "Epoch 1173/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.6412 - mean_squared_error: 14.6412 - val_loss: 18.2387 - val_mean_squared_error: 18.2387\n",
      "Epoch 1174/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.5457 - mean_squared_error: 14.5457 - val_loss: 18.1545 - val_mean_squared_error: 18.1545\n",
      "Epoch 1175/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3876 - mean_squared_error: 14.3876 - val_loss: 17.6534 - val_mean_squared_error: 17.6534\n",
      "Epoch 1176/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.3960 - mean_squared_error: 14.3960 - val_loss: 18.2940 - val_mean_squared_error: 18.2940\n",
      "Epoch 1177/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4993 - mean_squared_error: 14.4993 - val_loss: 17.9939 - val_mean_squared_error: 17.9939\n",
      "Epoch 1178/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3956 - mean_squared_error: 14.3956 - val_loss: 17.7256 - val_mean_squared_error: 17.7256\n",
      "Epoch 1179/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 14.3685 - mean_squared_error: 14.3685 - val_loss: 17.9751 - val_mean_squared_error: 17.9751\n",
      "Epoch 1180/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.3894 - mean_squared_error: 14.3894 - val_loss: 17.6295 - val_mean_squared_error: 17.6295\n",
      "Epoch 1181/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.4381 - mean_squared_error: 14.4381 - val_loss: 18.6635 - val_mean_squared_error: 18.6635\n",
      "Epoch 1182/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.8666 - mean_squared_error: 15.8666 - val_loss: 20.6219 - val_mean_squared_error: 20.6219\n",
      "Epoch 1183/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.2390 - mean_squared_error: 15.2390 - val_loss: 17.8493 - val_mean_squared_error: 17.8493\n",
      "Epoch 1184/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.6656 - mean_squared_error: 14.6656 - val_loss: 19.3992 - val_mean_squared_error: 19.3992\n",
      "Epoch 1185/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.7804 - mean_squared_error: 14.7804 - val_loss: 17.9086 - val_mean_squared_error: 17.9086\n",
      "Epoch 1186/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3540 - mean_squared_error: 14.3540 - val_loss: 18.0335 - val_mean_squared_error: 18.0335\n",
      "Epoch 1187/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3562 - mean_squared_error: 14.3562 - val_loss: 17.8064 - val_mean_squared_error: 17.8064\n",
      "Epoch 1188/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3697 - mean_squared_error: 14.3697 - val_loss: 17.9478 - val_mean_squared_error: 17.9478\n",
      "Epoch 1189/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 14.5636 - mean_squared_error: 14.5636 - val_loss: 18.9595 - val_mean_squared_error: 18.9595\n",
      "Epoch 1190/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.9961 - mean_squared_error: 14.9961 - val_loss: 18.4837 - val_mean_squared_error: 18.4837\n",
      "Epoch 1191/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.3996 - mean_squared_error: 14.3996 - val_loss: 17.7262 - val_mean_squared_error: 17.7262\n",
      "Epoch 1192/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.5997 - mean_squared_error: 14.5997 - val_loss: 17.7260 - val_mean_squared_error: 17.7260\n",
      "Epoch 1193/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4878 - mean_squared_error: 14.4878 - val_loss: 17.6864 - val_mean_squared_error: 17.6864\n",
      "Epoch 1194/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.4937 - mean_squared_error: 14.4937 - val_loss: 17.6672 - val_mean_squared_error: 17.6672\n",
      "Epoch 1195/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 14.3756 - mean_squared_error: 14.3756 - val_loss: 18.3336 - val_mean_squared_error: 18.3336\n",
      "Epoch 1196/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4121 - mean_squared_error: 14.4121 - val_loss: 17.7225 - val_mean_squared_error: 17.7225\n",
      "Epoch 1197/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 11.9700 - mean_squared_error: 11.97 - 0s 29us/sample - loss: 14.3325 - mean_squared_error: 14.3325 - val_loss: 17.7989 - val_mean_squared_error: 17.7989\n",
      "Epoch 1198/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.3474 - mean_squared_error: 14.3474 - val_loss: 17.5996 - val_mean_squared_error: 17.5996\n",
      "Epoch 1199/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.9198 - mean_squared_error: 14.9198 - val_loss: 17.8404 - val_mean_squared_error: 17.8404\n",
      "Epoch 1200/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.9543 - mean_squared_error: 14.9543 - val_loss: 17.5980 - val_mean_squared_error: 17.5980\n",
      "Epoch 1201/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.5853 - mean_squared_error: 14.5853 - val_loss: 19.3425 - val_mean_squared_error: 19.3425\n",
      "Epoch 1202/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.9489 - mean_squared_error: 14.9489 - val_loss: 17.9835 - val_mean_squared_error: 17.9835\n",
      "Epoch 1203/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 14.4079 - mean_squared_error: 14.4079 - val_loss: 18.0941 - val_mean_squared_error: 18.0941\n",
      "Epoch 1204/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4439 - mean_squared_error: 14.4439 - val_loss: 18.0945 - val_mean_squared_error: 18.0945\n",
      "Epoch 1205/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5134 - mean_squared_error: 14.5134 - val_loss: 18.2439 - val_mean_squared_error: 18.2439\n",
      "Epoch 1206/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3759 - mean_squared_error: 14.3759 - val_loss: 17.6809 - val_mean_squared_error: 17.6809\n",
      "Epoch 1207/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.3461 - mean_squared_error: 14.3461 - val_loss: 18.1295 - val_mean_squared_error: 18.1295\n",
      "Epoch 1208/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5976 - mean_squared_error: 14.5976 - val_loss: 18.4460 - val_mean_squared_error: 18.4460\n",
      "Epoch 1209/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.4068 - mean_squared_error: 14.4068 - val_loss: 17.7206 - val_mean_squared_error: 17.7206\n",
      "Epoch 1210/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4194 - mean_squared_error: 14.4194 - val_loss: 18.2256 - val_mean_squared_error: 18.2256\n",
      "Epoch 1211/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.8076 - mean_squared_error: 14.8076 - val_loss: 19.0255 - val_mean_squared_error: 19.0255\n",
      "Epoch 1212/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 15.0349 - mean_squared_error: 15.0349 - val_loss: 18.6075 - val_mean_squared_error: 18.6075\n",
      "Epoch 1213/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4448 - mean_squared_error: 14.4448 - val_loss: 17.6962 - val_mean_squared_error: 17.6962\n",
      "Epoch 1214/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3535 - mean_squared_error: 14.3535 - val_loss: 18.3220 - val_mean_squared_error: 18.3220\n",
      "Epoch 1215/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.3559 - mean_squared_error: 14.3559 - val_loss: 17.6532 - val_mean_squared_error: 17.6532\n",
      "Epoch 1216/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.3785 - mean_squared_error: 14.3785 - val_loss: 17.7003 - val_mean_squared_error: 17.7003\n",
      "Epoch 1217/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.3122 - mean_squared_error: 14.3122 - val_loss: 17.8359 - val_mean_squared_error: 17.8359\n",
      "Epoch 1218/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.6142 - mean_squared_error: 14.6142 - val_loss: 18.9238 - val_mean_squared_error: 18.9238\n",
      "Epoch 1219/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4601 - mean_squared_error: 14.4601 - val_loss: 17.6475 - val_mean_squared_error: 17.6475\n",
      "Epoch 1220/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.7380 - mean_squared_error: 14.7380 - val_loss: 17.7335 - val_mean_squared_error: 17.7335\n",
      "Epoch 1221/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.5069 - mean_squared_error: 14.5069 - val_loss: 17.7667 - val_mean_squared_error: 17.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1222/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.3378 - mean_squared_error: 14.3378 - val_loss: 18.1165 - val_mean_squared_error: 18.1165\n",
      "Epoch 1223/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3659 - mean_squared_error: 14.3659 - val_loss: 17.7464 - val_mean_squared_error: 17.7464\n",
      "Epoch 1224/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2990 - mean_squared_error: 14.2990 - val_loss: 17.7003 - val_mean_squared_error: 17.7003\n",
      "Epoch 1225/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3105 - mean_squared_error: 14.3105 - val_loss: 17.8588 - val_mean_squared_error: 17.8588\n",
      "Epoch 1226/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3239 - mean_squared_error: 14.3239 - val_loss: 17.8021 - val_mean_squared_error: 17.8021\n",
      "Epoch 1227/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4678 - mean_squared_error: 14.4678 - val_loss: 18.2840 - val_mean_squared_error: 18.2840\n",
      "Epoch 1228/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5386 - mean_squared_error: 14.5386 - val_loss: 18.0059 - val_mean_squared_error: 18.0059\n",
      "Epoch 1229/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3882 - mean_squared_error: 14.3882 - val_loss: 17.6000 - val_mean_squared_error: 17.6000\n",
      "Epoch 1230/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.2897 - mean_squared_error: 14.2897 - val_loss: 17.5187 - val_mean_squared_error: 17.5187\n",
      "Epoch 1231/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.3020 - mean_squared_error: 14.3020 - val_loss: 18.0734 - val_mean_squared_error: 18.0734\n",
      "Epoch 1232/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3612 - mean_squared_error: 14.3612 - val_loss: 17.6141 - val_mean_squared_error: 17.6141\n",
      "Epoch 1233/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4052 - mean_squared_error: 14.4052 - val_loss: 17.4671 - val_mean_squared_error: 17.4671\n",
      "Epoch 1234/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3619 - mean_squared_error: 14.3619 - val_loss: 18.0726 - val_mean_squared_error: 18.0726\n",
      "Epoch 1235/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.5200 - mean_squared_error: 14.5200 - val_loss: 18.2093 - val_mean_squared_error: 18.2093\n",
      "Epoch 1236/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.3252 - mean_squared_error: 14.3252 - val_loss: 17.5219 - val_mean_squared_error: 17.5219\n",
      "Epoch 1237/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.8212 - mean_squared_error: 14.8212 - val_loss: 17.6236 - val_mean_squared_error: 17.6236\n",
      "Epoch 1238/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.9339 - mean_squared_error: 14.9339 - val_loss: 17.4870 - val_mean_squared_error: 17.4870\n",
      "Epoch 1239/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.3059 - mean_squared_error: 14.3059 - val_loss: 17.9644 - val_mean_squared_error: 17.9644\n",
      "Epoch 1240/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4340 - mean_squared_error: 14.4340 - val_loss: 17.9330 - val_mean_squared_error: 17.9330\n",
      "Epoch 1241/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4653 - mean_squared_error: 14.4653 - val_loss: 18.1874 - val_mean_squared_error: 18.1874\n",
      "Epoch 1242/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.5028 - mean_squared_error: 14.5028 - val_loss: 17.8493 - val_mean_squared_error: 17.8493\n",
      "Epoch 1243/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 15.0646 - mean_squared_error: 15.0646 - val_loss: 17.4486 - val_mean_squared_error: 17.4486\n",
      "Epoch 1244/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3673 - mean_squared_error: 14.3673 - val_loss: 18.5598 - val_mean_squared_error: 18.5598\n",
      "Epoch 1245/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.8365 - mean_squared_error: 14.8365 - val_loss: 18.2174 - val_mean_squared_error: 18.2174\n",
      "Epoch 1246/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3426 - mean_squared_error: 14.3426 - val_loss: 17.5529 - val_mean_squared_error: 17.5529\n",
      "Epoch 1247/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.9039 - mean_squared_error: 14.9039 - val_loss: 17.9574 - val_mean_squared_error: 17.9574\n",
      "Epoch 1248/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 15.6799 - mean_squared_error: 15.6799 - val_loss: 17.6870 - val_mean_squared_error: 17.6870\n",
      "Epoch 1249/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.6643 - mean_squared_error: 14.6643 - val_loss: 17.4607 - val_mean_squared_error: 17.4607\n",
      "Epoch 1250/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3156 - mean_squared_error: 14.3156 - val_loss: 17.4326 - val_mean_squared_error: 17.4326\n",
      "Epoch 1251/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2634 - mean_squared_error: 14.2634 - val_loss: 17.4726 - val_mean_squared_error: 17.4726\n",
      "Epoch 1252/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.3297 - mean_squared_error: 14.3297 - val_loss: 17.3441 - val_mean_squared_error: 17.3441\n",
      "Epoch 1253/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.2875 - mean_squared_error: 14.2875 - val_loss: 18.0329 - val_mean_squared_error: 18.0329\n",
      "Epoch 1254/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4296 - mean_squared_error: 14.4296 - val_loss: 17.6713 - val_mean_squared_error: 17.6713\n",
      "Epoch 1255/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.2513 - mean_squared_error: 14.2513 - val_loss: 17.4092 - val_mean_squared_error: 17.4092\n",
      "Epoch 1256/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.3168 - mean_squared_error: 14.3168 - val_loss: 17.3708 - val_mean_squared_error: 17.3708\n",
      "Epoch 1257/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2630 - mean_squared_error: 14.2630 - val_loss: 17.5498 - val_mean_squared_error: 17.5498\n",
      "Epoch 1258/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3378 - mean_squared_error: 14.3378 - val_loss: 18.0761 - val_mean_squared_error: 18.0761\n",
      "Epoch 1259/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.8737 - mean_squared_error: 14.8737 - val_loss: 18.9663 - val_mean_squared_error: 18.9663\n",
      "Epoch 1260/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.9740 - mean_squared_error: 14.9740 - val_loss: 18.1684 - val_mean_squared_error: 18.1684\n",
      "Epoch 1261/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.8991 - mean_squared_error: 14.8991 - val_loss: 18.9580 - val_mean_squared_error: 18.9580\n",
      "Epoch 1262/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.1118 - mean_squared_error: 15.1118 - val_loss: 18.6651 - val_mean_squared_error: 18.6651\n",
      "Epoch 1263/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.7032 - mean_squared_error: 14.7032 - val_loss: 18.0652 - val_mean_squared_error: 18.0652\n",
      "Epoch 1264/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3040 - mean_squared_error: 14.3040 - val_loss: 17.5672 - val_mean_squared_error: 17.5672\n",
      "Epoch 1265/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.4258 - mean_squared_error: 14.4258 - val_loss: 18.7446 - val_mean_squared_error: 18.7446\n",
      "Epoch 1266/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5910 - mean_squared_error: 14.5910 - val_loss: 17.6862 - val_mean_squared_error: 17.6862\n",
      "Epoch 1267/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 14.2275 - mean_squared_error: 14.2275 - val_loss: 17.4897 - val_mean_squared_error: 17.4897\n",
      "Epoch 1268/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.2575 - mean_squared_error: 14.2575 - val_loss: 17.8674 - val_mean_squared_error: 17.8674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1269/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.3340 - mean_squared_error: 14.3340 - val_loss: 17.7219 - val_mean_squared_error: 17.7219\n",
      "Epoch 1270/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3038 - mean_squared_error: 14.3038 - val_loss: 17.7770 - val_mean_squared_error: 17.7770\n",
      "Epoch 1271/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.8725 - mean_squared_error: 14.8725 - val_loss: 19.4104 - val_mean_squared_error: 19.4104\n",
      "Epoch 1272/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5313 - mean_squared_error: 14.5313 - val_loss: 17.5747 - val_mean_squared_error: 17.5747\n",
      "Epoch 1273/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.4892 - mean_squared_error: 14.4892 - val_loss: 17.6076 - val_mean_squared_error: 17.6076\n",
      "Epoch 1274/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2449 - mean_squared_error: 14.2449 - val_loss: 17.6536 - val_mean_squared_error: 17.6536\n",
      "Epoch 1275/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.5931 - mean_squared_error: 14.5931 - val_loss: 17.6075 - val_mean_squared_error: 17.6075\n",
      "Epoch 1276/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.1355 - mean_squared_error: 15.1355 - val_loss: 17.3135 - val_mean_squared_error: 17.3135\n",
      "Epoch 1277/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4040 - mean_squared_error: 14.4040 - val_loss: 19.0777 - val_mean_squared_error: 19.0777\n",
      "Epoch 1278/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 15.0037 - mean_squared_error: 15.0037 - val_loss: 17.9401 - val_mean_squared_error: 17.9401\n",
      "Epoch 1279/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.2773 - mean_squared_error: 14.2773 - val_loss: 17.4282 - val_mean_squared_error: 17.4282\n",
      "Epoch 1280/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.3015 - mean_squared_error: 14.3015 - val_loss: 18.1838 - val_mean_squared_error: 18.1838\n",
      "Epoch 1281/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3367 - mean_squared_error: 14.3367 - val_loss: 17.3891 - val_mean_squared_error: 17.3891\n",
      "Epoch 1282/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.3330 - mean_squared_error: 14.3330 - val_loss: 17.3196 - val_mean_squared_error: 17.3196\n",
      "Epoch 1283/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.2970 - mean_squared_error: 14.2970 - val_loss: 17.7128 - val_mean_squared_error: 17.7128\n",
      "Epoch 1284/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.2334 - mean_squared_error: 14.2334 - val_loss: 17.3692 - val_mean_squared_error: 17.3692\n",
      "Epoch 1285/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 14.2419 - mean_squared_error: 14.2419 - val_loss: 18.0036 - val_mean_squared_error: 18.0036\n",
      "Epoch 1286/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.4258 - mean_squared_error: 14.4258 - val_loss: 17.5868 - val_mean_squared_error: 17.5868\n",
      "Epoch 1287/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 14.5042 - mean_squared_error: 14.5042 - val_loss: 18.3826 - val_mean_squared_error: 18.3826\n",
      "Epoch 1288/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5237 - mean_squared_error: 14.5237 - val_loss: 17.5493 - val_mean_squared_error: 17.5493\n",
      "Epoch 1289/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.6360 - mean_squared_error: 14.6360 - val_loss: 19.0122 - val_mean_squared_error: 19.0122\n",
      "Epoch 1290/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 15.2448 - mean_squared_error: 15.2448 - val_loss: 18.3431 - val_mean_squared_error: 18.3431\n",
      "Epoch 1291/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.3689 - mean_squared_error: 14.3689 - val_loss: 17.3237 - val_mean_squared_error: 17.3237\n",
      "Epoch 1292/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2084 - mean_squared_error: 14.2084 - val_loss: 17.6961 - val_mean_squared_error: 17.6961\n",
      "Epoch 1293/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4555 - mean_squared_error: 14.4555 - val_loss: 17.9898 - val_mean_squared_error: 17.9898\n",
      "Epoch 1294/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.3729 - mean_squared_error: 14.3729 - val_loss: 17.7401 - val_mean_squared_error: 17.7401\n",
      "Epoch 1295/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.2311 - mean_squared_error: 14.2311 - val_loss: 17.4986 - val_mean_squared_error: 17.4986\n",
      "Epoch 1296/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2197 - mean_squared_error: 14.2197 - val_loss: 17.3896 - val_mean_squared_error: 17.3896\n",
      "Epoch 1297/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2126 - mean_squared_error: 14.2126 - val_loss: 17.4185 - val_mean_squared_error: 17.4185\n",
      "Epoch 1298/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2178 - mean_squared_error: 14.2178 - val_loss: 17.6687 - val_mean_squared_error: 17.6687\n",
      "Epoch 1299/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3398 - mean_squared_error: 14.3398 - val_loss: 17.6979 - val_mean_squared_error: 17.6979\n",
      "Epoch 1300/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2130 - mean_squared_error: 14.2130 - val_loss: 17.2811 - val_mean_squared_error: 17.2811\n",
      "Epoch 1301/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2299 - mean_squared_error: 14.2299 - val_loss: 17.3078 - val_mean_squared_error: 17.3078\n",
      "Epoch 1302/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.3219 - mean_squared_error: 14.3219 - val_loss: 17.2864 - val_mean_squared_error: 17.2864\n",
      "Epoch 1303/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.2564 - mean_squared_error: 14.2564 - val_loss: 18.2242 - val_mean_squared_error: 18.2242\n",
      "Epoch 1304/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.5124 - mean_squared_error: 14.5124 - val_loss: 17.6870 - val_mean_squared_error: 17.6870\n",
      "Epoch 1305/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.1928 - mean_squared_error: 14.1928 - val_loss: 17.4809 - val_mean_squared_error: 17.4809\n",
      "Epoch 1306/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3722 - mean_squared_error: 14.3722 - val_loss: 17.4072 - val_mean_squared_error: 17.4072\n",
      "Epoch 1307/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6696 - mean_squared_error: 14.6696 - val_loss: 17.3096 - val_mean_squared_error: 17.3096\n",
      "Epoch 1308/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5367 - mean_squared_error: 14.5367 - val_loss: 17.4055 - val_mean_squared_error: 17.4055\n",
      "Epoch 1309/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.2596 - mean_squared_error: 14.2596 - val_loss: 18.0245 - val_mean_squared_error: 18.0245\n",
      "Epoch 1310/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.3969 - mean_squared_error: 14.3969 - val_loss: 17.5141 - val_mean_squared_error: 17.5141\n",
      "Epoch 1311/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.5602 - mean_squared_error: 14.5602 - val_loss: 18.6478 - val_mean_squared_error: 18.6478\n",
      "Epoch 1312/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.8013 - mean_squared_error: 14.8013 - val_loss: 17.8657 - val_mean_squared_error: 17.8657\n",
      "Epoch 1313/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.2252 - mean_squared_error: 14.2252 - val_loss: 17.4002 - val_mean_squared_error: 17.4002\n",
      "Epoch 1314/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.2776 - mean_squared_error: 14.2776 - val_loss: 18.1199 - val_mean_squared_error: 18.1199\n",
      "Epoch 1315/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.3355 - mean_squared_error: 14.3355 - val_loss: 17.3959 - val_mean_squared_error: 17.3959\n",
      "Epoch 1316/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 26us/sample - loss: 14.1731 - mean_squared_error: 14.1731 - val_loss: 17.3180 - val_mean_squared_error: 17.3180\n",
      "Epoch 1317/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.4784 - mean_squared_error: 14.4784 - val_loss: 19.1090 - val_mean_squared_error: 19.1090\n",
      "Epoch 1318/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.5066 - mean_squared_error: 14.5066 - val_loss: 17.3047 - val_mean_squared_error: 17.3047\n",
      "Epoch 1319/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2524 - mean_squared_error: 14.2524 - val_loss: 17.9106 - val_mean_squared_error: 17.9106\n",
      "Epoch 1320/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4786 - mean_squared_error: 14.4786 - val_loss: 17.9574 - val_mean_squared_error: 17.9574\n",
      "Epoch 1321/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.2271 - mean_squared_error: 14.2271 - val_loss: 17.2592 - val_mean_squared_error: 17.2592\n",
      "Epoch 1322/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.9089 - mean_squared_error: 14.9089 - val_loss: 17.4941 - val_mean_squared_error: 17.4941\n",
      "Epoch 1323/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4418 - mean_squared_error: 14.4418 - val_loss: 17.5870 - val_mean_squared_error: 17.5870\n",
      "Epoch 1324/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1775 - mean_squared_error: 14.1775 - val_loss: 17.2234 - val_mean_squared_error: 17.2234\n",
      "Epoch 1325/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 15.5447 - mean_squared_error: 15.54 - 0s 44us/sample - loss: 14.4603 - mean_squared_error: 14.4603 - val_loss: 19.0322 - val_mean_squared_error: 19.0322\n",
      "Epoch 1326/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.7884 - mean_squared_error: 14.7884 - val_loss: 17.4234 - val_mean_squared_error: 17.4234\n",
      "Epoch 1327/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.6097 - mean_squared_error: 14.6097 - val_loss: 18.9378 - val_mean_squared_error: 18.9378\n",
      "Epoch 1328/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3817 - mean_squared_error: 14.3817 - val_loss: 17.3476 - val_mean_squared_error: 17.3476\n",
      "Epoch 1329/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.2518 - mean_squared_error: 14.2518 - val_loss: 18.0856 - val_mean_squared_error: 18.0856\n",
      "Epoch 1330/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.2023 - mean_squared_error: 14.2023 - val_loss: 17.2130 - val_mean_squared_error: 17.2130\n",
      "Epoch 1331/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.6103 - mean_squared_error: 14.6103 - val_loss: 17.1615 - val_mean_squared_error: 17.1615\n",
      "Epoch 1332/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.1939 - mean_squared_error: 14.1939 - val_loss: 17.6245 - val_mean_squared_error: 17.6245\n",
      "Epoch 1333/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.1948 - mean_squared_error: 14.1948 - val_loss: 17.2635 - val_mean_squared_error: 17.2635\n",
      "Epoch 1334/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.1527 - mean_squared_error: 14.1527 - val_loss: 17.4580 - val_mean_squared_error: 17.4580\n",
      "Epoch 1335/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.3993 - mean_squared_error: 14.3993 - val_loss: 17.3946 - val_mean_squared_error: 17.3946\n",
      "Epoch 1336/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.4155 - mean_squared_error: 14.4155 - val_loss: 18.0049 - val_mean_squared_error: 18.0049\n",
      "Epoch 1337/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 14.4921 - mean_squared_error: 14.4921 - val_loss: 17.6143 - val_mean_squared_error: 17.6143\n",
      "Epoch 1338/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.1665 - mean_squared_error: 14.1665 - val_loss: 17.1617 - val_mean_squared_error: 17.1617\n",
      "Epoch 1339/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.2390 - mean_squared_error: 14.2390 - val_loss: 17.1487 - val_mean_squared_error: 17.1487\n",
      "Epoch 1340/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.1513 - mean_squared_error: 14.1513 - val_loss: 17.4555 - val_mean_squared_error: 17.4555\n",
      "Epoch 1341/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.1469 - mean_squared_error: 14.1469 - val_loss: 17.1209 - val_mean_squared_error: 17.1209\n",
      "Epoch 1342/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.1850 - mean_squared_error: 14.1850 - val_loss: 17.3568 - val_mean_squared_error: 17.3568\n",
      "Epoch 1343/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.1382 - mean_squared_error: 14.1382 - val_loss: 17.1030 - val_mean_squared_error: 17.1030\n",
      "Epoch 1344/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.1281 - mean_squared_error: 14.1281 - val_loss: 17.3559 - val_mean_squared_error: 17.3559\n",
      "Epoch 1345/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.2404 - mean_squared_error: 14.2404 - val_loss: 17.5737 - val_mean_squared_error: 17.5737\n",
      "Epoch 1346/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.4015 - mean_squared_error: 14.4015 - val_loss: 17.6896 - val_mean_squared_error: 17.6896\n",
      "Epoch 1347/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.4342 - mean_squared_error: 14.4342 - val_loss: 17.7413 - val_mean_squared_error: 17.7413\n",
      "Epoch 1348/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.6677 - mean_squared_error: 14.6677 - val_loss: 18.2453 - val_mean_squared_error: 18.2453\n",
      "Epoch 1349/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 12.0567 - mean_squared_error: 12.05 - 0s 39us/sample - loss: 14.4636 - mean_squared_error: 14.4636 - val_loss: 17.5122 - val_mean_squared_error: 17.5122\n",
      "Epoch 1350/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.3697 - mean_squared_error: 14.3697 - val_loss: 17.9959 - val_mean_squared_error: 17.9959\n",
      "Epoch 1351/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.8188 - mean_squared_error: 14.8188 - val_loss: 18.5361 - val_mean_squared_error: 18.5361\n",
      "Epoch 1352/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.6035 - mean_squared_error: 14.6035 - val_loss: 17.5570 - val_mean_squared_error: 17.5570\n",
      "Epoch 1353/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 14.1279 - mean_squared_error: 14.1279 - val_loss: 17.1544 - val_mean_squared_error: 17.1544\n",
      "Epoch 1354/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3087 - mean_squared_error: 14.3087 - val_loss: 17.0706 - val_mean_squared_error: 17.0706\n",
      "Epoch 1355/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1326 - mean_squared_error: 14.1326 - val_loss: 17.7818 - val_mean_squared_error: 17.7818\n",
      "Epoch 1356/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.2066 - mean_squared_error: 14.2066 - val_loss: 17.1005 - val_mean_squared_error: 17.1005\n",
      "Epoch 1357/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.1599 - mean_squared_error: 14.1599 - val_loss: 17.0295 - val_mean_squared_error: 17.0295\n",
      "Epoch 1358/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4087 - mean_squared_error: 14.4087 - val_loss: 18.9967 - val_mean_squared_error: 18.9967\n",
      "Epoch 1359/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4112 - mean_squared_error: 14.4112 - val_loss: 17.1311 - val_mean_squared_error: 17.1311\n",
      "Epoch 1360/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.4762 - mean_squared_error: 14.4762 - val_loss: 17.0166 - val_mean_squared_error: 17.0166\n",
      "Epoch 1361/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1829 - mean_squared_error: 14.1829 - val_loss: 17.0415 - val_mean_squared_error: 17.0415\n",
      "Epoch 1362/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 28us/sample - loss: 14.1086 - mean_squared_error: 14.1086 - val_loss: 17.4403 - val_mean_squared_error: 17.4403\n",
      "Epoch 1363/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2889 - mean_squared_error: 14.2889 - val_loss: 17.5868 - val_mean_squared_error: 17.5868\n",
      "Epoch 1364/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.5733 - mean_squared_error: 14.5733 - val_loss: 18.2163 - val_mean_squared_error: 18.2163\n",
      "Epoch 1365/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2577 - mean_squared_error: 14.2577 - val_loss: 17.0753 - val_mean_squared_error: 17.0753\n",
      "Epoch 1366/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8271 - mean_squared_error: 14.8271 - val_loss: 17.1903 - val_mean_squared_error: 17.1903\n",
      "Epoch 1367/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4279 - mean_squared_error: 14.4279 - val_loss: 17.0389 - val_mean_squared_error: 17.0389\n",
      "Epoch 1368/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.0878 - mean_squared_error: 14.0878 - val_loss: 17.2601 - val_mean_squared_error: 17.2601\n",
      "Epoch 1369/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.1935 - mean_squared_error: 14.1935 - val_loss: 17.4298 - val_mean_squared_error: 17.4298\n",
      "Epoch 1370/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1222 - mean_squared_error: 14.1222 - val_loss: 17.1560 - val_mean_squared_error: 17.1560\n",
      "Epoch 1371/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.1392 - mean_squared_error: 14.1392 - val_loss: 17.5665 - val_mean_squared_error: 17.5665\n",
      "Epoch 1372/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.1673 - mean_squared_error: 14.1673 - val_loss: 16.9285 - val_mean_squared_error: 16.9285\n",
      "Epoch 1373/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.4232 - mean_squared_error: 14.4232 - val_loss: 16.8432 - val_mean_squared_error: 16.8432\n",
      "Epoch 1374/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.0804 - mean_squared_error: 14.0804 - val_loss: 17.2173 - val_mean_squared_error: 17.2173\n",
      "Epoch 1375/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.2123 - mean_squared_error: 14.2123 - val_loss: 17.3679 - val_mean_squared_error: 17.3679\n",
      "Epoch 1376/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.1244 - mean_squared_error: 14.1244 - val_loss: 16.9483 - val_mean_squared_error: 16.9483\n",
      "Epoch 1377/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4277 - mean_squared_error: 14.4277 - val_loss: 16.9127 - val_mean_squared_error: 16.9127\n",
      "Epoch 1378/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.8359 - mean_squared_error: 14.8359 - val_loss: 16.9390 - val_mean_squared_error: 16.9390\n",
      "Epoch 1379/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.2124 - mean_squared_error: 14.2124 - val_loss: 18.8413 - val_mean_squared_error: 18.8413\n",
      "Epoch 1380/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3972 - mean_squared_error: 14.3972 - val_loss: 17.0371 - val_mean_squared_error: 17.0371\n",
      "Epoch 1381/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.4202 - mean_squared_error: 15.4202 - val_loss: 17.2178 - val_mean_squared_error: 17.2178\n",
      "Epoch 1382/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.4281 - mean_squared_error: 14.4281 - val_loss: 17.1321 - val_mean_squared_error: 17.1321\n",
      "Epoch 1383/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.1020 - mean_squared_error: 14.1020 - val_loss: 17.0883 - val_mean_squared_error: 17.0883\n",
      "Epoch 1384/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.1340 - mean_squared_error: 14.1340 - val_loss: 16.8052 - val_mean_squared_error: 16.8052\n",
      "Epoch 1385/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 15.1100 - mean_squared_error: 15.1100 - val_loss: 17.3735 - val_mean_squared_error: 17.3735\n",
      "Epoch 1386/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.9809 - mean_squared_error: 14.9809 - val_loss: 16.7174 - val_mean_squared_error: 16.7174\n",
      "Epoch 1387/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.1233 - mean_squared_error: 14.1233 - val_loss: 17.5353 - val_mean_squared_error: 17.5353\n",
      "Epoch 1388/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.2551 - mean_squared_error: 14.2551 - val_loss: 17.1217 - val_mean_squared_error: 17.1217\n",
      "Epoch 1389/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2479 - mean_squared_error: 14.2479 - val_loss: 17.5521 - val_mean_squared_error: 17.5521\n",
      "Epoch 1390/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.1850 - mean_squared_error: 14.1850 - val_loss: 16.8697 - val_mean_squared_error: 16.8697\n",
      "Epoch 1391/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.0440 - mean_squared_error: 14.0440 - val_loss: 16.8336 - val_mean_squared_error: 16.8336\n",
      "Epoch 1392/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3338 - mean_squared_error: 14.3338 - val_loss: 16.9635 - val_mean_squared_error: 16.9635\n",
      "Epoch 1393/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.1494 - mean_squared_error: 14.1494 - val_loss: 18.0615 - val_mean_squared_error: 18.0615\n",
      "Epoch 1394/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.4389 - mean_squared_error: 14.4389 - val_loss: 17.0820 - val_mean_squared_error: 17.0820\n",
      "Epoch 1395/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.5304 - mean_squared_error: 14.5304 - val_loss: 17.4426 - val_mean_squared_error: 17.4426\n",
      "Epoch 1396/4000\n",
      "339/339 [==============================] - 0s 16us/sample - loss: 15.4006 - mean_squared_error: 15.4006 - val_loss: 16.7529 - val_mean_squared_error: 16.7529\n",
      "Epoch 1397/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.2204 - mean_squared_error: 14.2204 - val_loss: 16.7830 - val_mean_squared_error: 16.7830\n",
      "Epoch 1398/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.1417 - mean_squared_error: 14.1417 - val_loss: 16.7604 - val_mean_squared_error: 16.7604\n",
      "Epoch 1399/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 14.1706 - mean_squared_error: 14.1706 - val_loss: 16.8831 - val_mean_squared_error: 16.8831\n",
      "Epoch 1400/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.0904 - mean_squared_error: 14.0904 - val_loss: 17.1220 - val_mean_squared_error: 17.1220\n",
      "Epoch 1401/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 14.3265 - mean_squared_error: 14.3265 - val_loss: 17.6313 - val_mean_squared_error: 17.6313\n",
      "Epoch 1402/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4468 - mean_squared_error: 14.4468 - val_loss: 17.5058 - val_mean_squared_error: 17.5058\n",
      "Epoch 1403/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7943 - mean_squared_error: 14.7943 - val_loss: 18.3889 - val_mean_squared_error: 18.3889\n",
      "Epoch 1404/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3907 - mean_squared_error: 14.3907 - val_loss: 16.8767 - val_mean_squared_error: 16.8767\n",
      "Epoch 1405/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.2539 - mean_squared_error: 14.2539 - val_loss: 16.9070 - val_mean_squared_error: 16.9070\n",
      "Epoch 1406/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1905 - mean_squared_error: 15.1905 - val_loss: 17.1836 - val_mean_squared_error: 17.1836\n",
      "Epoch 1407/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.2965 - mean_squared_error: 15.2965 - val_loss: 16.9471 - val_mean_squared_error: 16.9471\n",
      "Epoch 1408/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 15.0719 - mean_squared_error: 15.07 - 0s 39us/sample - loss: 14.1359 - mean_squared_error: 14.1359 - val_loss: 18.0969 - val_mean_squared_error: 18.0969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1409/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.6417 - mean_squared_error: 14.6417 - val_loss: 17.3711 - val_mean_squared_error: 17.3711\n",
      "Epoch 1410/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.1502 - mean_squared_error: 14.1502 - val_loss: 17.0557 - val_mean_squared_error: 17.0557\n",
      "Epoch 1411/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.0264 - mean_squared_error: 14.0264 - val_loss: 16.9251 - val_mean_squared_error: 16.9251\n",
      "Epoch 1412/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 14.0735 - mean_squared_error: 14.0735 - val_loss: 17.4770 - val_mean_squared_error: 17.4770\n",
      "Epoch 1413/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.1333 - mean_squared_error: 14.1333 - val_loss: 16.9548 - val_mean_squared_error: 16.9548\n",
      "Epoch 1414/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.0625 - mean_squared_error: 14.0625 - val_loss: 16.9503 - val_mean_squared_error: 16.9503\n",
      "Epoch 1415/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.0340 - mean_squared_error: 14.0340 - val_loss: 16.8802 - val_mean_squared_error: 16.8802\n",
      "Epoch 1416/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.0755 - mean_squared_error: 14.0755 - val_loss: 16.8241 - val_mean_squared_error: 16.8241\n",
      "Epoch 1417/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.2070 - mean_squared_error: 14.2070 - val_loss: 16.7306 - val_mean_squared_error: 16.7306\n",
      "Epoch 1418/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.0806 - mean_squared_error: 14.0806 - val_loss: 17.2944 - val_mean_squared_error: 17.2944\n",
      "Epoch 1419/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.0462 - mean_squared_error: 14.0462 - val_loss: 16.7816 - val_mean_squared_error: 16.7816\n",
      "Epoch 1420/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.2242 - mean_squared_error: 14.2242 - val_loss: 16.7794 - val_mean_squared_error: 16.7794\n",
      "Epoch 1421/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.1569 - mean_squared_error: 14.1569 - val_loss: 18.1561 - val_mean_squared_error: 18.1561\n",
      "Epoch 1422/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.4625 - mean_squared_error: 14.4625 - val_loss: 17.2681 - val_mean_squared_error: 17.2681\n",
      "Epoch 1423/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.0353 - mean_squared_error: 14.0353 - val_loss: 16.8691 - val_mean_squared_error: 16.8691\n",
      "Epoch 1424/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.1172 - mean_squared_error: 14.1172 - val_loss: 16.7839 - val_mean_squared_error: 16.7839\n",
      "Epoch 1425/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2795 - mean_squared_error: 14.2795 - val_loss: 16.7101 - val_mean_squared_error: 16.7101\n",
      "Epoch 1426/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 14.0317 - mean_squared_error: 14.0317 - val_loss: 17.5807 - val_mean_squared_error: 17.5807\n",
      "Epoch 1427/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3299 - mean_squared_error: 14.3299 - val_loss: 17.2526 - val_mean_squared_error: 17.2526\n",
      "Epoch 1428/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.1325 - mean_squared_error: 14.1325 - val_loss: 17.1042 - val_mean_squared_error: 17.1042\n",
      "Epoch 1429/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.4280 - mean_squared_error: 14.4280 - val_loss: 18.3674 - val_mean_squared_error: 18.3674\n",
      "Epoch 1430/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.7096 - mean_squared_error: 14.7096 - val_loss: 17.2242 - val_mean_squared_error: 17.2242\n",
      "Epoch 1431/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3037 - mean_squared_error: 14.3037 - val_loss: 17.5540 - val_mean_squared_error: 17.5540\n",
      "Epoch 1432/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.3834 - mean_squared_error: 14.3834 - val_loss: 17.3343 - val_mean_squared_error: 17.3343\n",
      "Epoch 1433/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.0340 - mean_squared_error: 14.0340 - val_loss: 16.7319 - val_mean_squared_error: 16.7319\n",
      "Epoch 1434/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.0625 - mean_squared_error: 14.0625 - val_loss: 16.7670 - val_mean_squared_error: 16.7670\n",
      "Epoch 1435/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.4261 - mean_squared_error: 14.4261 - val_loss: 18.6754 - val_mean_squared_error: 18.6754\n",
      "Epoch 1436/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 15.1545 - mean_squared_error: 15.1545 - val_loss: 17.6607 - val_mean_squared_error: 17.6607\n",
      "Epoch 1437/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.1011 - mean_squared_error: 14.1011 - val_loss: 16.6556 - val_mean_squared_error: 16.6556\n",
      "Epoch 1438/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 14.0364 - mean_squared_error: 14.0364 - val_loss: 17.2030 - val_mean_squared_error: 17.2030\n",
      "Epoch 1439/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.1798 - mean_squared_error: 14.1798 - val_loss: 17.1129 - val_mean_squared_error: 17.1129\n",
      "Epoch 1440/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.1020 - mean_squared_error: 14.1020 - val_loss: 16.5660 - val_mean_squared_error: 16.5660\n",
      "Epoch 1441/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.0991 - mean_squared_error: 14.0991 - val_loss: 16.6338 - val_mean_squared_error: 16.6338\n",
      "Epoch 1442/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.1253 - mean_squared_error: 14.1253 - val_loss: 16.5436 - val_mean_squared_error: 16.5436\n",
      "Epoch 1443/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.0915 - mean_squared_error: 14.0915 - val_loss: 16.7620 - val_mean_squared_error: 16.7620\n",
      "Epoch 1444/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.9756 - mean_squared_error: 13.9756 - val_loss: 16.8622 - val_mean_squared_error: 16.8622\n",
      "Epoch 1445/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.9789 - mean_squared_error: 13.9789 - val_loss: 16.6200 - val_mean_squared_error: 16.6200\n",
      "Epoch 1446/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.0192 - mean_squared_error: 14.0192 - val_loss: 16.7584 - val_mean_squared_error: 16.7584\n",
      "Epoch 1447/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.1345 - mean_squared_error: 14.1345 - val_loss: 16.7323 - val_mean_squared_error: 16.7323\n",
      "Epoch 1448/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.7113 - mean_squared_error: 14.7113 - val_loss: 16.7738 - val_mean_squared_error: 16.7738\n",
      "Epoch 1449/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 14.2836 - mean_squared_error: 14.2836 - val_loss: 16.6751 - val_mean_squared_error: 16.6751\n",
      "Epoch 1450/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.9543 - mean_squared_error: 13.9543 - val_loss: 16.7228 - val_mean_squared_error: 16.7228\n",
      "Epoch 1451/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9632 - mean_squared_error: 13.9632 - val_loss: 16.7253 - val_mean_squared_error: 16.7253\n",
      "Epoch 1452/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 14.0410 - mean_squared_error: 14.0410 - val_loss: 16.6010 - val_mean_squared_error: 16.6010\n",
      "Epoch 1453/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.2826 - mean_squared_error: 14.2826 - val_loss: 18.8092 - val_mean_squared_error: 18.8092\n",
      "Epoch 1454/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.7338 - mean_squared_error: 14.7338 - val_loss: 16.9642 - val_mean_squared_error: 16.9642\n",
      "Epoch 1455/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.0728 - mean_squared_error: 14.0728 - val_loss: 16.7507 - val_mean_squared_error: 16.7507\n",
      "Epoch 1456/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 27us/sample - loss: 14.1479 - mean_squared_error: 14.1479 - val_loss: 16.9294 - val_mean_squared_error: 16.9294\n",
      "Epoch 1457/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9486 - mean_squared_error: 13.9486 - val_loss: 16.6650 - val_mean_squared_error: 16.6650\n",
      "Epoch 1458/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9608 - mean_squared_error: 13.9608 - val_loss: 16.8516 - val_mean_squared_error: 16.8516\n",
      "Epoch 1459/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.0418 - mean_squared_error: 14.0418 - val_loss: 16.6932 - val_mean_squared_error: 16.6932\n",
      "Epoch 1460/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.6673 - mean_squared_error: 14.6673 - val_loss: 16.7701 - val_mean_squared_error: 16.7701\n",
      "Epoch 1461/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2162 - mean_squared_error: 14.2162 - val_loss: 16.7157 - val_mean_squared_error: 16.7157\n",
      "Epoch 1462/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.9711 - mean_squared_error: 13.9711 - val_loss: 16.8251 - val_mean_squared_error: 16.8251\n",
      "Epoch 1463/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 14.2425 - mean_squared_error: 14.2425 - val_loss: 17.6059 - val_mean_squared_error: 17.6059\n",
      "Epoch 1464/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.5543 - mean_squared_error: 14.5543 - val_loss: 17.3464 - val_mean_squared_error: 17.3464\n",
      "Epoch 1465/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.7295 - mean_squared_error: 14.7295 - val_loss: 17.8862 - val_mean_squared_error: 17.8862\n",
      "Epoch 1466/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.1434 - mean_squared_error: 14.1434 - val_loss: 16.6327 - val_mean_squared_error: 16.6327\n",
      "Epoch 1467/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.1358 - mean_squared_error: 14.1358 - val_loss: 16.5174 - val_mean_squared_error: 16.5174\n",
      "Epoch 1468/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.9968 - mean_squared_error: 13.9968 - val_loss: 17.2740 - val_mean_squared_error: 17.2740\n",
      "Epoch 1469/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 13.1576 - mean_squared_error: 13.15 - 0s 30us/sample - loss: 13.9999 - mean_squared_error: 13.9999 - val_loss: 16.6911 - val_mean_squared_error: 16.6911\n",
      "Epoch 1470/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.4085 - mean_squared_error: 14.4085 - val_loss: 16.5048 - val_mean_squared_error: 16.5048\n",
      "Epoch 1471/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.9646 - mean_squared_error: 13.9646 - val_loss: 17.3361 - val_mean_squared_error: 17.3361\n",
      "Epoch 1472/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.3682 - mean_squared_error: 14.3682 - val_loss: 17.1888 - val_mean_squared_error: 17.1888\n",
      "Epoch 1473/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.0499 - mean_squared_error: 14.0499 - val_loss: 16.6915 - val_mean_squared_error: 16.6915\n",
      "Epoch 1474/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.0297 - mean_squared_error: 14.0297 - val_loss: 16.5775 - val_mean_squared_error: 16.5775\n",
      "Epoch 1475/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4246 - mean_squared_error: 14.4246 - val_loss: 16.4472 - val_mean_squared_error: 16.4472\n",
      "Epoch 1476/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.1602 - mean_squared_error: 14.1602 - val_loss: 16.4021 - val_mean_squared_error: 16.4021\n",
      "Epoch 1477/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9447 - mean_squared_error: 13.9447 - val_loss: 16.4955 - val_mean_squared_error: 16.4955\n",
      "Epoch 1478/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.9188 - mean_squared_error: 13.9188 - val_loss: 16.5647 - val_mean_squared_error: 16.5647\n",
      "Epoch 1479/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.1076 - mean_squared_error: 14.1076 - val_loss: 17.6614 - val_mean_squared_error: 17.6614\n",
      "Epoch 1480/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.0942 - mean_squared_error: 14.0942 - val_loss: 16.4108 - val_mean_squared_error: 16.4108\n",
      "Epoch 1481/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.2385 - mean_squared_error: 14.2385 - val_loss: 16.4543 - val_mean_squared_error: 16.4543\n",
      "Epoch 1482/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 14.2036 - mean_squared_error: 14.2036 - val_loss: 16.4562 - val_mean_squared_error: 16.4562\n",
      "Epoch 1483/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.0289 - mean_squared_error: 14.0289 - val_loss: 17.5434 - val_mean_squared_error: 17.5434\n",
      "Epoch 1484/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.6959 - mean_squared_error: 14.6959 - val_loss: 17.7184 - val_mean_squared_error: 17.7184\n",
      "Epoch 1485/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.2561 - mean_squared_error: 14.2561 - val_loss: 16.7323 - val_mean_squared_error: 16.7323\n",
      "Epoch 1486/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.9224 - mean_squared_error: 13.9224 - val_loss: 16.4761 - val_mean_squared_error: 16.4761\n",
      "Epoch 1487/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9159 - mean_squared_error: 13.9159 - val_loss: 16.9355 - val_mean_squared_error: 16.9355\n",
      "Epoch 1488/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 13.4008 - mean_squared_error: 13.40 - 0s 49us/sample - loss: 14.3529 - mean_squared_error: 14.3529 - val_loss: 17.7157 - val_mean_squared_error: 17.7157\n",
      "Epoch 1489/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.5721 - mean_squared_error: 14.5721 - val_loss: 17.0344 - val_mean_squared_error: 17.0344\n",
      "Epoch 1490/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.9832 - mean_squared_error: 13.9832 - val_loss: 16.4604 - val_mean_squared_error: 16.4604\n",
      "Epoch 1491/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.9690 - mean_squared_error: 13.9690 - val_loss: 16.4395 - val_mean_squared_error: 16.4395\n",
      "Epoch 1492/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9258 - mean_squared_error: 13.9258 - val_loss: 16.7891 - val_mean_squared_error: 16.7891\n",
      "Epoch 1493/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 14.0403 - mean_squared_error: 14.0403 - val_loss: 17.0199 - val_mean_squared_error: 17.0199\n",
      "Epoch 1494/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9455 - mean_squared_error: 13.9455 - val_loss: 16.4842 - val_mean_squared_error: 16.4842\n",
      "Epoch 1495/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.2097 - mean_squared_error: 14.2097 - val_loss: 16.4688 - val_mean_squared_error: 16.4688\n",
      "Epoch 1496/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9552 - mean_squared_error: 13.9552 - val_loss: 17.4941 - val_mean_squared_error: 17.4941\n",
      "Epoch 1497/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.0300 - mean_squared_error: 14.0300 - val_loss: 16.4307 - val_mean_squared_error: 16.4307\n",
      "Epoch 1498/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.9154 - mean_squared_error: 13.9154 - val_loss: 16.9283 - val_mean_squared_error: 16.9283\n",
      "Epoch 1499/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.9718 - mean_squared_error: 13.9718 - val_loss: 16.6231 - val_mean_squared_error: 16.6231\n",
      "Epoch 1500/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.9090 - mean_squared_error: 13.9090 - val_loss: 16.4724 - val_mean_squared_error: 16.4724\n",
      "Epoch 1501/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.0640 - mean_squared_error: 14.0640 - val_loss: 17.9094 - val_mean_squared_error: 17.9094\n",
      "Epoch 1502/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 40us/sample - loss: 15.1480 - mean_squared_error: 15.1480 - val_loss: 18.0526 - val_mean_squared_error: 18.0526\n",
      "Epoch 1503/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.2441 - mean_squared_error: 14.2441 - val_loss: 16.5934 - val_mean_squared_error: 16.5934\n",
      "Epoch 1504/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.8864 - mean_squared_error: 13.8864 - val_loss: 16.6085 - val_mean_squared_error: 16.6085\n",
      "Epoch 1505/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.9524 - mean_squared_error: 13.9524 - val_loss: 16.4032 - val_mean_squared_error: 16.4032\n",
      "Epoch 1506/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.9290 - mean_squared_error: 13.9290 - val_loss: 17.1420 - val_mean_squared_error: 17.1420\n",
      "Epoch 1507/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 15.0018 - mean_squared_error: 15.0018 - val_loss: 18.9755 - val_mean_squared_error: 18.9755\n",
      "Epoch 1508/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 14.9683 - mean_squared_error: 14.9683 - val_loss: 17.0416 - val_mean_squared_error: 17.0416\n",
      "Epoch 1509/4000\n",
      "339/339 [==============================] - 0s 74us/sample - loss: 14.1654 - mean_squared_error: 14.1654 - val_loss: 17.0259 - val_mean_squared_error: 17.0259\n",
      "Epoch 1510/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.8817 - mean_squared_error: 14.8817 - val_loss: 16.4246 - val_mean_squared_error: 16.4246\n",
      "Epoch 1511/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.0365 - mean_squared_error: 14.0365 - val_loss: 16.4944 - val_mean_squared_error: 16.4944\n",
      "Epoch 1512/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.9245 - mean_squared_error: 13.9245 - val_loss: 16.8571 - val_mean_squared_error: 16.8571\n",
      "Epoch 1513/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.9603 - mean_squared_error: 13.9603 - val_loss: 16.5105 - val_mean_squared_error: 16.5105\n",
      "Epoch 1514/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.8787 - mean_squared_error: 13.8787 - val_loss: 16.3616 - val_mean_squared_error: 16.3616\n",
      "Epoch 1515/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.2266 - mean_squared_error: 14.2266 - val_loss: 16.4427 - val_mean_squared_error: 16.4427\n",
      "Epoch 1516/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3172 - mean_squared_error: 14.3172 - val_loss: 16.3827 - val_mean_squared_error: 16.3827\n",
      "Epoch 1517/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.1119 - mean_squared_error: 14.1119 - val_loss: 16.3253 - val_mean_squared_error: 16.3253\n",
      "Epoch 1518/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.9110 - mean_squared_error: 13.9110 - val_loss: 16.5379 - val_mean_squared_error: 16.5379\n",
      "Epoch 1519/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.9585 - mean_squared_error: 13.9585 - val_loss: 16.7869 - val_mean_squared_error: 16.7869\n",
      "Epoch 1520/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.9273 - mean_squared_error: 13.9273 - val_loss: 16.4547 - val_mean_squared_error: 16.4547\n",
      "Epoch 1521/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.8592 - mean_squared_error: 13.8592 - val_loss: 16.4167 - val_mean_squared_error: 16.4167\n",
      "Epoch 1522/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.8572 - mean_squared_error: 13.8572 - val_loss: 16.3737 - val_mean_squared_error: 16.3737\n",
      "Epoch 1523/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.9709 - mean_squared_error: 13.9709 - val_loss: 17.1271 - val_mean_squared_error: 17.1271\n",
      "Epoch 1524/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.2089 - mean_squared_error: 14.2089 - val_loss: 16.9059 - val_mean_squared_error: 16.9059\n",
      "Epoch 1525/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.2201 - mean_squared_error: 14.2201 - val_loss: 17.1748 - val_mean_squared_error: 17.1748\n",
      "Epoch 1526/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 16.4420 - mean_squared_error: 16.44 - 0s 41us/sample - loss: 14.1355 - mean_squared_error: 14.1355 - val_loss: 16.7995 - val_mean_squared_error: 16.7995\n",
      "Epoch 1527/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.8897 - mean_squared_error: 13.8897 - val_loss: 16.4354 - val_mean_squared_error: 16.4354\n",
      "Epoch 1528/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.9455 - mean_squared_error: 13.9455 - val_loss: 16.3612 - val_mean_squared_error: 16.3612\n",
      "Epoch 1529/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.9306 - mean_squared_error: 13.9306 - val_loss: 16.8409 - val_mean_squared_error: 16.8409\n",
      "Epoch 1530/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.9411 - mean_squared_error: 13.9411 - val_loss: 16.6315 - val_mean_squared_error: 16.6315\n",
      "Epoch 1531/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.0474 - mean_squared_error: 14.0474 - val_loss: 17.1578 - val_mean_squared_error: 17.1578\n",
      "Epoch 1532/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 11.1409 - mean_squared_error: 11.14 - 0s 56us/sample - loss: 13.9553 - mean_squared_error: 13.9553 - val_loss: 16.3728 - val_mean_squared_error: 16.3728\n",
      "Epoch 1533/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.1928 - mean_squared_error: 14.1928 - val_loss: 16.2325 - val_mean_squared_error: 16.2325\n",
      "Epoch 1534/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.1154 - mean_squared_error: 14.1154 - val_loss: 16.2803 - val_mean_squared_error: 16.2803\n",
      "Epoch 1535/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.4215 - mean_squared_error: 14.4215 - val_loss: 16.3197 - val_mean_squared_error: 16.3197\n",
      "Epoch 1536/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.9826 - mean_squared_error: 13.9826 - val_loss: 16.5300 - val_mean_squared_error: 16.5300\n",
      "Epoch 1537/4000\n",
      "339/339 [==============================] - 0s 58us/sample - loss: 13.8677 - mean_squared_error: 13.8677 - val_loss: 16.2671 - val_mean_squared_error: 16.2671\n",
      "Epoch 1538/4000\n",
      "339/339 [==============================] - 0s 64us/sample - loss: 14.1800 - mean_squared_error: 14.1800 - val_loss: 16.2294 - val_mean_squared_error: 16.2294\n",
      "Epoch 1539/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.0698 - mean_squared_error: 14.0698 - val_loss: 16.2311 - val_mean_squared_error: 16.2311\n",
      "Epoch 1540/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9211 - mean_squared_error: 13.9211 - val_loss: 16.2677 - val_mean_squared_error: 16.2677\n",
      "Epoch 1541/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.9137 - mean_squared_error: 13.9137 - val_loss: 16.9608 - val_mean_squared_error: 16.9608\n",
      "Epoch 1542/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.1830 - mean_squared_error: 14.1830 - val_loss: 16.7791 - val_mean_squared_error: 16.7791\n",
      "Epoch 1543/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.9221 - mean_squared_error: 13.9221 - val_loss: 16.4759 - val_mean_squared_error: 16.4759\n",
      "Epoch 1544/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 13.8812 - mean_squared_error: 13.8812 - val_loss: 16.5068 - val_mean_squared_error: 16.5068\n",
      "Epoch 1545/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.8403 - mean_squared_error: 13.8403 - val_loss: 16.3215 - val_mean_squared_error: 16.3215\n",
      "Epoch 1546/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.8509 - mean_squared_error: 13.8509 - val_loss: 16.3130 - val_mean_squared_error: 16.3130\n",
      "Epoch 1547/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.5720 - mean_squared_error: 14.5720 - val_loss: 16.9410 - val_mean_squared_error: 16.9410\n",
      "Epoch 1548/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 50us/sample - loss: 14.8096 - mean_squared_error: 14.8096 - val_loss: 16.2099 - val_mean_squared_error: 16.2099\n",
      "Epoch 1549/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.8312 - mean_squared_error: 13.8312 - val_loss: 16.6281 - val_mean_squared_error: 16.6281\n",
      "Epoch 1550/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.0505 - mean_squared_error: 14.0505 - val_loss: 16.5884 - val_mean_squared_error: 16.5884\n",
      "Epoch 1551/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.7408 - mean_squared_error: 15.7408 - val_loss: 16.8307 - val_mean_squared_error: 16.8307\n",
      "Epoch 1552/4000\n",
      "339/339 [==============================] - 0s 75us/sample - loss: 14.5899 - mean_squared_error: 14.5899 - val_loss: 16.1771 - val_mean_squared_error: 16.1771\n",
      "Epoch 1553/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.8774 - mean_squared_error: 13.8774 - val_loss: 16.1366 - val_mean_squared_error: 16.1366\n",
      "Epoch 1554/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.9108 - mean_squared_error: 13.9108 - val_loss: 16.2732 - val_mean_squared_error: 16.2732\n",
      "Epoch 1555/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.8249 - mean_squared_error: 13.8249 - val_loss: 16.3573 - val_mean_squared_error: 16.3573\n",
      "Epoch 1556/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.8367 - mean_squared_error: 13.8367 - val_loss: 16.2389 - val_mean_squared_error: 16.2389\n",
      "Epoch 1557/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.9781 - mean_squared_error: 13.9781 - val_loss: 17.2795 - val_mean_squared_error: 17.2795\n",
      "Epoch 1558/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.5321 - mean_squared_error: 14.5321 - val_loss: 17.2845 - val_mean_squared_error: 17.2845\n",
      "Epoch 1559/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 7.7610 - mean_squared_error: 7.76 - 0s 52us/sample - loss: 13.9199 - mean_squared_error: 13.9199 - val_loss: 16.3722 - val_mean_squared_error: 16.3722\n",
      "Epoch 1560/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 14.0116 - mean_squared_error: 14.0116 - val_loss: 16.3439 - val_mean_squared_error: 16.3439\n",
      "Epoch 1561/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.8971 - mean_squared_error: 13.8971 - val_loss: 16.9559 - val_mean_squared_error: 16.9559\n",
      "Epoch 1562/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9804 - mean_squared_error: 13.9804 - val_loss: 16.2076 - val_mean_squared_error: 16.2076\n",
      "Epoch 1563/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.8637 - mean_squared_error: 13.8637 - val_loss: 16.0963 - val_mean_squared_error: 16.0963\n",
      "Epoch 1564/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8585 - mean_squared_error: 13.8585 - val_loss: 16.1944 - val_mean_squared_error: 16.1944\n",
      "Epoch 1565/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.8167 - mean_squared_error: 13.8167 - val_loss: 16.3923 - val_mean_squared_error: 16.3923\n",
      "Epoch 1566/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.9488 - mean_squared_error: 13.9488 - val_loss: 16.6408 - val_mean_squared_error: 16.6408\n",
      "Epoch 1567/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8070 - mean_squared_error: 13.8070 - val_loss: 16.1797 - val_mean_squared_error: 16.1797\n",
      "Epoch 1568/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3486 - mean_squared_error: 14.3486 - val_loss: 16.4011 - val_mean_squared_error: 16.4011\n",
      "Epoch 1569/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.0217 - mean_squared_error: 14.0217 - val_loss: 16.6804 - val_mean_squared_error: 16.6804\n",
      "Epoch 1570/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.8264 - mean_squared_error: 13.8264 - val_loss: 16.2185 - val_mean_squared_error: 16.2185\n",
      "Epoch 1571/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9326 - mean_squared_error: 13.9326 - val_loss: 16.3502 - val_mean_squared_error: 16.3502\n",
      "Epoch 1572/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.8172 - mean_squared_error: 13.8172 - val_loss: 16.1356 - val_mean_squared_error: 16.1356\n",
      "Epoch 1573/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.8274 - mean_squared_error: 13.8274 - val_loss: 16.3493 - val_mean_squared_error: 16.3493\n",
      "Epoch 1574/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.8240 - mean_squared_error: 13.8240 - val_loss: 16.1068 - val_mean_squared_error: 16.1068\n",
      "Epoch 1575/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 14.1189 - mean_squared_error: 14.1189 - val_loss: 16.2826 - val_mean_squared_error: 16.2826\n",
      "Epoch 1576/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.1111 - mean_squared_error: 14.1111 - val_loss: 16.2699 - val_mean_squared_error: 16.2699\n",
      "Epoch 1577/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.7874 - mean_squared_error: 13.7874 - val_loss: 16.4006 - val_mean_squared_error: 16.4006\n",
      "Epoch 1578/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.8642 - mean_squared_error: 13.8642 - val_loss: 16.1691 - val_mean_squared_error: 16.1691\n",
      "Epoch 1579/4000\n",
      "339/339 [==============================] - 0s 70us/sample - loss: 14.2921 - mean_squared_error: 14.2921 - val_loss: 16.0180 - val_mean_squared_error: 16.0180\n",
      "Epoch 1580/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 14.4756 - mean_squared_error: 14.47 - 0s 51us/sample - loss: 13.7953 - mean_squared_error: 13.7953 - val_loss: 16.4301 - val_mean_squared_error: 16.4301\n",
      "Epoch 1581/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 14.6278 - mean_squared_error: 14.6278 - val_loss: 18.4919 - val_mean_squared_error: 18.4919\n",
      "Epoch 1582/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.7484 - mean_squared_error: 14.7484 - val_loss: 16.4996 - val_mean_squared_error: 16.4996\n",
      "Epoch 1583/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.8833 - mean_squared_error: 13.8833 - val_loss: 16.4539 - val_mean_squared_error: 16.4539\n",
      "Epoch 1584/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.8063 - mean_squared_error: 13.8063 - val_loss: 16.1473 - val_mean_squared_error: 16.1473\n",
      "Epoch 1585/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.9312 - mean_squared_error: 13.9312 - val_loss: 17.1354 - val_mean_squared_error: 17.1354\n",
      "Epoch 1586/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 14.2865 - mean_squared_error: 14.2865 - val_loss: 16.6143 - val_mean_squared_error: 16.6143\n",
      "Epoch 1587/4000\n",
      "339/339 [==============================] - 0s 66us/sample - loss: 13.9065 - mean_squared_error: 13.9065 - val_loss: 16.4049 - val_mean_squared_error: 16.4049\n",
      "Epoch 1588/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.9983 - mean_squared_error: 13.9983 - val_loss: 16.9198 - val_mean_squared_error: 16.9198\n",
      "Epoch 1589/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 14.6943 - mean_squared_error: 14.6943 - val_loss: 17.9374 - val_mean_squared_error: 17.9374\n",
      "Epoch 1590/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.9411 - mean_squared_error: 14.9411 - val_loss: 17.5804 - val_mean_squared_error: 17.5804\n",
      "Epoch 1591/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.9541 - mean_squared_error: 13.9541 - val_loss: 16.2265 - val_mean_squared_error: 16.2265\n",
      "Epoch 1592/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.0470 - mean_squared_error: 14.0470 - val_loss: 16.1591 - val_mean_squared_error: 16.1591\n",
      "Epoch 1593/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.8001 - mean_squared_error: 13.8001 - val_loss: 16.6096 - val_mean_squared_error: 16.6096\n",
      "Epoch 1594/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 45us/sample - loss: 13.8151 - mean_squared_error: 13.8151 - val_loss: 16.2284 - val_mean_squared_error: 16.2284\n",
      "Epoch 1595/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.7917 - mean_squared_error: 13.7917 - val_loss: 16.4289 - val_mean_squared_error: 16.4289\n",
      "Epoch 1596/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.9962 - mean_squared_error: 13.9962 - val_loss: 16.1598 - val_mean_squared_error: 16.1598\n",
      "Epoch 1597/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.9689 - mean_squared_error: 13.9689 - val_loss: 16.2758 - val_mean_squared_error: 16.2758\n",
      "Epoch 1598/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.9188 - mean_squared_error: 13.9188 - val_loss: 16.1830 - val_mean_squared_error: 16.1830\n",
      "Epoch 1599/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.5583 - mean_squared_error: 14.5583 - val_loss: 16.1972 - val_mean_squared_error: 16.1972\n",
      "Epoch 1600/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.0558 - mean_squared_error: 14.0558 - val_loss: 16.1099 - val_mean_squared_error: 16.1099\n",
      "Epoch 1601/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.8083 - mean_squared_error: 13.8083 - val_loss: 15.9775 - val_mean_squared_error: 15.9775\n",
      "Epoch 1602/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.9284 - mean_squared_error: 13.9284 - val_loss: 17.7785 - val_mean_squared_error: 17.7785\n",
      "Epoch 1603/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2902 - mean_squared_error: 14.2902 - val_loss: 16.1019 - val_mean_squared_error: 16.1019\n",
      "Epoch 1604/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.8240 - mean_squared_error: 13.8240 - val_loss: 16.0113 - val_mean_squared_error: 16.0113\n",
      "Epoch 1605/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.9354 - mean_squared_error: 13.9354 - val_loss: 16.0305 - val_mean_squared_error: 16.0305\n",
      "Epoch 1606/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.9335 - mean_squared_error: 13.9335 - val_loss: 17.3970 - val_mean_squared_error: 17.3970\n",
      "Epoch 1607/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2570 - mean_squared_error: 14.2570 - val_loss: 16.5865 - val_mean_squared_error: 16.5865\n",
      "Epoch 1608/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7841 - mean_squared_error: 13.7841 - val_loss: 16.1156 - val_mean_squared_error: 16.1156\n",
      "Epoch 1609/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.8045 - mean_squared_error: 13.8045 - val_loss: 16.9301 - val_mean_squared_error: 16.9301\n",
      "Epoch 1610/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.9941 - mean_squared_error: 13.9941 - val_loss: 16.2391 - val_mean_squared_error: 16.2391\n",
      "Epoch 1611/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.7525 - mean_squared_error: 13.7525 - val_loss: 15.9990 - val_mean_squared_error: 15.9990\n",
      "Epoch 1612/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.8230 - mean_squared_error: 13.8230 - val_loss: 15.9715 - val_mean_squared_error: 15.9715\n",
      "Epoch 1613/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9536 - mean_squared_error: 13.9536 - val_loss: 15.9936 - val_mean_squared_error: 15.9936\n",
      "Epoch 1614/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.1182 - mean_squared_error: 14.1182 - val_loss: 15.9986 - val_mean_squared_error: 15.9986\n",
      "Epoch 1615/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.3395 - mean_squared_error: 14.3395 - val_loss: 16.1734 - val_mean_squared_error: 16.1734\n",
      "Epoch 1616/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.5981 - mean_squared_error: 14.5981 - val_loss: 16.0855 - val_mean_squared_error: 16.0855\n",
      "Epoch 1617/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8500 - mean_squared_error: 13.8500 - val_loss: 17.5091 - val_mean_squared_error: 17.5091\n",
      "Epoch 1618/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9293 - mean_squared_error: 13.9293 - val_loss: 16.0465 - val_mean_squared_error: 16.0465\n",
      "Epoch 1619/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8350 - mean_squared_error: 13.8350 - val_loss: 16.6684 - val_mean_squared_error: 16.6684\n",
      "Epoch 1620/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.8201 - mean_squared_error: 14.8201 - val_loss: 18.5653 - val_mean_squared_error: 18.5653\n",
      "Epoch 1621/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 14.3840 - mean_squared_error: 14.3840 - val_loss: 16.1270 - val_mean_squared_error: 16.1270\n",
      "Epoch 1622/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.8031 - mean_squared_error: 13.8031 - val_loss: 16.0642 - val_mean_squared_error: 16.0642\n",
      "Epoch 1623/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.8148 - mean_squared_error: 13.8148 - val_loss: 16.1034 - val_mean_squared_error: 16.1034\n",
      "Epoch 1624/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.8120 - mean_squared_error: 13.8120 - val_loss: 16.0255 - val_mean_squared_error: 16.0255\n",
      "Epoch 1625/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.5139 - mean_squared_error: 14.5139 - val_loss: 16.5043 - val_mean_squared_error: 16.5043\n",
      "Epoch 1626/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 14.3441 - mean_squared_error: 14.3441 - val_loss: 16.0457 - val_mean_squared_error: 16.0457\n",
      "Epoch 1627/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7374 - mean_squared_error: 13.7374 - val_loss: 16.0206 - val_mean_squared_error: 16.0206\n",
      "Epoch 1628/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.4723 - mean_squared_error: 14.4723 - val_loss: 19.5735 - val_mean_squared_error: 19.5735\n",
      "Epoch 1629/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.6650 - mean_squared_error: 14.6650 - val_loss: 16.0656 - val_mean_squared_error: 16.0656\n",
      "Epoch 1630/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.7643 - mean_squared_error: 13.7643 - val_loss: 16.2768 - val_mean_squared_error: 16.2768\n",
      "Epoch 1631/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7555 - mean_squared_error: 13.7555 - val_loss: 16.0870 - val_mean_squared_error: 16.0870\n",
      "Epoch 1632/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.0940 - mean_squared_error: 14.0940 - val_loss: 16.2136 - val_mean_squared_error: 16.2136\n",
      "Epoch 1633/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.1698 - mean_squared_error: 14.1698 - val_loss: 16.0438 - val_mean_squared_error: 16.0438\n",
      "Epoch 1634/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.9226 - mean_squared_error: 13.9227 - val_loss: 16.0138 - val_mean_squared_error: 16.0138\n",
      "Epoch 1635/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.8687 - mean_squared_error: 13.8687 - val_loss: 16.0679 - val_mean_squared_error: 16.0679\n",
      "Epoch 1636/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.7714 - mean_squared_error: 13.7714 - val_loss: 15.9693 - val_mean_squared_error: 15.9693\n",
      "Epoch 1637/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.7548 - mean_squared_error: 13.7548 - val_loss: 16.3080 - val_mean_squared_error: 16.3080\n",
      "Epoch 1638/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7311 - mean_squared_error: 13.7311 - val_loss: 15.9908 - val_mean_squared_error: 15.9908\n",
      "Epoch 1639/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.9604 - mean_squared_error: 13.9604 - val_loss: 17.3481 - val_mean_squared_error: 17.3481\n",
      "Epoch 1640/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.0024 - mean_squared_error: 14.0024 - val_loss: 16.1012 - val_mean_squared_error: 16.1012\n",
      "Epoch 1641/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6992 - mean_squared_error: 13.6992 - val_loss: 16.1132 - val_mean_squared_error: 16.1132\n",
      "Epoch 1642/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.9679 - mean_squared_error: 13.9679 - val_loss: 16.1546 - val_mean_squared_error: 16.1546\n",
      "Epoch 1643/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.0662 - mean_squared_error: 14.0662 - val_loss: 16.0276 - val_mean_squared_error: 16.0276\n",
      "Epoch 1644/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.9451 - mean_squared_error: 13.9451 - val_loss: 17.1620 - val_mean_squared_error: 17.1620\n",
      "Epoch 1645/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9352 - mean_squared_error: 13.9352 - val_loss: 16.0645 - val_mean_squared_error: 16.0645\n",
      "Epoch 1646/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8455 - mean_squared_error: 13.8455 - val_loss: 15.9573 - val_mean_squared_error: 15.9573\n",
      "Epoch 1647/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.9652 - mean_squared_error: 13.9652 - val_loss: 15.9327 - val_mean_squared_error: 15.9327\n",
      "Epoch 1648/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.7109 - mean_squared_error: 13.7109 - val_loss: 16.4985 - val_mean_squared_error: 16.4985\n",
      "Epoch 1649/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7819 - mean_squared_error: 13.7819 - val_loss: 16.1072 - val_mean_squared_error: 16.1072\n",
      "Epoch 1650/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.4419 - mean_squared_error: 14.4419 - val_loss: 15.9188 - val_mean_squared_error: 15.9188\n",
      "Epoch 1651/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7961 - mean_squared_error: 13.7961 - val_loss: 16.2584 - val_mean_squared_error: 16.2584\n",
      "Epoch 1652/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.3366 - mean_squared_error: 14.3366 - val_loss: 17.9950 - val_mean_squared_error: 17.9950\n",
      "Epoch 1653/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.3599 - mean_squared_error: 14.3598 - val_loss: 16.0985 - val_mean_squared_error: 16.0985\n",
      "Epoch 1654/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8342 - mean_squared_error: 13.8342 - val_loss: 16.6610 - val_mean_squared_error: 16.6610\n",
      "Epoch 1655/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.7981 - mean_squared_error: 13.7981 - val_loss: 16.0239 - val_mean_squared_error: 16.0239\n",
      "Epoch 1656/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8490 - mean_squared_error: 13.8490 - val_loss: 16.1639 - val_mean_squared_error: 16.1639\n",
      "Epoch 1657/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6914 - mean_squared_error: 13.6914 - val_loss: 15.9230 - val_mean_squared_error: 15.9230\n",
      "Epoch 1658/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.5819 - mean_squared_error: 14.5819 - val_loss: 16.7363 - val_mean_squared_error: 16.7363\n",
      "Epoch 1659/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.6066 - mean_squared_error: 15.6066 - val_loss: 16.0077 - val_mean_squared_error: 16.0077\n",
      "Epoch 1660/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.0775 - mean_squared_error: 14.0775 - val_loss: 15.8134 - val_mean_squared_error: 15.8134\n",
      "Epoch 1661/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.1882 - mean_squared_error: 14.1882 - val_loss: 16.0476 - val_mean_squared_error: 16.0476\n",
      "Epoch 1662/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 14.9627 - mean_squared_error: 14.9627 - val_loss: 16.0418 - val_mean_squared_error: 16.0418\n",
      "Epoch 1663/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 15.1172 - mean_squared_error: 15.1172 - val_loss: 16.2752 - val_mean_squared_error: 16.2752\n",
      "Epoch 1664/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3855 - mean_squared_error: 14.3855 - val_loss: 15.8924 - val_mean_squared_error: 15.8924\n",
      "Epoch 1665/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.0197 - mean_squared_error: 14.0197 - val_loss: 16.0918 - val_mean_squared_error: 16.0918\n",
      "Epoch 1666/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.8526 - mean_squared_error: 13.8526 - val_loss: 16.7453 - val_mean_squared_error: 16.7453\n",
      "Epoch 1667/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7624 - mean_squared_error: 13.7624 - val_loss: 15.8588 - val_mean_squared_error: 15.8588\n",
      "Epoch 1668/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 14.0909 - mean_squared_error: 14.0909 - val_loss: 15.9902 - val_mean_squared_error: 15.9902\n",
      "Epoch 1669/4000\n",
      "339/339 [==============================] - 0s 11us/sample - loss: 13.9500 - mean_squared_error: 13.9500 - val_loss: 15.9748 - val_mean_squared_error: 15.9748\n",
      "Epoch 1670/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.2701 - mean_squared_error: 14.2701 - val_loss: 18.1135 - val_mean_squared_error: 18.1135\n",
      "Epoch 1671/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.5143 - mean_squared_error: 14.5143 - val_loss: 16.3491 - val_mean_squared_error: 16.3491\n",
      "Epoch 1672/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.7802 - mean_squared_error: 13.7802 - val_loss: 15.9068 - val_mean_squared_error: 15.9068\n",
      "Epoch 1673/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.2600 - mean_squared_error: 14.2600 - val_loss: 15.9489 - val_mean_squared_error: 15.9489\n",
      "Epoch 1674/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.3420 - mean_squared_error: 14.3420 - val_loss: 15.9160 - val_mean_squared_error: 15.9160\n",
      "Epoch 1675/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.0148 - mean_squared_error: 14.0148 - val_loss: 15.7990 - val_mean_squared_error: 15.7990\n",
      "Epoch 1676/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7219 - mean_squared_error: 13.7219 - val_loss: 15.7809 - val_mean_squared_error: 15.7809\n",
      "Epoch 1677/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.6685 - mean_squared_error: 13.6685 - val_loss: 16.0209 - val_mean_squared_error: 16.0209\n",
      "Epoch 1678/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.6633 - mean_squared_error: 13.6633 - val_loss: 15.8716 - val_mean_squared_error: 15.8716\n",
      "Epoch 1679/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.6740 - mean_squared_error: 13.6740 - val_loss: 15.8812 - val_mean_squared_error: 15.8812\n",
      "Epoch 1680/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6840 - mean_squared_error: 13.6840 - val_loss: 16.1216 - val_mean_squared_error: 16.1216\n",
      "Epoch 1681/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.7289 - mean_squared_error: 13.7289 - val_loss: 16.2066 - val_mean_squared_error: 16.2066\n",
      "Epoch 1682/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7582 - mean_squared_error: 13.7582 - val_loss: 16.2063 - val_mean_squared_error: 16.2063\n",
      "Epoch 1683/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.6792 - mean_squared_error: 13.6792 - val_loss: 15.8696 - val_mean_squared_error: 15.8696\n",
      "Epoch 1684/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.1170 - mean_squared_error: 14.1170 - val_loss: 17.8479 - val_mean_squared_error: 17.8479\n",
      "Epoch 1685/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 14.2952 - mean_squared_error: 14.2952 - val_loss: 15.9247 - val_mean_squared_error: 15.9247\n",
      "Epoch 1686/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6692 - mean_squared_error: 13.6692 - val_loss: 15.8915 - val_mean_squared_error: 15.8915\n",
      "Epoch 1687/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6862 - mean_squared_error: 13.6862 - val_loss: 16.4635 - val_mean_squared_error: 16.4635\n",
      "Epoch 1688/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 21us/sample - loss: 14.0439 - mean_squared_error: 14.0439 - val_loss: 16.6198 - val_mean_squared_error: 16.6198\n",
      "Epoch 1689/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.7429 - mean_squared_error: 13.7429 - val_loss: 15.8936 - val_mean_squared_error: 15.8936\n",
      "Epoch 1690/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7319 - mean_squared_error: 13.7319 - val_loss: 16.4200 - val_mean_squared_error: 16.4200\n",
      "Epoch 1691/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9160 - mean_squared_error: 13.9159 - val_loss: 16.5408 - val_mean_squared_error: 16.5408\n",
      "Epoch 1692/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9410 - mean_squared_error: 13.9410 - val_loss: 16.5444 - val_mean_squared_error: 16.5444\n",
      "Epoch 1693/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7695 - mean_squared_error: 13.7695 - val_loss: 15.9748 - val_mean_squared_error: 15.9748\n",
      "Epoch 1694/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6950 - mean_squared_error: 13.6950 - val_loss: 15.7965 - val_mean_squared_error: 15.7965\n",
      "Epoch 1695/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.6771 - mean_squared_error: 13.6771 - val_loss: 16.2389 - val_mean_squared_error: 16.2389\n",
      "Epoch 1696/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5231 - mean_squared_error: 14.5231 - val_loss: 18.3012 - val_mean_squared_error: 18.3012\n",
      "Epoch 1697/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.0350 - mean_squared_error: 16.0350 - val_loss: 18.6328 - val_mean_squared_error: 18.6328\n",
      "Epoch 1698/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.9042 - mean_squared_error: 14.9042 - val_loss: 16.4715 - val_mean_squared_error: 16.4715\n",
      "Epoch 1699/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2820 - mean_squared_error: 14.2820 - val_loss: 17.5216 - val_mean_squared_error: 17.5216\n",
      "Epoch 1700/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.0464 - mean_squared_error: 14.0464 - val_loss: 16.1150 - val_mean_squared_error: 16.1150\n",
      "Epoch 1701/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.8596 - mean_squared_error: 13.8596 - val_loss: 17.1430 - val_mean_squared_error: 17.1430\n",
      "Epoch 1702/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7755 - mean_squared_error: 13.7755 - val_loss: 15.9143 - val_mean_squared_error: 15.9143\n",
      "Epoch 1703/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9841 - mean_squared_error: 13.9841 - val_loss: 18.6947 - val_mean_squared_error: 18.6947\n",
      "Epoch 1704/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 16.0740 - mean_squared_error: 16.0740 - val_loss: 18.1574 - val_mean_squared_error: 18.1574\n",
      "Epoch 1705/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3862 - mean_squared_error: 14.3862 - val_loss: 15.9892 - val_mean_squared_error: 15.9892\n",
      "Epoch 1706/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.7167 - mean_squared_error: 13.7167 - val_loss: 16.4848 - val_mean_squared_error: 16.4848\n",
      "Epoch 1707/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.0873 - mean_squared_error: 14.0873 - val_loss: 16.7514 - val_mean_squared_error: 16.7514\n",
      "Epoch 1708/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7333 - mean_squared_error: 13.7333 - val_loss: 15.8985 - val_mean_squared_error: 15.8985\n",
      "Epoch 1709/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8252 - mean_squared_error: 13.8252 - val_loss: 15.9115 - val_mean_squared_error: 15.9115\n",
      "Epoch 1710/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.7976 - mean_squared_error: 13.7976 - val_loss: 15.8691 - val_mean_squared_error: 15.8691\n",
      "Epoch 1711/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.3241 - mean_squared_error: 14.3241 - val_loss: 15.9438 - val_mean_squared_error: 15.9438\n",
      "Epoch 1712/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.7865 - mean_squared_error: 13.7865 - val_loss: 16.7830 - val_mean_squared_error: 16.7830\n",
      "Epoch 1713/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7353 - mean_squared_error: 13.7353 - val_loss: 16.0542 - val_mean_squared_error: 16.0542\n",
      "Epoch 1714/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2627 - mean_squared_error: 14.2627 - val_loss: 15.8691 - val_mean_squared_error: 15.8691\n",
      "Epoch 1715/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2589 - mean_squared_error: 14.2589 - val_loss: 15.8620 - val_mean_squared_error: 15.8620\n",
      "Epoch 1716/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1262 - mean_squared_error: 14.1262 - val_loss: 15.7329 - val_mean_squared_error: 15.7329\n",
      "Epoch 1717/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6774 - mean_squared_error: 13.6774 - val_loss: 16.4933 - val_mean_squared_error: 16.4933\n",
      "Epoch 1718/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.7057 - mean_squared_error: 13.7057 - val_loss: 15.7654 - val_mean_squared_error: 15.7654\n",
      "Epoch 1719/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.6553 - mean_squared_error: 13.6553 - val_loss: 16.2696 - val_mean_squared_error: 16.2696\n",
      "Epoch 1720/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6609 - mean_squared_error: 13.6609 - val_loss: 15.6588 - val_mean_squared_error: 15.6588\n",
      "Epoch 1721/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6630 - mean_squared_error: 13.6630 - val_loss: 15.9940 - val_mean_squared_error: 15.9940\n",
      "Epoch 1722/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.8728 - mean_squared_error: 13.8728 - val_loss: 16.6905 - val_mean_squared_error: 16.6905\n",
      "Epoch 1723/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.9381 - mean_squared_error: 13.9381 - val_loss: 16.1460 - val_mean_squared_error: 16.1460\n",
      "Epoch 1724/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7438 - mean_squared_error: 13.7438 - val_loss: 16.1574 - val_mean_squared_error: 16.1574\n",
      "Epoch 1725/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6493 - mean_squared_error: 13.6493 - val_loss: 15.8084 - val_mean_squared_error: 15.8084\n",
      "Epoch 1726/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.6007 - mean_squared_error: 13.6007 - val_loss: 15.9700 - val_mean_squared_error: 15.9700\n",
      "Epoch 1727/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.8345 - mean_squared_error: 13.8345 - val_loss: 16.4643 - val_mean_squared_error: 16.4643\n",
      "Epoch 1728/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 11.9090 - mean_squared_error: 11.90 - 0s 35us/sample - loss: 13.7371 - mean_squared_error: 13.7371 - val_loss: 15.7472 - val_mean_squared_error: 15.7472\n",
      "Epoch 1729/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.6165 - mean_squared_error: 13.6165 - val_loss: 15.7052 - val_mean_squared_error: 15.7052\n",
      "Epoch 1730/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6239 - mean_squared_error: 13.6239 - val_loss: 16.2760 - val_mean_squared_error: 16.2760\n",
      "Epoch 1731/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.1904 - mean_squared_error: 14.1904 - val_loss: 16.7929 - val_mean_squared_error: 16.7929\n",
      "Epoch 1732/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.7834 - mean_squared_error: 13.7834 - val_loss: 15.6570 - val_mean_squared_error: 15.6570\n",
      "Epoch 1733/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.8159 - mean_squared_error: 13.8159 - val_loss: 15.5772 - val_mean_squared_error: 15.5772\n",
      "Epoch 1734/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 14.4007 - mean_squared_error: 14.4007 - val_loss: 16.0720 - val_mean_squared_error: 16.0720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1735/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.4003 - mean_squared_error: 14.4003 - val_loss: 15.6714 - val_mean_squared_error: 15.6714\n",
      "Epoch 1736/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.9088 - mean_squared_error: 13.9088 - val_loss: 17.7519 - val_mean_squared_error: 17.7519\n",
      "Epoch 1737/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.4162 - mean_squared_error: 14.4162 - val_loss: 15.8647 - val_mean_squared_error: 15.8647\n",
      "Epoch 1738/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.6177 - mean_squared_error: 13.6177 - val_loss: 15.7573 - val_mean_squared_error: 15.7573\n",
      "Epoch 1739/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.8866 - mean_squared_error: 13.8866 - val_loss: 16.8265 - val_mean_squared_error: 16.8265\n",
      "Epoch 1740/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.8211 - mean_squared_error: 13.8211 - val_loss: 15.5909 - val_mean_squared_error: 15.5909\n",
      "Epoch 1741/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6020 - mean_squared_error: 13.6020 - val_loss: 15.6726 - val_mean_squared_error: 15.6726\n",
      "Epoch 1742/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.5889 - mean_squared_error: 13.5889 - val_loss: 15.7112 - val_mean_squared_error: 15.7112\n",
      "Epoch 1743/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7838 - mean_squared_error: 13.7838 - val_loss: 16.7749 - val_mean_squared_error: 16.7749\n",
      "Epoch 1744/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.8351 - mean_squared_error: 13.8351 - val_loss: 15.6843 - val_mean_squared_error: 15.6843\n",
      "Epoch 1745/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.6105 - mean_squared_error: 13.6105 - val_loss: 15.8229 - val_mean_squared_error: 15.8229\n",
      "Epoch 1746/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6281 - mean_squared_error: 13.6281 - val_loss: 15.6354 - val_mean_squared_error: 15.6354\n",
      "Epoch 1747/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7200 - mean_squared_error: 13.7200 - val_loss: 15.9665 - val_mean_squared_error: 15.9665\n",
      "Epoch 1748/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.7653 - mean_squared_error: 13.7653 - val_loss: 16.4005 - val_mean_squared_error: 16.4005\n",
      "Epoch 1749/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.8309 - mean_squared_error: 13.8309 - val_loss: 15.9279 - val_mean_squared_error: 15.9279\n",
      "Epoch 1750/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.5846 - mean_squared_error: 13.5846 - val_loss: 15.6543 - val_mean_squared_error: 15.6543\n",
      "Epoch 1751/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.6809 - mean_squared_error: 13.6809 - val_loss: 15.6267 - val_mean_squared_error: 15.6267\n",
      "Epoch 1752/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.8339 - mean_squared_error: 13.8339 - val_loss: 15.6224 - val_mean_squared_error: 15.6224\n",
      "Epoch 1753/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5868 - mean_squared_error: 13.5868 - val_loss: 15.9693 - val_mean_squared_error: 15.9693\n",
      "Epoch 1754/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.2391 - mean_squared_error: 14.2391 - val_loss: 17.5538 - val_mean_squared_error: 17.5538\n",
      "Epoch 1755/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 15.1561 - mean_squared_error: 15.1561 - val_loss: 17.4022 - val_mean_squared_error: 17.4022\n",
      "Epoch 1756/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.3699 - mean_squared_error: 14.3699 - val_loss: 16.0493 - val_mean_squared_error: 16.0493\n",
      "Epoch 1757/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6315 - mean_squared_error: 13.6315 - val_loss: 15.6161 - val_mean_squared_error: 15.6161\n",
      "Epoch 1758/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.7323 - mean_squared_error: 13.7323 - val_loss: 15.6273 - val_mean_squared_error: 15.6273\n",
      "Epoch 1759/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.7193 - mean_squared_error: 13.7193 - val_loss: 16.4981 - val_mean_squared_error: 16.4981\n",
      "Epoch 1760/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.7936 - mean_squared_error: 14.7936 - val_loss: 17.7611 - val_mean_squared_error: 17.7611\n",
      "Epoch 1761/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.3858 - mean_squared_error: 14.3858 - val_loss: 15.7661 - val_mean_squared_error: 15.7661\n",
      "Epoch 1762/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.8081 - mean_squared_error: 13.8081 - val_loss: 16.5456 - val_mean_squared_error: 16.5456\n",
      "Epoch 1763/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.8118 - mean_squared_error: 13.8118 - val_loss: 15.8972 - val_mean_squared_error: 15.8972\n",
      "Epoch 1764/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.6636 - mean_squared_error: 13.6636 - val_loss: 16.1126 - val_mean_squared_error: 16.1126\n",
      "Epoch 1765/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7201 - mean_squared_error: 13.7201 - val_loss: 15.9706 - val_mean_squared_error: 15.9706\n",
      "Epoch 1766/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.6024 - mean_squared_error: 13.6024 - val_loss: 15.7731 - val_mean_squared_error: 15.7731\n",
      "Epoch 1767/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.6451 - mean_squared_error: 13.6452 - val_loss: 16.1076 - val_mean_squared_error: 16.1076\n",
      "Epoch 1768/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.8637 - mean_squared_error: 13.8637 - val_loss: 16.5501 - val_mean_squared_error: 16.5501\n",
      "Epoch 1769/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.2815 - mean_squared_error: 14.2815 - val_loss: 17.2375 - val_mean_squared_error: 17.2375\n",
      "Epoch 1770/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 15.3457 - mean_squared_error: 15.3457 - val_loss: 18.5678 - val_mean_squared_error: 18.5678\n",
      "Epoch 1771/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.5581 - mean_squared_error: 14.5581 - val_loss: 15.7974 - val_mean_squared_error: 15.7974\n",
      "Epoch 1772/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.5907 - mean_squared_error: 13.5907 - val_loss: 15.6078 - val_mean_squared_error: 15.6078\n",
      "Epoch 1773/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.6897 - mean_squared_error: 13.6897 - val_loss: 16.8092 - val_mean_squared_error: 16.8092\n",
      "Epoch 1774/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.8456 - mean_squared_error: 13.8456 - val_loss: 15.7025 - val_mean_squared_error: 15.7025\n",
      "Epoch 1775/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5605 - mean_squared_error: 13.5605 - val_loss: 15.9057 - val_mean_squared_error: 15.9057\n",
      "Epoch 1776/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.5458 - mean_squared_error: 13.5457 - val_loss: 15.6214 - val_mean_squared_error: 15.6214\n",
      "Epoch 1777/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.8509 - mean_squared_error: 13.8509 - val_loss: 15.5813 - val_mean_squared_error: 15.5813\n",
      "Epoch 1778/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6941 - mean_squared_error: 13.6941 - val_loss: 15.6210 - val_mean_squared_error: 15.6210\n",
      "Epoch 1779/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6036 - mean_squared_error: 13.6036 - val_loss: 15.4556 - val_mean_squared_error: 15.4556\n",
      "Epoch 1780/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.1056 - mean_squared_error: 14.1056 - val_loss: 18.0945 - val_mean_squared_error: 18.0945\n",
      "Epoch 1781/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.3711 - mean_squared_error: 14.3711 - val_loss: 15.6918 - val_mean_squared_error: 15.6918\n",
      "Epoch 1782/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6626 - mean_squared_error: 13.6626 - val_loss: 15.6542 - val_mean_squared_error: 15.6542\n",
      "Epoch 1783/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.6772 - mean_squared_error: 13.6772 - val_loss: 16.7465 - val_mean_squared_error: 16.7465\n",
      "Epoch 1784/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.7329 - mean_squared_error: 13.7329 - val_loss: 15.8910 - val_mean_squared_error: 15.8910\n",
      "Epoch 1785/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.0421 - mean_squared_error: 14.0421 - val_loss: 15.5833 - val_mean_squared_error: 15.5833\n",
      "Epoch 1786/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.5446 - mean_squared_error: 13.5446 - val_loss: 15.9268 - val_mean_squared_error: 15.9268\n",
      "Epoch 1787/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7915 - mean_squared_error: 13.7915 - val_loss: 16.1629 - val_mean_squared_error: 16.1629\n",
      "Epoch 1788/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.6864 - mean_squared_error: 13.6864 - val_loss: 15.8341 - val_mean_squared_error: 15.8341\n",
      "Epoch 1789/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.5879 - mean_squared_error: 13.5879 - val_loss: 15.6367 - val_mean_squared_error: 15.6367\n",
      "Epoch 1790/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.6673 - mean_squared_error: 13.6673 - val_loss: 17.0246 - val_mean_squared_error: 17.0246\n",
      "Epoch 1791/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.7640 - mean_squared_error: 13.7640 - val_loss: 15.5982 - val_mean_squared_error: 15.5982\n",
      "Epoch 1792/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.5828 - mean_squared_error: 13.5828 - val_loss: 16.1128 - val_mean_squared_error: 16.1128\n",
      "Epoch 1793/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5609 - mean_squared_error: 13.5609 - val_loss: 15.6109 - val_mean_squared_error: 15.6109\n",
      "Epoch 1794/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.8138 - mean_squared_error: 13.8138 - val_loss: 15.5901 - val_mean_squared_error: 15.5901\n",
      "Epoch 1795/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.0344 - mean_squared_error: 14.0344 - val_loss: 15.5093 - val_mean_squared_error: 15.5093\n",
      "Epoch 1796/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.6669 - mean_squared_error: 13.6669 - val_loss: 15.5701 - val_mean_squared_error: 15.5701\n",
      "Epoch 1797/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.5242 - mean_squared_error: 13.5242 - val_loss: 15.7218 - val_mean_squared_error: 15.7218\n",
      "Epoch 1798/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.6082 - mean_squared_error: 13.6082 - val_loss: 15.9388 - val_mean_squared_error: 15.9388\n",
      "Epoch 1799/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.5735 - mean_squared_error: 13.5735 - val_loss: 15.5796 - val_mean_squared_error: 15.5796\n",
      "Epoch 1800/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.8641 - mean_squared_error: 13.8641 - val_loss: 15.7127 - val_mean_squared_error: 15.7127\n",
      "Epoch 1801/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.7690 - mean_squared_error: 13.7690 - val_loss: 15.7588 - val_mean_squared_error: 15.7588\n",
      "Epoch 1802/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.6258 - mean_squared_error: 13.6258 - val_loss: 15.9677 - val_mean_squared_error: 15.9677\n",
      "Epoch 1803/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.5645 - mean_squared_error: 13.5645 - val_loss: 15.4908 - val_mean_squared_error: 15.4908\n",
      "Epoch 1804/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.5306 - mean_squared_error: 13.5306 - val_loss: 15.8652 - val_mean_squared_error: 15.8652\n",
      "Epoch 1805/4000\n",
      "339/339 [==============================] - 0s 72us/sample - loss: 14.3823 - mean_squared_error: 14.3823 - val_loss: 17.8034 - val_mean_squared_error: 17.8034\n",
      "Epoch 1806/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 16.6622 - mean_squared_error: 16.6622 - val_loss: 20.0879 - val_mean_squared_error: 20.0879\n",
      "Epoch 1807/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8814 - mean_squared_error: 14.8814 - val_loss: 15.6494 - val_mean_squared_error: 15.6494\n",
      "Epoch 1808/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.6035 - mean_squared_error: 13.6035 - val_loss: 16.6256 - val_mean_squared_error: 16.6256\n",
      "Epoch 1809/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.3597 - mean_squared_error: 14.3597 - val_loss: 16.9223 - val_mean_squared_error: 16.9223\n",
      "Epoch 1810/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.8669 - mean_squared_error: 13.8669 - val_loss: 16.3936 - val_mean_squared_error: 16.3936\n",
      "Epoch 1811/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 14.8455 - mean_squared_error: 14.8455 - val_loss: 15.5235 - val_mean_squared_error: 15.5235\n",
      "Epoch 1812/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.7955 - mean_squared_error: 13.7955 - val_loss: 15.5361 - val_mean_squared_error: 15.5361\n",
      "Epoch 1813/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6806 - mean_squared_error: 13.6806 - val_loss: 15.5014 - val_mean_squared_error: 15.5014\n",
      "Epoch 1814/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.6468 - mean_squared_error: 13.6468 - val_loss: 16.5795 - val_mean_squared_error: 16.5795\n",
      "Epoch 1815/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.8052 - mean_squared_error: 13.8052 - val_loss: 16.5675 - val_mean_squared_error: 16.5675\n",
      "Epoch 1816/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.5492 - mean_squared_error: 14.5492 - val_loss: 15.5611 - val_mean_squared_error: 15.5611\n",
      "Epoch 1817/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.5109 - mean_squared_error: 13.5109 - val_loss: 15.5703 - val_mean_squared_error: 15.5703\n",
      "Epoch 1818/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5828 - mean_squared_error: 13.5828 - val_loss: 15.5000 - val_mean_squared_error: 15.5000\n",
      "Epoch 1819/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.5829 - mean_squared_error: 13.5829 - val_loss: 15.5991 - val_mean_squared_error: 15.5991\n",
      "Epoch 1820/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.7288 - mean_squared_error: 13.7288 - val_loss: 16.7501 - val_mean_squared_error: 16.7501\n",
      "Epoch 1821/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.7278 - mean_squared_error: 13.7278 - val_loss: 15.4766 - val_mean_squared_error: 15.4766\n",
      "Epoch 1822/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.5330 - mean_squared_error: 13.5330 - val_loss: 16.0385 - val_mean_squared_error: 16.0385\n",
      "Epoch 1823/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.5943 - mean_squared_error: 13.5943 - val_loss: 15.4814 - val_mean_squared_error: 15.4814\n",
      "Epoch 1824/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.5230 - mean_squared_error: 13.5230 - val_loss: 15.8964 - val_mean_squared_error: 15.8964\n",
      "Epoch 1825/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.6257 - mean_squared_error: 13.6257 - val_loss: 15.6760 - val_mean_squared_error: 15.6760\n",
      "Epoch 1826/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.9216 - mean_squared_error: 13.9216 - val_loss: 16.9522 - val_mean_squared_error: 16.9522\n",
      "Epoch 1827/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.6673 - mean_squared_error: 14.6673 - val_loss: 16.8341 - val_mean_squared_error: 16.8341\n",
      "Epoch 1828/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.2752 - mean_squared_error: 15.2752 - val_loss: 18.5552 - val_mean_squared_error: 18.5552\n",
      "Epoch 1829/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 42us/sample - loss: 14.0112 - mean_squared_error: 14.0112 - val_loss: 15.7919 - val_mean_squared_error: 15.7919\n",
      "Epoch 1830/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.0803 - mean_squared_error: 14.0803 - val_loss: 15.4714 - val_mean_squared_error: 15.4714\n",
      "Epoch 1831/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5880 - mean_squared_error: 13.5880 - val_loss: 15.5026 - val_mean_squared_error: 15.5026\n",
      "Epoch 1832/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.5362 - mean_squared_error: 13.5362 - val_loss: 15.4270 - val_mean_squared_error: 15.4270\n",
      "Epoch 1833/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.5049 - mean_squared_error: 13.5049 - val_loss: 15.5466 - val_mean_squared_error: 15.5466\n",
      "Epoch 1834/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.5486 - mean_squared_error: 13.5486 - val_loss: 15.8435 - val_mean_squared_error: 15.8435\n",
      "Epoch 1835/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.5271 - mean_squared_error: 13.5271 - val_loss: 15.4248 - val_mean_squared_error: 15.4248\n",
      "Epoch 1836/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.5117 - mean_squared_error: 13.5117 - val_loss: 15.4778 - val_mean_squared_error: 15.4778\n",
      "Epoch 1837/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.3805 - mean_squared_error: 14.3805 - val_loss: 16.4927 - val_mean_squared_error: 16.4927\n",
      "Epoch 1838/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2778 - mean_squared_error: 14.2778 - val_loss: 15.6776 - val_mean_squared_error: 15.6776\n",
      "Epoch 1839/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5078 - mean_squared_error: 13.5078 - val_loss: 15.3352 - val_mean_squared_error: 15.3352\n",
      "Epoch 1840/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.5826 - mean_squared_error: 13.5826 - val_loss: 15.4344 - val_mean_squared_error: 15.4344\n",
      "Epoch 1841/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.7172 - mean_squared_error: 13.7172 - val_loss: 16.5397 - val_mean_squared_error: 16.5397\n",
      "Epoch 1842/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.6206 - mean_squared_error: 13.6206 - val_loss: 15.4238 - val_mean_squared_error: 15.4238\n",
      "Epoch 1843/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.7114 - mean_squared_error: 13.7114 - val_loss: 15.4346 - val_mean_squared_error: 15.4346\n",
      "Epoch 1844/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.6607 - mean_squared_error: 13.6607 - val_loss: 15.4207 - val_mean_squared_error: 15.4207\n",
      "Epoch 1845/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.6068 - mean_squared_error: 13.6068 - val_loss: 15.4389 - val_mean_squared_error: 15.4389\n",
      "Epoch 1846/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4600 - mean_squared_error: 13.4600 - val_loss: 15.4757 - val_mean_squared_error: 15.4757\n",
      "Epoch 1847/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 16.7303 - mean_squared_error: 16.73 - 0s 38us/sample - loss: 13.7235 - mean_squared_error: 13.7235 - val_loss: 16.5590 - val_mean_squared_error: 16.5590\n",
      "Epoch 1848/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.6489 - mean_squared_error: 13.6489 - val_loss: 15.3736 - val_mean_squared_error: 15.3736\n",
      "Epoch 1849/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5778 - mean_squared_error: 13.5778 - val_loss: 16.1857 - val_mean_squared_error: 16.1857\n",
      "Epoch 1850/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.6870 - mean_squared_error: 13.6870 - val_loss: 15.5821 - val_mean_squared_error: 15.5821\n",
      "Epoch 1851/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.5565 - mean_squared_error: 13.5565 - val_loss: 15.4324 - val_mean_squared_error: 15.4324\n",
      "Epoch 1852/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.0975 - mean_squared_error: 14.0975 - val_loss: 15.4176 - val_mean_squared_error: 15.4176\n",
      "Epoch 1853/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6749 - mean_squared_error: 13.6749 - val_loss: 15.3263 - val_mean_squared_error: 15.3263\n",
      "Epoch 1854/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4850 - mean_squared_error: 13.4850 - val_loss: 15.2980 - val_mean_squared_error: 15.2980\n",
      "Epoch 1855/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.6128 - mean_squared_error: 14.6128 - val_loss: 16.5253 - val_mean_squared_error: 16.5253\n",
      "Epoch 1856/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.5330 - mean_squared_error: 14.5330 - val_loss: 15.3962 - val_mean_squared_error: 15.3962\n",
      "Epoch 1857/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.5053 - mean_squared_error: 13.5053 - val_loss: 15.6354 - val_mean_squared_error: 15.6354\n",
      "Epoch 1858/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.7063 - mean_squared_error: 13.7063 - val_loss: 15.9265 - val_mean_squared_error: 15.9265\n",
      "Epoch 1859/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.4954 - mean_squared_error: 13.4954 - val_loss: 15.3240 - val_mean_squared_error: 15.3240\n",
      "Epoch 1860/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6641 - mean_squared_error: 13.6641 - val_loss: 17.0069 - val_mean_squared_error: 17.0069\n",
      "Epoch 1861/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7301 - mean_squared_error: 13.7301 - val_loss: 15.3316 - val_mean_squared_error: 15.3316\n",
      "Epoch 1862/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.7392 - mean_squared_error: 13.7392 - val_loss: 15.2594 - val_mean_squared_error: 15.2594\n",
      "Epoch 1863/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.4705 - mean_squared_error: 13.4705 - val_loss: 15.5866 - val_mean_squared_error: 15.5866\n",
      "Epoch 1864/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.4741 - mean_squared_error: 13.4741 - val_loss: 15.2592 - val_mean_squared_error: 15.2592\n",
      "Epoch 1865/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5947 - mean_squared_error: 13.5947 - val_loss: 15.2849 - val_mean_squared_error: 15.2849\n",
      "Epoch 1866/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.2330 - mean_squared_error: 14.2330 - val_loss: 15.6569 - val_mean_squared_error: 15.6569\n",
      "Epoch 1867/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.2055 - mean_squared_error: 14.2055 - val_loss: 15.3088 - val_mean_squared_error: 15.3088\n",
      "Epoch 1868/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5432 - mean_squared_error: 13.5432 - val_loss: 15.2901 - val_mean_squared_error: 15.2901\n",
      "Epoch 1869/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4663 - mean_squared_error: 13.4663 - val_loss: 15.5033 - val_mean_squared_error: 15.5033\n",
      "Epoch 1870/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.0689 - mean_squared_error: 14.0689 - val_loss: 16.3805 - val_mean_squared_error: 16.3805\n",
      "Epoch 1871/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.8080 - mean_squared_error: 14.8080 - val_loss: 15.2950 - val_mean_squared_error: 15.2950\n",
      "Epoch 1872/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5918 - mean_squared_error: 13.5918 - val_loss: 15.2879 - val_mean_squared_error: 15.2879\n",
      "Epoch 1873/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4954 - mean_squared_error: 13.4954 - val_loss: 15.4186 - val_mean_squared_error: 15.4186\n",
      "Epoch 1874/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4680 - mean_squared_error: 13.4680 - val_loss: 15.7581 - val_mean_squared_error: 15.7581\n",
      "Epoch 1875/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.4598 - mean_squared_error: 13.4598 - val_loss: 15.3456 - val_mean_squared_error: 15.3456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1876/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.5034 - mean_squared_error: 13.5034 - val_loss: 15.2476 - val_mean_squared_error: 15.2476\n",
      "Epoch 1877/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.5312 - mean_squared_error: 13.5312 - val_loss: 16.3279 - val_mean_squared_error: 16.3279\n",
      "Epoch 1878/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7346 - mean_squared_error: 13.7346 - val_loss: 15.4358 - val_mean_squared_error: 15.4358\n",
      "Epoch 1879/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.4268 - mean_squared_error: 13.4268 - val_loss: 15.3378 - val_mean_squared_error: 15.3378\n",
      "Epoch 1880/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5080 - mean_squared_error: 13.5080 - val_loss: 16.0750 - val_mean_squared_error: 16.0750\n",
      "Epoch 1881/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.7907 - mean_squared_error: 13.7907 - val_loss: 15.7575 - val_mean_squared_error: 15.7575\n",
      "Epoch 1882/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5930 - mean_squared_error: 13.5930 - val_loss: 15.4581 - val_mean_squared_error: 15.4581\n",
      "Epoch 1883/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.4961 - mean_squared_error: 13.4961 - val_loss: 15.2122 - val_mean_squared_error: 15.2122\n",
      "Epoch 1884/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4866 - mean_squared_error: 13.4866 - val_loss: 15.6112 - val_mean_squared_error: 15.6112\n",
      "Epoch 1885/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4822 - mean_squared_error: 13.4822 - val_loss: 15.2455 - val_mean_squared_error: 15.2455\n",
      "Epoch 1886/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.4256 - mean_squared_error: 13.4256 - val_loss: 15.1925 - val_mean_squared_error: 15.1925\n",
      "Epoch 1887/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.6228 - mean_squared_error: 13.6228 - val_loss: 15.1287 - val_mean_squared_error: 15.1287\n",
      "Epoch 1888/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4529 - mean_squared_error: 13.4529 - val_loss: 15.7478 - val_mean_squared_error: 15.7478\n",
      "Epoch 1889/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.9871 - mean_squared_error: 13.9871 - val_loss: 16.4577 - val_mean_squared_error: 16.4577\n",
      "Epoch 1890/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.2836 - mean_squared_error: 14.2836 - val_loss: 16.3779 - val_mean_squared_error: 16.3779\n",
      "Epoch 1891/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.2773 - mean_squared_error: 14.2773 - val_loss: 16.6301 - val_mean_squared_error: 16.6301\n",
      "Epoch 1892/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.1673 - mean_squared_error: 14.1673 - val_loss: 16.0477 - val_mean_squared_error: 16.0477\n",
      "Epoch 1893/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7895 - mean_squared_error: 13.7895 - val_loss: 15.9870 - val_mean_squared_error: 15.9870\n",
      "Epoch 1894/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.8802 - mean_squared_error: 13.8802 - val_loss: 16.3546 - val_mean_squared_error: 16.3546\n",
      "Epoch 1895/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.5362 - mean_squared_error: 13.5362 - val_loss: 15.3138 - val_mean_squared_error: 15.3138\n",
      "Epoch 1896/4000\n",
      "339/339 [==============================] - 0s 61us/sample - loss: 13.6288 - mean_squared_error: 13.6288 - val_loss: 15.2592 - val_mean_squared_error: 15.2592\n",
      "Epoch 1897/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.4757 - mean_squared_error: 13.4757 - val_loss: 16.2148 - val_mean_squared_error: 16.2148\n",
      "Epoch 1898/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7892 - mean_squared_error: 13.7892 - val_loss: 15.6845 - val_mean_squared_error: 15.6845\n",
      "Epoch 1899/4000\n",
      "339/339 [==============================] - 0s 68us/sample - loss: 13.6259 - mean_squared_error: 13.6259 - val_loss: 15.7940 - val_mean_squared_error: 15.7940\n",
      "Epoch 1900/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.9162 - mean_squared_error: 13.9162 - val_loss: 16.5624 - val_mean_squared_error: 16.5624\n",
      "Epoch 1901/4000\n",
      "339/339 [==============================] - 0s 11us/sample - loss: 13.8177 - mean_squared_error: 13.8177 - val_loss: 15.6228 - val_mean_squared_error: 15.6228\n",
      "Epoch 1902/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.5738 - mean_squared_error: 13.5738 - val_loss: 15.6040 - val_mean_squared_error: 15.6040\n",
      "Epoch 1903/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6909 - mean_squared_error: 13.6909 - val_loss: 15.5667 - val_mean_squared_error: 15.5667\n",
      "Epoch 1904/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.6011 - mean_squared_error: 13.6011 - val_loss: 16.1975 - val_mean_squared_error: 16.1975\n",
      "Epoch 1905/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9228 - mean_squared_error: 13.9228 - val_loss: 16.0137 - val_mean_squared_error: 16.0137\n",
      "Epoch 1906/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 13.4594 - mean_squared_error: 13.4594 - val_loss: 15.4522 - val_mean_squared_error: 15.4522\n",
      "Epoch 1907/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.6992 - mean_squared_error: 14.6992 - val_loss: 15.9361 - val_mean_squared_error: 15.9361\n",
      "Epoch 1908/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7277 - mean_squared_error: 13.7277 - val_loss: 16.4589 - val_mean_squared_error: 16.4589\n",
      "Epoch 1909/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.6205 - mean_squared_error: 13.6205 - val_loss: 15.2418 - val_mean_squared_error: 15.2418\n",
      "Epoch 1910/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.4525 - mean_squared_error: 13.4525 - val_loss: 15.9179 - val_mean_squared_error: 15.9179\n",
      "Epoch 1911/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.5078 - mean_squared_error: 13.5078 - val_loss: 15.1902 - val_mean_squared_error: 15.1902\n",
      "Epoch 1912/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4333 - mean_squared_error: 13.4333 - val_loss: 15.1849 - val_mean_squared_error: 15.1849\n",
      "Epoch 1913/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4991 - mean_squared_error: 13.4991 - val_loss: 15.1833 - val_mean_squared_error: 15.1833\n",
      "Epoch 1914/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4908 - mean_squared_error: 13.4908 - val_loss: 15.2570 - val_mean_squared_error: 15.2570\n",
      "Epoch 1915/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4861 - mean_squared_error: 13.4861 - val_loss: 15.1710 - val_mean_squared_error: 15.1710\n",
      "Epoch 1916/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.5755 - mean_squared_error: 13.5755 - val_loss: 15.1825 - val_mean_squared_error: 15.1825\n",
      "Epoch 1917/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.7981 - mean_squared_error: 13.7981 - val_loss: 15.3539 - val_mean_squared_error: 15.3539\n",
      "Epoch 1918/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.0308 - mean_squared_error: 15.0308 - val_loss: 15.8308 - val_mean_squared_error: 15.8308\n",
      "Epoch 1919/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.2420 - mean_squared_error: 14.2420 - val_loss: 15.0815 - val_mean_squared_error: 15.0815\n",
      "Epoch 1920/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9729 - mean_squared_error: 13.9729 - val_loss: 15.5028 - val_mean_squared_error: 15.5028\n",
      "Epoch 1921/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.4442 - mean_squared_error: 14.4442 - val_loss: 15.1775 - val_mean_squared_error: 15.1775\n",
      "Epoch 1922/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6826 - mean_squared_error: 13.6826 - val_loss: 15.0871 - val_mean_squared_error: 15.0871\n",
      "Epoch 1923/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 25us/sample - loss: 13.4020 - mean_squared_error: 13.4020 - val_loss: 15.1196 - val_mean_squared_error: 15.1196\n",
      "Epoch 1924/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.4148 - mean_squared_error: 13.4148 - val_loss: 15.4696 - val_mean_squared_error: 15.4696\n",
      "Epoch 1925/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.6306 - mean_squared_error: 13.6306 - val_loss: 15.7795 - val_mean_squared_error: 15.7795\n",
      "Epoch 1926/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.5142 - mean_squared_error: 13.5142 - val_loss: 15.2041 - val_mean_squared_error: 15.2041\n",
      "Epoch 1927/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.3827 - mean_squared_error: 13.3827 - val_loss: 15.3021 - val_mean_squared_error: 15.3021\n",
      "Epoch 1928/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6350 - mean_squared_error: 13.6350 - val_loss: 16.4180 - val_mean_squared_error: 16.4180\n",
      "Epoch 1929/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.5838 - mean_squared_error: 13.5838 - val_loss: 15.1461 - val_mean_squared_error: 15.1461\n",
      "Epoch 1930/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4045 - mean_squared_error: 13.4045 - val_loss: 15.1490 - val_mean_squared_error: 15.1490\n",
      "Epoch 1931/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.4467 - mean_squared_error: 13.4467 - val_loss: 15.8471 - val_mean_squared_error: 15.8471\n",
      "Epoch 1932/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4580 - mean_squared_error: 13.4580 - val_loss: 15.1220 - val_mean_squared_error: 15.1220\n",
      "Epoch 1933/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4673 - mean_squared_error: 13.4673 - val_loss: 16.1838 - val_mean_squared_error: 16.1838\n",
      "Epoch 1934/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7596 - mean_squared_error: 13.7596 - val_loss: 15.2013 - val_mean_squared_error: 15.2013\n",
      "Epoch 1935/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.4699 - mean_squared_error: 13.4699 - val_loss: 15.1862 - val_mean_squared_error: 15.1862\n",
      "Epoch 1936/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.7697 - mean_squared_error: 14.7697 - val_loss: 15.9449 - val_mean_squared_error: 15.9449\n",
      "Epoch 1937/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.0364 - mean_squared_error: 14.0364 - val_loss: 15.3397 - val_mean_squared_error: 15.3397\n",
      "Epoch 1938/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4472 - mean_squared_error: 13.4472 - val_loss: 15.5458 - val_mean_squared_error: 15.5458\n",
      "Epoch 1939/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.3841 - mean_squared_error: 13.3841 - val_loss: 15.1361 - val_mean_squared_error: 15.1361\n",
      "Epoch 1940/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.3751 - mean_squared_error: 13.3751 - val_loss: 15.6582 - val_mean_squared_error: 15.6582\n",
      "Epoch 1941/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.5090 - mean_squared_error: 13.5090 - val_loss: 15.3504 - val_mean_squared_error: 15.3504\n",
      "Epoch 1942/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.3768 - mean_squared_error: 13.3768 - val_loss: 15.1424 - val_mean_squared_error: 15.1424\n",
      "Epoch 1943/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4034 - mean_squared_error: 13.4034 - val_loss: 15.2668 - val_mean_squared_error: 15.2668\n",
      "Epoch 1944/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.4787 - mean_squared_error: 13.4787 - val_loss: 15.1825 - val_mean_squared_error: 15.1825\n",
      "Epoch 1945/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.4403 - mean_squared_error: 13.4403 - val_loss: 15.4646 - val_mean_squared_error: 15.4646\n",
      "Epoch 1946/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3908 - mean_squared_error: 13.3908 - val_loss: 15.1078 - val_mean_squared_error: 15.1078\n",
      "Epoch 1947/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.7209 - mean_squared_error: 13.7209 - val_loss: 15.2945 - val_mean_squared_error: 15.2945\n",
      "Epoch 1948/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.6021 - mean_squared_error: 13.6021 - val_loss: 15.3349 - val_mean_squared_error: 15.3349\n",
      "Epoch 1949/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.6479 - mean_squared_error: 13.6479 - val_loss: 16.1246 - val_mean_squared_error: 16.1246\n",
      "Epoch 1950/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.9168 - mean_squared_error: 13.9168 - val_loss: 15.7275 - val_mean_squared_error: 15.7275\n",
      "Epoch 1951/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.0037 - mean_squared_error: 14.0037 - val_loss: 16.4911 - val_mean_squared_error: 16.4911\n",
      "Epoch 1952/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.4917 - mean_squared_error: 13.4917 - val_loss: 15.2991 - val_mean_squared_error: 15.2991\n",
      "Epoch 1953/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.5023 - mean_squared_error: 13.5023 - val_loss: 15.7105 - val_mean_squared_error: 15.7105\n",
      "Epoch 1954/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.4393 - mean_squared_error: 13.4393 - val_loss: 15.2781 - val_mean_squared_error: 15.2781\n",
      "Epoch 1955/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.3934 - mean_squared_error: 13.3934 - val_loss: 15.1379 - val_mean_squared_error: 15.1379\n",
      "Epoch 1956/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.4757 - mean_squared_error: 13.4757 - val_loss: 16.3090 - val_mean_squared_error: 16.3090\n",
      "Epoch 1957/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.6689 - mean_squared_error: 13.6689 - val_loss: 15.3941 - val_mean_squared_error: 15.3941\n",
      "Epoch 1958/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6132 - mean_squared_error: 13.6132 - val_loss: 15.4000 - val_mean_squared_error: 15.4000\n",
      "Epoch 1959/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.8385 - mean_squared_error: 13.8385 - val_loss: 15.0664 - val_mean_squared_error: 15.0664\n",
      "Epoch 1960/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4446 - mean_squared_error: 13.4446 - val_loss: 16.0585 - val_mean_squared_error: 16.0585\n",
      "Epoch 1961/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7968 - mean_squared_error: 13.7968 - val_loss: 15.7386 - val_mean_squared_error: 15.7386\n",
      "Epoch 1962/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5406 - mean_squared_error: 13.5406 - val_loss: 15.5796 - val_mean_squared_error: 15.5796\n",
      "Epoch 1963/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.3720 - mean_squared_error: 13.3720 - val_loss: 15.2090 - val_mean_squared_error: 15.2090\n",
      "Epoch 1964/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 13.4429 - mean_squared_error: 13.4429 - val_loss: 15.3722 - val_mean_squared_error: 15.3722\n",
      "Epoch 1965/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.5988 - mean_squared_error: 13.5988 - val_loss: 16.1853 - val_mean_squared_error: 16.1853\n",
      "Epoch 1966/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.4638 - mean_squared_error: 14.4638 - val_loss: 17.1958 - val_mean_squared_error: 17.1958\n",
      "Epoch 1967/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.9746 - mean_squared_error: 13.9746 - val_loss: 15.3801 - val_mean_squared_error: 15.3801\n",
      "Epoch 1968/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.4518 - mean_squared_error: 13.4518 - val_loss: 15.5923 - val_mean_squared_error: 15.5923\n",
      "Epoch 1969/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5710 - mean_squared_error: 13.5710 - val_loss: 15.8116 - val_mean_squared_error: 15.8116\n",
      "Epoch 1970/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 25us/sample - loss: 13.4109 - mean_squared_error: 13.4109 - val_loss: 15.1746 - val_mean_squared_error: 15.1746\n",
      "Epoch 1971/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.3612 - mean_squared_error: 13.3612 - val_loss: 15.2114 - val_mean_squared_error: 15.2114\n",
      "Epoch 1972/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5724 - mean_squared_error: 13.5724 - val_loss: 16.3883 - val_mean_squared_error: 16.3883\n",
      "Epoch 1973/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7783 - mean_squared_error: 13.7783 - val_loss: 15.4728 - val_mean_squared_error: 15.4728\n",
      "Epoch 1974/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6163 - mean_squared_error: 13.6163 - val_loss: 16.1817 - val_mean_squared_error: 16.1817\n",
      "Epoch 1975/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9558 - mean_squared_error: 13.9558 - val_loss: 16.0787 - val_mean_squared_error: 16.0787\n",
      "Epoch 1976/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.6748 - mean_squared_error: 13.6748 - val_loss: 15.2010 - val_mean_squared_error: 15.2010\n",
      "Epoch 1977/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6090 - mean_squared_error: 13.6090 - val_loss: 16.1181 - val_mean_squared_error: 16.1181\n",
      "Epoch 1978/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.6452 - mean_squared_error: 13.6452 - val_loss: 15.2734 - val_mean_squared_error: 15.2734\n",
      "Epoch 1979/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.4611 - mean_squared_error: 13.4611 - val_loss: 15.2456 - val_mean_squared_error: 15.2456\n",
      "Epoch 1980/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.3092 - mean_squared_error: 14.3092 - val_loss: 15.3284 - val_mean_squared_error: 15.3284\n",
      "Epoch 1981/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 14.3194 - mean_squared_error: 14.3194 - val_loss: 15.1561 - val_mean_squared_error: 15.1561\n",
      "Epoch 1982/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9319 - mean_squared_error: 13.9319 - val_loss: 14.9981 - val_mean_squared_error: 14.9981\n",
      "Epoch 1983/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.6633 - mean_squared_error: 13.6633 - val_loss: 14.9299 - val_mean_squared_error: 14.9299\n",
      "Epoch 1984/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.8647 - mean_squared_error: 13.8647 - val_loss: 15.1353 - val_mean_squared_error: 15.1353\n",
      "Epoch 1985/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.6705 - mean_squared_error: 13.6705 - val_loss: 15.0296 - val_mean_squared_error: 15.0296\n",
      "Epoch 1986/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.0654 - mean_squared_error: 14.0654 - val_loss: 15.9086 - val_mean_squared_error: 15.9086\n",
      "Epoch 1987/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.9817 - mean_squared_error: 14.9817 - val_loss: 15.0977 - val_mean_squared_error: 15.0977\n",
      "Epoch 1988/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.5966 - mean_squared_error: 13.5966 - val_loss: 15.0277 - val_mean_squared_error: 15.0277\n",
      "Epoch 1989/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7492 - mean_squared_error: 13.7492 - val_loss: 15.3573 - val_mean_squared_error: 15.3573\n",
      "Epoch 1990/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 15.0769 - mean_squared_error: 15.0769 - val_loss: 15.6563 - val_mean_squared_error: 15.6563\n",
      "Epoch 1991/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7929 - mean_squared_error: 13.7929 - val_loss: 15.2642 - val_mean_squared_error: 15.2642\n",
      "Epoch 1992/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.8573 - mean_squared_error: 13.8573 - val_loss: 16.5437 - val_mean_squared_error: 16.5437\n",
      "Epoch 1993/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 15.0026 - mean_squared_error: 15.0026 - val_loss: 17.4158 - val_mean_squared_error: 17.4158\n",
      "Epoch 1994/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9238 - mean_squared_error: 13.9238 - val_loss: 15.0726 - val_mean_squared_error: 15.0726\n",
      "Epoch 1995/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.5250 - mean_squared_error: 13.5250 - val_loss: 16.6846 - val_mean_squared_error: 16.6846\n",
      "Epoch 1996/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6772 - mean_squared_error: 13.6772 - val_loss: 15.0855 - val_mean_squared_error: 15.0855\n",
      "Epoch 1997/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.5135 - mean_squared_error: 13.5135 - val_loss: 15.0942 - val_mean_squared_error: 15.0942\n",
      "Epoch 1998/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.4851 - mean_squared_error: 13.4851 - val_loss: 15.0671 - val_mean_squared_error: 15.0671\n",
      "Epoch 1999/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6883 - mean_squared_error: 13.6883 - val_loss: 16.8528 - val_mean_squared_error: 16.8528\n",
      "Epoch 2000/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6684 - mean_squared_error: 13.6684 - val_loss: 15.0414 - val_mean_squared_error: 15.0414\n",
      "Epoch 2001/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4267 - mean_squared_error: 13.4267 - val_loss: 15.0787 - val_mean_squared_error: 15.0787\n",
      "Epoch 2002/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3675 - mean_squared_error: 13.3675 - val_loss: 15.6361 - val_mean_squared_error: 15.6361\n",
      "Epoch 2003/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.3824 - mean_squared_error: 13.3824 - val_loss: 15.0651 - val_mean_squared_error: 15.0651\n",
      "Epoch 2004/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4627 - mean_squared_error: 13.4627 - val_loss: 15.1319 - val_mean_squared_error: 15.1319\n",
      "Epoch 2005/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.4204 - mean_squared_error: 13.4204 - val_loss: 15.4452 - val_mean_squared_error: 15.4452\n",
      "Epoch 2006/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.3556 - mean_squared_error: 13.3556 - val_loss: 15.2816 - val_mean_squared_error: 15.2816\n",
      "Epoch 2007/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3710 - mean_squared_error: 13.3710 - val_loss: 15.4233 - val_mean_squared_error: 15.4233\n",
      "Epoch 2008/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.0234 - mean_squared_error: 14.0234 - val_loss: 17.2146 - val_mean_squared_error: 17.2146\n",
      "Epoch 2009/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 14.0151 - mean_squared_error: 14.0151 - val_loss: 15.1811 - val_mean_squared_error: 15.1811\n",
      "Epoch 2010/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.3843 - mean_squared_error: 13.3843 - val_loss: 15.6653 - val_mean_squared_error: 15.6653\n",
      "Epoch 2011/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.9276 - mean_squared_error: 13.9276 - val_loss: 16.5303 - val_mean_squared_error: 16.5303\n",
      "Epoch 2012/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 15.1656 - mean_squared_error: 15.1656 - val_loss: 17.9868 - val_mean_squared_error: 17.9868\n",
      "Epoch 2013/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.8088 - mean_squared_error: 14.8088 - val_loss: 15.8533 - val_mean_squared_error: 15.8533\n",
      "Epoch 2014/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.3305 - mean_squared_error: 13.3305 - val_loss: 15.1393 - val_mean_squared_error: 15.1393\n",
      "Epoch 2015/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.3891 - mean_squared_error: 13.3891 - val_loss: 16.3495 - val_mean_squared_error: 16.3495\n",
      "Epoch 2016/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4878 - mean_squared_error: 13.4878 - val_loss: 15.0557 - val_mean_squared_error: 15.0557\n",
      "Epoch 2017/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4199 - mean_squared_error: 13.4199 - val_loss: 16.1902 - val_mean_squared_error: 16.1902\n",
      "Epoch 2018/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.5623 - mean_squared_error: 13.5623 - val_loss: 15.1073 - val_mean_squared_error: 15.1073\n",
      "Epoch 2019/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7693 - mean_squared_error: 13.7693 - val_loss: 15.7263 - val_mean_squared_error: 15.7263\n",
      "Epoch 2020/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.7044 - mean_squared_error: 13.7044 - val_loss: 15.4355 - val_mean_squared_error: 15.4355\n",
      "Epoch 2021/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6538 - mean_squared_error: 13.6538 - val_loss: 16.0440 - val_mean_squared_error: 16.0440\n",
      "Epoch 2022/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 10.8515 - mean_squared_error: 10.85 - 0s 26us/sample - loss: 13.4035 - mean_squared_error: 13.4035 - val_loss: 15.1277 - val_mean_squared_error: 15.1277\n",
      "Epoch 2023/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.3329 - mean_squared_error: 13.3329 - val_loss: 16.0089 - val_mean_squared_error: 16.0089\n",
      "Epoch 2024/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.7779 - mean_squared_error: 13.7779 - val_loss: 15.5837 - val_mean_squared_error: 15.5837\n",
      "Epoch 2025/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4172 - mean_squared_error: 13.4172 - val_loss: 15.1633 - val_mean_squared_error: 15.1633\n",
      "Epoch 2026/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.3039 - mean_squared_error: 13.3039 - val_loss: 15.1419 - val_mean_squared_error: 15.1419\n",
      "Epoch 2027/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6193 - mean_squared_error: 13.6193 - val_loss: 16.3157 - val_mean_squared_error: 16.3157\n",
      "Epoch 2028/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.4759 - mean_squared_error: 13.4759 - val_loss: 14.9743 - val_mean_squared_error: 14.9743\n",
      "Epoch 2029/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.3227 - mean_squared_error: 13.3227 - val_loss: 15.1182 - val_mean_squared_error: 15.1182\n",
      "Epoch 2030/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.3117 - mean_squared_error: 13.3117 - val_loss: 15.1967 - val_mean_squared_error: 15.1967\n",
      "Epoch 2031/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.2944 - mean_squared_error: 13.2944 - val_loss: 15.0767 - val_mean_squared_error: 15.0767\n",
      "Epoch 2032/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.0878 - mean_squared_error: 14.0878 - val_loss: 15.9002 - val_mean_squared_error: 15.9002\n",
      "Epoch 2033/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 15.0297 - mean_squared_error: 15.0297 - val_loss: 15.1592 - val_mean_squared_error: 15.1592\n",
      "Epoch 2034/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.9462 - mean_squared_error: 13.9462 - val_loss: 14.9367 - val_mean_squared_error: 14.9367\n",
      "Epoch 2035/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.9047 - mean_squared_error: 13.9047 - val_loss: 14.9988 - val_mean_squared_error: 14.9988\n",
      "Epoch 2036/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.6361 - mean_squared_error: 13.6361 - val_loss: 14.8905 - val_mean_squared_error: 14.8905\n",
      "Epoch 2037/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.4448 - mean_squared_error: 13.4448 - val_loss: 14.9646 - val_mean_squared_error: 14.9646\n",
      "Epoch 2038/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.3996 - mean_squared_error: 13.3996 - val_loss: 15.0986 - val_mean_squared_error: 15.0986\n",
      "Epoch 2039/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.5806 - mean_squared_error: 13.5806 - val_loss: 15.2736 - val_mean_squared_error: 15.2736\n",
      "Epoch 2040/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 15.3697 - mean_squared_error: 15.3697 - val_loss: 15.6804 - val_mean_squared_error: 15.6804\n",
      "Epoch 2041/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 14.8185 - mean_squared_error: 14.8185 - val_loss: 15.0319 - val_mean_squared_error: 15.0319\n",
      "Epoch 2042/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.7095 - mean_squared_error: 13.7095 - val_loss: 14.9026 - val_mean_squared_error: 14.9026\n",
      "Epoch 2043/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4106 - mean_squared_error: 13.4106 - val_loss: 16.5605 - val_mean_squared_error: 16.5605\n",
      "Epoch 2044/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.7832 - mean_squared_error: 14.7832 - val_loss: 16.6112 - val_mean_squared_error: 16.6112\n",
      "Epoch 2045/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 14.1193 - mean_squared_error: 14.1193 - val_loss: 15.4344 - val_mean_squared_error: 15.4344\n",
      "Epoch 2046/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3264 - mean_squared_error: 13.3264 - val_loss: 14.9660 - val_mean_squared_error: 14.9660\n",
      "Epoch 2047/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.6078 - mean_squared_error: 13.6078 - val_loss: 15.0811 - val_mean_squared_error: 15.0811\n",
      "Epoch 2048/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.7404 - mean_squared_error: 13.7404 - val_loss: 14.8507 - val_mean_squared_error: 14.8507\n",
      "Epoch 2049/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4409 - mean_squared_error: 13.4409 - val_loss: 16.6825 - val_mean_squared_error: 16.6825\n",
      "Epoch 2050/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.9340 - mean_squared_error: 13.9340 - val_loss: 15.1365 - val_mean_squared_error: 15.1365\n",
      "Epoch 2051/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.3082 - mean_squared_error: 13.3082 - val_loss: 15.2277 - val_mean_squared_error: 15.2277\n",
      "Epoch 2052/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.4765 - mean_squared_error: 13.4765 - val_loss: 15.8786 - val_mean_squared_error: 15.8786\n",
      "Epoch 2053/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.9332 - mean_squared_error: 13.9332 - val_loss: 15.9631 - val_mean_squared_error: 15.9631\n",
      "Epoch 2054/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.6468 - mean_squared_error: 13.6468 - val_loss: 15.2683 - val_mean_squared_error: 15.2683\n",
      "Epoch 2055/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.3249 - mean_squared_error: 13.3249 - val_loss: 15.3132 - val_mean_squared_error: 15.3132\n",
      "Epoch 2056/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.3029 - mean_squared_error: 13.3029 - val_loss: 15.0093 - val_mean_squared_error: 15.0093\n",
      "Epoch 2057/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.2659 - mean_squared_error: 13.2659 - val_loss: 15.5543 - val_mean_squared_error: 15.5543\n",
      "Epoch 2058/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.3048 - mean_squared_error: 13.3048 - val_loss: 14.9693 - val_mean_squared_error: 14.9693\n",
      "Epoch 2059/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.4613 - mean_squared_error: 13.4613 - val_loss: 15.0943 - val_mean_squared_error: 15.0943\n",
      "Epoch 2060/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.3636 - mean_squared_error: 13.3636 - val_loss: 16.0271 - val_mean_squared_error: 16.0271\n",
      "Epoch 2061/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6095 - mean_squared_error: 13.6095 - val_loss: 15.1404 - val_mean_squared_error: 15.1404\n",
      "Epoch 2062/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.3181 - mean_squared_error: 13.3181 - val_loss: 15.2285 - val_mean_squared_error: 15.2285\n",
      "Epoch 2063/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.2710 - mean_squared_error: 13.2710 - val_loss: 14.9742 - val_mean_squared_error: 14.9742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2064/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.2940 - mean_squared_error: 13.2940 - val_loss: 14.8815 - val_mean_squared_error: 14.8815\n",
      "Epoch 2065/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.2976 - mean_squared_error: 13.2976 - val_loss: 15.3198 - val_mean_squared_error: 15.3198\n",
      "Epoch 2066/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.9224 - mean_squared_error: 13.9224 - val_loss: 16.8372 - val_mean_squared_error: 16.8372\n",
      "Epoch 2067/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.3079 - mean_squared_error: 14.3079 - val_loss: 15.7672 - val_mean_squared_error: 15.7672\n",
      "Epoch 2068/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.2928 - mean_squared_error: 13.2928 - val_loss: 14.9808 - val_mean_squared_error: 14.9808\n",
      "Epoch 2069/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.2977 - mean_squared_error: 13.2977 - val_loss: 15.8660 - val_mean_squared_error: 15.8660\n",
      "Epoch 2070/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.3696 - mean_squared_error: 13.3696 - val_loss: 14.9095 - val_mean_squared_error: 14.9095\n",
      "Epoch 2071/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.7191 - mean_squared_error: 13.7191 - val_loss: 14.8362 - val_mean_squared_error: 14.8362\n",
      "Epoch 2072/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.3294 - mean_squared_error: 13.3294 - val_loss: 14.8442 - val_mean_squared_error: 14.8442\n",
      "Epoch 2073/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.4679 - mean_squared_error: 13.4679 - val_loss: 16.4562 - val_mean_squared_error: 16.4562\n",
      "Epoch 2074/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.4683 - mean_squared_error: 14.4683 - val_loss: 16.2930 - val_mean_squared_error: 16.2930\n",
      "Epoch 2075/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9937 - mean_squared_error: 13.9937 - val_loss: 15.7402 - val_mean_squared_error: 15.7402\n",
      "Epoch 2076/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4693 - mean_squared_error: 13.4693 - val_loss: 15.1957 - val_mean_squared_error: 15.1957\n",
      "Epoch 2077/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.2260 - mean_squared_error: 13.2260 - val_loss: 14.9093 - val_mean_squared_error: 14.9093\n",
      "Epoch 2078/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.2555 - mean_squared_error: 13.2555 - val_loss: 14.8812 - val_mean_squared_error: 14.8812\n",
      "Epoch 2079/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.6724 - mean_squared_error: 13.6724 - val_loss: 15.2460 - val_mean_squared_error: 15.2460\n",
      "Epoch 2080/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6944 - mean_squared_error: 13.6944 - val_loss: 14.8192 - val_mean_squared_error: 14.8192\n",
      "Epoch 2081/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.2215 - mean_squared_error: 13.2215 - val_loss: 14.9558 - val_mean_squared_error: 14.9558\n",
      "Epoch 2082/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.3162 - mean_squared_error: 13.3162 - val_loss: 15.2949 - val_mean_squared_error: 15.2949\n",
      "Epoch 2083/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.2805 - mean_squared_error: 13.2805 - val_loss: 15.0544 - val_mean_squared_error: 15.0544\n",
      "Epoch 2084/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.5261 - mean_squared_error: 13.5261 - val_loss: 14.8741 - val_mean_squared_error: 14.8741\n",
      "Epoch 2085/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.3004 - mean_squared_error: 13.3004 - val_loss: 14.7638 - val_mean_squared_error: 14.7638\n",
      "Epoch 2086/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3100 - mean_squared_error: 13.3100 - val_loss: 15.8442 - val_mean_squared_error: 15.8442\n",
      "Epoch 2087/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4040 - mean_squared_error: 13.4040 - val_loss: 14.7324 - val_mean_squared_error: 14.7324\n",
      "Epoch 2088/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.5199 - mean_squared_error: 13.5199 - val_loss: 14.7324 - val_mean_squared_error: 14.7324\n",
      "Epoch 2089/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.7063 - mean_squared_error: 13.7063 - val_loss: 14.7926 - val_mean_squared_error: 14.7926\n",
      "Epoch 2090/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4185 - mean_squared_error: 13.4185 - val_loss: 14.7823 - val_mean_squared_error: 14.7823\n",
      "Epoch 2091/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4844 - mean_squared_error: 13.4844 - val_loss: 15.0059 - val_mean_squared_error: 15.0059\n",
      "Epoch 2092/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4251 - mean_squared_error: 13.4251 - val_loss: 15.1233 - val_mean_squared_error: 15.1233\n",
      "Epoch 2093/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.2809 - mean_squared_error: 13.2809 - val_loss: 14.9080 - val_mean_squared_error: 14.9080\n",
      "Epoch 2094/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.8295 - mean_squared_error: 13.8295 - val_loss: 14.7390 - val_mean_squared_error: 14.7390\n",
      "Epoch 2095/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.5572 - mean_squared_error: 13.5572 - val_loss: 14.6910 - val_mean_squared_error: 14.6910\n",
      "Epoch 2096/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.2590 - mean_squared_error: 13.2590 - val_loss: 14.9618 - val_mean_squared_error: 14.9618\n",
      "Epoch 2097/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.1936 - mean_squared_error: 13.1936 - val_loss: 14.7326 - val_mean_squared_error: 14.7326\n",
      "Epoch 2098/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.2144 - mean_squared_error: 13.2144 - val_loss: 14.8170 - val_mean_squared_error: 14.8170\n",
      "Epoch 2099/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.2678 - mean_squared_error: 13.2678 - val_loss: 15.3729 - val_mean_squared_error: 15.3729\n",
      "Epoch 2100/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.5389 - mean_squared_error: 13.5389 - val_loss: 15.3334 - val_mean_squared_error: 15.3334\n",
      "Epoch 2101/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.2768 - mean_squared_error: 13.2768 - val_loss: 14.8205 - val_mean_squared_error: 14.8205\n",
      "Epoch 2102/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.4386 - mean_squared_error: 13.4386 - val_loss: 14.9177 - val_mean_squared_error: 14.9177\n",
      "Epoch 2103/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.3201 - mean_squared_error: 14.3201 - val_loss: 15.1248 - val_mean_squared_error: 15.1248\n",
      "Epoch 2104/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4229 - mean_squared_error: 13.4229 - val_loss: 15.3869 - val_mean_squared_error: 15.3869\n",
      "Epoch 2105/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.2912 - mean_squared_error: 13.2912 - val_loss: 14.8414 - val_mean_squared_error: 14.8414\n",
      "Epoch 2106/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.3163 - mean_squared_error: 13.3163 - val_loss: 15.5286 - val_mean_squared_error: 15.5286\n",
      "Epoch 2107/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 14.9302 - mean_squared_error: 14.93 - 0s 28us/sample - loss: 14.0993 - mean_squared_error: 14.0993 - val_loss: 16.7515 - val_mean_squared_error: 16.7515\n",
      "Epoch 2108/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.7687 - mean_squared_error: 13.7687 - val_loss: 14.8684 - val_mean_squared_error: 14.8684\n",
      "Epoch 2109/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.3609 - mean_squared_error: 13.3609 - val_loss: 15.8792 - val_mean_squared_error: 15.8792\n",
      "Epoch 2110/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4322 - mean_squared_error: 13.4322 - val_loss: 14.9309 - val_mean_squared_error: 14.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2111/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4722 - mean_squared_error: 13.4722 - val_loss: 16.4966 - val_mean_squared_error: 16.4966\n",
      "Epoch 2112/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.1043 - mean_squared_error: 14.1043 - val_loss: 15.4123 - val_mean_squared_error: 15.4123\n",
      "Epoch 2113/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 14.3208 - mean_squared_error: 14.3208 - val_loss: 17.3255 - val_mean_squared_error: 17.3255\n",
      "Epoch 2114/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.7422 - mean_squared_error: 13.7422 - val_loss: 14.7583 - val_mean_squared_error: 14.7583\n",
      "Epoch 2115/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.3343 - mean_squared_error: 13.3343 - val_loss: 14.8154 - val_mean_squared_error: 14.8154\n",
      "Epoch 2116/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5242 - mean_squared_error: 13.5242 - val_loss: 14.9916 - val_mean_squared_error: 14.9916\n",
      "Epoch 2117/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.3241 - mean_squared_error: 13.3241 - val_loss: 15.7607 - val_mean_squared_error: 15.7607\n",
      "Epoch 2118/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.4329 - mean_squared_error: 13.4329 - val_loss: 14.9534 - val_mean_squared_error: 14.9534\n",
      "Epoch 2119/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1919 - mean_squared_error: 13.1919 - val_loss: 14.9800 - val_mean_squared_error: 14.9800\n",
      "Epoch 2120/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.1661 - mean_squared_error: 13.1661 - val_loss: 14.7742 - val_mean_squared_error: 14.7742\n",
      "Epoch 2121/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.2055 - mean_squared_error: 13.2055 - val_loss: 14.7354 - val_mean_squared_error: 14.7354\n",
      "Epoch 2122/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.1921 - mean_squared_error: 13.1921 - val_loss: 14.6888 - val_mean_squared_error: 14.6888\n",
      "Epoch 2123/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.3957 - mean_squared_error: 13.3957 - val_loss: 14.7677 - val_mean_squared_error: 14.7677\n",
      "Epoch 2124/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.3018 - mean_squared_error: 13.3018 - val_loss: 14.8607 - val_mean_squared_error: 14.8607\n",
      "Epoch 2125/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.2457 - mean_squared_error: 13.2457 - val_loss: 14.7431 - val_mean_squared_error: 14.7431\n",
      "Epoch 2126/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.3220 - mean_squared_error: 13.3220 - val_loss: 14.7896 - val_mean_squared_error: 14.7896\n",
      "Epoch 2127/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.2350 - mean_squared_error: 13.2350 - val_loss: 14.7329 - val_mean_squared_error: 14.7329\n",
      "Epoch 2128/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.2993 - mean_squared_error: 13.2993 - val_loss: 14.8009 - val_mean_squared_error: 14.8009\n",
      "Epoch 2129/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.3239 - mean_squared_error: 13.3239 - val_loss: 15.9981 - val_mean_squared_error: 15.9981\n",
      "Epoch 2130/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.3185 - mean_squared_error: 13.3185 - val_loss: 14.7720 - val_mean_squared_error: 14.7720\n",
      "Epoch 2131/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.5461 - mean_squared_error: 13.5461 - val_loss: 14.7043 - val_mean_squared_error: 14.7043\n",
      "Epoch 2132/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.2545 - mean_squared_error: 13.2545 - val_loss: 15.7236 - val_mean_squared_error: 15.7236\n",
      "Epoch 2133/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.9545 - mean_squared_error: 13.9545 - val_loss: 15.9169 - val_mean_squared_error: 15.9169\n",
      "Epoch 2134/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.8977 - mean_squared_error: 13.8977 - val_loss: 15.4637 - val_mean_squared_error: 15.4637\n",
      "Epoch 2135/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.3916 - mean_squared_error: 13.3916 - val_loss: 14.8622 - val_mean_squared_error: 14.8622\n",
      "Epoch 2136/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.2256 - mean_squared_error: 13.2256 - val_loss: 14.8026 - val_mean_squared_error: 14.8026\n",
      "Epoch 2137/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.2504 - mean_squared_error: 13.2504 - val_loss: 14.9984 - val_mean_squared_error: 14.9984\n",
      "Epoch 2138/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.1525 - mean_squared_error: 13.1525 - val_loss: 14.6961 - val_mean_squared_error: 14.6961\n",
      "Epoch 2139/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.1513 - mean_squared_error: 13.1513 - val_loss: 14.8000 - val_mean_squared_error: 14.8000\n",
      "Epoch 2140/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.1438 - mean_squared_error: 13.1438 - val_loss: 14.7299 - val_mean_squared_error: 14.7299\n",
      "Epoch 2141/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.1267 - mean_squared_error: 13.1267 - val_loss: 14.7265 - val_mean_squared_error: 14.7265\n",
      "Epoch 2142/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.2860 - mean_squared_error: 13.2860 - val_loss: 14.8067 - val_mean_squared_error: 14.8067\n",
      "Epoch 2143/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.5962 - mean_squared_error: 13.5962 - val_loss: 14.6617 - val_mean_squared_error: 14.6617\n",
      "Epoch 2144/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.5292 - mean_squared_error: 13.5292 - val_loss: 14.7746 - val_mean_squared_error: 14.7746\n",
      "Epoch 2145/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.2471 - mean_squared_error: 13.2471 - val_loss: 15.3137 - val_mean_squared_error: 15.3137\n",
      "Epoch 2146/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.3492 - mean_squared_error: 13.3492 - val_loss: 14.9155 - val_mean_squared_error: 14.9155\n",
      "Epoch 2147/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.2082 - mean_squared_error: 13.2082 - val_loss: 14.8870 - val_mean_squared_error: 14.8870\n",
      "Epoch 2148/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.2345 - mean_squared_error: 13.2345 - val_loss: 14.6941 - val_mean_squared_error: 14.6941\n",
      "Epoch 2149/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.2742 - mean_squared_error: 13.2742 - val_loss: 14.7591 - val_mean_squared_error: 14.7591\n",
      "Epoch 2150/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.1860 - mean_squared_error: 13.1860 - val_loss: 14.5726 - val_mean_squared_error: 14.5726\n",
      "Epoch 2151/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.1463 - mean_squared_error: 13.1463 - val_loss: 14.8281 - val_mean_squared_error: 14.8281\n",
      "Epoch 2152/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1658 - mean_squared_error: 13.1658 - val_loss: 14.8356 - val_mean_squared_error: 14.8356\n",
      "Epoch 2153/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.5089 - mean_squared_error: 13.5089 - val_loss: 16.1653 - val_mean_squared_error: 16.1653\n",
      "Epoch 2154/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.7392 - mean_squared_error: 13.7392 - val_loss: 15.2149 - val_mean_squared_error: 15.2149\n",
      "Epoch 2155/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.3458 - mean_squared_error: 13.3458 - val_loss: 15.2618 - val_mean_squared_error: 15.2618\n",
      "Epoch 2156/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.1546 - mean_squared_error: 13.1546 - val_loss: 14.8047 - val_mean_squared_error: 14.8047\n",
      "Epoch 2157/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.5421 - mean_squared_error: 13.5421 - val_loss: 15.0108 - val_mean_squared_error: 15.0108\n",
      "Epoch 2158/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 51us/sample - loss: 13.5629 - mean_squared_error: 13.5629 - val_loss: 14.7116 - val_mean_squared_error: 14.7116\n",
      "Epoch 2159/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1872 - mean_squared_error: 13.1872 - val_loss: 14.7179 - val_mean_squared_error: 14.7179\n",
      "Epoch 2160/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.2288 - mean_squared_error: 13.2288 - val_loss: 14.6901 - val_mean_squared_error: 14.6901\n",
      "Epoch 2161/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.1386 - mean_squared_error: 13.1386 - val_loss: 14.7885 - val_mean_squared_error: 14.7885\n",
      "Epoch 2162/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.4927 - mean_squared_error: 13.4927 - val_loss: 16.1340 - val_mean_squared_error: 16.1340\n",
      "Epoch 2163/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 13.9603 - mean_squared_error: 13.9603 - val_loss: 15.4330 - val_mean_squared_error: 15.4330\n",
      "Epoch 2164/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.4221 - mean_squared_error: 13.4221 - val_loss: 15.1070 - val_mean_squared_error: 15.1070\n",
      "Epoch 2165/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 11.3114 - mean_squared_error: 11.31 - 0s 52us/sample - loss: 13.2295 - mean_squared_error: 13.2295 - val_loss: 15.0687 - val_mean_squared_error: 15.0687\n",
      "Epoch 2166/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.1563 - mean_squared_error: 13.1563 - val_loss: 14.6716 - val_mean_squared_error: 14.6716\n",
      "Epoch 2167/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.1850 - mean_squared_error: 13.1850 - val_loss: 14.8041 - val_mean_squared_error: 14.8041\n",
      "Epoch 2168/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.4810 - mean_squared_error: 13.4810 - val_loss: 15.0523 - val_mean_squared_error: 15.0523\n",
      "Epoch 2169/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.8076 - mean_squared_error: 13.8076 - val_loss: 14.6109 - val_mean_squared_error: 14.6109\n",
      "Epoch 2170/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.2481 - mean_squared_error: 13.2481 - val_loss: 15.8187 - val_mean_squared_error: 15.8187\n",
      "Epoch 2171/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.2583 - mean_squared_error: 13.2583 - val_loss: 14.9545 - val_mean_squared_error: 14.9545\n",
      "Epoch 2172/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.0152 - mean_squared_error: 14.0152 - val_loss: 14.6780 - val_mean_squared_error: 14.6780\n",
      "Epoch 2173/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.3590 - mean_squared_error: 13.3590 - val_loss: 14.6595 - val_mean_squared_error: 14.6595\n",
      "Epoch 2174/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.2122 - mean_squared_error: 13.2122 - val_loss: 14.6296 - val_mean_squared_error: 14.6296\n",
      "Epoch 2175/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.1618 - mean_squared_error: 13.1618 - val_loss: 14.6816 - val_mean_squared_error: 14.6816\n",
      "Epoch 2176/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.1355 - mean_squared_error: 13.1355 - val_loss: 14.5931 - val_mean_squared_error: 14.5931\n",
      "Epoch 2177/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.2202 - mean_squared_error: 13.2202 - val_loss: 15.6800 - val_mean_squared_error: 15.6800\n",
      "Epoch 2178/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.9475 - mean_squared_error: 13.9475 - val_loss: 15.7556 - val_mean_squared_error: 15.7556\n",
      "Epoch 2179/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.2937 - mean_squared_error: 13.2937 - val_loss: 14.6196 - val_mean_squared_error: 14.6196\n",
      "Epoch 2180/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.5619 - mean_squared_error: 13.5619 - val_loss: 14.7464 - val_mean_squared_error: 14.7464\n",
      "Epoch 2181/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.4728 - mean_squared_error: 13.4728 - val_loss: 14.5878 - val_mean_squared_error: 14.5878\n",
      "Epoch 2182/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.7077 - mean_squared_error: 13.7077 - val_loss: 17.4244 - val_mean_squared_error: 17.4244\n",
      "Epoch 2183/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.9451 - mean_squared_error: 13.9451 - val_loss: 14.5650 - val_mean_squared_error: 14.5650\n",
      "Epoch 2184/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.0910 - mean_squared_error: 13.0910 - val_loss: 14.8697 - val_mean_squared_error: 14.8697\n",
      "Epoch 2185/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.4059 - mean_squared_error: 13.4059 - val_loss: 15.1668 - val_mean_squared_error: 15.1668\n",
      "Epoch 2186/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.8021 - mean_squared_error: 13.8021 - val_loss: 14.5355 - val_mean_squared_error: 14.5355\n",
      "Epoch 2187/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.0919 - mean_squared_error: 13.0919 - val_loss: 14.7648 - val_mean_squared_error: 14.7648\n",
      "Epoch 2188/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.2842 - mean_squared_error: 13.2842 - val_loss: 15.2974 - val_mean_squared_error: 15.2974\n",
      "Epoch 2189/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 10.6991 - mean_squared_error: 10.69 - 0s 60us/sample - loss: 13.1766 - mean_squared_error: 13.1766 - val_loss: 14.7163 - val_mean_squared_error: 14.7163\n",
      "Epoch 2190/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.2981 - mean_squared_error: 13.2981 - val_loss: 14.6430 - val_mean_squared_error: 14.6430\n",
      "Epoch 2191/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.1986 - mean_squared_error: 13.1986 - val_loss: 15.4502 - val_mean_squared_error: 15.4502\n",
      "Epoch 2192/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.2394 - mean_squared_error: 13.2394 - val_loss: 14.5805 - val_mean_squared_error: 14.5805\n",
      "Epoch 2193/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.1696 - mean_squared_error: 13.1696 - val_loss: 14.6099 - val_mean_squared_error: 14.6099\n",
      "Epoch 2194/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.7757 - mean_squared_error: 13.7757 - val_loss: 15.1462 - val_mean_squared_error: 15.1462\n",
      "Epoch 2195/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.9356 - mean_squared_error: 13.9356 - val_loss: 14.5071 - val_mean_squared_error: 14.5071\n",
      "Epoch 2196/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.1032 - mean_squared_error: 13.1032 - val_loss: 14.9105 - val_mean_squared_error: 14.9105\n",
      "Epoch 2197/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.3509 - mean_squared_error: 13.3509 - val_loss: 15.2680 - val_mean_squared_error: 15.2680\n",
      "Epoch 2198/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1903 - mean_squared_error: 13.1903 - val_loss: 14.5052 - val_mean_squared_error: 14.5052\n",
      "Epoch 2199/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.0986 - mean_squared_error: 13.0986 - val_loss: 14.9014 - val_mean_squared_error: 14.9014\n",
      "Epoch 2200/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.1702 - mean_squared_error: 13.1702 - val_loss: 14.6445 - val_mean_squared_error: 14.6445\n",
      "Epoch 2201/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.2459 - mean_squared_error: 13.2459 - val_loss: 14.6754 - val_mean_squared_error: 14.6754\n",
      "Epoch 2202/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.3973 - mean_squared_error: 13.3973 - val_loss: 17.3426 - val_mean_squared_error: 17.3426\n",
      "Epoch 2203/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.8314 - mean_squared_error: 13.8314 - val_loss: 14.7172 - val_mean_squared_error: 14.7172\n",
      "Epoch 2204/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 36us/sample - loss: 13.1191 - mean_squared_error: 13.1191 - val_loss: 14.7298 - val_mean_squared_error: 14.7298\n",
      "Epoch 2205/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1306 - mean_squared_error: 13.1306 - val_loss: 14.5592 - val_mean_squared_error: 14.5592\n",
      "Epoch 2206/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.5531 - mean_squared_error: 13.5531 - val_loss: 15.1906 - val_mean_squared_error: 15.1906\n",
      "Epoch 2207/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.8248 - mean_squared_error: 14.8248 - val_loss: 14.8034 - val_mean_squared_error: 14.8034\n",
      "Epoch 2208/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.4217 - mean_squared_error: 13.4217 - val_loss: 14.6348 - val_mean_squared_error: 14.6348\n",
      "Epoch 2209/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.5336 - mean_squared_error: 13.5336 - val_loss: 15.2343 - val_mean_squared_error: 15.2343\n",
      "Epoch 2210/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.5232 - mean_squared_error: 13.5232 - val_loss: 15.0424 - val_mean_squared_error: 15.0424\n",
      "Epoch 2211/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.0937 - mean_squared_error: 13.0937 - val_loss: 14.5656 - val_mean_squared_error: 14.5656\n",
      "Epoch 2212/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.3997 - mean_squared_error: 13.3997 - val_loss: 16.4768 - val_mean_squared_error: 16.4768\n",
      "Epoch 2213/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.4454 - mean_squared_error: 13.4454 - val_loss: 14.6233 - val_mean_squared_error: 14.6233\n",
      "Epoch 2214/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.3375 - mean_squared_error: 13.3375 - val_loss: 16.8551 - val_mean_squared_error: 16.8551\n",
      "Epoch 2215/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.9506 - mean_squared_error: 13.9506 - val_loss: 14.7707 - val_mean_squared_error: 14.7707\n",
      "Epoch 2216/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.4555 - mean_squared_error: 13.4555 - val_loss: 15.9989 - val_mean_squared_error: 15.9989\n",
      "Epoch 2217/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.7099 - mean_squared_error: 13.7099 - val_loss: 14.8776 - val_mean_squared_error: 14.8776\n",
      "Epoch 2218/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.2432 - mean_squared_error: 13.2432 - val_loss: 15.1988 - val_mean_squared_error: 15.1988\n",
      "Epoch 2219/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.1261 - mean_squared_error: 13.1261 - val_loss: 14.5999 - val_mean_squared_error: 14.5999\n",
      "Epoch 2220/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.5642 - mean_squared_error: 13.5642 - val_loss: 14.8202 - val_mean_squared_error: 14.8202\n",
      "Epoch 2221/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.3015 - mean_squared_error: 13.3015 - val_loss: 14.9787 - val_mean_squared_error: 14.9787\n",
      "Epoch 2222/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.0894 - mean_squared_error: 13.0894 - val_loss: 14.5314 - val_mean_squared_error: 14.5314\n",
      "Epoch 2223/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.5163 - mean_squared_error: 13.5162 - val_loss: 14.6748 - val_mean_squared_error: 14.6748\n",
      "Epoch 2224/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1938 - mean_squared_error: 13.1938 - val_loss: 15.8024 - val_mean_squared_error: 15.8024\n",
      "Epoch 2225/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.3253 - mean_squared_error: 13.3253 - val_loss: 14.6054 - val_mean_squared_error: 14.6054\n",
      "Epoch 2226/4000\n",
      "339/339 [==============================] - 0s 59us/sample - loss: 13.0698 - mean_squared_error: 13.0698 - val_loss: 14.8154 - val_mean_squared_error: 14.8154\n",
      "Epoch 2227/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.0727 - mean_squared_error: 13.0727 - val_loss: 14.6980 - val_mean_squared_error: 14.6980\n",
      "Epoch 2228/4000\n",
      "339/339 [==============================] - 0s 61us/sample - loss: 13.1268 - mean_squared_error: 13.1268 - val_loss: 15.2677 - val_mean_squared_error: 15.2677\n",
      "Epoch 2229/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.2432 - mean_squared_error: 13.2432 - val_loss: 14.7638 - val_mean_squared_error: 14.7638\n",
      "Epoch 2230/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.0963 - mean_squared_error: 13.0963 - val_loss: 14.8568 - val_mean_squared_error: 14.8568\n",
      "Epoch 2231/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.5138 - mean_squared_error: 13.5138 - val_loss: 15.7656 - val_mean_squared_error: 15.7656\n",
      "Epoch 2232/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.1072 - mean_squared_error: 14.1072 - val_loss: 16.0278 - val_mean_squared_error: 16.0278\n",
      "Epoch 2233/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.3292 - mean_squared_error: 13.3292 - val_loss: 14.6003 - val_mean_squared_error: 14.6003\n",
      "Epoch 2234/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.3404 - mean_squared_error: 13.3404 - val_loss: 14.5588 - val_mean_squared_error: 14.5588\n",
      "Epoch 2235/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.1537 - mean_squared_error: 13.1537 - val_loss: 14.6760 - val_mean_squared_error: 14.6760\n",
      "Epoch 2236/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.0730 - mean_squared_error: 13.0730 - val_loss: 14.7589 - val_mean_squared_error: 14.7589\n",
      "Epoch 2237/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.0740 - mean_squared_error: 13.0740 - val_loss: 14.6463 - val_mean_squared_error: 14.6463\n",
      "Epoch 2238/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.0778 - mean_squared_error: 13.0778 - val_loss: 14.8264 - val_mean_squared_error: 14.8264\n",
      "Epoch 2239/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.0679 - mean_squared_error: 13.0679 - val_loss: 14.6367 - val_mean_squared_error: 14.6367\n",
      "Epoch 2240/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.0786 - mean_squared_error: 13.0786 - val_loss: 14.8657 - val_mean_squared_error: 14.8657\n",
      "Epoch 2241/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.6541 - mean_squared_error: 13.6541 - val_loss: 16.1271 - val_mean_squared_error: 16.1271\n",
      "Epoch 2242/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.4141 - mean_squared_error: 13.4141 - val_loss: 14.5025 - val_mean_squared_error: 14.5025\n",
      "Epoch 2243/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.0525 - mean_squared_error: 13.0525 - val_loss: 14.8321 - val_mean_squared_error: 14.8321\n",
      "Epoch 2244/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.2661 - mean_squared_error: 13.2661 - val_loss: 15.0132 - val_mean_squared_error: 15.0132\n",
      "Epoch 2245/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.2636 - mean_squared_error: 13.2636 - val_loss: 14.8137 - val_mean_squared_error: 14.8137\n",
      "Epoch 2246/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.0742 - mean_squared_error: 13.0742 - val_loss: 14.4893 - val_mean_squared_error: 14.4893\n",
      "Epoch 2247/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.1921 - mean_squared_error: 13.1921 - val_loss: 14.5123 - val_mean_squared_error: 14.5123\n",
      "Epoch 2248/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.0438 - mean_squared_error: 13.0438 - val_loss: 14.9361 - val_mean_squared_error: 14.9361\n",
      "Epoch 2249/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.0912 - mean_squared_error: 13.0912 - val_loss: 14.5890 - val_mean_squared_error: 14.5890\n",
      "Epoch 2250/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0849 - mean_squared_error: 13.0849 - val_loss: 14.4615 - val_mean_squared_error: 14.4615\n",
      "Epoch 2251/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1134 - mean_squared_error: 13.1134 - val_loss: 14.4361 - val_mean_squared_error: 14.4361\n",
      "Epoch 2252/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.0648 - mean_squared_error: 13.0648 - val_loss: 14.4177 - val_mean_squared_error: 14.4177\n",
      "Epoch 2253/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.0828 - mean_squared_error: 13.0828 - val_loss: 14.4063 - val_mean_squared_error: 14.4063\n",
      "Epoch 2254/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0526 - mean_squared_error: 13.0526 - val_loss: 14.9223 - val_mean_squared_error: 14.9223\n",
      "Epoch 2255/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.0555 - mean_squared_error: 13.0555 - val_loss: 14.4884 - val_mean_squared_error: 14.4884\n",
      "Epoch 2256/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.1678 - mean_squared_error: 13.1678 - val_loss: 14.4925 - val_mean_squared_error: 14.4925\n",
      "Epoch 2257/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.0627 - mean_squared_error: 13.0627 - val_loss: 14.8552 - val_mean_squared_error: 14.8552\n",
      "Epoch 2258/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.1349 - mean_squared_error: 13.1349 - val_loss: 14.4988 - val_mean_squared_error: 14.4988\n",
      "Epoch 2259/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.0557 - mean_squared_error: 13.0557 - val_loss: 14.6704 - val_mean_squared_error: 14.6704\n",
      "Epoch 2260/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.0826 - mean_squared_error: 13.0826 - val_loss: 14.6380 - val_mean_squared_error: 14.6380\n",
      "Epoch 2261/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0982 - mean_squared_error: 13.0982 - val_loss: 14.6990 - val_mean_squared_error: 14.6990\n",
      "Epoch 2262/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.5114 - mean_squared_error: 13.5114 - val_loss: 15.9908 - val_mean_squared_error: 15.9908\n",
      "Epoch 2263/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.9089 - mean_squared_error: 13.9089 - val_loss: 15.1312 - val_mean_squared_error: 15.1312\n",
      "Epoch 2264/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.3703 - mean_squared_error: 14.3703 - val_loss: 17.1147 - val_mean_squared_error: 17.1147\n",
      "Epoch 2265/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.4940 - mean_squared_error: 13.4940 - val_loss: 15.0492 - val_mean_squared_error: 15.0492\n",
      "Epoch 2266/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.7020 - mean_squared_error: 13.7020 - val_loss: 14.4449 - val_mean_squared_error: 14.4449\n",
      "Epoch 2267/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.0648 - mean_squared_error: 13.0648 - val_loss: 14.3887 - val_mean_squared_error: 14.3887\n",
      "Epoch 2268/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.3057 - mean_squared_error: 13.3057 - val_loss: 14.3663 - val_mean_squared_error: 14.3663\n",
      "Epoch 2269/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.0437 - mean_squared_error: 13.0437 - val_loss: 14.8067 - val_mean_squared_error: 14.8067\n",
      "Epoch 2270/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.0396 - mean_squared_error: 13.0396 - val_loss: 14.3687 - val_mean_squared_error: 14.3687\n",
      "Epoch 2271/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.0180 - mean_squared_error: 13.0180 - val_loss: 14.6149 - val_mean_squared_error: 14.6149\n",
      "Epoch 2272/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.0004 - mean_squared_error: 13.0004 - val_loss: 14.4397 - val_mean_squared_error: 14.4397\n",
      "Epoch 2273/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.3326 - mean_squared_error: 13.3326 - val_loss: 14.5720 - val_mean_squared_error: 14.5720\n",
      "Epoch 2274/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 14.3594 - mean_squared_error: 14.3594 - val_loss: 14.9727 - val_mean_squared_error: 14.9727\n",
      "Epoch 2275/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.7687 - mean_squared_error: 13.7687 - val_loss: 14.3432 - val_mean_squared_error: 14.3432\n",
      "Epoch 2276/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.0372 - mean_squared_error: 13.0372 - val_loss: 14.7254 - val_mean_squared_error: 14.7254\n",
      "Epoch 2277/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.1024 - mean_squared_error: 13.1024 - val_loss: 14.7237 - val_mean_squared_error: 14.7237\n",
      "Epoch 2278/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1856 - mean_squared_error: 13.1856 - val_loss: 14.8810 - val_mean_squared_error: 14.8810\n",
      "Epoch 2279/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0267 - mean_squared_error: 13.0267 - val_loss: 14.4421 - val_mean_squared_error: 14.4421\n",
      "Epoch 2280/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1686 - mean_squared_error: 13.1686 - val_loss: 14.5101 - val_mean_squared_error: 14.5101\n",
      "Epoch 2281/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.1209 - mean_squared_error: 13.1209 - val_loss: 15.8466 - val_mean_squared_error: 15.8466\n",
      "Epoch 2282/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.1564 - mean_squared_error: 13.1564 - val_loss: 14.6125 - val_mean_squared_error: 14.6125\n",
      "Epoch 2283/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1837 - mean_squared_error: 13.1837 - val_loss: 14.8789 - val_mean_squared_error: 14.8789\n",
      "Epoch 2284/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0681 - mean_squared_error: 13.0681 - val_loss: 14.5736 - val_mean_squared_error: 14.5736\n",
      "Epoch 2285/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.0129 - mean_squared_error: 13.0129 - val_loss: 14.6389 - val_mean_squared_error: 14.6389\n",
      "Epoch 2286/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.0595 - mean_squared_error: 13.0595 - val_loss: 14.4721 - val_mean_squared_error: 14.4721\n",
      "Epoch 2287/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.4154 - mean_squared_error: 13.4154 - val_loss: 14.3918 - val_mean_squared_error: 14.3918\n",
      "Epoch 2288/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.0331 - mean_squared_error: 13.0331 - val_loss: 14.5146 - val_mean_squared_error: 14.5146\n",
      "Epoch 2289/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.0944 - mean_squared_error: 13.0944 - val_loss: 14.8974 - val_mean_squared_error: 14.8974\n",
      "Epoch 2290/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.1381 - mean_squared_error: 13.1381 - val_loss: 14.6221 - val_mean_squared_error: 14.6221\n",
      "Epoch 2291/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.5292 - mean_squared_error: 13.5292 - val_loss: 16.0230 - val_mean_squared_error: 16.0230\n",
      "Epoch 2292/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.4593 - mean_squared_error: 13.4593 - val_loss: 14.5442 - val_mean_squared_error: 14.5442\n",
      "Epoch 2293/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.0346 - mean_squared_error: 13.0346 - val_loss: 14.3506 - val_mean_squared_error: 14.3506\n",
      "Epoch 2294/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.4062 - mean_squared_error: 13.4062 - val_loss: 14.4736 - val_mean_squared_error: 14.4736\n",
      "Epoch 2295/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.1372 - mean_squared_error: 13.1372 - val_loss: 14.5164 - val_mean_squared_error: 14.5164\n",
      "Epoch 2296/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.9731 - mean_squared_error: 12.9731 - val_loss: 14.3459 - val_mean_squared_error: 14.3459\n",
      "Epoch 2297/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.0654 - mean_squared_error: 13.0654 - val_loss: 15.1518 - val_mean_squared_error: 15.1518\n",
      "Epoch 2298/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1250 - mean_squared_error: 13.1250 - val_loss: 14.4382 - val_mean_squared_error: 14.4382\n",
      "Epoch 2299/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.0920 - mean_squared_error: 13.0920 - val_loss: 15.3391 - val_mean_squared_error: 15.3391\n",
      "Epoch 2300/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.0819 - mean_squared_error: 13.0819 - val_loss: 14.4155 - val_mean_squared_error: 14.4155\n",
      "Epoch 2301/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.3670 - mean_squared_error: 13.3670 - val_loss: 17.0424 - val_mean_squared_error: 17.0424\n",
      "Epoch 2302/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 14.0272 - mean_squared_error: 14.0272 - val_loss: 14.7033 - val_mean_squared_error: 14.7033\n",
      "Epoch 2303/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.5494 - mean_squared_error: 13.5494 - val_loss: 16.5232 - val_mean_squared_error: 16.5232\n",
      "Epoch 2304/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.2936 - mean_squared_error: 13.2936 - val_loss: 14.8704 - val_mean_squared_error: 14.8704\n",
      "Epoch 2305/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 14.9276 - mean_squared_error: 14.92 - 0s 64us/sample - loss: 14.4530 - mean_squared_error: 14.4530 - val_loss: 14.7563 - val_mean_squared_error: 14.7563\n",
      "Epoch 2306/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.1870 - mean_squared_error: 13.1870 - val_loss: 14.9914 - val_mean_squared_error: 14.9914\n",
      "Epoch 2307/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.0014 - mean_squared_error: 13.0014 - val_loss: 14.4668 - val_mean_squared_error: 14.4668\n",
      "Epoch 2308/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.3917 - mean_squared_error: 13.3917 - val_loss: 14.3849 - val_mean_squared_error: 14.3849\n",
      "Epoch 2309/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.5373 - mean_squared_error: 13.5373 - val_loss: 14.5205 - val_mean_squared_error: 14.5205\n",
      "Epoch 2310/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.2191 - mean_squared_error: 13.2191 - val_loss: 14.4669 - val_mean_squared_error: 14.4669\n",
      "Epoch 2311/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.9722 - mean_squared_error: 12.9722 - val_loss: 14.3374 - val_mean_squared_error: 14.3374\n",
      "Epoch 2312/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.0799 - mean_squared_error: 13.0799 - val_loss: 15.2113 - val_mean_squared_error: 15.2113\n",
      "Epoch 2313/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.1568 - mean_squared_error: 13.1568 - val_loss: 14.2616 - val_mean_squared_error: 14.2616\n",
      "Epoch 2314/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 14.0815 - mean_squared_error: 14.0815 - val_loss: 15.7595 - val_mean_squared_error: 15.7595\n",
      "Epoch 2315/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 14.6808 - mean_squared_error: 14.6808 - val_loss: 14.3021 - val_mean_squared_error: 14.3021\n",
      "Epoch 2316/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.0088 - mean_squared_error: 13.0088 - val_loss: 14.3493 - val_mean_squared_error: 14.3493\n",
      "Epoch 2317/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.1673 - mean_squared_error: 13.1673 - val_loss: 15.4450 - val_mean_squared_error: 15.4450\n",
      "Epoch 2318/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.1028 - mean_squared_error: 13.1028 - val_loss: 14.3433 - val_mean_squared_error: 14.3433\n",
      "Epoch 2319/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.9972 - mean_squared_error: 12.9972 - val_loss: 14.5102 - val_mean_squared_error: 14.5102\n",
      "Epoch 2320/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.9702 - mean_squared_error: 12.9702 - val_loss: 14.3175 - val_mean_squared_error: 14.3175\n",
      "Epoch 2321/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.1648 - mean_squared_error: 13.1648 - val_loss: 14.2690 - val_mean_squared_error: 14.2690\n",
      "Epoch 2322/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.3062 - mean_squared_error: 13.3062 - val_loss: 14.3665 - val_mean_squared_error: 14.3665\n",
      "Epoch 2323/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.4910 - mean_squared_error: 13.4910 - val_loss: 14.3760 - val_mean_squared_error: 14.3760\n",
      "Epoch 2324/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.3962 - mean_squared_error: 13.3962 - val_loss: 14.3427 - val_mean_squared_error: 14.3427\n",
      "Epoch 2325/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.3327 - mean_squared_error: 13.3327 - val_loss: 14.2566 - val_mean_squared_error: 14.2566\n",
      "Epoch 2326/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.9644 - mean_squared_error: 12.9644 - val_loss: 14.9480 - val_mean_squared_error: 14.9480\n",
      "Epoch 2327/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.1648 - mean_squared_error: 13.1648 - val_loss: 14.3252 - val_mean_squared_error: 14.3252\n",
      "Epoch 2328/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.9880 - mean_squared_error: 12.9880 - val_loss: 14.1938 - val_mean_squared_error: 14.1938\n",
      "Epoch 2329/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.0028 - mean_squared_error: 13.0028 - val_loss: 15.2753 - val_mean_squared_error: 15.2753\n",
      "Epoch 2330/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.2057 - mean_squared_error: 13.2057 - val_loss: 14.2920 - val_mean_squared_error: 14.2920\n",
      "Epoch 2331/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.0035 - mean_squared_error: 13.0035 - val_loss: 14.1653 - val_mean_squared_error: 14.1653\n",
      "Epoch 2332/4000\n",
      "339/339 [==============================] - 0s 21us/sample - loss: 12.9659 - mean_squared_error: 12.9659 - val_loss: 14.3820 - val_mean_squared_error: 14.3820\n",
      "Epoch 2333/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.0968 - mean_squared_error: 13.0968 - val_loss: 14.4339 - val_mean_squared_error: 14.4339\n",
      "Epoch 2334/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.1584 - mean_squared_error: 13.1584 - val_loss: 14.8142 - val_mean_squared_error: 14.8142\n",
      "Epoch 2335/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.1612 - mean_squared_error: 13.1612 - val_loss: 14.4883 - val_mean_squared_error: 14.4883\n",
      "Epoch 2336/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.9965 - mean_squared_error: 12.9965 - val_loss: 14.4326 - val_mean_squared_error: 14.4326\n",
      "Epoch 2337/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.1878 - mean_squared_error: 13.1878 - val_loss: 15.5505 - val_mean_squared_error: 15.5505\n",
      "Epoch 2338/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.6219 - mean_squared_error: 13.6219 - val_loss: 14.6633 - val_mean_squared_error: 14.6633\n",
      "Epoch 2339/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.9544 - mean_squared_error: 12.9544 - val_loss: 14.2187 - val_mean_squared_error: 14.2187\n",
      "Epoch 2340/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 11.4907 - mean_squared_error: 11.49 - 0s 44us/sample - loss: 12.9303 - mean_squared_error: 12.9303 - val_loss: 14.5298 - val_mean_squared_error: 14.5298\n",
      "Epoch 2341/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.1878 - mean_squared_error: 13.1878 - val_loss: 15.0668 - val_mean_squared_error: 15.0668\n",
      "Epoch 2342/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.0369 - mean_squared_error: 13.0369 - val_loss: 14.2242 - val_mean_squared_error: 14.2242\n",
      "Epoch 2343/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.0455 - mean_squared_error: 13.0455 - val_loss: 14.3740 - val_mean_squared_error: 14.3740\n",
      "Epoch 2344/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 31us/sample - loss: 12.9784 - mean_squared_error: 12.9784 - val_loss: 14.7099 - val_mean_squared_error: 14.7099\n",
      "Epoch 2345/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.4208 - mean_squared_error: 13.4208 - val_loss: 15.4496 - val_mean_squared_error: 15.4496\n",
      "Epoch 2346/4000\n",
      "339/339 [==============================] - 0s 122us/sample - loss: 13.2218 - mean_squared_error: 13.2218 - val_loss: 14.1669 - val_mean_squared_error: 14.1669\n",
      "Epoch 2347/4000\n",
      "339/339 [==============================] - 0s 157us/sample - loss: 12.9743 - mean_squared_error: 12.9743 - val_loss: 14.1828 - val_mean_squared_error: 14.1828\n",
      "Epoch 2348/4000\n",
      "339/339 [==============================] - 0s 60us/sample - loss: 13.1090 - mean_squared_error: 13.1090 - val_loss: 15.4579 - val_mean_squared_error: 15.4579\n",
      "Epoch 2349/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.1573 - mean_squared_error: 14.1573 - val_loss: 16.1223 - val_mean_squared_error: 16.1223\n",
      "Epoch 2350/4000\n",
      "339/339 [==============================] - 0s 80us/sample - loss: 13.3011 - mean_squared_error: 13.3011 - val_loss: 14.2942 - val_mean_squared_error: 14.2942\n",
      "Epoch 2351/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.0557 - mean_squared_error: 13.0557 - val_loss: 14.2630 - val_mean_squared_error: 14.2630\n",
      "Epoch 2352/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 12.9216 - mean_squared_error: 12.9216 - val_loss: 14.3161 - val_mean_squared_error: 14.3161\n",
      "Epoch 2353/4000\n",
      "339/339 [==============================] - 0s 130us/sample - loss: 12.9453 - mean_squared_error: 12.9453 - val_loss: 14.2837 - val_mean_squared_error: 14.2837\n",
      "Epoch 2354/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.9754 - mean_squared_error: 12.9754 - val_loss: 15.1308 - val_mean_squared_error: 15.1308\n",
      "Epoch 2355/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.0114 - mean_squared_error: 13.0114 - val_loss: 14.2799 - val_mean_squared_error: 14.2799\n",
      "Epoch 2356/4000\n",
      "339/339 [==============================] - 0s 66us/sample - loss: 14.3965 - mean_squared_error: 14.3965 - val_loss: 15.6324 - val_mean_squared_error: 15.6324\n",
      "Epoch 2357/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.5087 - mean_squared_error: 14.5087 - val_loss: 14.2448 - val_mean_squared_error: 14.2448\n",
      "Epoch 2358/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9468 - mean_squared_error: 12.9468 - val_loss: 14.5811 - val_mean_squared_error: 14.5811\n",
      "Epoch 2359/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.9951 - mean_squared_error: 12.9951 - val_loss: 14.3063 - val_mean_squared_error: 14.3063\n",
      "Epoch 2360/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.8312 - mean_squared_error: 13.8312 - val_loss: 15.7748 - val_mean_squared_error: 15.7748\n",
      "Epoch 2361/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.8050 - mean_squared_error: 13.8050 - val_loss: 14.7177 - val_mean_squared_error: 14.7177\n",
      "Epoch 2362/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.0689 - mean_squared_error: 13.0689 - val_loss: 14.5242 - val_mean_squared_error: 14.5242\n",
      "Epoch 2363/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.2546 - mean_squared_error: 13.2546 - val_loss: 15.3834 - val_mean_squared_error: 15.3834\n",
      "Epoch 2364/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.2557 - mean_squared_error: 13.2557 - val_loss: 14.4166 - val_mean_squared_error: 14.4166\n",
      "Epoch 2365/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.8910 - mean_squared_error: 12.8910 - val_loss: 14.3710 - val_mean_squared_error: 14.3710\n",
      "Epoch 2366/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.0575 - mean_squared_error: 13.0575 - val_loss: 14.4049 - val_mean_squared_error: 14.4049\n",
      "Epoch 2367/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.0804 - mean_squared_error: 14.0804 - val_loss: 14.6820 - val_mean_squared_error: 14.6820\n",
      "Epoch 2368/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 14.0567 - mean_squared_error: 14.0567 - val_loss: 14.4078 - val_mean_squared_error: 14.4078\n",
      "Epoch 2369/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.4916 - mean_squared_error: 14.4916 - val_loss: 15.1188 - val_mean_squared_error: 15.1188\n",
      "Epoch 2370/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.9876 - mean_squared_error: 13.9876 - val_loss: 14.1365 - val_mean_squared_error: 14.1365\n",
      "Epoch 2371/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.9656 - mean_squared_error: 12.9656 - val_loss: 14.2331 - val_mean_squared_error: 14.2331\n",
      "Epoch 2372/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.2520 - mean_squared_error: 13.2520 - val_loss: 16.0499 - val_mean_squared_error: 16.0499\n",
      "Epoch 2373/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.0539 - mean_squared_error: 14.0539 - val_loss: 15.3749 - val_mean_squared_error: 15.3749\n",
      "Epoch 2374/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.9492 - mean_squared_error: 13.9492 - val_loss: 15.7572 - val_mean_squared_error: 15.7572\n",
      "Epoch 2375/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 14.5657 - mean_squared_error: 14.5657 - val_loss: 16.6065 - val_mean_squared_error: 16.6065\n",
      "Epoch 2376/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.4836 - mean_squared_error: 13.4836 - val_loss: 14.2967 - val_mean_squared_error: 14.2967\n",
      "Epoch 2377/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.0791 - mean_squared_error: 13.0791 - val_loss: 14.3166 - val_mean_squared_error: 14.3166\n",
      "Epoch 2378/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.1413 - mean_squared_error: 13.1413 - val_loss: 14.2503 - val_mean_squared_error: 14.2503\n",
      "Epoch 2379/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9219 - mean_squared_error: 12.9219 - val_loss: 14.9173 - val_mean_squared_error: 14.9173\n",
      "Epoch 2380/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.7590 - mean_squared_error: 13.7590 - val_loss: 15.8077 - val_mean_squared_error: 15.8077\n",
      "Epoch 2381/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 13.5485 - mean_squared_error: 13.5485 - val_loss: 14.6726 - val_mean_squared_error: 14.6726\n",
      "Epoch 2382/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 12.9330 - mean_squared_error: 12.9330 - val_loss: 14.2959 - val_mean_squared_error: 14.2959\n",
      "Epoch 2383/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9664 - mean_squared_error: 12.9664 - val_loss: 14.9280 - val_mean_squared_error: 14.9280\n",
      "Epoch 2384/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.9747 - mean_squared_error: 12.9747 - val_loss: 14.2440 - val_mean_squared_error: 14.2440\n",
      "Epoch 2385/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4920 - mean_squared_error: 13.4920 - val_loss: 14.8382 - val_mean_squared_error: 14.8382\n",
      "Epoch 2386/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.4530 - mean_squared_error: 13.4530 - val_loss: 14.3327 - val_mean_squared_error: 14.3327\n",
      "Epoch 2387/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.8775 - mean_squared_error: 12.8775 - val_loss: 14.2134 - val_mean_squared_error: 14.2134\n",
      "Epoch 2388/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9400 - mean_squared_error: 12.9400 - val_loss: 14.2291 - val_mean_squared_error: 14.2291\n",
      "Epoch 2389/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9253 - mean_squared_error: 12.9253 - val_loss: 15.0475 - val_mean_squared_error: 15.0475\n",
      "Epoch 2390/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.9926 - mean_squared_error: 12.9926 - val_loss: 14.2055 - val_mean_squared_error: 14.2055\n",
      "Epoch 2391/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 28us/sample - loss: 12.8807 - mean_squared_error: 12.8807 - val_loss: 14.2605 - val_mean_squared_error: 14.2605\n",
      "Epoch 2392/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.9785 - mean_squared_error: 12.9785 - val_loss: 14.8337 - val_mean_squared_error: 14.8337\n",
      "Epoch 2393/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.9344 - mean_squared_error: 12.9344 - val_loss: 14.1877 - val_mean_squared_error: 14.1877\n",
      "Epoch 2394/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.9862 - mean_squared_error: 12.9862 - val_loss: 15.4176 - val_mean_squared_error: 15.4176\n",
      "Epoch 2395/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.1197 - mean_squared_error: 13.1197 - val_loss: 14.1976 - val_mean_squared_error: 14.1976\n",
      "Epoch 2396/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.9710 - mean_squared_error: 12.9710 - val_loss: 14.1123 - val_mean_squared_error: 14.1123\n",
      "Epoch 2397/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9347 - mean_squared_error: 12.9347 - val_loss: 14.1543 - val_mean_squared_error: 14.1543\n",
      "Epoch 2398/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.0550 - mean_squared_error: 13.0550 - val_loss: 14.1832 - val_mean_squared_error: 14.1832\n",
      "Epoch 2399/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9534 - mean_squared_error: 12.9534 - val_loss: 14.6571 - val_mean_squared_error: 14.6571\n",
      "Epoch 2400/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.9627 - mean_squared_error: 12.9627 - val_loss: 14.1331 - val_mean_squared_error: 14.1331\n",
      "Epoch 2401/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.8756 - mean_squared_error: 12.8756 - val_loss: 14.3337 - val_mean_squared_error: 14.3337\n",
      "Epoch 2402/4000\n",
      "339/339 [==============================] - 0s 22us/sample - loss: 13.1045 - mean_squared_error: 13.1045 - val_loss: 14.5524 - val_mean_squared_error: 14.5524\n",
      "Epoch 2403/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.2727 - mean_squared_error: 13.2727 - val_loss: 14.4126 - val_mean_squared_error: 14.4126\n",
      "Epoch 2404/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.9381 - mean_squared_error: 12.9381 - val_loss: 14.5306 - val_mean_squared_error: 14.5306\n",
      "Epoch 2405/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.8746 - mean_squared_error: 12.8746 - val_loss: 14.1149 - val_mean_squared_error: 14.1149\n",
      "Epoch 2406/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.6009 - mean_squared_error: 13.6009 - val_loss: 14.8938 - val_mean_squared_error: 14.8938\n",
      "Epoch 2407/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 14.0790 - mean_squared_error: 14.0790 - val_loss: 14.0942 - val_mean_squared_error: 14.0942\n",
      "Epoch 2408/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9641 - mean_squared_error: 12.9641 - val_loss: 14.4048 - val_mean_squared_error: 14.4048\n",
      "Epoch 2409/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.8751 - mean_squared_error: 12.8751 - val_loss: 14.1465 - val_mean_squared_error: 14.1465\n",
      "Epoch 2410/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.8779 - mean_squared_error: 12.8779 - val_loss: 14.4438 - val_mean_squared_error: 14.4438\n",
      "Epoch 2411/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.2384 - mean_squared_error: 13.2384 - val_loss: 14.9389 - val_mean_squared_error: 14.9389\n",
      "Epoch 2412/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.2998 - mean_squared_error: 13.2998 - val_loss: 14.9226 - val_mean_squared_error: 14.9226\n",
      "Epoch 2413/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.0447 - mean_squared_error: 13.0447 - val_loss: 14.1081 - val_mean_squared_error: 14.1081\n",
      "Epoch 2414/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9447 - mean_squared_error: 12.9447 - val_loss: 14.0844 - val_mean_squared_error: 14.0844\n",
      "Epoch 2415/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.9455 - mean_squared_error: 12.9455 - val_loss: 14.1638 - val_mean_squared_error: 14.1638\n",
      "Epoch 2416/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.8517 - mean_squared_error: 12.8517 - val_loss: 14.2055 - val_mean_squared_error: 14.2055\n",
      "Epoch 2417/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.8499 - mean_squared_error: 12.8499 - val_loss: 14.0875 - val_mean_squared_error: 14.0875\n",
      "Epoch 2418/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.8565 - mean_squared_error: 12.8565 - val_loss: 14.1276 - val_mean_squared_error: 14.1276\n",
      "Epoch 2419/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.9541 - mean_squared_error: 12.9541 - val_loss: 14.7953 - val_mean_squared_error: 14.7953\n",
      "Epoch 2420/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.6763 - mean_squared_error: 13.6763 - val_loss: 15.3809 - val_mean_squared_error: 15.3809\n",
      "Epoch 2421/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.8652 - mean_squared_error: 13.8652 - val_loss: 15.2596 - val_mean_squared_error: 15.2596\n",
      "Epoch 2422/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.4517 - mean_squared_error: 13.4517 - val_loss: 14.4807 - val_mean_squared_error: 14.4807\n",
      "Epoch 2423/4000\n",
      "339/339 [==============================] - 0s 16us/sample - loss: 12.9789 - mean_squared_error: 12.9789 - val_loss: 14.3713 - val_mean_squared_error: 14.3713\n",
      "Epoch 2424/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9010 - mean_squared_error: 12.9010 - val_loss: 14.3856 - val_mean_squared_error: 14.3856\n",
      "Epoch 2425/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.1073 - mean_squared_error: 13.1073 - val_loss: 15.0038 - val_mean_squared_error: 15.0038\n",
      "Epoch 2426/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 12.9788 - mean_squared_error: 12.9788 - val_loss: 14.1968 - val_mean_squared_error: 14.1968\n",
      "Epoch 2427/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.9918 - mean_squared_error: 12.9918 - val_loss: 14.2378 - val_mean_squared_error: 14.2378\n",
      "Epoch 2428/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.5009 - mean_squared_error: 13.5009 - val_loss: 14.3766 - val_mean_squared_error: 14.3766\n",
      "Epoch 2429/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.1347 - mean_squared_error: 14.1347 - val_loss: 14.4910 - val_mean_squared_error: 14.4910\n",
      "Epoch 2430/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 16.7463 - mean_squared_error: 16.74 - 0s 32us/sample - loss: 13.3110 - mean_squared_error: 13.3110 - val_loss: 14.1210 - val_mean_squared_error: 14.1210\n",
      "Epoch 2431/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.8171 - mean_squared_error: 12.8171 - val_loss: 14.1555 - val_mean_squared_error: 14.1555\n",
      "Epoch 2432/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.8376 - mean_squared_error: 12.8376 - val_loss: 14.0151 - val_mean_squared_error: 14.0151\n",
      "Epoch 2433/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.8425 - mean_squared_error: 12.8425 - val_loss: 14.2214 - val_mean_squared_error: 14.2214\n",
      "Epoch 2434/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.8961 - mean_squared_error: 12.8961 - val_loss: 14.4279 - val_mean_squared_error: 14.4279\n",
      "Epoch 2435/4000\n",
      "339/339 [==============================] - 0s 24us/sample - loss: 13.4696 - mean_squared_error: 13.4696 - val_loss: 15.5808 - val_mean_squared_error: 15.5808\n",
      "Epoch 2436/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.1033 - mean_squared_error: 13.1033 - val_loss: 14.1297 - val_mean_squared_error: 14.1297\n",
      "Epoch 2437/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.0987 - mean_squared_error: 13.0987 - val_loss: 14.1667 - val_mean_squared_error: 14.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2438/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.9134 - mean_squared_error: 12.9134 - val_loss: 14.2956 - val_mean_squared_error: 14.2956\n",
      "Epoch 2439/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.8134 - mean_squared_error: 12.8134 - val_loss: 14.1121 - val_mean_squared_error: 14.1121\n",
      "Epoch 2440/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.0678 - mean_squared_error: 13.0678 - val_loss: 14.1241 - val_mean_squared_error: 14.1241\n",
      "Epoch 2441/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.0110 - mean_squared_error: 13.0110 - val_loss: 15.8690 - val_mean_squared_error: 15.8690\n",
      "Epoch 2442/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.1263 - mean_squared_error: 13.1263 - val_loss: 14.1574 - val_mean_squared_error: 14.1574\n",
      "Epoch 2443/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.8801 - mean_squared_error: 12.8801 - val_loss: 15.1445 - val_mean_squared_error: 15.1445\n",
      "Epoch 2444/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.0107 - mean_squared_error: 13.0107 - val_loss: 14.0804 - val_mean_squared_error: 14.0804\n",
      "Epoch 2445/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.8034 - mean_squared_error: 12.8034 - val_loss: 14.2263 - val_mean_squared_error: 14.2263\n",
      "Epoch 2446/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.8519 - mean_squared_error: 12.8519 - val_loss: 14.1894 - val_mean_squared_error: 14.1894\n",
      "Epoch 2447/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.8923 - mean_squared_error: 12.8923 - val_loss: 14.4345 - val_mean_squared_error: 14.4345\n",
      "Epoch 2448/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.3502 - mean_squared_error: 13.3502 - val_loss: 15.7057 - val_mean_squared_error: 15.7057\n",
      "Epoch 2449/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.3602 - mean_squared_error: 13.3602 - val_loss: 14.1731 - val_mean_squared_error: 14.1731\n",
      "Epoch 2450/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0071 - mean_squared_error: 13.0071 - val_loss: 15.0583 - val_mean_squared_error: 15.0583\n",
      "Epoch 2451/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.9824 - mean_squared_error: 12.9824 - val_loss: 14.1441 - val_mean_squared_error: 14.1441\n",
      "Epoch 2452/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.9686 - mean_squared_error: 12.9686 - val_loss: 14.1280 - val_mean_squared_error: 14.1280\n",
      "Epoch 2453/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.4353 - mean_squared_error: 13.4353 - val_loss: 14.2973 - val_mean_squared_error: 14.2973\n",
      "Epoch 2454/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.0814 - mean_squared_error: 13.0814 - val_loss: 14.1222 - val_mean_squared_error: 14.1222\n",
      "Epoch 2455/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.7890 - mean_squared_error: 12.7890 - val_loss: 14.1549 - val_mean_squared_error: 14.1549\n",
      "Epoch 2456/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 12.8565 - mean_squared_error: 12.8565 - val_loss: 14.3983 - val_mean_squared_error: 14.3983\n",
      "Epoch 2457/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.3519 - mean_squared_error: 13.3519 - val_loss: 15.4008 - val_mean_squared_error: 15.4008\n",
      "Epoch 2458/4000\n",
      "339/339 [==============================] - 0s 68us/sample - loss: 13.1874 - mean_squared_error: 13.1874 - val_loss: 14.2143 - val_mean_squared_error: 14.2143\n",
      "Epoch 2459/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.9054 - mean_squared_error: 12.9054 - val_loss: 14.1511 - val_mean_squared_error: 14.1511\n",
      "Epoch 2460/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.9333 - mean_squared_error: 12.9333 - val_loss: 14.1733 - val_mean_squared_error: 14.1733\n",
      "Epoch 2461/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.8973 - mean_squared_error: 12.8973 - val_loss: 14.1368 - val_mean_squared_error: 14.1368\n",
      "Epoch 2462/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.0065 - mean_squared_error: 13.0065 - val_loss: 14.0798 - val_mean_squared_error: 14.0798\n",
      "Epoch 2463/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.7699 - mean_squared_error: 12.7699 - val_loss: 14.1229 - val_mean_squared_error: 14.1229\n",
      "Epoch 2464/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 12.9042 - mean_squared_error: 12.9042 - val_loss: 14.7970 - val_mean_squared_error: 14.7970\n",
      "Epoch 2465/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.6881 - mean_squared_error: 13.6881 - val_loss: 15.5696 - val_mean_squared_error: 15.5696\n",
      "Epoch 2466/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.1077 - mean_squared_error: 14.1077 - val_loss: 15.3870 - val_mean_squared_error: 15.3870\n",
      "Epoch 2467/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.8413 - mean_squared_error: 13.8413 - val_loss: 15.1876 - val_mean_squared_error: 15.1876\n",
      "Epoch 2468/4000\n",
      "339/339 [==============================] - 0s 63us/sample - loss: 13.6742 - mean_squared_error: 13.6742 - val_loss: 15.0434 - val_mean_squared_error: 15.0434\n",
      "Epoch 2469/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.9328 - mean_squared_error: 12.9328 - val_loss: 14.1483 - val_mean_squared_error: 14.1483\n",
      "Epoch 2470/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.1254 - mean_squared_error: 13.1254 - val_loss: 14.0627 - val_mean_squared_error: 14.0627\n",
      "Epoch 2471/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.4247 - mean_squared_error: 13.4247 - val_loss: 14.4090 - val_mean_squared_error: 14.4090\n",
      "Epoch 2472/4000\n",
      "339/339 [==============================] - 0s 56us/sample - loss: 13.7852 - mean_squared_error: 13.7852 - val_loss: 14.0712 - val_mean_squared_error: 14.0712\n",
      "Epoch 2473/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.9920 - mean_squared_error: 12.9920 - val_loss: 14.0509 - val_mean_squared_error: 14.0509\n",
      "Epoch 2474/4000\n",
      "339/339 [==============================] - 0s 62us/sample - loss: 12.9074 - mean_squared_error: 12.9074 - val_loss: 15.0044 - val_mean_squared_error: 15.0044\n",
      "Epoch 2475/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 13.9143 - mean_squared_error: 13.9143 - val_loss: 15.5929 - val_mean_squared_error: 15.5929\n",
      "Epoch 2476/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 14.2066 - mean_squared_error: 14.2066 - val_loss: 15.8362 - val_mean_squared_error: 15.8362\n",
      "Epoch 2477/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.1492 - mean_squared_error: 13.1492 - val_loss: 14.1168 - val_mean_squared_error: 14.1168\n",
      "Epoch 2478/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 12.9549 - mean_squared_error: 12.9549 - val_loss: 14.0791 - val_mean_squared_error: 14.0791\n",
      "Epoch 2479/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.9082 - mean_squared_error: 12.9082 - val_loss: 14.0703 - val_mean_squared_error: 14.0703\n",
      "Epoch 2480/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.0172 - mean_squared_error: 13.0173 - val_loss: 14.1951 - val_mean_squared_error: 14.1951\n",
      "Epoch 2481/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 12.9088 - mean_squared_error: 12.9088 - val_loss: 14.2963 - val_mean_squared_error: 14.2963\n",
      "Epoch 2482/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.8272 - mean_squared_error: 12.8272 - val_loss: 14.0268 - val_mean_squared_error: 14.0268\n",
      "Epoch 2483/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.2116 - mean_squared_error: 13.2116 - val_loss: 14.0579 - val_mean_squared_error: 14.0579\n",
      "Epoch 2484/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 10.8401 - mean_squared_error: 10.84 - 0s 50us/sample - loss: 13.7672 - mean_squared_error: 13.7672 - val_loss: 14.4573 - val_mean_squared_error: 14.4573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2485/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 13.2663 - mean_squared_error: 13.2663 - val_loss: 14.1988 - val_mean_squared_error: 14.1988\n",
      "Epoch 2486/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.2113 - mean_squared_error: 13.2113 - val_loss: 15.4797 - val_mean_squared_error: 15.4797\n",
      "Epoch 2487/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5346 - mean_squared_error: 13.5346 - val_loss: 14.5605 - val_mean_squared_error: 14.5605\n",
      "Epoch 2488/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 12.7918 - mean_squared_error: 12.7918 - val_loss: 14.0394 - val_mean_squared_error: 14.0394\n",
      "Epoch 2489/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 12.8129 - mean_squared_error: 12.8129 - val_loss: 14.0042 - val_mean_squared_error: 14.0042\n",
      "Epoch 2490/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.9353 - mean_squared_error: 12.9353 - val_loss: 14.0780 - val_mean_squared_error: 14.0780\n",
      "Epoch 2491/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.8940 - mean_squared_error: 12.8940 - val_loss: 14.4021 - val_mean_squared_error: 14.4021\n",
      "Epoch 2492/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.0122 - mean_squared_error: 13.0122 - val_loss: 14.5828 - val_mean_squared_error: 14.5828\n",
      "Epoch 2493/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.9892 - mean_squared_error: 12.9892 - val_loss: 14.7939 - val_mean_squared_error: 14.7939\n",
      "Epoch 2494/4000\n",
      "339/339 [==============================] - 0s 69us/sample - loss: 13.5716 - mean_squared_error: 13.5716 - val_loss: 14.0848 - val_mean_squared_error: 14.0848\n",
      "Epoch 2495/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.7718 - mean_squared_error: 12.7718 - val_loss: 14.1544 - val_mean_squared_error: 14.1544\n",
      "Epoch 2496/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 12.8082 - mean_squared_error: 12.8082 - val_loss: 14.0770 - val_mean_squared_error: 14.0770\n",
      "Epoch 2497/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.7192 - mean_squared_error: 13.7192 - val_loss: 14.4560 - val_mean_squared_error: 14.4560\n",
      "Epoch 2498/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.0201 - mean_squared_error: 13.0201 - val_loss: 14.5672 - val_mean_squared_error: 14.5672\n",
      "Epoch 2499/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.8875 - mean_squared_error: 12.8875 - val_loss: 14.0992 - val_mean_squared_error: 14.0992\n",
      "Epoch 2500/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.7846 - mean_squared_error: 12.7846 - val_loss: 13.9303 - val_mean_squared_error: 13.9303\n",
      "Epoch 2501/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.7615 - mean_squared_error: 12.7615 - val_loss: 14.2578 - val_mean_squared_error: 14.2578\n",
      "Epoch 2502/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.7890 - mean_squared_error: 12.7890 - val_loss: 14.0568 - val_mean_squared_error: 14.0568\n",
      "Epoch 2503/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.9942 - mean_squared_error: 12.9942 - val_loss: 13.9737 - val_mean_squared_error: 13.9737\n",
      "Epoch 2504/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.1362 - mean_squared_error: 13.1362 - val_loss: 13.8928 - val_mean_squared_error: 13.8928\n",
      "Epoch 2505/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.7723 - mean_squared_error: 12.7723 - val_loss: 13.9814 - val_mean_squared_error: 13.9814\n",
      "Epoch 2506/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.7901 - mean_squared_error: 12.7901 - val_loss: 13.8866 - val_mean_squared_error: 13.8866\n",
      "Epoch 2507/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.9754 - mean_squared_error: 12.9754 - val_loss: 16.0080 - val_mean_squared_error: 16.0080\n",
      "Epoch 2508/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.8743 - mean_squared_error: 13.8743 - val_loss: 14.6039 - val_mean_squared_error: 14.6039\n",
      "Epoch 2509/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.8369 - mean_squared_error: 13.8369 - val_loss: 16.4400 - val_mean_squared_error: 16.4400\n",
      "Epoch 2510/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.3800 - mean_squared_error: 13.3800 - val_loss: 14.0304 - val_mean_squared_error: 14.0304\n",
      "Epoch 2511/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.7412 - mean_squared_error: 12.7412 - val_loss: 14.1021 - val_mean_squared_error: 14.1021\n",
      "Epoch 2512/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 12.8576 - mean_squared_error: 12.8576 - val_loss: 14.6047 - val_mean_squared_error: 14.6047\n",
      "Epoch 2513/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.8545 - mean_squared_error: 12.8545 - val_loss: 14.0443 - val_mean_squared_error: 14.0443\n",
      "Epoch 2514/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 12.8729 - mean_squared_error: 12.8729 - val_loss: 14.6265 - val_mean_squared_error: 14.6265\n",
      "Epoch 2515/4000\n",
      "339/339 [==============================] - 0s 65us/sample - loss: 12.8058 - mean_squared_error: 12.8058 - val_loss: 14.0161 - val_mean_squared_error: 14.0161\n",
      "Epoch 2516/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.8479 - mean_squared_error: 12.8479 - val_loss: 14.0526 - val_mean_squared_error: 14.0526\n",
      "Epoch 2517/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 12.7547 - mean_squared_error: 12.7547 - val_loss: 14.1935 - val_mean_squared_error: 14.1935\n",
      "Epoch 2518/4000\n",
      "339/339 [==============================] - 0s 52us/sample - loss: 12.7296 - mean_squared_error: 12.7296 - val_loss: 13.9041 - val_mean_squared_error: 13.9041\n",
      "Epoch 2519/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.7714 - mean_squared_error: 12.7714 - val_loss: 14.5794 - val_mean_squared_error: 14.5794\n",
      "Epoch 2520/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.0547 - mean_squared_error: 13.0547 - val_loss: 14.2943 - val_mean_squared_error: 14.2943\n",
      "Epoch 2521/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.2912 - mean_squared_error: 13.2912 - val_loss: 15.3393 - val_mean_squared_error: 15.3393\n",
      "Epoch 2522/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.9377 - mean_squared_error: 12.9377 - val_loss: 13.9588 - val_mean_squared_error: 13.9588\n",
      "Epoch 2523/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 13.0214 - mean_squared_error: 13.0214 - val_loss: 13.9334 - val_mean_squared_error: 13.9334\n",
      "Epoch 2524/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.9369 - mean_squared_error: 12.9369 - val_loss: 13.9260 - val_mean_squared_error: 13.9260\n",
      "Epoch 2525/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.9887 - mean_squared_error: 12.9887 - val_loss: 13.8074 - val_mean_squared_error: 13.8074\n",
      "Epoch 2526/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.0165 - mean_squared_error: 13.0165 - val_loss: 13.8861 - val_mean_squared_error: 13.8861\n",
      "Epoch 2527/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.5231 - mean_squared_error: 13.5231 - val_loss: 13.9641 - val_mean_squared_error: 13.9641\n",
      "Epoch 2528/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.8939 - mean_squared_error: 12.8939 - val_loss: 13.9508 - val_mean_squared_error: 13.9508\n",
      "Epoch 2529/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.7411 - mean_squared_error: 12.7411 - val_loss: 14.0325 - val_mean_squared_error: 14.0325\n",
      "Epoch 2530/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.6971 - mean_squared_error: 12.6971 - val_loss: 13.8086 - val_mean_squared_error: 13.8086\n",
      "Epoch 2531/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.2376 - mean_squared_error: 13.2376 - val_loss: 14.2480 - val_mean_squared_error: 14.2480\n",
      "Epoch 2532/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 35us/sample - loss: 14.9017 - mean_squared_error: 14.9017 - val_loss: 15.1709 - val_mean_squared_error: 15.1709\n",
      "Epoch 2533/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 14.1672 - mean_squared_error: 14.1672 - val_loss: 13.7962 - val_mean_squared_error: 13.7962\n",
      "Epoch 2534/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.4589 - mean_squared_error: 13.4589 - val_loss: 14.4897 - val_mean_squared_error: 14.4897\n",
      "Epoch 2535/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 13.6913 - mean_squared_error: 13.6913 - val_loss: 13.7718 - val_mean_squared_error: 13.7718\n",
      "Epoch 2536/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.7506 - mean_squared_error: 12.7506 - val_loss: 14.5783 - val_mean_squared_error: 14.5783\n",
      "Epoch 2537/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.8939 - mean_squared_error: 12.8939 - val_loss: 13.8926 - val_mean_squared_error: 13.8926\n",
      "Epoch 2538/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 12.9806 - mean_squared_error: 12.9806 - val_loss: 15.1961 - val_mean_squared_error: 15.1961\n",
      "Epoch 2539/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.9997 - mean_squared_error: 12.9997 - val_loss: 14.6430 - val_mean_squared_error: 14.6430\n",
      "Epoch 2540/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.7426 - mean_squared_error: 13.7426 - val_loss: 13.7921 - val_mean_squared_error: 13.7921\n",
      "Epoch 2541/4000\n",
      "339/339 [==============================] - ETA: 0s - loss: 15.8779 - mean_squared_error: 15.87 - 0s 36us/sample - loss: 12.7616 - mean_squared_error: 12.7616 - val_loss: 13.8422 - val_mean_squared_error: 13.8422\n",
      "Epoch 2542/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.7096 - mean_squared_error: 12.7096 - val_loss: 14.3934 - val_mean_squared_error: 14.3934\n",
      "Epoch 2543/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.8656 - mean_squared_error: 13.8656 - val_loss: 16.6170 - val_mean_squared_error: 16.6170\n",
      "Epoch 2544/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 15.0335 - mean_squared_error: 15.0335 - val_loss: 15.8328 - val_mean_squared_error: 15.8328\n",
      "Epoch 2545/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.2740 - mean_squared_error: 13.2740 - val_loss: 13.9502 - val_mean_squared_error: 13.9502\n",
      "Epoch 2546/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.7862 - mean_squared_error: 12.7862 - val_loss: 13.9941 - val_mean_squared_error: 13.9941\n",
      "Epoch 2547/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.3046 - mean_squared_error: 13.3046 - val_loss: 13.9995 - val_mean_squared_error: 13.9995\n",
      "Epoch 2548/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.0105 - mean_squared_error: 13.0105 - val_loss: 13.7666 - val_mean_squared_error: 13.7666\n",
      "Epoch 2549/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.7108 - mean_squared_error: 12.7108 - val_loss: 13.8080 - val_mean_squared_error: 13.8080\n",
      "Epoch 2550/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.6581 - mean_squared_error: 12.6581 - val_loss: 13.9769 - val_mean_squared_error: 13.9769\n",
      "Epoch 2551/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 12.6987 - mean_squared_error: 12.6987 - val_loss: 13.7586 - val_mean_squared_error: 13.7586\n",
      "Epoch 2552/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.9170 - mean_squared_error: 12.9170 - val_loss: 13.8852 - val_mean_squared_error: 13.8852\n",
      "Epoch 2553/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 14.8880 - mean_squared_error: 14.8880 - val_loss: 16.1531 - val_mean_squared_error: 16.1531\n",
      "Epoch 2554/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 14.1104 - mean_squared_error: 14.1104 - val_loss: 14.0806 - val_mean_squared_error: 14.0806\n",
      "Epoch 2555/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.0601 - mean_squared_error: 13.0601 - val_loss: 14.8766 - val_mean_squared_error: 14.8766\n",
      "Epoch 2556/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.8686 - mean_squared_error: 12.8686 - val_loss: 13.7759 - val_mean_squared_error: 13.7759\n",
      "Epoch 2557/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.7009 - mean_squared_error: 12.7009 - val_loss: 14.1465 - val_mean_squared_error: 14.1465\n",
      "Epoch 2558/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.8936 - mean_squared_error: 12.8936 - val_loss: 14.3225 - val_mean_squared_error: 14.3225\n",
      "Epoch 2559/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.8279 - mean_squared_error: 12.8279 - val_loss: 14.1161 - val_mean_squared_error: 14.1161\n",
      "Epoch 2560/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.8072 - mean_squared_error: 12.8072 - val_loss: 14.1920 - val_mean_squared_error: 14.1920\n",
      "Epoch 2561/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7975 - mean_squared_error: 12.7975 - val_loss: 13.9205 - val_mean_squared_error: 13.9205\n",
      "Epoch 2562/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.7236 - mean_squared_error: 12.7236 - val_loss: 13.8765 - val_mean_squared_error: 13.8765\n",
      "Epoch 2563/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.9291 - mean_squared_error: 13.9291 - val_loss: 14.4771 - val_mean_squared_error: 14.4771\n",
      "Epoch 2564/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.1305 - mean_squared_error: 13.1305 - val_loss: 13.9761 - val_mean_squared_error: 13.9761\n",
      "Epoch 2565/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.6592 - mean_squared_error: 12.6592 - val_loss: 13.7851 - val_mean_squared_error: 13.7851\n",
      "Epoch 2566/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.6692 - mean_squared_error: 12.6692 - val_loss: 13.9821 - val_mean_squared_error: 13.9821\n",
      "Epoch 2567/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.6858 - mean_squared_error: 12.6858 - val_loss: 13.8046 - val_mean_squared_error: 13.8046\n",
      "Epoch 2568/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.6897 - mean_squared_error: 12.6897 - val_loss: 13.7518 - val_mean_squared_error: 13.7518\n",
      "Epoch 2569/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7573 - mean_squared_error: 12.7573 - val_loss: 14.6865 - val_mean_squared_error: 14.6865\n",
      "Epoch 2570/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7804 - mean_squared_error: 12.7804 - val_loss: 13.8742 - val_mean_squared_error: 13.8742\n",
      "Epoch 2571/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.8518 - mean_squared_error: 12.8518 - val_loss: 13.7992 - val_mean_squared_error: 13.7992\n",
      "Epoch 2572/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.9075 - mean_squared_error: 12.9075 - val_loss: 13.9847 - val_mean_squared_error: 13.9847\n",
      "Epoch 2573/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.7654 - mean_squared_error: 12.7654 - val_loss: 14.5051 - val_mean_squared_error: 14.5051\n",
      "Epoch 2574/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.0401 - mean_squared_error: 13.0401 - val_loss: 14.1784 - val_mean_squared_error: 14.1784\n",
      "Epoch 2575/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.7328 - mean_squared_error: 12.7329 - val_loss: 13.9560 - val_mean_squared_error: 13.9560\n",
      "Epoch 2576/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.8783 - mean_squared_error: 12.8782 - val_loss: 14.7473 - val_mean_squared_error: 14.7473\n",
      "Epoch 2577/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.0848 - mean_squared_error: 13.0848 - val_loss: 14.4153 - val_mean_squared_error: 14.4153\n",
      "Epoch 2578/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.8848 - mean_squared_error: 12.8848 - val_loss: 14.3335 - val_mean_squared_error: 14.3335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2579/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.8516 - mean_squared_error: 12.8516 - val_loss: 14.3591 - val_mean_squared_error: 14.3591\n",
      "Epoch 2580/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.7923 - mean_squared_error: 12.7923 - val_loss: 14.0141 - val_mean_squared_error: 14.0141\n",
      "Epoch 2581/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.9083 - mean_squared_error: 12.9083 - val_loss: 14.8385 - val_mean_squared_error: 14.8385\n",
      "Epoch 2582/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.8751 - mean_squared_error: 12.8751 - val_loss: 13.8959 - val_mean_squared_error: 13.8959\n",
      "Epoch 2583/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.6911 - mean_squared_error: 12.6911 - val_loss: 13.8461 - val_mean_squared_error: 13.8461\n",
      "Epoch 2584/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.6826 - mean_squared_error: 12.6826 - val_loss: 14.2046 - val_mean_squared_error: 14.2046\n",
      "Epoch 2585/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 13.7126 - mean_squared_error: 13.7126 - val_loss: 16.5948 - val_mean_squared_error: 16.5948\n",
      "Epoch 2586/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 14.0486 - mean_squared_error: 14.0486 - val_loss: 14.4353 - val_mean_squared_error: 14.4353\n",
      "Epoch 2587/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.8218 - mean_squared_error: 12.8218 - val_loss: 14.0491 - val_mean_squared_error: 14.0491\n",
      "Epoch 2588/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.6171 - mean_squared_error: 12.6171 - val_loss: 13.8254 - val_mean_squared_error: 13.8254\n",
      "Epoch 2589/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7951 - mean_squared_error: 12.7951 - val_loss: 13.8727 - val_mean_squared_error: 13.8727\n",
      "Epoch 2590/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.7934 - mean_squared_error: 12.7934 - val_loss: 13.7957 - val_mean_squared_error: 13.7957\n",
      "Epoch 2591/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.6055 - mean_squared_error: 12.6055 - val_loss: 13.8334 - val_mean_squared_error: 13.8334\n",
      "Epoch 2592/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.6529 - mean_squared_error: 12.6529 - val_loss: 13.8202 - val_mean_squared_error: 13.8202\n",
      "Epoch 2593/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.5991 - mean_squared_error: 12.5991 - val_loss: 14.0717 - val_mean_squared_error: 14.0717\n",
      "Epoch 2594/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.6432 - mean_squared_error: 12.6432 - val_loss: 13.8516 - val_mean_squared_error: 13.8516\n",
      "Epoch 2595/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.7038 - mean_squared_error: 12.7038 - val_loss: 13.9800 - val_mean_squared_error: 13.9800\n",
      "Epoch 2596/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.6831 - mean_squared_error: 12.6831 - val_loss: 14.1834 - val_mean_squared_error: 14.1834\n",
      "Epoch 2597/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.7638 - mean_squared_error: 12.7638 - val_loss: 14.1956 - val_mean_squared_error: 14.1956\n",
      "Epoch 2598/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.7092 - mean_squared_error: 12.7092 - val_loss: 13.7836 - val_mean_squared_error: 13.7836\n",
      "Epoch 2599/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.7429 - mean_squared_error: 12.7429 - val_loss: 14.3157 - val_mean_squared_error: 14.3157\n",
      "Epoch 2600/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 12.8950 - mean_squared_error: 12.8950 - val_loss: 14.3935 - val_mean_squared_error: 14.3935\n",
      "Epoch 2601/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.9283 - mean_squared_error: 12.9283 - val_loss: 14.3105 - val_mean_squared_error: 14.3105\n",
      "Epoch 2602/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7622 - mean_squared_error: 12.7622 - val_loss: 13.8399 - val_mean_squared_error: 13.8399\n",
      "Epoch 2603/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.6404 - mean_squared_error: 12.6404 - val_loss: 13.7212 - val_mean_squared_error: 13.7212\n",
      "Epoch 2604/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.7193 - mean_squared_error: 12.7193 - val_loss: 13.6935 - val_mean_squared_error: 13.6935\n",
      "Epoch 2605/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.6522 - mean_squared_error: 12.6522 - val_loss: 13.6942 - val_mean_squared_error: 13.6942\n",
      "Epoch 2606/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.6232 - mean_squared_error: 12.6232 - val_loss: 13.7202 - val_mean_squared_error: 13.7202\n",
      "Epoch 2607/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.6234 - mean_squared_error: 12.6234 - val_loss: 14.1671 - val_mean_squared_error: 14.1671\n",
      "Epoch 2608/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.3785 - mean_squared_error: 13.3785 - val_loss: 15.3819 - val_mean_squared_error: 15.3819\n",
      "Epoch 2609/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.9259 - mean_squared_error: 12.9259 - val_loss: 13.8184 - val_mean_squared_error: 13.8184\n",
      "Epoch 2610/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.0588 - mean_squared_error: 13.0588 - val_loss: 13.6447 - val_mean_squared_error: 13.6447\n",
      "Epoch 2611/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.8253 - mean_squared_error: 12.8253 - val_loss: 15.6098 - val_mean_squared_error: 15.6098\n",
      "Epoch 2612/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 14.1314 - mean_squared_error: 14.1314 - val_loss: 15.4714 - val_mean_squared_error: 15.4714\n",
      "Epoch 2613/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 13.7176 - mean_squared_error: 13.7176 - val_loss: 14.9485 - val_mean_squared_error: 14.9485\n",
      "Epoch 2614/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.7619 - mean_squared_error: 13.7619 - val_loss: 15.6967 - val_mean_squared_error: 15.6967\n",
      "Epoch 2615/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.7871 - mean_squared_error: 13.7871 - val_loss: 14.9341 - val_mean_squared_error: 14.9341\n",
      "Epoch 2616/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.7282 - mean_squared_error: 12.7282 - val_loss: 13.9617 - val_mean_squared_error: 13.9617\n",
      "Epoch 2617/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.6398 - mean_squared_error: 12.6398 - val_loss: 13.9799 - val_mean_squared_error: 13.9799\n",
      "Epoch 2618/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 12.6303 - mean_squared_error: 12.6303 - val_loss: 13.9464 - val_mean_squared_error: 13.9464\n",
      "Epoch 2619/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.6104 - mean_squared_error: 12.6104 - val_loss: 13.8895 - val_mean_squared_error: 13.8895\n",
      "Epoch 2620/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.6013 - mean_squared_error: 12.6013 - val_loss: 14.1022 - val_mean_squared_error: 14.1022\n",
      "Epoch 2621/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.6534 - mean_squared_error: 12.6534 - val_loss: 14.1491 - val_mean_squared_error: 14.1491\n",
      "Epoch 2622/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.7062 - mean_squared_error: 12.7062 - val_loss: 14.0533 - val_mean_squared_error: 14.0533\n",
      "Epoch 2623/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.7668 - mean_squared_error: 12.7668 - val_loss: 14.1616 - val_mean_squared_error: 14.1616\n",
      "Epoch 2624/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.5799 - mean_squared_error: 12.5799 - val_loss: 13.8376 - val_mean_squared_error: 13.8376\n",
      "Epoch 2625/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.5942 - mean_squared_error: 12.5942 - val_loss: 14.2192 - val_mean_squared_error: 14.2192\n",
      "Epoch 2626/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 32us/sample - loss: 12.9240 - mean_squared_error: 12.9240 - val_loss: 14.5602 - val_mean_squared_error: 14.5602\n",
      "Epoch 2627/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.9550 - mean_squared_error: 12.9550 - val_loss: 14.2035 - val_mean_squared_error: 14.2035\n",
      "Epoch 2628/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.6884 - mean_squared_error: 12.6884 - val_loss: 14.0622 - val_mean_squared_error: 14.0622\n",
      "Epoch 2629/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.8486 - mean_squared_error: 12.8486 - val_loss: 14.7752 - val_mean_squared_error: 14.7752\n",
      "Epoch 2630/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.7193 - mean_squared_error: 12.7193 - val_loss: 13.8379 - val_mean_squared_error: 13.8379\n",
      "Epoch 2631/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.8335 - mean_squared_error: 12.8335 - val_loss: 13.9439 - val_mean_squared_error: 13.9439\n",
      "Epoch 2632/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.1327 - mean_squared_error: 13.1327 - val_loss: 13.8467 - val_mean_squared_error: 13.8467\n",
      "Epoch 2633/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.6295 - mean_squared_error: 12.6295 - val_loss: 14.0955 - val_mean_squared_error: 14.0955\n",
      "Epoch 2634/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.6111 - mean_squared_error: 12.6111 - val_loss: 13.8837 - val_mean_squared_error: 13.8837\n",
      "Epoch 2635/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.5705 - mean_squared_error: 12.5705 - val_loss: 13.8169 - val_mean_squared_error: 13.8169\n",
      "Epoch 2636/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 12.7146 - mean_squared_error: 12.7146 - val_loss: 14.6592 - val_mean_squared_error: 14.6592\n",
      "Epoch 2637/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 12.7533 - mean_squared_error: 12.7533 - val_loss: 14.1562 - val_mean_squared_error: 14.1562\n",
      "Epoch 2638/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.6617 - mean_squared_error: 13.6617 - val_loss: 13.9486 - val_mean_squared_error: 13.9486\n",
      "Epoch 2639/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 12.6542 - mean_squared_error: 12.6542 - val_loss: 14.8007 - val_mean_squared_error: 14.8007\n",
      "Epoch 2640/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.6878 - mean_squared_error: 12.6878 - val_loss: 14.1615 - val_mean_squared_error: 14.1615\n",
      "Epoch 2641/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1148 - mean_squared_error: 13.1148 - val_loss: 13.7421 - val_mean_squared_error: 13.7421\n",
      "Epoch 2642/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.9818 - mean_squared_error: 12.9818 - val_loss: 14.0005 - val_mean_squared_error: 14.0005\n",
      "Epoch 2643/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 13.4756 - mean_squared_error: 13.4756 - val_loss: 13.8073 - val_mean_squared_error: 13.8073\n",
      "Epoch 2644/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.7010 - mean_squared_error: 12.7010 - val_loss: 15.0635 - val_mean_squared_error: 15.0635\n",
      "Epoch 2645/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 13.1536 - mean_squared_error: 13.1536 - val_loss: 14.1691 - val_mean_squared_error: 14.1691\n",
      "Epoch 2646/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 13.6842 - mean_squared_error: 13.6842 - val_loss: 16.9655 - val_mean_squared_error: 16.9655\n",
      "Epoch 2647/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 14.8066 - mean_squared_error: 14.8066 - val_loss: 14.9514 - val_mean_squared_error: 14.9514\n",
      "Epoch 2648/4000\n",
      "339/339 [==============================] - 0s 51us/sample - loss: 13.5823 - mean_squared_error: 13.5823 - val_loss: 15.2984 - val_mean_squared_error: 15.2984\n",
      "Epoch 2649/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 13.7894 - mean_squared_error: 13.7894 - val_loss: 15.0277 - val_mean_squared_error: 15.0277\n",
      "Epoch 2650/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.0127 - mean_squared_error: 14.0127 - val_loss: 15.5892 - val_mean_squared_error: 15.5892\n",
      "Epoch 2651/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.1907 - mean_squared_error: 13.1907 - val_loss: 13.7510 - val_mean_squared_error: 13.7510\n",
      "Epoch 2652/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.5678 - mean_squared_error: 12.5678 - val_loss: 14.0289 - val_mean_squared_error: 14.0289\n",
      "Epoch 2653/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.6312 - mean_squared_error: 12.6312 - val_loss: 13.8532 - val_mean_squared_error: 13.8532\n",
      "Epoch 2654/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.5234 - mean_squared_error: 12.5234 - val_loss: 13.7758 - val_mean_squared_error: 13.7758\n",
      "Epoch 2655/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.5727 - mean_squared_error: 12.5727 - val_loss: 13.8238 - val_mean_squared_error: 13.8238\n",
      "Epoch 2656/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.5989 - mean_squared_error: 12.5989 - val_loss: 13.7612 - val_mean_squared_error: 13.7612\n",
      "Epoch 2657/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.5456 - mean_squared_error: 12.5456 - val_loss: 13.8979 - val_mean_squared_error: 13.8979\n",
      "Epoch 2658/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 13.4310 - mean_squared_error: 13.4310 - val_loss: 16.7332 - val_mean_squared_error: 16.7332\n",
      "Epoch 2659/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.5109 - mean_squared_error: 13.5109 - val_loss: 13.7910 - val_mean_squared_error: 13.7910\n",
      "Epoch 2660/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.5955 - mean_squared_error: 12.5955 - val_loss: 13.7006 - val_mean_squared_error: 13.7006\n",
      "Epoch 2661/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.9183 - mean_squared_error: 12.9183 - val_loss: 13.9085 - val_mean_squared_error: 13.9085\n",
      "Epoch 2662/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.9356 - mean_squared_error: 12.9356 - val_loss: 13.7167 - val_mean_squared_error: 13.7167\n",
      "Epoch 2663/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.9070 - mean_squared_error: 12.9070 - val_loss: 13.8992 - val_mean_squared_error: 13.8992\n",
      "Epoch 2664/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.2603 - mean_squared_error: 13.2603 - val_loss: 13.7167 - val_mean_squared_error: 13.7167\n",
      "Epoch 2665/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.8271 - mean_squared_error: 12.8271 - val_loss: 13.6312 - val_mean_squared_error: 13.6312\n",
      "Epoch 2666/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.8247 - mean_squared_error: 12.8247 - val_loss: 13.7081 - val_mean_squared_error: 13.7081\n",
      "Epoch 2667/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.6750 - mean_squared_error: 12.6750 - val_loss: 13.7505 - val_mean_squared_error: 13.7505\n",
      "Epoch 2668/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.4983 - mean_squared_error: 12.4983 - val_loss: 13.6202 - val_mean_squared_error: 13.6202\n",
      "Epoch 2669/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.5320 - mean_squared_error: 12.5320 - val_loss: 13.6594 - val_mean_squared_error: 13.6594\n",
      "Epoch 2670/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.5215 - mean_squared_error: 12.5215 - val_loss: 13.6979 - val_mean_squared_error: 13.6979\n",
      "Epoch 2671/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.5277 - mean_squared_error: 12.5277 - val_loss: 13.6772 - val_mean_squared_error: 13.6772\n",
      "Epoch 2672/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.5176 - mean_squared_error: 12.5176 - val_loss: 13.5704 - val_mean_squared_error: 13.5704\n",
      "Epoch 2673/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 36us/sample - loss: 12.6291 - mean_squared_error: 12.6291 - val_loss: 14.3356 - val_mean_squared_error: 14.3356\n",
      "Epoch 2674/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.6928 - mean_squared_error: 12.6928 - val_loss: 13.5935 - val_mean_squared_error: 13.5935\n",
      "Epoch 2675/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9435 - mean_squared_error: 12.9435 - val_loss: 14.1713 - val_mean_squared_error: 14.1713\n",
      "Epoch 2676/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.7647 - mean_squared_error: 12.7647 - val_loss: 14.5915 - val_mean_squared_error: 14.5915\n",
      "Epoch 2677/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.6633 - mean_squared_error: 12.6633 - val_loss: 13.6026 - val_mean_squared_error: 13.6026\n",
      "Epoch 2678/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.7060 - mean_squared_error: 12.7060 - val_loss: 13.5718 - val_mean_squared_error: 13.5718\n",
      "Epoch 2679/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.6296 - mean_squared_error: 12.6296 - val_loss: 13.5540 - val_mean_squared_error: 13.5540\n",
      "Epoch 2680/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 13.1333 - mean_squared_error: 13.1333 - val_loss: 14.1651 - val_mean_squared_error: 14.1651\n",
      "Epoch 2681/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.4268 - mean_squared_error: 13.4268 - val_loss: 13.5957 - val_mean_squared_error: 13.5957\n",
      "Epoch 2682/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.5817 - mean_squared_error: 12.5817 - val_loss: 14.4139 - val_mean_squared_error: 14.4139\n",
      "Epoch 2683/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.1974 - mean_squared_error: 13.1974 - val_loss: 14.7149 - val_mean_squared_error: 14.7149\n",
      "Epoch 2684/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.6871 - mean_squared_error: 12.6871 - val_loss: 13.6095 - val_mean_squared_error: 13.6095\n",
      "Epoch 2685/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.5310 - mean_squared_error: 12.5310 - val_loss: 14.1982 - val_mean_squared_error: 14.1982\n",
      "Epoch 2686/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.8585 - mean_squared_error: 12.8585 - val_loss: 14.2001 - val_mean_squared_error: 14.2001\n",
      "Epoch 2687/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.8106 - mean_squared_error: 12.8106 - val_loss: 14.0671 - val_mean_squared_error: 14.0671\n",
      "Epoch 2688/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.8290 - mean_squared_error: 12.8290 - val_loss: 14.3185 - val_mean_squared_error: 14.3185\n",
      "Epoch 2689/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.5617 - mean_squared_error: 12.5617 - val_loss: 13.7496 - val_mean_squared_error: 13.7496\n",
      "Epoch 2690/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.5478 - mean_squared_error: 12.5478 - val_loss: 13.9988 - val_mean_squared_error: 13.9988\n",
      "Epoch 2691/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.5089 - mean_squared_error: 12.5089 - val_loss: 13.7033 - val_mean_squared_error: 13.7033\n",
      "Epoch 2692/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.5908 - mean_squared_error: 12.5908 - val_loss: 13.8799 - val_mean_squared_error: 13.8799\n",
      "Epoch 2693/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.8117 - mean_squared_error: 12.8117 - val_loss: 14.7950 - val_mean_squared_error: 14.7950\n",
      "Epoch 2694/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.2569 - mean_squared_error: 13.2569 - val_loss: 14.6896 - val_mean_squared_error: 14.6896\n",
      "Epoch 2695/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.0646 - mean_squared_error: 13.0646 - val_loss: 14.4967 - val_mean_squared_error: 14.4967\n",
      "Epoch 2696/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.5566 - mean_squared_error: 12.5566 - val_loss: 13.8677 - val_mean_squared_error: 13.8677\n",
      "Epoch 2697/4000\n",
      "339/339 [==============================] - 0s 23us/sample - loss: 12.9474 - mean_squared_error: 12.9474 - val_loss: 13.7515 - val_mean_squared_error: 13.7515\n",
      "Epoch 2698/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.6031 - mean_squared_error: 13.6031 - val_loss: 14.8083 - val_mean_squared_error: 14.8083\n",
      "Epoch 2699/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 14.2418 - mean_squared_error: 14.2418 - val_loss: 13.7352 - val_mean_squared_error: 13.7352\n",
      "Epoch 2700/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.5771 - mean_squared_error: 12.5771 - val_loss: 14.4668 - val_mean_squared_error: 14.4668\n",
      "Epoch 2701/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.0405 - mean_squared_error: 13.0405 - val_loss: 14.2252 - val_mean_squared_error: 14.2252\n",
      "Epoch 2702/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.3480 - mean_squared_error: 13.3480 - val_loss: 15.4094 - val_mean_squared_error: 15.4094\n",
      "Epoch 2703/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.8150 - mean_squared_error: 12.8150 - val_loss: 13.6894 - val_mean_squared_error: 13.6894\n",
      "Epoch 2704/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.6378 - mean_squared_error: 12.6378 - val_loss: 13.6559 - val_mean_squared_error: 13.6559\n",
      "Epoch 2705/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.4940 - mean_squared_error: 12.4940 - val_loss: 13.8982 - val_mean_squared_error: 13.8982\n",
      "Epoch 2706/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.4852 - mean_squared_error: 12.4852 - val_loss: 13.6482 - val_mean_squared_error: 13.6482\n",
      "Epoch 2707/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.7143 - mean_squared_error: 12.7143 - val_loss: 13.7224 - val_mean_squared_error: 13.7224\n",
      "Epoch 2708/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.0683 - mean_squared_error: 13.0683 - val_loss: 13.7358 - val_mean_squared_error: 13.7358\n",
      "Epoch 2709/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.4024 - mean_squared_error: 13.4024 - val_loss: 14.0029 - val_mean_squared_error: 14.0029\n",
      "Epoch 2710/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 13.5739 - mean_squared_error: 13.5739 - val_loss: 13.6682 - val_mean_squared_error: 13.6682\n",
      "Epoch 2711/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 13.0962 - mean_squared_error: 13.0962 - val_loss: 13.5713 - val_mean_squared_error: 13.5713\n",
      "Epoch 2712/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4418 - mean_squared_error: 13.4418 - val_loss: 14.1155 - val_mean_squared_error: 14.1155\n",
      "Epoch 2713/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.2061 - mean_squared_error: 13.2061 - val_loss: 13.5007 - val_mean_squared_error: 13.5007\n",
      "Epoch 2714/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.5079 - mean_squared_error: 12.5079 - val_loss: 13.5086 - val_mean_squared_error: 13.5086\n",
      "Epoch 2715/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.7425 - mean_squared_error: 12.7425 - val_loss: 13.7120 - val_mean_squared_error: 13.7120\n",
      "Epoch 2716/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 13.5439 - mean_squared_error: 13.5439 - val_loss: 13.9281 - val_mean_squared_error: 13.9281\n",
      "Epoch 2717/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.4499 - mean_squared_error: 13.4499 - val_loss: 13.5544 - val_mean_squared_error: 13.5544\n",
      "Epoch 2718/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.5896 - mean_squared_error: 12.5896 - val_loss: 13.5274 - val_mean_squared_error: 13.5274\n",
      "Epoch 2719/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.7703 - mean_squared_error: 12.7703 - val_loss: 14.7470 - val_mean_squared_error: 14.7470\n",
      "Epoch 2720/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 36us/sample - loss: 12.9239 - mean_squared_error: 12.9239 - val_loss: 13.7101 - val_mean_squared_error: 13.7101\n",
      "Epoch 2721/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.4728 - mean_squared_error: 12.4728 - val_loss: 13.5731 - val_mean_squared_error: 13.5731\n",
      "Epoch 2722/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.6227 - mean_squared_error: 12.6227 - val_loss: 13.7233 - val_mean_squared_error: 13.7233\n",
      "Epoch 2723/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.7890 - mean_squared_error: 12.7890 - val_loss: 13.5672 - val_mean_squared_error: 13.5672\n",
      "Epoch 2724/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 12.8012 - mean_squared_error: 12.8012 - val_loss: 14.9521 - val_mean_squared_error: 14.9521\n",
      "Epoch 2725/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 14.1862 - mean_squared_error: 14.1862 - val_loss: 15.9646 - val_mean_squared_error: 15.9646\n",
      "Epoch 2726/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.2226 - mean_squared_error: 13.2226 - val_loss: 13.6584 - val_mean_squared_error: 13.6584\n",
      "Epoch 2727/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.6431 - mean_squared_error: 12.6431 - val_loss: 14.6544 - val_mean_squared_error: 14.6544\n",
      "Epoch 2728/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.7739 - mean_squared_error: 12.7739 - val_loss: 13.6249 - val_mean_squared_error: 13.6249\n",
      "Epoch 2729/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.6246 - mean_squared_error: 12.6246 - val_loss: 14.3209 - val_mean_squared_error: 14.3209\n",
      "Epoch 2730/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.6826 - mean_squared_error: 12.6826 - val_loss: 13.6781 - val_mean_squared_error: 13.6781\n",
      "Epoch 2731/4000\n",
      "339/339 [==============================] - 0s 66us/sample - loss: 12.5627 - mean_squared_error: 12.5627 - val_loss: 13.9751 - val_mean_squared_error: 13.9751\n",
      "Epoch 2732/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.9624 - mean_squared_error: 12.9624 - val_loss: 14.8216 - val_mean_squared_error: 14.8216\n",
      "Epoch 2733/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.6822 - mean_squared_error: 12.6822 - val_loss: 13.6398 - val_mean_squared_error: 13.6398\n",
      "Epoch 2734/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.4410 - mean_squared_error: 12.4410 - val_loss: 13.7591 - val_mean_squared_error: 13.7591\n",
      "Epoch 2735/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.4982 - mean_squared_error: 12.4982 - val_loss: 13.6312 - val_mean_squared_error: 13.6312\n",
      "Epoch 2736/4000\n",
      "339/339 [==============================] - 0s 186us/sample - loss: 12.8266 - mean_squared_error: 12.8266 - val_loss: 13.6560 - val_mean_squared_error: 13.6560\n",
      "Epoch 2737/4000\n",
      "339/339 [==============================] - 0s 77us/sample - loss: 13.5310 - mean_squared_error: 13.5310 - val_loss: 14.4676 - val_mean_squared_error: 14.4676\n",
      "Epoch 2738/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.0726 - mean_squared_error: 13.0726 - val_loss: 13.7694 - val_mean_squared_error: 13.7694\n",
      "Epoch 2739/4000\n",
      "339/339 [==============================] - 0s 54us/sample - loss: 12.4353 - mean_squared_error: 12.4353 - val_loss: 13.5766 - val_mean_squared_error: 13.5766\n",
      "Epoch 2740/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.5286 - mean_squared_error: 12.5286 - val_loss: 14.4939 - val_mean_squared_error: 14.4939\n",
      "Epoch 2741/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.5484 - mean_squared_error: 12.5484 - val_loss: 13.7787 - val_mean_squared_error: 13.7787\n",
      "Epoch 2742/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.6244 - mean_squared_error: 12.6244 - val_loss: 13.7614 - val_mean_squared_error: 13.7614\n",
      "Epoch 2743/4000\n",
      "339/339 [==============================] - 0s 78us/sample - loss: 12.7738 - mean_squared_error: 12.7738 - val_loss: 14.5273 - val_mean_squared_error: 14.5273\n",
      "Epoch 2744/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 13.1559 - mean_squared_error: 13.1559 - val_loss: 14.6922 - val_mean_squared_error: 14.6922\n",
      "Epoch 2745/4000\n",
      "339/339 [==============================] - 0s 26us/sample - loss: 13.1157 - mean_squared_error: 13.1157 - val_loss: 14.3350 - val_mean_squared_error: 14.3350\n",
      "Epoch 2746/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.5464 - mean_squared_error: 12.5464 - val_loss: 13.6204 - val_mean_squared_error: 13.6204\n",
      "Epoch 2747/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.4252 - mean_squared_error: 12.4252 - val_loss: 13.7160 - val_mean_squared_error: 13.7160\n",
      "Epoch 2748/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.4868 - mean_squared_error: 12.4868 - val_loss: 13.5550 - val_mean_squared_error: 13.5550\n",
      "Epoch 2749/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.4735 - mean_squared_error: 12.4735 - val_loss: 13.6311 - val_mean_squared_error: 13.6311\n",
      "Epoch 2750/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.5949 - mean_squared_error: 12.5949 - val_loss: 13.7667 - val_mean_squared_error: 13.7667\n",
      "Epoch 2751/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 13.4500 - mean_squared_error: 13.4500 - val_loss: 13.7719 - val_mean_squared_error: 13.7719\n",
      "Epoch 2752/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.7386 - mean_squared_error: 12.7386 - val_loss: 13.5817 - val_mean_squared_error: 13.5817\n",
      "Epoch 2753/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.4135 - mean_squared_error: 12.4135 - val_loss: 13.5108 - val_mean_squared_error: 13.5108\n",
      "Epoch 2754/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.5996 - mean_squared_error: 12.5996 - val_loss: 13.5515 - val_mean_squared_error: 13.5515\n",
      "Epoch 2755/4000\n",
      "339/339 [==============================] - 0s 66us/sample - loss: 12.6933 - mean_squared_error: 12.6933 - val_loss: 13.5001 - val_mean_squared_error: 13.5001\n",
      "Epoch 2756/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.8750 - mean_squared_error: 12.8750 - val_loss: 13.7261 - val_mean_squared_error: 13.7261\n",
      "Epoch 2757/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.6674 - mean_squared_error: 12.6674 - val_loss: 13.8239 - val_mean_squared_error: 13.8239\n",
      "Epoch 2758/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.4254 - mean_squared_error: 12.4254 - val_loss: 13.5434 - val_mean_squared_error: 13.5434\n",
      "Epoch 2759/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.4452 - mean_squared_error: 12.4452 - val_loss: 13.5332 - val_mean_squared_error: 13.5332\n",
      "Epoch 2760/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.4052 - mean_squared_error: 12.4052 - val_loss: 13.7316 - val_mean_squared_error: 13.7316\n",
      "Epoch 2761/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.4105 - mean_squared_error: 12.4105 - val_loss: 13.5260 - val_mean_squared_error: 13.5260\n",
      "Epoch 2762/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.4829 - mean_squared_error: 12.4829 - val_loss: 14.3540 - val_mean_squared_error: 14.3540\n",
      "Epoch 2763/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.6203 - mean_squared_error: 12.6203 - val_loss: 13.5552 - val_mean_squared_error: 13.5552\n",
      "Epoch 2764/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.4451 - mean_squared_error: 12.4451 - val_loss: 13.9440 - val_mean_squared_error: 13.9440\n",
      "Epoch 2765/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 13.2494 - mean_squared_error: 13.2494 - val_loss: 15.7386 - val_mean_squared_error: 15.7386\n",
      "Epoch 2766/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 13.7983 - mean_squared_error: 13.7983 - val_loss: 14.2210 - val_mean_squared_error: 14.2210\n",
      "Epoch 2767/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 34us/sample - loss: 12.5218 - mean_squared_error: 12.5218 - val_loss: 13.5807 - val_mean_squared_error: 13.5807\n",
      "Epoch 2768/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.4096 - mean_squared_error: 12.4096 - val_loss: 13.5879 - val_mean_squared_error: 13.5879\n",
      "Epoch 2769/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.4217 - mean_squared_error: 12.4217 - val_loss: 13.5496 - val_mean_squared_error: 13.5496\n",
      "Epoch 2770/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.3936 - mean_squared_error: 12.3936 - val_loss: 13.8300 - val_mean_squared_error: 13.8300\n",
      "Epoch 2771/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.5375 - mean_squared_error: 12.5375 - val_loss: 13.7959 - val_mean_squared_error: 13.7959\n",
      "Epoch 2772/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.4372 - mean_squared_error: 12.4372 - val_loss: 13.5768 - val_mean_squared_error: 13.5768\n",
      "Epoch 2773/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.5601 - mean_squared_error: 12.5601 - val_loss: 14.9372 - val_mean_squared_error: 14.9372\n",
      "Epoch 2774/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.7098 - mean_squared_error: 12.7098 - val_loss: 13.5115 - val_mean_squared_error: 13.5115\n",
      "Epoch 2775/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.4025 - mean_squared_error: 12.4025 - val_loss: 13.7176 - val_mean_squared_error: 13.7176\n",
      "Epoch 2776/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.7495 - mean_squared_error: 12.7495 - val_loss: 14.6181 - val_mean_squared_error: 14.6181\n",
      "Epoch 2777/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.7714 - mean_squared_error: 12.7714 - val_loss: 13.7027 - val_mean_squared_error: 13.7027\n",
      "Epoch 2778/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 12.4139 - mean_squared_error: 12.4139 - val_loss: 13.7903 - val_mean_squared_error: 13.7903\n",
      "Epoch 2779/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.5258 - mean_squared_error: 12.5258 - val_loss: 13.8932 - val_mean_squared_error: 13.8932\n",
      "Epoch 2780/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 12.7796 - mean_squared_error: 12.7796 - val_loss: 14.2875 - val_mean_squared_error: 14.2875\n",
      "Epoch 2781/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.7206 - mean_squared_error: 12.7206 - val_loss: 13.7168 - val_mean_squared_error: 13.7168\n",
      "Epoch 2782/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.4157 - mean_squared_error: 12.4157 - val_loss: 13.5302 - val_mean_squared_error: 13.5302\n",
      "Epoch 2783/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.7614 - mean_squared_error: 12.7614 - val_loss: 13.6090 - val_mean_squared_error: 13.6090\n",
      "Epoch 2784/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.4570 - mean_squared_error: 12.4570 - val_loss: 13.7877 - val_mean_squared_error: 13.7877\n",
      "Epoch 2785/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.5264 - mean_squared_error: 12.5264 - val_loss: 13.9274 - val_mean_squared_error: 13.9274\n",
      "Epoch 2786/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.4168 - mean_squared_error: 12.4168 - val_loss: 13.5290 - val_mean_squared_error: 13.5290\n",
      "Epoch 2787/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.5244 - mean_squared_error: 12.5244 - val_loss: 14.5784 - val_mean_squared_error: 14.5784\n",
      "Epoch 2788/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.5954 - mean_squared_error: 12.5954 - val_loss: 13.5226 - val_mean_squared_error: 13.5226\n",
      "Epoch 2789/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.6913 - mean_squared_error: 12.6913 - val_loss: 13.7075 - val_mean_squared_error: 13.7075\n",
      "Epoch 2790/4000\n",
      "339/339 [==============================] - 0s 55us/sample - loss: 13.2296 - mean_squared_error: 13.2296 - val_loss: 13.7037 - val_mean_squared_error: 13.7037\n",
      "Epoch 2791/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.6193 - mean_squared_error: 12.6193 - val_loss: 13.7160 - val_mean_squared_error: 13.7160\n",
      "Epoch 2792/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.3920 - mean_squared_error: 12.3920 - val_loss: 13.5231 - val_mean_squared_error: 13.5231\n",
      "Epoch 2793/4000\n",
      "339/339 [==============================] - 0s 48us/sample - loss: 12.4715 - mean_squared_error: 12.4715 - val_loss: 13.5132 - val_mean_squared_error: 13.5132\n",
      "Epoch 2794/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.4507 - mean_squared_error: 12.4507 - val_loss: 13.4980 - val_mean_squared_error: 13.4980\n",
      "Epoch 2795/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.5433 - mean_squared_error: 12.5433 - val_loss: 13.5849 - val_mean_squared_error: 13.5849\n",
      "Epoch 2796/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.6350 - mean_squared_error: 12.6350 - val_loss: 13.4185 - val_mean_squared_error: 13.4185\n",
      "Epoch 2797/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.4797 - mean_squared_error: 12.4797 - val_loss: 13.4241 - val_mean_squared_error: 13.4241\n",
      "Epoch 2798/4000\n",
      "339/339 [==============================] - 0s 47us/sample - loss: 12.3788 - mean_squared_error: 12.3788 - val_loss: 13.8417 - val_mean_squared_error: 13.8417\n",
      "Epoch 2799/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.3889 - mean_squared_error: 12.3889 - val_loss: 13.4706 - val_mean_squared_error: 13.4706\n",
      "Epoch 2800/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.3697 - mean_squared_error: 12.3697 - val_loss: 13.7227 - val_mean_squared_error: 13.7227\n",
      "Epoch 2801/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.3907 - mean_squared_error: 12.3907 - val_loss: 13.4706 - val_mean_squared_error: 13.4706\n",
      "Epoch 2802/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.0006 - mean_squared_error: 13.0006 - val_loss: 16.0664 - val_mean_squared_error: 16.0664\n",
      "Epoch 2803/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.8574 - mean_squared_error: 13.8574 - val_loss: 14.4097 - val_mean_squared_error: 14.4097\n",
      "Epoch 2804/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.7765 - mean_squared_error: 12.7765 - val_loss: 14.0191 - val_mean_squared_error: 14.0191\n",
      "Epoch 2805/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.6655 - mean_squared_error: 12.6655 - val_loss: 14.0609 - val_mean_squared_error: 14.0609\n",
      "Epoch 2806/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.4739 - mean_squared_error: 12.4739 - val_loss: 13.5071 - val_mean_squared_error: 13.5071\n",
      "Epoch 2807/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 13.4725 - mean_squared_error: 13.4725 - val_loss: 14.2125 - val_mean_squared_error: 14.2125\n",
      "Epoch 2808/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 13.6021 - mean_squared_error: 13.6021 - val_loss: 13.4607 - val_mean_squared_error: 13.4607\n",
      "Epoch 2809/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 12.4458 - mean_squared_error: 12.4458 - val_loss: 14.0235 - val_mean_squared_error: 14.0235\n",
      "Epoch 2810/4000\n",
      "339/339 [==============================] - 0s 50us/sample - loss: 12.6846 - mean_squared_error: 12.6846 - val_loss: 14.4745 - val_mean_squared_error: 14.4745\n",
      "Epoch 2811/4000\n",
      "339/339 [==============================] - 0s 44us/sample - loss: 13.7548 - mean_squared_error: 13.7548 - val_loss: 13.5124 - val_mean_squared_error: 13.5124\n",
      "Epoch 2812/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.9120 - mean_squared_error: 12.9120 - val_loss: 13.5899 - val_mean_squared_error: 13.5899\n",
      "Epoch 2813/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.6980 - mean_squared_error: 12.6980 - val_loss: 13.4024 - val_mean_squared_error: 13.4024\n",
      "Epoch 2814/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 30us/sample - loss: 12.4217 - mean_squared_error: 12.4217 - val_loss: 13.4759 - val_mean_squared_error: 13.4759\n",
      "Epoch 2815/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.3961 - mean_squared_error: 12.3961 - val_loss: 13.9865 - val_mean_squared_error: 13.9865\n",
      "Epoch 2816/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 13.6010 - mean_squared_error: 13.6010 - val_loss: 16.1882 - val_mean_squared_error: 16.1882\n",
      "Epoch 2817/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 13.5155 - mean_squared_error: 13.5155 - val_loss: 13.7508 - val_mean_squared_error: 13.7508\n",
      "Epoch 2818/4000\n",
      "339/339 [==============================] - 0s 37us/sample - loss: 12.4811 - mean_squared_error: 12.4811 - val_loss: 13.8923 - val_mean_squared_error: 13.8923\n",
      "Epoch 2819/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 13.1928 - mean_squared_error: 13.1928 - val_loss: 16.0163 - val_mean_squared_error: 16.0163\n",
      "Epoch 2820/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.4256 - mean_squared_error: 13.4256 - val_loss: 13.9792 - val_mean_squared_error: 13.9792\n",
      "Epoch 2821/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.3831 - mean_squared_error: 12.3831 - val_loss: 13.6219 - val_mean_squared_error: 13.6219\n",
      "Epoch 2822/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.3358 - mean_squared_error: 12.3358 - val_loss: 13.6151 - val_mean_squared_error: 13.6151\n",
      "Epoch 2823/4000\n",
      "339/339 [==============================] - 0s 49us/sample - loss: 12.4357 - mean_squared_error: 12.4357 - val_loss: 13.5334 - val_mean_squared_error: 13.5334\n",
      "Epoch 2824/4000\n",
      "339/339 [==============================] - 0s 42us/sample - loss: 12.4411 - mean_squared_error: 12.4411 - val_loss: 13.4802 - val_mean_squared_error: 13.4802\n",
      "Epoch 2825/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.4765 - mean_squared_error: 12.4765 - val_loss: 14.2484 - val_mean_squared_error: 14.2484\n",
      "Epoch 2826/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.6528 - mean_squared_error: 12.6528 - val_loss: 13.6773 - val_mean_squared_error: 13.6773\n",
      "Epoch 2827/4000\n",
      "339/339 [==============================] - 0s 46us/sample - loss: 12.5144 - mean_squared_error: 12.5144 - val_loss: 13.6541 - val_mean_squared_error: 13.6541\n",
      "Epoch 2828/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.5556 - mean_squared_error: 12.5556 - val_loss: 13.6377 - val_mean_squared_error: 13.6377\n",
      "Epoch 2829/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.4117 - mean_squared_error: 12.4117 - val_loss: 13.3865 - val_mean_squared_error: 13.3865\n",
      "Epoch 2830/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.4519 - mean_squared_error: 12.4519 - val_loss: 13.3830 - val_mean_squared_error: 13.3830\n",
      "Epoch 2831/4000\n",
      "339/339 [==============================] - 0s 45us/sample - loss: 12.3677 - mean_squared_error: 12.3677 - val_loss: 13.4146 - val_mean_squared_error: 13.4146\n",
      "Epoch 2832/4000\n",
      "339/339 [==============================] - 0s 38us/sample - loss: 12.3388 - mean_squared_error: 12.3388 - val_loss: 13.4769 - val_mean_squared_error: 13.4769\n",
      "Epoch 2833/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.4230 - mean_squared_error: 12.4230 - val_loss: 14.1112 - val_mean_squared_error: 14.1112\n",
      "Epoch 2834/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 14.0804 - mean_squared_error: 14.0804 - val_loss: 17.4135 - val_mean_squared_error: 17.4135\n",
      "Epoch 2835/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 13.3468 - mean_squared_error: 13.3468 - val_loss: 13.6718 - val_mean_squared_error: 13.6718\n",
      "Epoch 2836/4000\n",
      "339/339 [==============================] - 0s 40us/sample - loss: 12.6347 - mean_squared_error: 12.6347 - val_loss: 13.4670 - val_mean_squared_error: 13.4670\n",
      "Epoch 2837/4000\n",
      "339/339 [==============================] - 0s 43us/sample - loss: 12.3564 - mean_squared_error: 12.3564 - val_loss: 13.8838 - val_mean_squared_error: 13.8838\n",
      "Epoch 2838/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.3571 - mean_squared_error: 12.3571 - val_loss: 13.4368 - val_mean_squared_error: 13.4368\n",
      "Epoch 2839/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 13.5656 - mean_squared_error: 13.5656 - val_loss: 15.0505 - val_mean_squared_error: 15.0505\n",
      "Epoch 2840/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 16.1458 - mean_squared_error: 16.1458 - val_loss: 14.9328 - val_mean_squared_error: 14.9328\n",
      "Epoch 2841/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 13.2021 - mean_squared_error: 13.2021 - val_loss: 13.6290 - val_mean_squared_error: 13.6290\n",
      "Epoch 2842/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.3844 - mean_squared_error: 12.3844 - val_loss: 13.3781 - val_mean_squared_error: 13.3781\n",
      "Epoch 2843/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.6691 - mean_squared_error: 12.6691 - val_loss: 14.9789 - val_mean_squared_error: 14.9789\n",
      "Epoch 2844/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 13.0666 - mean_squared_error: 13.0666 - val_loss: 13.8358 - val_mean_squared_error: 13.8358\n",
      "Epoch 2845/4000\n",
      "339/339 [==============================] - 0s 36us/sample - loss: 12.3252 - mean_squared_error: 12.3252 - val_loss: 13.4831 - val_mean_squared_error: 13.4831\n",
      "Epoch 2846/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.4289 - mean_squared_error: 12.4289 - val_loss: 13.4400 - val_mean_squared_error: 13.4400\n",
      "Epoch 2847/4000\n",
      "339/339 [==============================] - 0s 41us/sample - loss: 12.3361 - mean_squared_error: 12.3361 - val_loss: 13.6244 - val_mean_squared_error: 13.6244\n",
      "Epoch 2848/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.3343 - mean_squared_error: 12.3343 - val_loss: 13.6607 - val_mean_squared_error: 13.6607\n",
      "Epoch 2849/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.3776 - mean_squared_error: 12.3776 - val_loss: 13.6053 - val_mean_squared_error: 13.6053\n",
      "Epoch 2850/4000\n",
      "339/339 [==============================] - 0s 57us/sample - loss: 12.4127 - mean_squared_error: 12.4127 - val_loss: 13.7463 - val_mean_squared_error: 13.7463\n",
      "Epoch 2851/4000\n",
      "339/339 [==============================] - 0s 53us/sample - loss: 12.5681 - mean_squared_error: 12.5681 - val_loss: 14.0444 - val_mean_squared_error: 14.0444\n",
      "Epoch 2852/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.5367 - mean_squared_error: 12.5367 - val_loss: 13.6601 - val_mean_squared_error: 13.6601\n",
      "Epoch 2853/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.4733 - mean_squared_error: 12.4733 - val_loss: 14.0298 - val_mean_squared_error: 14.0298\n",
      "Epoch 2854/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.3521 - mean_squared_error: 12.3521 - val_loss: 13.4701 - val_mean_squared_error: 13.4701\n",
      "Epoch 2855/4000\n",
      "339/339 [==============================] - 0s 35us/sample - loss: 12.3325 - mean_squared_error: 12.3325 - val_loss: 13.7822 - val_mean_squared_error: 13.7822\n",
      "Epoch 2856/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.3773 - mean_squared_error: 12.3773 - val_loss: 13.5682 - val_mean_squared_error: 13.5682\n",
      "Epoch 2857/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.4042 - mean_squared_error: 12.4042 - val_loss: 13.8166 - val_mean_squared_error: 13.8166\n",
      "Epoch 2858/4000\n",
      "339/339 [==============================] - 0s 25us/sample - loss: 12.4158 - mean_squared_error: 12.4158 - val_loss: 13.4142 - val_mean_squared_error: 13.4142\n",
      "Epoch 2859/4000\n",
      "339/339 [==============================] - 0s 33us/sample - loss: 12.3410 - mean_squared_error: 12.3410 - val_loss: 13.6424 - val_mean_squared_error: 13.6424\n",
      "Epoch 2860/4000\n",
      "339/339 [==============================] - 0s 34us/sample - loss: 12.3300 - mean_squared_error: 12.3300 - val_loss: 13.4919 - val_mean_squared_error: 13.4919\n",
      "Epoch 2861/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 0s 34us/sample - loss: 12.4801 - mean_squared_error: 12.4801 - val_loss: 13.6706 - val_mean_squared_error: 13.6706\n",
      "Epoch 2862/4000\n",
      "339/339 [==============================] - 0s 32us/sample - loss: 12.5378 - mean_squared_error: 12.5378 - val_loss: 13.6346 - val_mean_squared_error: 13.6346\n",
      "Epoch 2863/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.3795 - mean_squared_error: 12.3795 - val_loss: 13.6933 - val_mean_squared_error: 13.6933\n",
      "Epoch 2864/4000\n",
      "339/339 [==============================] - 0s 27us/sample - loss: 12.3388 - mean_squared_error: 12.3388 - val_loss: 13.4280 - val_mean_squared_error: 13.4280\n",
      "Epoch 2865/4000\n",
      "339/339 [==============================] - 0s 29us/sample - loss: 12.2900 - mean_squared_error: 12.2900 - val_loss: 13.3830 - val_mean_squared_error: 13.3830\n",
      "Epoch 2866/4000\n",
      "339/339 [==============================] - 0s 28us/sample - loss: 12.3102 - mean_squared_error: 12.3102 - val_loss: 13.4287 - val_mean_squared_error: 13.4287\n",
      "Epoch 2867/4000\n",
      "339/339 [==============================] - 0s 30us/sample - loss: 12.3218 - mean_squared_error: 12.3218 - val_loss: 13.4979 - val_mean_squared_error: 13.4979\n",
      "Epoch 2868/4000\n",
      "339/339 [==============================] - 0s 39us/sample - loss: 12.3616 - mean_squared_error: 12.3616 - val_loss: 13.4345 - val_mean_squared_error: 13.4345\n",
      "Epoch 2869/4000\n",
      "339/339 [==============================] - 0s 31us/sample - loss: 12.4531 - mean_squared_error: 12.4531 - val_loss: 13.4029 - val_mean_squared_error: 13.4029\n",
      "Epoch 2870/4000\n",
      "200/339 [================>.............] - ETA: 0s - loss: 14.4621 - mean_squared_error: 14.4621"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(bouston_housing_data_instances,\n",
    "                                                   boston_housing_data.target,\n",
    "                                                   test_size=0.33)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu', input_shape=(13,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer = tf.train.GradientDescentOptimizer(0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Execution\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    model.fit(train_X, train_y, epochs=4000, batch_size=200, validation_data = (test_X, test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
