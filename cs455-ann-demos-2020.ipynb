{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CS 455/595a: Artificial Neural Network Demonstrations - 2020</center></h1>\n",
    "<center>Richard S. Stansbury</center>\n",
    "\n",
    "This notebook applies the ANN techniques for the Titanic Survivors and Boston Housing Prediction models covered in [1] with the [Titanic](https://www.kaggle.com/c/titanic/) and [Boston Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) data sets.\n",
    "\n",
    "This demonstration focuses upon showcasing the Keras API to implement an ANN classifier and an ANN regressor for each.\n",
    "\n",
    "Reference:\n",
    "\n",
    "[1] Aurelen Geron. *Hands on Machine Learning with Scikit-Learn & TensorFlow* O'Reilley Media Inc, 2017.\n",
    "\n",
    "[2] Aurelen Geron. \"ageron/handson-ml: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\" Github.com, online at: https://github.com/ageron/handson-ml [last accessed 2019-03-01]\n",
    "\n",
    "[2] Aurelen Geron. *Hands on Machine Learning with Scikit-Learn, Keras, & TensorFlow* 2nd Edition, O'Reilley Media Inc, 2019.\n",
    "\n",
    "[3] Aurelen Geron. \"ageron/handson-ml: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.\" Github.com, online at: https://github.com/ageron/handson-ml2 [last accessed 2020-04-01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. [Titanic Survivor ANN Classifiers](#Titanic-Survivor-Classifier)\n",
    " \n",
    "2. [Boston Housing Cost Ensemble ANN Regressor](#Boston-Housing-Cost-Estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# TensorFlow â‰¥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "assert keras.__version__ >= \"2.0\"\n",
    "\n",
    "\n",
    "#From Ageron demo if running under Collaboratory this will remind you to turn on your GPU.\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data and apply pipelines to pre-process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 9)\n",
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data from input files into Pandas data frames\n",
    "data_path = os.path.join(\"datasets\",\"titanic\")\n",
    "train_filename = \"train.csv\"\n",
    "test_filename = \"test.csv\"\n",
    "\n",
    "def read_csv(data_path, filename):\n",
    "    joined_path = os.path.join(data_path, filename)\n",
    "    return pd.read_csv(joined_path)\n",
    "\n",
    "# Read CSV file into Pandas Dataframes\n",
    "train_df = read_csv(data_path, train_filename)\n",
    "\n",
    "# Defining Data Pre-Processing Pipelines\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, attributes):\n",
    "        self.attributes = attributes\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributes]\n",
    "\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent = pd.Series([X[c].value_counts().index[0] for c in X], \n",
    "                                       index = X.columns)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.most_frequent)\n",
    "\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Age\", \"Fare\", \"SibSp\", \"Parch\"])), # Selects Fields from dataframe\n",
    "        (\"Imputer\", SimpleImputer(strategy=\"median\")),   # Fills in NaN w/ median value for its column\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "categories_pipe = Pipeline([\n",
    "        (\"Select\", DataFrameSelector([\"Pclass\", \"Sex\"])), # Selects Fields from dataframe\n",
    "        (\"MostFreqImp\", MostFrequentImputer()), # Fill in NaN with most frequent\n",
    "        (\"OneHot\", OneHotEncoder(sparse=False, categories='auto')), # Onehot encode\n",
    "    ])\n",
    "\n",
    "preprocessing_pipe = FeatureUnion(transformer_list = [\n",
    "        (\"numeric pipeline\", numeric_pipe), \n",
    "        (\"categories pipeline\", categories_pipe)\n",
    "     ]) \n",
    "\n",
    "# Process Input Data Using Pipleines\n",
    "X_data = preprocessing_pipe.fit_transform(train_df)\n",
    "y_data = train_df[\"Survived\"].values.reshape(-1,1)\n",
    "\n",
    "# Process the output data.\n",
    "feature_names = [\"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Class0\", \"class1\",\"Sex0\", \"Sex1\"]\n",
    "\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 9)\n",
      "(179, 9)\n",
      "(235, 9)\n",
      "(477, 1)\n",
      "(179, 1)\n",
      "(235, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(50, activation='relu'),        \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x22fbadc8148>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22fc5fe4dc8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22fc606f0c8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,101\n",
      "Trainable params: 3,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image as PImage\n",
    "import pydot\n",
    "\n",
    "keras.utils.plot_model(model, \"Titanic survivor classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "lr = 0.1\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "              metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477 samples, validate on 235 samples\n",
      "Epoch 1/20\n",
      "477/477 [==============================] - 1s 2ms/sample - loss: 0.6564 - accuracy: 0.6352 - mse: 0.2307 - val_loss: 0.6016 - val_accuracy: 0.6809 - val_mse: 0.2060\n",
      "Epoch 2/20\n",
      "477/477 [==============================] - 0s 102us/sample - loss: 0.5674 - accuracy: 0.7086 - mse: 0.1905 - val_loss: 0.5442 - val_accuracy: 0.7702 - val_mse: 0.1799\n",
      "Epoch 3/20\n",
      "477/477 [==============================] - 0s 107us/sample - loss: 0.5241 - accuracy: 0.7526 - mse: 0.1717 - val_loss: 0.5135 - val_accuracy: 0.7872 - val_mse: 0.1667\n",
      "Epoch 4/20\n",
      "477/477 [==============================] - 0s 105us/sample - loss: 0.4964 - accuracy: 0.7757 - mse: 0.1602 - val_loss: 0.4929 - val_accuracy: 0.8000 - val_mse: 0.1583\n",
      "Epoch 5/20\n",
      "477/477 [==============================] - 0s 109us/sample - loss: 0.4767 - accuracy: 0.7862 - mse: 0.1524 - val_loss: 0.4788 - val_accuracy: 0.8085 - val_mse: 0.1528\n",
      "Epoch 6/20\n",
      "477/477 [==============================] - 0s 107us/sample - loss: 0.4628 - accuracy: 0.7966 - mse: 0.1474 - val_loss: 0.4702 - val_accuracy: 0.8085 - val_mse: 0.1495\n",
      "Epoch 7/20\n",
      "477/477 [==============================] - 0s 111us/sample - loss: 0.4513 - accuracy: 0.8050 - mse: 0.1432 - val_loss: 0.4627 - val_accuracy: 0.8085 - val_mse: 0.1467\n",
      "Epoch 8/20\n",
      "477/477 [==============================] - 0s 84us/sample - loss: 0.4447 - accuracy: 0.8113 - mse: 0.1411 - val_loss: 0.4613 - val_accuracy: 0.8043 - val_mse: 0.1465\n",
      "Epoch 9/20\n",
      "477/477 [==============================] - 0s 107us/sample - loss: 0.4394 - accuracy: 0.7987 - mse: 0.1391 - val_loss: 0.4572 - val_accuracy: 0.8043 - val_mse: 0.1449\n",
      "Epoch 10/20\n",
      "477/477 [==============================] - 0s 109us/sample - loss: 0.4369 - accuracy: 0.7987 - mse: 0.1386 - val_loss: 0.4561 - val_accuracy: 0.8043 - val_mse: 0.1447\n",
      "Epoch 11/20\n",
      "477/477 [==============================] - 0s 119us/sample - loss: 0.4320 - accuracy: 0.8008 - mse: 0.1368 - val_loss: 0.4577 - val_accuracy: 0.8000 - val_mse: 0.1457\n",
      "Epoch 12/20\n",
      "477/477 [==============================] - 0s 100us/sample - loss: 0.4299 - accuracy: 0.8050 - mse: 0.1362 - val_loss: 0.4551 - val_accuracy: 0.8000 - val_mse: 0.1446\n",
      "Epoch 13/20\n",
      "477/477 [==============================] - 0s 109us/sample - loss: 0.4261 - accuracy: 0.8092 - mse: 0.1351 - val_loss: 0.4534 - val_accuracy: 0.8043 - val_mse: 0.1439\n",
      "Epoch 14/20\n",
      "477/477 [==============================] - 0s 111us/sample - loss: 0.4241 - accuracy: 0.8071 - mse: 0.1341 - val_loss: 0.4529 - val_accuracy: 0.8043 - val_mse: 0.1438\n",
      "Epoch 15/20\n",
      "477/477 [==============================] - 0s 98us/sample - loss: 0.4238 - accuracy: 0.8092 - mse: 0.1344 - val_loss: 0.4521 - val_accuracy: 0.8043 - val_mse: 0.1434\n",
      "Epoch 16/20\n",
      "477/477 [==============================] - 0s 125us/sample - loss: 0.4203 - accuracy: 0.8050 - mse: 0.1332 - val_loss: 0.4525 - val_accuracy: 0.8043 - val_mse: 0.1438\n",
      "Epoch 17/20\n",
      "477/477 [==============================] - 0s 109us/sample - loss: 0.4195 - accuracy: 0.8050 - mse: 0.1329 - val_loss: 0.4515 - val_accuracy: 0.8043 - val_mse: 0.1432\n",
      "Epoch 18/20\n",
      "477/477 [==============================] - 0s 123us/sample - loss: 0.4167 - accuracy: 0.8092 - mse: 0.1317 - val_loss: 0.4515 - val_accuracy: 0.8043 - val_mse: 0.1432\n",
      "Epoch 19/20\n",
      "477/477 [==============================] - 0s 107us/sample - loss: 0.4157 - accuracy: 0.8092 - mse: 0.1316 - val_loss: 0.4509 - val_accuracy: 0.8043 - val_mse: 0.1430\n",
      "Epoch 20/20\n",
      "477/477 [==============================] - 0s 123us/sample - loss: 0.4156 - accuracy: 0.8050 - mse: 0.1316 - val_loss: 0.4497 - val_accuracy: 0.8085 - val_mse: 0.1422\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val,y_val))\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "def plot_precision_recall_curve(y, y_score):\n",
    "    \"\"\"\n",
    "    Prints a precision vs. recall curve.\n",
    "    \"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_score)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_roc(y, y_score):\n",
    "    \"\"\"\n",
    "    Prints a Receiver Operating Characteristic (ROC) Curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "    plt.show()\n",
    "    \n",
    "def evaluate_classifier(y, y_pred):\n",
    "    \"\"\"\n",
    "    Prints the confusion matrix, precision score, recall score, and f1 score\n",
    "    \"\"\"\n",
    "  \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print(\"Pecision Score = \" + str(precision_score(y, y_pred)))\n",
    "    print(\"Recall Score = \" + str(recall_score(y,y_pred)))\n",
    "    print(\"F1 Score = \" + str(f1_score(y,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[94 16]\n",
      " [15 54]]\n",
      "Pecision Score = 0.7714285714285715\n",
      "Recall Score = 0.782608695652174\n",
      "F1 Score = 0.7769784172661871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "plot_precision_recall_curve(y_test, y_pred_prob)\n",
    "plot_roc(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "y_pred = [1 if y > 0.5 else 0 for y in y_pred_prob]\n",
    "evaluate_classifier(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Cost Estimator\n",
    "\n",
    "Building off the classifier examples above, this section demonstrates an implementation of a simple ANN regressor for boston housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 13)\n",
      "(102, 13)\n",
      "(134, 13)\n",
      "(270,)\n",
      "(102,)\n",
      "(134,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data Set\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "boston_housing_data = datasets.load_boston()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "bouston_housing_data_instances = scaler.fit_transform(boston_housing_data.data)\n",
    "bouston_housing_data_instances.shape\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bouston_housing_data_instances,\n",
    "                                                   boston_housing_data.target,\n",
    "                                                   test_size=0.20)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.33)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "270/270 [==============================] - 1s 2ms/sample - loss: 551.2513 - mae: 21.7739 - val_loss: 517.9951 - val_mae: 21.0726\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 390.3072 - mae: 17.6357 - val_loss: 159.4104 - val_mae: 10.0055\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 102.2147 - mae: 7.5220 - val_loss: 83.8466 - val_mae: 6.9997\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 83.0619 - mae: 6.7098 - val_loss: 70.9035 - val_mae: 6.3450\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 70.6672 - mae: 6.1594 - val_loss: 62.1209 - val_mae: 5.7020\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 62.2358 - mae: 5.5921 - val_loss: 52.5895 - val_mae: 5.1302\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 54.5255 - mae: 5.1906 - val_loss: 46.6219 - val_mae: 5.1261\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 49.1558 - mae: 5.0871 - val_loss: 43.5546 - val_mae: 4.5210\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 45.1250 - mae: 4.8232 - val_loss: 44.3061 - val_mae: 4.5146\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 44.3011 - mae: 4.7052 - val_loss: 39.3745 - val_mae: 4.2179\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 41.8588 - mae: 4.6031 - val_loss: 35.4862 - val_mae: 4.5932\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 0s 137us/sample - loss: 40.8961 - mae: 4.6466 - val_loss: 31.7357 - val_mae: 3.9713\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 38.8959 - mae: 4.4474 - val_loss: 36.7154 - val_mae: 4.9431\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 38.8209 - mae: 4.4697 - val_loss: 34.9390 - val_mae: 4.8208\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 37.5639 - mae: 4.5004 - val_loss: 29.4571 - val_mae: 4.2024\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 36.4796 - mae: 4.3330 - val_loss: 25.8431 - val_mae: 3.6204\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 34.6721 - mae: 4.1519 - val_loss: 25.2298 - val_mae: 3.6978\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 32.4634 - mae: 4.1011 - val_loss: 25.1704 - val_mae: 3.3866\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 31.8077 - mae: 3.9801 - val_loss: 22.6781 - val_mae: 3.3348\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 30.3108 - mae: 3.9335 - val_loss: 24.9110 - val_mae: 3.3828\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 30.8803 - mae: 3.8280 - val_loss: 24.1754 - val_mae: 3.8649\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 29.2600 - mae: 3.8601 - val_loss: 20.3179 - val_mae: 3.1008\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 28.4152 - mae: 3.6988 - val_loss: 19.1098 - val_mae: 3.1458\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 27.8069 - mae: 3.7370 - val_loss: 19.6678 - val_mae: 3.3548\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 27.7964 - mae: 3.6472 - val_loss: 17.8338 - val_mae: 3.1040\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 26.8143 - mae: 3.6264 - val_loss: 18.3718 - val_mae: 3.2493\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 25.3105 - mae: 3.5736 - val_loss: 21.7279 - val_mae: 3.2574\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 0s 133us/sample - loss: 25.8313 - mae: 3.5468 - val_loss: 18.7663 - val_mae: 2.9998\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 25.0486 - mae: 3.4707 - val_loss: 15.4593 - val_mae: 2.7188\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 23.8697 - mae: 3.4693 - val_loss: 17.2594 - val_mae: 2.8763\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 23.6421 - mae: 3.3513 - val_loss: 15.3005 - val_mae: 2.9777\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 24.4716 - mae: 3.4726 - val_loss: 20.0171 - val_mae: 3.1894\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 26.7910 - mae: 3.5688 - val_loss: 14.0674 - val_mae: 2.8365\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 0s 126us/sample - loss: 22.7349 - mae: 3.3171 - val_loss: 13.6505 - val_mae: 2.5591\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 23.1234 - mae: 3.3234 - val_loss: 14.6216 - val_mae: 2.6729\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 24.0523 - mae: 3.3029 - val_loss: 12.5430 - val_mae: 2.4480\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 21.5732 - mae: 3.2616 - val_loss: 12.0811 - val_mae: 2.4015\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 24.2253 - mae: 3.3730 - val_loss: 13.1434 - val_mae: 2.5142\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 21.3733 - mae: 3.1960 - val_loss: 16.9827 - val_mae: 3.4161\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 22.4411 - mae: 3.2883 - val_loss: 23.0135 - val_mae: 4.1104\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 24.8515 - mae: 3.5665 - val_loss: 14.0849 - val_mae: 2.7035\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.4990 - mae: 3.1600 - val_loss: 11.8402 - val_mae: 2.4160\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.7343 - mae: 3.0591 - val_loss: 16.8460 - val_mae: 3.0248\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 21.6117 - mae: 3.2534 - val_loss: 10.5956 - val_mae: 2.3821\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 21.6623 - mae: 3.1737 - val_loss: 10.7698 - val_mae: 2.4735\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.7669 - mae: 3.0498 - val_loss: 10.4198 - val_mae: 2.4103\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 19.5303 - mae: 3.0578 - val_loss: 18.0175 - val_mae: 3.5899\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 20.2570 - mae: 3.1305 - val_loss: 10.7759 - val_mae: 2.5396\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 19.0962 - mae: 3.0117 - val_loss: 10.6616 - val_mae: 2.2846\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.2053 - mae: 2.9716 - val_loss: 9.9569 - val_mae: 2.2005\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 19.6816 - mae: 3.0431 - val_loss: 17.3408 - val_mae: 3.1125\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.0715 - mae: 3.0756 - val_loss: 9.9502 - val_mae: 2.3910\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.3792 - mae: 2.9723 - val_loss: 9.8138 - val_mae: 2.3820\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.3592 - mae: 3.0261 - val_loss: 10.5265 - val_mae: 2.5432\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 18.4461 - mae: 2.9564 - val_loss: 10.4615 - val_mae: 2.2599\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.3449 - mae: 3.1815 - val_loss: 11.7813 - val_mae: 2.4355\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 18.3576 - mae: 2.9043 - val_loss: 9.4938 - val_mae: 2.1740\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.6919 - mae: 2.9022 - val_loss: 22.9040 - val_mae: 4.1821\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 118us/sample - loss: 20.0382 - mae: 3.0814 - val_loss: 10.5381 - val_mae: 2.2909\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 19.0667 - mae: 2.9910 - val_loss: 9.1268 - val_mae: 2.2462\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.8680 - mae: 2.8683 - val_loss: 8.9911 - val_mae: 2.1767\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.7304 - mae: 2.9313 - val_loss: 9.7260 - val_mae: 2.4513\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2896 - mae: 2.9873 - val_loss: 9.1513 - val_mae: 2.3065\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.1183 - mae: 2.8329 - val_loss: 10.2378 - val_mae: 2.2600\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.8533 - mae: 2.8332 - val_loss: 12.3584 - val_mae: 2.9081\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.1837 - mae: 3.0640 - val_loss: 12.5959 - val_mae: 2.5852\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 19.1483 - mae: 2.9568 - val_loss: 11.2513 - val_mae: 2.3949\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.5934 - mae: 2.8568 - val_loss: 13.7370 - val_mae: 3.1137\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.6645 - mae: 2.9853 - val_loss: 8.5074 - val_mae: 2.1692\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 17.3983 - mae: 2.8058 - val_loss: 9.8013 - val_mae: 2.5102\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 0s 100us/sample - loss: 17.3335 - mae: 2.8136 - val_loss: 9.0760 - val_mae: 2.1276\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 20.7124 - mae: 3.1231 - val_loss: 8.7230 - val_mae: 2.1188\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.0340 - mae: 2.7910 - val_loss: 9.3161 - val_mae: 2.4224\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.3180 - mae: 2.7742 - val_loss: 9.0495 - val_mae: 2.3803\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 16.7714 - mae: 2.7951 - val_loss: 8.5029 - val_mae: 2.0924\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.0240 - mae: 2.7747 - val_loss: 8.5544 - val_mae: 2.2816\n",
      "Epoch 77/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2533 - mae: 2.8890 - val_loss: 17.5725 - val_mae: 3.2104\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 20.4248 - mae: 3.0734 - val_loss: 11.6949 - val_mae: 2.8628\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.2291 - mae: 2.8180 - val_loss: 8.8812 - val_mae: 2.3260\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 16.8098 - mae: 2.7906 - val_loss: 8.9851 - val_mae: 2.3762\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.3741 - mae: 2.8213 - val_loss: 8.8910 - val_mae: 2.1320\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.2206 - mae: 2.8155 - val_loss: 11.0995 - val_mae: 2.4094\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 16.7035 - mae: 2.7867 - val_loss: 9.4349 - val_mae: 2.1921\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.6741 - mae: 2.8337 - val_loss: 8.2216 - val_mae: 2.0775\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 16.8875 - mae: 2.6963 - val_loss: 8.0933 - val_mae: 2.1653\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 15.9101 - mae: 2.6642 - val_loss: 8.8722 - val_mae: 2.1362\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 15.9966 - mae: 2.6748 - val_loss: 23.7225 - val_mae: 4.2834\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 18.0020 - mae: 2.9834 - val_loss: 8.0108 - val_mae: 2.1264\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.3568 - mae: 2.7073 - val_loss: 8.3381 - val_mae: 2.1316\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 15.8496 - mae: 2.6561 - val_loss: 8.6825 - val_mae: 2.3463\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.4595 - mae: 2.8742 - val_loss: 8.1128 - val_mae: 2.0935\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.6085 - mae: 2.7166 - val_loss: 21.3299 - val_mae: 4.0532\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 18.5513 - mae: 3.0818 - val_loss: 12.4530 - val_mae: 2.5908\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.8401 - mae: 2.8576 - val_loss: 8.1813 - val_mae: 2.0518\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 17.3953 - mae: 2.8228 - val_loss: 7.9303 - val_mae: 2.1599\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 15.5966 - mae: 2.6561 - val_loss: 10.4579 - val_mae: 2.2929\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.3606 - mae: 2.6807 - val_loss: 18.5026 - val_mae: 3.7458\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.2753 - mae: 2.7813 - val_loss: 9.5435 - val_mae: 2.5420\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.7172 - mae: 2.8156 - val_loss: 8.0089 - val_mae: 2.2306\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 15.5794 - mae: 2.6514 - val_loss: 8.2721 - val_mae: 2.1915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(97, activation='relu'),             \n",
    "    keras.layers.Dense(97, activation='relu'),            \n",
    "    keras.layers.Dense(97, activation='relu'),  \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "lr = 0.00059\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=lr),\n",
    "              metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (X_val, y_val),\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of Hyperparameter Tuning using RandomSearch from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.42423481e-02 0.00000000e+00 7.00879765e-01 ... 2.23404255e-01\n",
      "  8.53799990e-01 1.04028698e-01]\n",
      " [2.42284243e-03 2.00000000e-01 2.38269795e-01 ... 6.38297872e-01\n",
      "  9.84542841e-01 1.33830022e-01]\n",
      " [3.00551153e-04 0.00000000e+00 1.73387097e-01 ... 8.08510638e-01\n",
      "  9.98083615e-01 1.87086093e-01]\n",
      " ...\n",
      " [9.58976229e-04 0.00000000e+00 3.79398827e-01 ... 7.02127660e-01\n",
      "  9.84895860e-01 1.04580574e-01]\n",
      " [2.74290580e-02 0.00000000e+00 7.00879765e-01 ... 2.23404255e-01\n",
      "  2.22678905e-01 3.97626932e-01]\n",
      " [8.50512555e-04 0.00000000e+00 4.93401760e-01 ... 3.61702128e-01\n",
      "  1.00000000e+00 2.39238411e-01]]\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 3ms/sample - loss: 1196.1835 - val_loss: 489.9852\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: inf - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard.stansbury\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py:1261: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   0.9s\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 3ms/sample - loss: 4071.7594 - val_loss: 593.7357\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 487.3055 - val_loss: 490.7452\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 394.8050 - val_loss: 83.0642\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 89.6556 - val_loss: 97.9206\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 85.1595 - val_loss: 441.2018\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 283.8864 - val_loss: 78.8014\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 87.7674 - val_loss: 94.3075\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.9689 - val_loss: 74.8846\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.0846 - val_loss: 76.4636\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 72.3035 - val_loss: 54.6272\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 232.5817 - val_loss: 140.4757\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 102.7994 - val_loss: 79.8646\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 86.9339 - val_loss: 81.4896\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 88.0677 - val_loss: 79.2212\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 88.7332 - val_loss: 86.8970\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 97.3773 - val_loss: 83.1989\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 86.8318 - val_loss: 80.3226\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 87.9985 - val_loss: 80.7258\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.6698 - val_loss: 79.3532\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 88.2716 - val_loss: 79.8297\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 102.6887\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   1.1s\n",
      "[CV] learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 4ms/sample - loss: 445.1516 - val_loss: 603.5752\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 572.1633 - val_loss: 433.8413\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 392.6016 - val_loss: 182.0408\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 268.3226 - val_loss: 93.2009\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 104.3659 - val_loss: 78.6911\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 97.9434 - val_loss: 167.1330\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 119.5082 - val_loss: 79.6405\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.7117 - val_loss: 84.6010\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 97.1188 - val_loss: 79.4042\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 93.0963 - val_loss: 84.2841\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 107.5139 - val_loss: 82.2481\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 94.8907 - val_loss: 65.9487\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.7086 - val_loss: 79.7591\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.0909 - val_loss: 80.2913\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 98.2528 - val_loss: 79.4545\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.2774 - val_loss: 79.8716\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 99.4910 - val_loss: 82.1039\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.6333 - val_loss: 79.6359\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.7536 - val_loss: 82.8442\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.5619 - val_loss: 79.9266\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 100.4783 - val_loss: 80.0640\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 96.8592 - val_loss: 79.6793\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 80.2155\n",
      "[CV]  learning_rate=0.012719852237765745, n_hidden=3, n_neurons=41, total=   1.4s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 583.7797 - val_loss: 531.9726\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 542.3634 - val_loss: 479.8772\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 476.8269 - val_loss: 390.2941\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 363.6850 - val_loss: 247.4429\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 210.4651 - val_loss: 117.4014\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 117.8568 - val_loss: 89.2351\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 98.7440 - val_loss: 81.9199\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 92.3410 - val_loss: 77.4409\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 86.5298 - val_loss: 75.2877\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 81.7997 - val_loss: 69.4355\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 77.3199 - val_loss: 66.6722\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.0878 - val_loss: 63.0074\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 70.1127 - val_loss: 60.3570\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 66.3542 - val_loss: 59.0198\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 63.4994 - val_loss: 56.3629\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 61.2649 - val_loss: 54.5337\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 58.9995 - val_loss: 53.1199\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 56.9271 - val_loss: 52.1059\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.3916 - val_loss: 51.2411\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.3790 - val_loss: 50.9837\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.8235 - val_loss: 51.2184\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.5640 - val_loss: 48.4566\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 49.5062 - val_loss: 47.9393\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 48.7413 - val_loss: 48.4681\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.6695 - val_loss: 47.0423\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 47.2045 - val_loss: 46.3419\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.1516 - val_loss: 46.2292\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 45.5682 - val_loss: 48.0000\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 44.3782 - val_loss: 45.8013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 43.4297 - val_loss: 44.5995\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.9528 - val_loss: 45.3071\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 42.2126 - val_loss: 44.5272\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 41.7152 - val_loss: 43.8896\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.0549 - val_loss: 43.6886\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.6928 - val_loss: 42.4251\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 39.7930 - val_loss: 44.8592\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 39.6122 - val_loss: 42.5034\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 38.7819 - val_loss: 42.0296\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2211 - val_loss: 41.3100\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.3489 - val_loss: 41.7248\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.3499 - val_loss: 43.6875\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 37.1641 - val_loss: 39.7794\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 36.8252 - val_loss: 38.9335\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 35.7526 - val_loss: 40.5145\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.5235 - val_loss: 38.7475\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.5412 - val_loss: 38.3194\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.2125 - val_loss: 38.3593\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.4591 - val_loss: 36.2904\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 33.2107 - val_loss: 36.1480\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.0645 - val_loss: 35.5697\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.7351 - val_loss: 35.1328\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 31.6435 - val_loss: 35.5708\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 31.1512 - val_loss: 34.9283\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.7651 - val_loss: 33.8636\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 30.9626 - val_loss: 33.9390\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 29.9562 - val_loss: 32.9494\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.7586 - val_loss: 33.0179\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.4059 - val_loss: 32.2688\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.8181 - val_loss: 32.0267\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 28.8011 - val_loss: 31.1387\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 28.4366 - val_loss: 30.9332\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.2684 - val_loss: 30.5029\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 27.2297 - val_loss: 30.0515\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.9857 - val_loss: 29.6176\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.1226 - val_loss: 29.3570\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 26.7261 - val_loss: 29.0925\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 25.8580 - val_loss: 28.6573\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.7459 - val_loss: 28.2816\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 25.2322 - val_loss: 27.8930\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.3190 - val_loss: 27.6857\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 24.6308 - val_loss: 27.3695\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 25.0803 - val_loss: 27.2393\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 24.5136 - val_loss: 26.9386\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 23.7843 - val_loss: 26.4403\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 23.5526 - val_loss: 26.2370\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 23.4551 - val_loss: 25.8713\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.2806 - val_loss: 25.6833\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.0706 - val_loss: 25.3069\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.6972 - val_loss: 25.1458\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.6965 - val_loss: 24.9145\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.2301 - val_loss: 24.7607\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 22.1495 - val_loss: 24.6766\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.7828 - val_loss: 24.5127\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 21.5901 - val_loss: 24.1974\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 21.9919 - val_loss: 24.1201\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2171 - val_loss: 23.9164\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 21.4234 - val_loss: 23.6494\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 21.1594 - val_loss: 23.6787\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 20.8313 - val_loss: 23.8310\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.1506 - val_loss: 23.0953\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 20.5405 - val_loss: 23.0980\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 20.7230 - val_loss: 22.7319\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 20.3362 - val_loss: 22.6780\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 14.32 - 0s 94us/sample - loss: 20.0572 - val_loss: 22.5184\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 20.1867 - val_loss: 22.2978\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 19.9761 - val_loss: 23.6290\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 19.9756 - val_loss: 22.4233\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 19.4255 - val_loss: 21.9657\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 19.4505 - val_loss: 21.9158\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.2382 - val_loss: 21.7045\n",
      "90/90 [==============================] - 0s 78us/sample - loss: 31.3270\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.7s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 602.7485 - val_loss: 557.2624\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 575.3454 - val_loss: 530.4937\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 545.2088 - val_loss: 493.4432\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 498.9029 - val_loss: 430.6394\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 416.7989 - val_loss: 318.2644\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 281.3849 - val_loss: 168.4011\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 149.0092 - val_loss: 95.2874\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 100.3981 - val_loss: 81.3638\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.3743 - val_loss: 76.5434\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 87.7582 - val_loss: 72.8280\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 81.9500 - val_loss: 67.9846\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 77.1646 - val_loss: 64.2875\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 73.5502 - val_loss: 61.2137\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 69.8475 - val_loss: 58.0457\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 67.4297 - val_loss: 55.4899\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 64.4646 - val_loss: 53.3532\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.6790 - val_loss: 52.0856\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 59.0744 - val_loss: 51.2324\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 57.1451 - val_loss: 48.8714\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.3552 - val_loss: 48.3929\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 54.9375 - val_loss: 45.7128\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 52.3582 - val_loss: 44.1756\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 51.5947 - val_loss: 43.5074\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.6124 - val_loss: 45.3071\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 48.6673 - val_loss: 41.7514\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.5484 - val_loss: 42.2001\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 46.5655 - val_loss: 41.0079\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 46.1942 - val_loss: 39.9473\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.9663 - val_loss: 40.4982\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 44.8533 - val_loss: 39.6646\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 43.5024 - val_loss: 38.7414\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 42.9852 - val_loss: 38.0160\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.0815 - val_loss: 38.3334\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.5584 - val_loss: 37.8924\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 40.9878 - val_loss: 39.4592\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 40.4170 - val_loss: 37.2954\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 39.6981 - val_loss: 35.5659\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 39.4808 - val_loss: 34.8061\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.8596 - val_loss: 34.4328\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2799 - val_loss: 35.1436\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.4214 - val_loss: 33.4548\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.0093 - val_loss: 34.1194\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 36.3131 - val_loss: 33.7965\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.9952 - val_loss: 34.0139\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.5563 - val_loss: 32.0245\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 34.8933 - val_loss: 31.7303\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 34.2444 - val_loss: 31.9557\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.7479 - val_loss: 30.9528\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.4016 - val_loss: 29.9012\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 33.4603 - val_loss: 29.5483\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 32.4278 - val_loss: 32.1541\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 32.4625 - val_loss: 29.0811\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 31.6642 - val_loss: 28.3505\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.6325 - val_loss: 28.3835\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 31.3313 - val_loss: 27.8748\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.6947 - val_loss: 28.5230\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.4120 - val_loss: 27.3228\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.6085 - val_loss: 26.8152\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.0630 - val_loss: 26.7440\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.8790 - val_loss: 26.3719\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.6517 - val_loss: 26.1003\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.3352 - val_loss: 26.2219\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.0684 - val_loss: 25.2522\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.8335 - val_loss: 24.8601\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 27.5862 - val_loss: 24.6445\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.9959 - val_loss: 24.1916\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.1329 - val_loss: 24.1483\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.3906 - val_loss: 24.1205\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 26.5925 - val_loss: 23.9581\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.3013 - val_loss: 23.4974\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 25.7826 - val_loss: 23.0591\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 25.5006 - val_loss: 23.1012\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.3523 - val_loss: 22.6246\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 25.3340 - val_loss: 22.6888\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 25.2873 - val_loss: 22.4420\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 24.9116 - val_loss: 22.5231\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 24.7654 - val_loss: 22.6870\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 24.4640 - val_loss: 22.0619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 24.1087 - val_loss: 21.6599\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 23.9778 - val_loss: 21.5151\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.3527 - val_loss: 21.3341\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.6168 - val_loss: 21.2123\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.4092 - val_loss: 21.5334\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 23.3348 - val_loss: 21.1635\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 23.2385 - val_loss: 21.0390\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 23.5192 - val_loss: 21.2083\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.7264 - val_loss: 20.7094\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.0864 - val_loss: 20.5214\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 22.6088 - val_loss: 20.5623\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.5704 - val_loss: 20.5847\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.7278 - val_loss: 20.2171\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.4643 - val_loss: 20.1014\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 22.2456 - val_loss: 20.0581\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.8001 - val_loss: 19.9486\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.9356 - val_loss: 20.7049\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.1638 - val_loss: 19.8749\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.9830 - val_loss: 20.5769\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.0278 - val_loss: 20.0015\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.3245 - val_loss: 21.1010\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 22.0682 - val_loss: 19.5279\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 23.9843\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.9s\n",
      "[CV] learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 594.2191 - val_loss: 521.9863\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 552.5587 - val_loss: 469.6328\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 481.0902 - val_loss: 372.9343\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 355.0832 - val_loss: 227.8407\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 205.1798 - val_loss: 123.8707\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 130.4755 - val_loss: 103.5755\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 116.2079 - val_loss: 97.7259\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 109.6279 - val_loss: 91.5179\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 104.0866 - val_loss: 86.2834\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.7701 - val_loss: 81.7999\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 92.6158 - val_loss: 78.0110\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 87.6263 - val_loss: 74.2585\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 84.6423 - val_loss: 68.8091\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.0250 - val_loss: 65.7680\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 75.8686 - val_loss: 64.8568\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 72.4448 - val_loss: 61.4633\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 69.8068 - val_loss: 59.0015\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 66.6695 - val_loss: 55.5106\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 64.6097 - val_loss: 58.2178\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 62.4907 - val_loss: 52.1103\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.9262 - val_loss: 50.6431\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 58.7433 - val_loss: 49.9030\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.1293 - val_loss: 49.0560\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.9205 - val_loss: 51.3842\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.3495 - val_loss: 46.8961\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.2129 - val_loss: 46.0986\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.8444 - val_loss: 45.6739\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.4180 - val_loss: 44.3884\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.5452 - val_loss: 44.4663\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.3983 - val_loss: 42.9069\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 49.4880 - val_loss: 41.8672\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 48.5004 - val_loss: 42.7324\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.5068 - val_loss: 42.0412\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.8687 - val_loss: 40.5045\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.4408 - val_loss: 40.0545\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.4599 - val_loss: 40.6602\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 44.7967 - val_loss: 39.5589\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.3931 - val_loss: 39.6587\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 43.4559 - val_loss: 37.5374\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.9518 - val_loss: 36.7054\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.6200 - val_loss: 35.9171\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 41.9205 - val_loss: 36.0189\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.3589 - val_loss: 35.7409\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 40.6214 - val_loss: 34.7031\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.1226 - val_loss: 34.1748\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 39.4465 - val_loss: 34.8993\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.0009 - val_loss: 32.7476\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.6736 - val_loss: 33.1886\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 38.1987 - val_loss: 32.9842\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.6065 - val_loss: 32.0609\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.9757 - val_loss: 31.4996\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.5130 - val_loss: 30.3694\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.2646 - val_loss: 30.4014\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.7933 - val_loss: 29.2214\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.2785 - val_loss: 29.0749\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.8152 - val_loss: 28.9475\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 34.5357 - val_loss: 28.7314\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 123us/sample - loss: 34.5498 - val_loss: 28.0452\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 33.7645 - val_loss: 27.8877\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 33.7796 - val_loss: 26.5854\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 33.2838 - val_loss: 26.1687\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 33.0180 - val_loss: 26.6295\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 32.6119 - val_loss: 25.3303\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 32.2002 - val_loss: 25.8042\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 31.6578 - val_loss: 24.6502\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.4290 - val_loss: 24.9805\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.7875 - val_loss: 24.7579\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.5079 - val_loss: 23.5232\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4887 - val_loss: 24.7319\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.7654 - val_loss: 26.1937\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.1495 - val_loss: 23.6390\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 29.3300 - val_loss: 22.3526\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 29.2948 - val_loss: 22.6499\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.6737 - val_loss: 22.0141\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.5511 - val_loss: 21.6818\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.7586 - val_loss: 21.4342\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 28.6753 - val_loss: 21.1175\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 28.1275 - val_loss: 20.9829\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.9250 - val_loss: 20.8198\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 27.9438 - val_loss: 20.9198\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.4647 - val_loss: 20.8637\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.3668 - val_loss: 20.5703\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 27.1873 - val_loss: 19.9309\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0727 - val_loss: 19.8688\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 26.8623 - val_loss: 19.6935\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.7492 - val_loss: 19.5442\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.3724 - val_loss: 19.4766\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.3581 - val_loss: 19.3633\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.5194 - val_loss: 19.1501\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.9850 - val_loss: 19.5126\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.5581 - val_loss: 18.9605\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.7239 - val_loss: 19.0745\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.3954 - val_loss: 19.1324\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 25.6107 - val_loss: 19.2892\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.2960 - val_loss: 18.6340\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.5362 - val_loss: 18.4546\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 25.0642 - val_loss: 18.2786\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.0723 - val_loss: 18.1228\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 24.6865 - val_loss: 18.1514\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.5527 - val_loss: 18.8076\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 16.7894\n",
      "[CV]  learning_rate=0.0004835259467821781, n_hidden=2, n_neurons=30, total=   2.7s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 610.6600 - val_loss: 404.5937\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 209.8927 - val_loss: 301.3063\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 399.0133 - val_loss: 228.9976\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 153.2370 - val_loss: 79.7621\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.3701 - val_loss: 91.2239\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.1526 - val_loss: 80.4193\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 97.9559 - val_loss: 83.2246\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 98.3185 - val_loss: 84.6922\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 81.8317 - val_loss: 826.5580\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 321.4719 - val_loss: 173.8261\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 173.2118 - val_loss: 130.4395\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 136.6235 - val_loss: 107.1841\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 116.4706 - val_loss: 93.8274\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 104.6383 - val_loss: 86.8330\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 105.2870\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.0s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 4439.8046 - val_loss: 922.3849\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 755.7691 - val_loss: 633.6982\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 402.1666 - val_loss: 105.4683\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 133.2059 - val_loss: 170.3268\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 129.8231 - val_loss: 117.1512\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 97.5021 - val_loss: 84.0153\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 112.9258 - val_loss: 83.2723\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.4448 - val_loss: 102.6894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 90.4947 - val_loss: 79.2227\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 91.3755 - val_loss: 139.3293\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 128.0515 - val_loss: 278.6838\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 177.3534 - val_loss: 79.3570\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 104.2123 - val_loss: 80.0164\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 91.1814 - val_loss: 141.2271\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 115.6222 - val_loss: 83.7780\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 90.9751 - val_loss: 82.2361\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 85.9124 - val_loss: 83.9539\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 112.2447 - val_loss: 85.5812\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 102.4606 - val_loss: 79.5650\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 100.4243\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.3s\n",
      "[CV] learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 14311.1967 - val_loss: 7649.3546\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 3353.1078 - val_loss: 1166.1938\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 1010.4317 - val_loss: 396.0609\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 1000.4827 - val_loss: 536.1684\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 494.1543 - val_loss: 329.3832\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 320.2677 - val_loss: 216.2705\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 222.9120 - val_loss: 153.2327\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 168.1145 - val_loss: 118.5135\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 137.1067 - val_loss: 100.3391\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 119.7802 - val_loss: 89.7200\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 109.6846 - val_loss: 84.3199\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 103.9451 - val_loss: 81.5928\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 101.0271 - val_loss: 80.2373\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 98.9809 - val_loss: 79.5133\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 97.8668 - val_loss: 79.2208\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 97.1606 - val_loss: 79.1877\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.9428 - val_loss: 79.2169\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.5891 - val_loss: 79.2802\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.5444 - val_loss: 79.3956\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 96.4285 - val_loss: 79.4509\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.4371 - val_loss: 79.4542\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.3503 - val_loss: 79.5917\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 96.3669 - val_loss: 79.6458\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.3260 - val_loss: 79.6538\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 96.3462 - val_loss: 79.6824\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 96.3044 - val_loss: 79.6591\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 80.1973\n",
      "[CV]  learning_rate=0.023176773626083516, n_hidden=2, n_neurons=51, total=   1.3s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 525.7688 - val_loss: 400.5583\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 379.6618 - val_loss: 291.9819\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 285.5802 - val_loss: 223.5341\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 225.3918 - val_loss: 178.6345\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 185.9342 - val_loss: 149.7741\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 160.0115 - val_loss: 130.3720\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 142.4004 - val_loss: 117.5924\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 130.4601 - val_loss: 108.5663\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 122.0868 - val_loss: 102.4651\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 116.0314 - val_loss: 97.9478\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 111.6606 - val_loss: 94.2560\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 107.7598 - val_loss: 91.3314\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 104.6483 - val_loss: 88.9372\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 102.0132 - val_loss: 86.7641\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 99.8319 - val_loss: 84.8653\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 97.5845 - val_loss: 83.0614\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 115.300 - 0s 105us/sample - loss: 95.5822 - val_loss: 81.3773\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 93.7602 - val_loss: 79.7791\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 91.9041 - val_loss: 78.2413\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.2187 - val_loss: 76.7499\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 88.5688 - val_loss: 75.3713\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 87.0426 - val_loss: 73.9917\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 85.3546 - val_loss: 72.6614\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 83.9077 - val_loss: 71.4355\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 82.4446 - val_loss: 70.1945\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 81.0451 - val_loss: 69.0841\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 79.8559 - val_loss: 67.9932\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 78.4819 - val_loss: 66.9350\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 77.2764 - val_loss: 65.9402\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 76.0970 - val_loss: 64.9693\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.0922 - val_loss: 64.0186\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 73.9144 - val_loss: 63.1308\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 72.8883 - val_loss: 62.2945\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 71.8083 - val_loss: 61.5227\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 71.0152 - val_loss: 60.7779\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.9314 - val_loss: 60.0351\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 69.0798 - val_loss: 59.2839\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 68.1913 - val_loss: 58.5629\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 67.2579 - val_loss: 57.8993\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 66.4400 - val_loss: 57.2313\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 65.6277 - val_loss: 56.6088\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 64.7941 - val_loss: 56.0195\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 64.0982 - val_loss: 55.4896\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 63.3942 - val_loss: 54.9825\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 62.8017 - val_loss: 54.4561\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 62.1182 - val_loss: 53.9283\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.3189 - val_loss: 53.4300\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 60.6612 - val_loss: 52.9468\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.0272 - val_loss: 52.4903\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.4558 - val_loss: 52.0529\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 59.0115 - val_loss: 51.6421\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.3648 - val_loss: 51.2507\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.8101 - val_loss: 50.9452\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 57.3160 - val_loss: 50.5975\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.8213 - val_loss: 50.2526\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 56.2589 - val_loss: 49.9586\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.7978 - val_loss: 49.6720\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 55.3143 - val_loss: 49.3060\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 54.8607 - val_loss: 49.0608\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.4512 - val_loss: 48.7867\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 53.9951 - val_loss: 48.5397\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.6099 - val_loss: 48.2485\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 53.2685 - val_loss: 48.0874\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 52.8069 - val_loss: 47.8304\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.3908 - val_loss: 47.5419\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 52.0560 - val_loss: 47.3082\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 51.7454 - val_loss: 47.0221\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 77us/sample - loss: 51.3453 - val_loss: 46.7839\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 50.9967 - val_loss: 46.5859\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.6877 - val_loss: 46.3882\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.3649 - val_loss: 46.2014\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 50.0292 - val_loss: 46.0120\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 49.7788 - val_loss: 45.8006\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.4814 - val_loss: 45.6087\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 49.2056 - val_loss: 45.4818\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 48.9004 - val_loss: 45.3189\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.7378 - val_loss: 45.2429\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 48.4465 - val_loss: 45.1042\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 48.1276 - val_loss: 44.9855\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.8604 - val_loss: 44.8168\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.6769 - val_loss: 44.7127\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.3541 - val_loss: 44.5505\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.1745 - val_loss: 44.4249\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.9776 - val_loss: 44.3046\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.7049 - val_loss: 44.1472\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.4856 - val_loss: 44.0279\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 46.2266 - val_loss: 43.8780\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.0415 - val_loss: 43.7705\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.8272 - val_loss: 43.6385\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 45.6594 - val_loss: 43.4608\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.4312 - val_loss: 43.3782\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.2127 - val_loss: 43.2755\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 45.0241 - val_loss: 43.1879\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.8545 - val_loss: 43.1223\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 44.6382 - val_loss: 43.0125\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.4672 - val_loss: 42.9674\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.3391 - val_loss: 42.8760\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 44.1013 - val_loss: 42.7885\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 43.9630 - val_loss: 42.7187\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 43.7721 - val_loss: 42.6302\n",
      "90/90 [==============================] - 0s 44us/sample - loss: 55.2019\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.5s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 528.2889 - val_loss: 406.7119\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 378.9616 - val_loss: 296.7624\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 282.9333 - val_loss: 227.6561\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 222.6929 - val_loss: 183.8853\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 184.4613 - val_loss: 156.4904\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 159.5979 - val_loss: 136.2819\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/sample - loss: 141.7907 - val_loss: 123.5227\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 130.1258 - val_loss: 114.6833\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 122.1616 - val_loss: 108.3150\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 116.1314 - val_loss: 103.5973\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 111.5833 - val_loss: 99.9667\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 108.1346 - val_loss: 96.9019\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 105.1211 - val_loss: 94.2317\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 102.3965 - val_loss: 92.0104\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 100.2853 - val_loss: 89.9146\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 98.0775 - val_loss: 88.1076\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.2115 - val_loss: 86.3020\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 94.3945 - val_loss: 84.6624\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.7506 - val_loss: 83.1050\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.1419 - val_loss: 81.5914\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 89.5416 - val_loss: 80.1673\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 88.1342 - val_loss: 78.7701\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 86.7117 - val_loss: 77.4378\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 85.3002 - val_loss: 76.1554\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 84.0564 - val_loss: 74.9224\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 82.7917 - val_loss: 73.7264\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 81.5867 - val_loss: 72.6115\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 80.4451 - val_loss: 71.5363\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 79.3643 - val_loss: 70.5682\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 78.3156 - val_loss: 69.5961\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.2394 - val_loss: 68.6249\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 76.2149 - val_loss: 67.6318\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.3438 - val_loss: 66.7383\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 74.4548 - val_loss: 65.9123\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 73.5164 - val_loss: 65.1234\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 72.5809 - val_loss: 64.3209\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 71.7328 - val_loss: 63.5971\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 70.9147 - val_loss: 62.7902\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 70.1393 - val_loss: 62.0768\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.3212 - val_loss: 61.3683\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 68.6171 - val_loss: 60.7248\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 67.8993 - val_loss: 60.1295\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 67.2741 - val_loss: 59.4650\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 66.5527 - val_loss: 58.8966\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 65.9508 - val_loss: 58.3094\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 65.5484 - val_loss: 57.7913\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 64.7719 - val_loss: 57.2613\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 64.2016 - val_loss: 56.8023\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 63.5951 - val_loss: 56.3028\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 63.1268 - val_loss: 55.8519\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 62.5845 - val_loss: 55.3338\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 62.0359 - val_loss: 54.8821\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.5417 - val_loss: 54.4636\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.0708 - val_loss: 54.0671\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 60.6659 - val_loss: 53.5889\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 60.1641 - val_loss: 53.2403\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 59.7913 - val_loss: 52.8735\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 59.3692 - val_loss: 52.5821\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.9851 - val_loss: 52.2866\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.5680 - val_loss: 51.9749\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.1735 - val_loss: 51.6046\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.8723 - val_loss: 51.2903\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 57.4683 - val_loss: 50.9791\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.1418 - val_loss: 50.7159\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 56.7571 - val_loss: 50.4303\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 56.4468 - val_loss: 50.2453\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 56.1014 - val_loss: 49.9362\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 126us/sample - loss: 55.7997 - val_loss: 49.6641\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.5855 - val_loss: 49.4035\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 55.1855 - val_loss: 49.1402\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.8948 - val_loss: 48.8922\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 54.5903 - val_loss: 48.6774\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 54.3156 - val_loss: 48.3966\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 54.0290 - val_loss: 48.1705\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.8496 - val_loss: 47.9613\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.5378 - val_loss: 47.6822\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 53.2436 - val_loss: 47.5082\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.0222 - val_loss: 47.3677\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 52.8473 - val_loss: 47.1698\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.6468 - val_loss: 46.9121\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 52.3541 - val_loss: 46.8344\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 52.0662 - val_loss: 46.6574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 51.8723 - val_loss: 46.4510\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.6482 - val_loss: 46.2719\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 51.5660 - val_loss: 46.0483\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 51.2983 - val_loss: 45.8767\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 51.0613 - val_loss: 45.7235\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.8892 - val_loss: 45.5241\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.6711 - val_loss: 45.3926\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 50.4710 - val_loss: 45.3194\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 50.3085 - val_loss: 45.1962\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.0475 - val_loss: 45.0367\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.9259 - val_loss: 44.8086\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.7396 - val_loss: 44.5987\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.5369 - val_loss: 44.4830\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.4010 - val_loss: 44.3806\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.2604 - val_loss: 44.2295\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 49.0509 - val_loss: 44.1212\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 48.8922 - val_loss: 43.9530\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.7526 - val_loss: 43.8595\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 52.3163\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.5s\n",
      "[CV] learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 542.3533 - val_loss: 392.0698\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 389.5951 - val_loss: 281.0448\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 290.4840 - val_loss: 212.2117\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 228.1418 - val_loss: 168.2484\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 187.3720 - val_loss: 140.3590\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 161.0592 - val_loss: 122.1371\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 143.5358 - val_loss: 110.6617\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 132.0153 - val_loss: 102.7960\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 123.9175 - val_loss: 97.2802\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 117.8847 - val_loss: 93.0346\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 113.1794 - val_loss: 89.9556\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 109.7832 - val_loss: 87.5802\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.6840 - val_loss: 85.5003\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 104.2214 - val_loss: 83.6263\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 102.0859 - val_loss: 81.9446\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 99.9252 - val_loss: 80.3800\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 98.0011 - val_loss: 78.9467\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.2942 - val_loss: 77.6053\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 94.6614 - val_loss: 76.2126\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 93.0867 - val_loss: 74.9343\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 91.5666 - val_loss: 73.7788\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.2104 - val_loss: 72.6676\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 88.8879 - val_loss: 71.5768\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 87.4832 - val_loss: 70.5135\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 86.3481 - val_loss: 69.4497\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 85.1507 - val_loss: 68.3995\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 84.1497 - val_loss: 67.5103\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 82.7769 - val_loss: 66.5556\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 81.6175 - val_loss: 65.6493\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 80.5973 - val_loss: 64.8244\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 79.5817 - val_loss: 63.9626\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 78.5978 - val_loss: 63.1391\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 77.6674 - val_loss: 62.4028\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 76.8722 - val_loss: 61.7431\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 76.0274 - val_loss: 61.0711\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 75.2003 - val_loss: 60.4802\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 74.3657 - val_loss: 59.7651\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 97us/sample - loss: 73.5829 - val_loss: 59.1296\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 72.9124 - val_loss: 58.4737\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 72.0960 - val_loss: 57.8461\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 71.4726 - val_loss: 57.3027\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 70.7988 - val_loss: 56.8274\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 70.1403 - val_loss: 56.4382\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 69.5068 - val_loss: 55.9501\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 68.9216 - val_loss: 55.3885\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 68.4201 - val_loss: 54.9852\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 67.7892 - val_loss: 54.6032\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 67.2092 - val_loss: 54.1386\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 66.6822 - val_loss: 53.6897\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 66.1639 - val_loss: 53.3602\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 65.6271 - val_loss: 53.0271\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 65.1919 - val_loss: 52.6680\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 64.8082 - val_loss: 52.2385\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 64.3632 - val_loss: 51.8138\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 63.8643 - val_loss: 51.5740\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 63.4321 - val_loss: 51.2414\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 62.9777 - val_loss: 50.9833\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 62.5809 - val_loss: 50.6511\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 62.2004 - val_loss: 50.4315\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 61.8611 - val_loss: 50.2842\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 61.4529 - val_loss: 50.0034\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 61.1156 - val_loss: 49.7573\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.8847 - val_loss: 49.5653\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.3963 - val_loss: 49.3344\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 60.0501 - val_loss: 49.0921\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 59.8195 - val_loss: 48.8030\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 59.4798 - val_loss: 48.6576\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.1901 - val_loss: 48.3912\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.8727 - val_loss: 48.1406\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 58.6104 - val_loss: 48.0350\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 58.4628 - val_loss: 47.8963\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 58.0796 - val_loss: 47.7538\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 57.7921 - val_loss: 47.6104\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 57.5480 - val_loss: 47.3280\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 57.3196 - val_loss: 47.1869\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.1024 - val_loss: 46.9941\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 56.8806 - val_loss: 46.8760\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.6187 - val_loss: 46.6163\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 56.3681 - val_loss: 46.4170\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 56.1493 - val_loss: 46.3737\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 55.9271 - val_loss: 46.1949\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 55.7228 - val_loss: 46.0747\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 55.5379 - val_loss: 46.0332\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 55.3032 - val_loss: 45.7998\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.1055 - val_loss: 45.6307\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.9551 - val_loss: 45.4462\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 54.7209 - val_loss: 45.4056\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 54.5831 - val_loss: 45.3195\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 54.3896 - val_loss: 45.1232\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 78us/sample - loss: 54.2135 - val_loss: 45.0458\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 53.9997 - val_loss: 44.9004\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.8300 - val_loss: 44.7714\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.7160 - val_loss: 44.7024\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 53.5283 - val_loss: 44.5870\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.3290 - val_loss: 44.4778\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 53.2170 - val_loss: 44.4078\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.1287 - val_loss: 44.2448\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 52.9631 - val_loss: 44.0491\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7575 - val_loss: 43.9876\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 52.5804 - val_loss: 43.8560\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 41.6843\n",
      "[CV]  learning_rate=0.005022103731860003, n_hidden=0, n_neurons=87, total=   2.4s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 4ms/sample - loss: 607.6163 - val_loss: 568.1834\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 591.0724 - val_loss: 553.9462\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 576.2385 - val_loss: 538.4478\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 558.5792 - val_loss: 517.4774\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 532.9808 - val_loss: 484.6780\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 490.0720 - val_loss: 424.7034\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 408.6617 - val_loss: 309.3816\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 267.5840 - val_loss: 158.9773\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 146.1976 - val_loss: 106.2526\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 118.0285 - val_loss: 98.2595\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 110.1847 - val_loss: 91.0195\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 102.4682 - val_loss: 85.2935\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 96.6771 - val_loss: 79.4117\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 89.4858 - val_loss: 73.6567\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 83.4402 - val_loss: 69.4642\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 78.0293 - val_loss: 64.4239\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 73.1097 - val_loss: 60.1089\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 69.1954 - val_loss: 56.6942\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 63.1917 - val_loss: 54.2578\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 59.7897 - val_loss: 50.7500\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 57.5697 - val_loss: 48.0807\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 53.2066 - val_loss: 45.9944\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 50.5294 - val_loss: 44.5004\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 47.8748 - val_loss: 43.3853\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 46.5976 - val_loss: 42.5578\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.1830 - val_loss: 41.5521\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.5321 - val_loss: 43.7113\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 41.2803 - val_loss: 40.6166\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 161us/sample - loss: 40.2021 - val_loss: 39.7264\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 39.2853 - val_loss: 39.5705\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.9969 - val_loss: 39.1921\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.4670 - val_loss: 38.8147\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 37.0423 - val_loss: 38.8581\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 35.7608 - val_loss: 37.6312\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.2284 - val_loss: 38.6807\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.7451 - val_loss: 37.1923\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 33.8927 - val_loss: 36.8175\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 32.8654 - val_loss: 41.9142\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 33.9945 - val_loss: 37.2031\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 32.4226 - val_loss: 34.9425\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.7648 - val_loss: 35.4725\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 31.1745 - val_loss: 34.2155\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 30.1693 - val_loss: 33.3834\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 29.5588 - val_loss: 33.1723\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 29.2700 - val_loss: 32.7749\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 29.7199 - val_loss: 33.6107\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 28.1348 - val_loss: 33.6416\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 28.2829 - val_loss: 30.9817\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.1386 - val_loss: 31.7888\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 26.7433 - val_loss: 30.6001\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 26.5252 - val_loss: 30.8884\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 25.8136 - val_loss: 28.9599\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.2234 - val_loss: 28.4693\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 24.9440 - val_loss: 28.5278\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.3125 - val_loss: 28.6353\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.2326 - val_loss: 27.7643\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.1803 - val_loss: 27.0702\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 23.4938 - val_loss: 27.5737\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 23.2320 - val_loss: 26.2813\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 22.8057 - val_loss: 26.3048\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 21.9169 - val_loss: 25.4870\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 22.1316 - val_loss: 25.3615\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 177us/sample - loss: 21.7923 - val_loss: 26.1917\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 21.7242 - val_loss: 24.3309\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 20.8055 - val_loss: 24.2308\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 169us/sample - loss: 20.6712 - val_loss: 23.8096\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 177us/sample - loss: 20.6829 - val_loss: 23.7743\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 20.2548 - val_loss: 23.8885\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.8805 - val_loss: 23.0403\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.6156 - val_loss: 22.8144\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.8865 - val_loss: 22.6985\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9847 - val_loss: 22.4072\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 19.7122 - val_loss: 23.8761\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 18.9643 - val_loss: 22.1882\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 19.4355 - val_loss: 21.7965\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.1141 - val_loss: 23.3148\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.3613 - val_loss: 21.4480\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 18.1819 - val_loss: 21.2559\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.5945 - val_loss: 20.9970\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 17.7345 - val_loss: 20.9839\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 17.9046 - val_loss: 20.6746\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.1598 - val_loss: 20.7913\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 17.9015 - val_loss: 20.8575\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 17.8569 - val_loss: 20.6757\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 17.1751 - val_loss: 20.3565\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 17.4267 - val_loss: 20.3389\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 17.7064 - val_loss: 20.4884\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 17.0656 - val_loss: 20.1164\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.6237 - val_loss: 19.8468\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 16.6949 - val_loss: 19.7272\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.5440 - val_loss: 19.5957\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 16.3087 - val_loss: 19.9320\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.3013 - val_loss: 19.5038\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.3678 - val_loss: 19.3590\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 16.4630 - val_loss: 19.4309\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 15.9353 - val_loss: 19.3590\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 16.0186 - val_loss: 19.2058\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 15.9591 - val_loss: 21.6124\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 16.4845 - val_loss: 19.2571\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 16.0006 - val_loss: 19.1574\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 28.0789\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.7s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 591.3251 - val_loss: 552.9586\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 571.9180 - val_loss: 530.9104\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 544.7608 - val_loss: 495.9012\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 498.5259 - val_loss: 431.3949\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 409.3816 - val_loss: 302.8565\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 253.2303 - val_loss: 147.0416\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 135.4197 - val_loss: 109.8441\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 114.2382 - val_loss: 99.8815\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 105.7058 - val_loss: 92.4394\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 99.1502 - val_loss: 87.4847\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 93.1126 - val_loss: 80.3130\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 85.8618 - val_loss: 75.2218\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 81.3600 - val_loss: 70.4064\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 75.6884 - val_loss: 65.7261\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 71.9132 - val_loss: 62.1106\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 67.5774 - val_loss: 58.9308\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 64.4241 - val_loss: 55.9864\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 61.7617 - val_loss: 53.7326\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 58.1131 - val_loss: 52.9528\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 56.3864 - val_loss: 50.2870\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 53.6545 - val_loss: 52.7831\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 52.6955 - val_loss: 47.6296\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 51.6207 - val_loss: 46.1927\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 49.2750 - val_loss: 44.8574\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 49.6569 - val_loss: 43.8103\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 46.8888 - val_loss: 45.9339\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 47.2544 - val_loss: 41.9786\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.8985 - val_loss: 40.8073\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 44.3825 - val_loss: 41.6792\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 42.8937 - val_loss: 39.4497\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 42.8302 - val_loss: 38.5274\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 41.3984 - val_loss: 40.3417\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 40.8811 - val_loss: 37.9493\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 39.3392 - val_loss: 36.7039\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 38.8186 - val_loss: 36.6216\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.9487 - val_loss: 34.5280\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 37.5527 - val_loss: 36.9032\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.1239 - val_loss: 33.7194\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.4379 - val_loss: 33.7431\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 34.8727 - val_loss: 31.9968\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.3391 - val_loss: 33.1634\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 33.6878 - val_loss: 30.4876\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.8682 - val_loss: 31.0998\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 32.0611 - val_loss: 29.1725\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.8533 - val_loss: 29.6083\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.7566 - val_loss: 28.0070\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 30.5172 - val_loss: 27.4157\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.0629 - val_loss: 27.0504\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 29.1973 - val_loss: 26.2713\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 166us/sample - loss: 29.1493 - val_loss: 26.2232\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 28.4105 - val_loss: 25.5266\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.7017 - val_loss: 26.4279\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.2233 - val_loss: 24.4730\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.8967 - val_loss: 24.1370\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 26.3131 - val_loss: 24.2202\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.4191 - val_loss: 25.9028\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.9428 - val_loss: 22.9571\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.2274 - val_loss: 24.7618\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.8880 - val_loss: 23.9360\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 24.8565 - val_loss: 23.3938\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 25.0360 - val_loss: 24.7910\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.5086 - val_loss: 22.7062\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 24.1097 - val_loss: 21.2291\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.4553 - val_loss: 21.0903\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 23.2949 - val_loss: 20.7989\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 23.5690 - val_loss: 21.6023\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.9142 - val_loss: 22.9214\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.5929 - val_loss: 20.3317\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.8756 - val_loss: 20.0293\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.7054 - val_loss: 20.6524\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 21.9820 - val_loss: 19.7043\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.2839 - val_loss: 19.5976\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 21.5768 - val_loss: 19.4302\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.9598 - val_loss: 19.2889\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.2645 - val_loss: 19.2276\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 21.4315 - val_loss: 21.6596\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.0274 - val_loss: 18.7499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 20.8723 - val_loss: 18.7402\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.2806 - val_loss: 18.5253\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.3637 - val_loss: 18.8502\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.9587 - val_loss: 18.3616\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.4930 - val_loss: 18.6234\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 20.4069 - val_loss: 19.0064\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 20.5167 - val_loss: 17.9761\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9304 - val_loss: 17.8402\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.3702 - val_loss: 18.1544\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 20.2131 - val_loss: 17.6503\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.9840 - val_loss: 18.1051\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.0228 - val_loss: 17.6722\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 19.8508 - val_loss: 17.4335\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 20.2384 - val_loss: 17.3744\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 19.8703 - val_loss: 17.3191\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.1980 - val_loss: 17.3958\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 19.2400 - val_loss: 17.1773\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 19.1576 - val_loss: 17.4490\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 19.1623 - val_loss: 18.3253\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 18.9979 - val_loss: 17.0018\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 18.8154 - val_loss: 17.3380\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 18.3341 - val_loss: 18.3425\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 18.8931 - val_loss: 17.2795\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 20.8547\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.4s\n",
      "[CV] learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64 ..\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 627.1999 - val_loss: 565.5895\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 611.5902 - val_loss: 549.4668\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 593.5261 - val_loss: 528.4976\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 568.2365 - val_loss: 496.7654\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 527.1144 - val_loss: 441.2921\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 451.2816 - val_loss: 333.5417\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 308.6633 - val_loss: 165.0809\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 155.1866 - val_loss: 96.0191\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 114.0606 - val_loss: 86.6093\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 104.8299 - val_loss: 80.8416\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 98.5604 - val_loss: 75.3000\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 91.8093 - val_loss: 69.3902\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 86.4497 - val_loss: 65.9301\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 79.4918 - val_loss: 61.0978\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 75.0707 - val_loss: 58.0077\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 70.9535 - val_loss: 53.9424\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 66.9655 - val_loss: 53.1327\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 64.8191 - val_loss: 52.2101\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 61.9223 - val_loss: 47.2198\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 59.2939 - val_loss: 48.8405\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 56.8491 - val_loss: 45.0578\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 55.1274 - val_loss: 43.6622\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 53.7450 - val_loss: 42.5151\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 51.8197 - val_loss: 44.2883\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 51.6114 - val_loss: 40.5661\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 50.3236 - val_loss: 41.3313\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 48.7961 - val_loss: 40.9448\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 48.2694 - val_loss: 39.5790\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.7368 - val_loss: 38.2465\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 46.8281 - val_loss: 38.0484\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 45.6549 - val_loss: 38.6547\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 44.8910 - val_loss: 37.4347\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 44.4274 - val_loss: 38.1359\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 43.4540 - val_loss: 37.0402\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 42.6717 - val_loss: 35.9230\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 42.7545 - val_loss: 35.9409\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 42.1421 - val_loss: 38.7916\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 41.6687 - val_loss: 34.7484\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 40.4855 - val_loss: 36.9202\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 40.2734 - val_loss: 35.2219\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 39.2116 - val_loss: 32.5263\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 39.1228 - val_loss: 31.9536\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 38.3377 - val_loss: 31.0201\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 37.8550 - val_loss: 34.4287\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 37.5283 - val_loss: 30.1705\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 36.6988 - val_loss: 30.3210\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 37.1279 - val_loss: 30.6794\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.9500 - val_loss: 29.1870\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 35.8874 - val_loss: 30.0798\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 35.0521 - val_loss: 27.8809\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 34.3794 - val_loss: 28.0022\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 34.0395 - val_loss: 27.0907\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 33.5570 - val_loss: 26.6993\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 34.2495 - val_loss: 26.1841\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 32.8034 - val_loss: 27.5623\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 33.2275 - val_loss: 25.5248\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 32.0157 - val_loss: 25.6495\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 32.0524 - val_loss: 26.9062\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 31.5567 - val_loss: 25.5028\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 31.3049 - val_loss: 23.7925\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 31.2111 - val_loss: 23.6322\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 30.6136 - val_loss: 23.2305\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 30.0632 - val_loss: 24.3587\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.2327 - val_loss: 22.9136\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 29.0140 - val_loss: 23.8880\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 28.8477 - val_loss: 22.0596\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 29.0109 - val_loss: 22.3506\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.8674 - val_loss: 21.8171\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.6274 - val_loss: 21.7252\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 27.0097 - val_loss: 21.1103\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.4954 - val_loss: 20.8300\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 27.2643 - val_loss: 20.7175\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: 27.3428 - val_loss: 20.7561\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 26.2945 - val_loss: 21.0610\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.1814 - val_loss: 19.7647\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 25.9541 - val_loss: 20.3223\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.5354 - val_loss: 20.2145\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.8444 - val_loss: 19.3253\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 25.1955 - val_loss: 19.3440\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 24.7736 - val_loss: 18.9820\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.0397 - val_loss: 18.9762\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.6332 - val_loss: 18.7016\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.0796 - val_loss: 20.8399\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.9974 - val_loss: 18.7315\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 24.7958 - val_loss: 19.2262\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 24.0893 - val_loss: 19.3084\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.7155 - val_loss: 17.9746\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.5798 - val_loss: 17.8177\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.9727 - val_loss: 17.7241\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.8279 - val_loss: 18.0103\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.9352 - val_loss: 18.0104\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.3251 - val_loss: 17.7891\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 23.1504 - val_loss: 17.2392\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 23.3088 - val_loss: 17.5511\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.7584 - val_loss: 17.2097\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 23.1475 - val_loss: 17.7259\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.5218 - val_loss: 16.9863\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.8195 - val_loss: 18.9613\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 22.6184 - val_loss: 16.9178\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 22.1845 - val_loss: 16.8099\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 14.1986\n",
      "[CV]  learning_rate=0.00031819783764683556, n_hidden=3, n_neurons=64, total=   3.4s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 416.9764 - val_loss: 215.8233\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 180.5233 - val_loss: 62.2413\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 72.6323 - val_loss: 170.6845\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 123.0773 - val_loss: 96.8774\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.7662 - val_loss: 43.8455\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 98.3084 - val_loss: 41.7299\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.4279 - val_loss: 119.2476\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 112.4265 - val_loss: 51.9273\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 99.7454 - val_loss: 203.0290\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 110.7026 - val_loss: 31.9753\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.4457 - val_loss: 44.2968\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.6352 - val_loss: 89.6619\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 52.0178 - val_loss: 30.0090\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.3301 - val_loss: 24.9550\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 33.7967 - val_loss: 29.1734\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 30.0394 - val_loss: 76.6121\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 33.0626 - val_loss: 43.6603\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 46.0603 - val_loss: 21.8060\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 47.4927 - val_loss: 38.6081\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.6426 - val_loss: 26.8088\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.3138 - val_loss: 21.8955\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.1235 - val_loss: 20.3407\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 21.8224 - val_loss: 41.3642\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/sample - loss: 30.3901 - val_loss: 88.2973\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 45.4769 - val_loss: 21.7680\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 18.3134 - val_loss: 19.4928\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0234 - val_loss: 45.1553\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.7848 - val_loss: 30.3373\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.4112 - val_loss: 23.5503\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 16.3015 - val_loss: 24.3554\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 19.9543 - val_loss: 38.4057\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.7563 - val_loss: 18.1166\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.4293 - val_loss: 26.8983\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 24.2852 - val_loss: 20.5685\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 38.4054 - val_loss: 36.5160\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 20.2934 - val_loss: 26.7602\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 30.7795 - val_loss: 18.4387\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 29.2564 - val_loss: 16.9120\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 16.9587 - val_loss: 25.7582\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 37.7561 - val_loss: 31.6676\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.1497 - val_loss: 35.2783\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 24.4491 - val_loss: 16.7764\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 22.7059 - val_loss: 17.7345\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 14.0291 - val_loss: 18.6260\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.9418 - val_loss: 27.4769\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 14.4841 - val_loss: 16.1991\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 14.9937 - val_loss: 20.3807\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 13.4932 - val_loss: 17.7372\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 13.4474 - val_loss: 19.7147\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.9447 - val_loss: 27.0007\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.6068 - val_loss: 15.5034\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.0080 - val_loss: 16.9317\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 15.9408 - val_loss: 15.4154\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.0151 - val_loss: 18.3162\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 35.0307 - val_loss: 17.3151\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 17.7709 - val_loss: 24.3279\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 16.5283 - val_loss: 15.9697\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 11.5943 - val_loss: 17.9647\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 20.4185 - val_loss: 15.0466\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 13.1998 - val_loss: 21.3925\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 13.5435 - val_loss: 20.2768\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 21.5040 - val_loss: 15.7348\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 11.5297 - val_loss: 20.5755\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 14.1738 - val_loss: 15.7221\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: 15.5893 - val_loss: 17.6743\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 16.9077 - val_loss: 15.4158\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 14.1375 - val_loss: 44.0930\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.0100 - val_loss: 16.1174\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 12.5086 - val_loss: 14.7633\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.9799 - val_loss: 15.1035\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 16.6776 - val_loss: 21.8484\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 13.3210 - val_loss: 27.4394\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 13.7652 - val_loss: 14.6895\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 10.8897 - val_loss: 15.3865\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 11.2344 - val_loss: 19.3209\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 11.5518 - val_loss: 14.6169\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 10.3264 - val_loss: 15.8505\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 24.1590 - val_loss: 23.4610\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 19.7003 - val_loss: 14.6715\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 11.0791 - val_loss: 15.5680\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 12.1551 - val_loss: 15.7712\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 13.3233 - val_loss: 14.5539\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 11.2976 - val_loss: 24.9073\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 16.7018 - val_loss: 16.7513\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 11.5310 - val_loss: 15.6141\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 10.8127 - val_loss: 19.1148\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 11.2587 - val_loss: 18.3201\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.7281 - val_loss: 17.3076\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 14.6158 - val_loss: 14.5571\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 11.4520 - val_loss: 24.8249\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 13.1044 - val_loss: 18.6836\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 11.1502 - val_loss: 18.5739\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 26.9460\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   2.6s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 346.3227 - val_loss: 231.2678\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 188.0277 - val_loss: 147.1319\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 180.2637 - val_loss: 45.0602\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 69.0386 - val_loss: 336.6258\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 127.8046 - val_loss: 133.9302\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 93.0111 - val_loss: 33.3082\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 53.6454 - val_loss: 175.5648\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 62.6118 - val_loss: 37.5231\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 60.9865 - val_loss: 30.2308\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.1821 - val_loss: 27.5342\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 69.5778 - val_loss: 250.1388\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 98.9868 - val_loss: 27.0119\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.9054 - val_loss: 67.9924\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 42.0926 - val_loss: 33.0371\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 26.9643 - val_loss: 23.5522\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 39.5553 - val_loss: 23.9716\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 35.1569 - val_loss: 119.5428\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.3338 - val_loss: 65.7121\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 53.3198 - val_loss: 23.2518\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 25.1684 - val_loss: 33.9488\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 45.0822 - val_loss: 33.3379\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.3891 - val_loss: 22.8125\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 29.0480 - val_loss: 19.1000\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 21.7855 - val_loss: 19.1820\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 24.8362 - val_loss: 34.7543\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.5203 - val_loss: 19.5251\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 20.0122 - val_loss: 18.7050\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.7267 - val_loss: 23.6556\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.5393 - val_loss: 17.3303\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 21.8375 - val_loss: 18.4328\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 24.1023 - val_loss: 31.2533\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.2052 - val_loss: 17.9908\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 18.4793 - val_loss: 27.7141\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.1164 - val_loss: 16.3662\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.3745 - val_loss: 25.1037\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 106us/sample - loss: 23.1320 - val_loss: 19.1185\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.7348 - val_loss: 44.1542\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.3734 - val_loss: 20.9734\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.9847 - val_loss: 20.9745\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.1684 - val_loss: 35.1423\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 24.5450 - val_loss: 17.2789\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 21.2419 - val_loss: 16.5852\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.0109 - val_loss: 17.5163\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 18.2043 - val_loss: 24.2648\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 30.5339\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   1.5s\n",
      "[CV] learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 432.7643 - val_loss: 93.2372\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 163.6381 - val_loss: 120.3915\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 118.8667 - val_loss: 296.6670\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 399.6561 - val_loss: 105.3164\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 58.5972 - val_loss: 41.6874\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 75.9730 - val_loss: 170.7400\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.5028 - val_loss: 49.5470\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 40.6517 - val_loss: 37.6921\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.4698 - val_loss: 30.8859\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.2656 - val_loss: 62.5567\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.9614 - val_loss: 33.3312\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.2472 - val_loss: 28.2856\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.2218 - val_loss: 43.4284\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 95.1074 - val_loss: 23.9647\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.2709 - val_loss: 93.8931\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 59.6511 - val_loss: 87.6154\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 58.1805 - val_loss: 40.9635\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 40.3304 - val_loss: 26.2555\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.0690 - val_loss: 49.1013\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 60.2191 - val_loss: 20.1399\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 38.8166 - val_loss: 21.4576\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 28.2471 - val_loss: 23.1737\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 31.9175 - val_loss: 22.8579\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 34.0806 - val_loss: 19.5297\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.7926 - val_loss: 18.5872\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.7497 - val_loss: 27.1700\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.0120 - val_loss: 24.1765\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 73.8704 - val_loss: 21.3104\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 25.5388 - val_loss: 17.9634\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 23.6307 - val_loss: 42.0183\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 26.6408 - val_loss: 17.2087\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 22.2633 - val_loss: 15.6067\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 22.9249 - val_loss: 14.9963\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 116us/sample - loss: 20.9548 - val_loss: 14.9118\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 33.0493 - val_loss: 46.5557\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 29.5350 - val_loss: 14.4745\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.5460 - val_loss: 16.2668\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.6752 - val_loss: 20.1559\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.3779 - val_loss: 14.6114\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.8150 - val_loss: 56.6781\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.8866 - val_loss: 45.5416\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 30.5656 - val_loss: 65.9133\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.2996 - val_loss: 17.4183\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.1611 - val_loss: 16.8994\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.9485 - val_loss: 13.8405\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 32.5585 - val_loss: 24.2824\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.1457 - val_loss: 13.4858\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 26.6828 - val_loss: 51.3454\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4724 - val_loss: 38.1481\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 37.8832 - val_loss: 44.4929\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.9190 - val_loss: 13.1485\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.1989 - val_loss: 16.9056\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.3614 - val_loss: 17.2227\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 24.9321 - val_loss: 48.8349\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 26.5503 - val_loss: 12.8037\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.8913 - val_loss: 12.6165\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 25.4978 - val_loss: 39.0859\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 31.7207 - val_loss: 12.3616\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 26.1311 - val_loss: 13.0945\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.0691 - val_loss: 17.0362\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.5668 - val_loss: 59.2500\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 52.7778 - val_loss: 33.2119\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 35.2971 - val_loss: 13.2070\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.7063 - val_loss: 12.2682\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 23.6043 - val_loss: 42.7843\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 47.2734 - val_loss: 14.1308\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 18.0480 - val_loss: 11.9868\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 19.7992 - val_loss: 28.9757\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.0298 - val_loss: 13.6720\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 17.3548 - val_loss: 11.2185\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.0914 - val_loss: 11.6156\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 19.5238 - val_loss: 18.6347\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.4528 - val_loss: 15.0221\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 19.1753 - val_loss: 18.7201\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 18.2143 - val_loss: 13.7574\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 15.9942 - val_loss: 11.7456\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 23.8554 - val_loss: 15.0163\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 18.7004 - val_loss: 14.5111\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 21.1205 - val_loss: 10.7480\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.3147 - val_loss: 50.0438\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 32.4828 - val_loss: 31.2692\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2085 - val_loss: 31.8198\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 32.8412 - val_loss: 14.6728\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.9644 - val_loss: 12.4047\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.5669 - val_loss: 19.0741\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 19.5422 - val_loss: 12.7891\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 17.7907 - val_loss: 10.6801\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 15.5481 - val_loss: 11.5863\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 22.0290 - val_loss: 20.2338\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 27.9043 - val_loss: 11.2140\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.5909 - val_loss: 14.0238\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 17.2718 - val_loss: 12.8778\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.0508 - val_loss: 13.7606\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.6996 - val_loss: 30.9698\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.6490 - val_loss: 11.2629\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.4942 - val_loss: 10.7327\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.3418 - val_loss: 10.8867\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 11.0095\n",
      "[CV]  learning_rate=0.004983739112162762, n_hidden=2, n_neurons=15, total=   2.8s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 93673272186005684232716367691776.0000 - val_loss: inf\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   1.0s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: inf - val_loss: nan\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 67us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   1.0s\n",
      "[CV] learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87 .....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 3ms/sample - loss: 495447616299288678629376.0000 - val_loss: inf\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: nan - val_loss: nan\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 155us/sample - loss: nan - val_loss: nan\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: nan - val_loss: nan\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 150us/sample - loss: nan - val_loss: nan\n",
      "90/90 [==============================] - 0s 78us/sample - loss: nan\n",
      "[CV]  learning_rate=0.02888184485135846, n_hidden=3, n_neurons=87, total=   0.9s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 5602.7596 - val_loss: 3775503.3134\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 673868.3168 - val_loss: 2406.5233\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 1932.4003 - val_loss: 1373.7660\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 1108.9102 - val_loss: 799.2755\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 652.3206 - val_loss: 479.0129\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 399.4668 - val_loss: 304.1972\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 262.0329 - val_loss: 205.9980\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 185.3709 - val_loss: 151.1539\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 142.9753 - val_loss: 120.1448\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 119.4573 - val_loss: 103.5699\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 106.7803 - val_loss: 93.0079\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 99.3596 - val_loss: 87.9918\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 95.6889 - val_loss: 84.4736\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 93.2194 - val_loss: 82.5243\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 91.9392 - val_loss: 81.1381\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 91.1134 - val_loss: 80.5507\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.7677 - val_loss: 79.9886\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.4915 - val_loss: 79.7786\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3808 - val_loss: 79.6011\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.3890 - val_loss: 79.5497\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.2839 - val_loss: 79.4288\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 90.4482 - val_loss: 79.4025\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.3627 - val_loss: 79.3776\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2904 - val_loss: 79.4340\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 90.3384 - val_loss: 79.4069\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3732 - val_loss: 79.4413\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2691 - val_loss: 79.4779\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 90.3472 - val_loss: 79.3666\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 90.2445 - val_loss: 79.3807\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3391 - val_loss: 79.3647\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.2506 - val_loss: 79.3759\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3596 - val_loss: 79.3348\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3475 - val_loss: 79.3591\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.2715 - val_loss: 79.4129\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 90.3046 - val_loss: 79.3983\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 90.3099 - val_loss: 79.3316\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3048 - val_loss: 79.3038\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.2900 - val_loss: 79.2923\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3171 - val_loss: 79.3656\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.3427 - val_loss: 79.2890\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 90.3061 - val_loss: 79.2742\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 90.2343 - val_loss: 79.3056\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.3106 - val_loss: 79.3763\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 90.2376 - val_loss: 79.3783\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 90.2565 - val_loss: 79.3679\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 90.3453 - val_loss: 79.4050\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 90.3289 - val_loss: 79.4331\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.3576 - val_loss: 79.3438\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 90.2701 - val_loss: 79.3631\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 90.3221 - val_loss: 79.3853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 90.2400 - val_loss: 79.3363\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 92.3742\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.7s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 424.1770 - val_loss: 1424.9258\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 565.7866 - val_loss: 129.1448\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 103.8966 - val_loss: 71.6629\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 100.0820 - val_loss: 86.8151\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 87.9412 - val_loss: 86.9664\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 95.6688 - val_loss: 100.6473\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 92.5963 - val_loss: 83.5309\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 90.7026 - val_loss: 80.0017\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 101.4225 - val_loss: 102.3710\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 92.4501 - val_loss: 89.8063\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 94.5100 - val_loss: 147.5924\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 101.3110 - val_loss: 81.1870\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 87.3318 - val_loss: 106.8812\n",
      "90/90 [==============================] - 0s 66us/sample - loss: 120.6674\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.0s\n",
      "[CV] learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 5426.0371 - val_loss: 685.2263\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 616.1946 - val_loss: 409.3563\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 385.5592 - val_loss: 256.2172\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 256.5754 - val_loss: 174.3019\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 185.8148 - val_loss: 129.4701\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 146.4004 - val_loss: 104.8119\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 123.8078 - val_loss: 91.9050\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 111.5546 - val_loss: 85.0155\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 104.6207 - val_loss: 81.8314\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 100.9618 - val_loss: 80.1412\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 98.9269 - val_loss: 79.3331\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 97.5006 - val_loss: 79.2057\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 97.1562 - val_loss: 79.1885\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.7631 - val_loss: 79.2579\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 96.5994 - val_loss: 79.3584\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.4312 - val_loss: 79.4655\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 96.4226 - val_loss: 79.5520\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 96.4775 - val_loss: 79.4939\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 96.3487 - val_loss: 79.6180\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 96.3289 - val_loss: 79.6783\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 96.3985 - val_loss: 79.6849\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 96.3671 - val_loss: 79.6680\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.4522 - val_loss: 79.6755\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 80.2120\n",
      "[CV]  learning_rate=0.024044126525986375, n_hidden=2, n_neurons=11, total=   1.0s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 571.8534 - val_loss: 504.6908\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 498.9862 - val_loss: 423.3043\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 406.4291 - val_loss: 320.7082\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 299.1494 - val_loss: 221.9892\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 207.2815 - val_loss: 149.0317\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 149.9752 - val_loss: 119.0017\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 126.9423 - val_loss: 107.2033\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 116.8159 - val_loss: 99.8152\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 110.4116 - val_loss: 94.8927\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 105.2483 - val_loss: 90.3992\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 108us/sample - loss: 100.2128 - val_loss: 86.2177\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 96.4084 - val_loss: 82.3851\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 92.0097 - val_loss: 79.2612\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 88.0137 - val_loss: 75.6200\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 84.2707 - val_loss: 72.6480\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 80.8575 - val_loss: 69.7217\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 77.7278 - val_loss: 66.7589\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 74.4459 - val_loss: 64.3750\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 71.4892 - val_loss: 61.5267\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 68.3823 - val_loss: 59.2807\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 66.0013 - val_loss: 57.8586\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 63.5239 - val_loss: 55.8948\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.3490 - val_loss: 54.3114\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 59.3878 - val_loss: 52.5792\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 57.9291 - val_loss: 51.2504\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 55.7315 - val_loss: 50.2070\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.1725 - val_loss: 49.1033\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7075 - val_loss: 48.3759\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 51.2353 - val_loss: 47.2250\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 50.1425 - val_loss: 46.6675\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 48.9409 - val_loss: 46.1281\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 47.7725 - val_loss: 45.1955\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.9812 - val_loss: 44.6650\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 46.1312 - val_loss: 43.9973\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.1124 - val_loss: 43.6132\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.5162 - val_loss: 43.3470\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.5881 - val_loss: 43.0087\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 42.9814 - val_loss: 42.5331\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 42.4301 - val_loss: 42.3536\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 41.7523 - val_loss: 42.2510\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 41.1923 - val_loss: 42.0600\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.6675 - val_loss: 41.5021\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 40.2395 - val_loss: 41.4486\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.8219 - val_loss: 41.1009\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 39.4637 - val_loss: 41.2497\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 39.3074 - val_loss: 40.7422\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 38.5731 - val_loss: 40.8495\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 38.2235 - val_loss: 40.6047\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 37.7310 - val_loss: 40.1726\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 37.3532 - val_loss: 39.7625\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 37.0876 - val_loss: 39.4629\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.7661 - val_loss: 39.5260\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.4999 - val_loss: 39.0507\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.1026 - val_loss: 38.7721\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.7528 - val_loss: 38.8402\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 35.4612 - val_loss: 38.5696\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 35.2652 - val_loss: 38.3185\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.9893 - val_loss: 38.3203\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 34.5138 - val_loss: 37.7459\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 34.4360 - val_loss: 37.7583\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 34.0039 - val_loss: 37.3704\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 33.6429 - val_loss: 37.2506\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.5787 - val_loss: 37.0614\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 33.0899 - val_loss: 36.8020\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 32.8420 - val_loss: 36.5641\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.7364 - val_loss: 36.4460\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 32.3633 - val_loss: 36.0470\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 32.2913 - val_loss: 35.6931\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 32.1434 - val_loss: 35.5310\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 31.8269 - val_loss: 35.1528\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 31.5457 - val_loss: 34.9611\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 31.3333 - val_loss: 34.9193\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.9726 - val_loss: 35.0449\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.7498 - val_loss: 34.4833\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 30.6521 - val_loss: 34.4956\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 30.2870 - val_loss: 34.3766\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.0610 - val_loss: 34.1944\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.8935 - val_loss: 33.4899\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 29.6473 - val_loss: 33.3201\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 29.5667 - val_loss: 33.1011\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 29.3451 - val_loss: 33.0068\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 29.2026 - val_loss: 32.7636\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.9182 - val_loss: 32.5248\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.6340 - val_loss: 32.4012\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 28.5077 - val_loss: 32.4413\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 28.2467 - val_loss: 31.9734\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 28.1951 - val_loss: 32.0927\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 27.9979 - val_loss: 31.9263\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 27.8391 - val_loss: 31.6041\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 27.5074 - val_loss: 31.3838\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.3570 - val_loss: 31.2926\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 27.1844 - val_loss: 30.9698\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 27.0431 - val_loss: 30.9106\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 26.8593 - val_loss: 30.5606\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 26.7542 - val_loss: 30.3774\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.4343 - val_loss: 30.3164\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 26.2308 - val_loss: 30.0802\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 26.2162 - val_loss: 29.9559\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 25.8995 - val_loss: 29.8861\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.9957 - val_loss: 29.5787\n",
      "90/90 [==============================] - 0s 55us/sample - loss: 40.8671\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.6s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 601.0300 - val_loss: 543.9716\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 551.1588 - val_loss: 490.7246\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 489.2354 - val_loss: 417.9571\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 403.8156 - val_loss: 321.2414\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 127us/sample - loss: 299.4022 - val_loss: 219.5985\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 203.0182 - val_loss: 147.2800\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 143.9796 - val_loss: 113.2914\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 118.2880 - val_loss: 100.3576\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 107.9825 - val_loss: 94.4724\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 102.7802 - val_loss: 90.4203\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 98.6381 - val_loss: 87.0540\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 95.1821 - val_loss: 83.8089\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 91.9516 - val_loss: 80.7091\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 88.9259 - val_loss: 77.9654\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 161us/sample - loss: 86.1148 - val_loss: 75.3156\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 83.3093 - val_loss: 72.9090\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 80.8398 - val_loss: 70.2720\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 78.3403 - val_loss: 68.4429\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 76.0941 - val_loss: 66.2572\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 73.9730 - val_loss: 64.1917\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 72.4458 - val_loss: 62.3248\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 70.0284 - val_loss: 60.6015\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 68.3812 - val_loss: 59.1537\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 66.6244 - val_loss: 58.0177\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 65.0505 - val_loss: 57.0025\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 63.5990 - val_loss: 55.4453\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 62.4018 - val_loss: 53.5631\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 60.8655 - val_loss: 52.8176\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 59.5336 - val_loss: 52.0833\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.6665 - val_loss: 51.2228\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 57.5989 - val_loss: 50.0884\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 56.3967 - val_loss: 49.4671\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 55.6032 - val_loss: 48.7317\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.6730 - val_loss: 48.0525\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 54.0034 - val_loss: 47.4059\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 53.3878 - val_loss: 47.0987\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 70.81 - 0s 94us/sample - loss: 52.8640 - val_loss: 46.8532\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 51.9563 - val_loss: 46.0292\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.3088 - val_loss: 45.1580\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 50.6825 - val_loss: 44.8002\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 50.1589 - val_loss: 44.5146\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 49.6865 - val_loss: 43.6615\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.1927 - val_loss: 43.4507\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 48.6877 - val_loss: 43.2815\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 48.2595 - val_loss: 42.8741\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 47.7049 - val_loss: 42.4540\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 47.6261 - val_loss: 42.1682\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 47.0126 - val_loss: 41.8557\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.6709 - val_loss: 41.9118\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.2687 - val_loss: 41.4211\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.6946 - val_loss: 41.4101\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 45.4240 - val_loss: 40.7003\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 44.8910 - val_loss: 40.6676\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.7224 - val_loss: 39.8514\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 44.3390 - val_loss: 39.9398\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 43.8249 - val_loss: 39.2981\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 43.5150 - val_loss: 38.6912\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 43.2460 - val_loss: 38.7720\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 42.8035 - val_loss: 38.7603\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.5555 - val_loss: 38.3668\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.3878 - val_loss: 37.9038\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 41.9440 - val_loss: 37.7885\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.5780 - val_loss: 37.8606\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.4201 - val_loss: 37.4089\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 41.2099 - val_loss: 36.6635\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 40.8685 - val_loss: 36.2593\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 40.4583 - val_loss: 36.2826\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.0981 - val_loss: 35.9317\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 40.1949 - val_loss: 35.4944\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.5953 - val_loss: 35.3115\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 39.3571 - val_loss: 35.2162\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.9690 - val_loss: 35.5998\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 38.8693 - val_loss: 34.8816\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 38.3828 - val_loss: 34.4112\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.3022 - val_loss: 34.1255\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.8641 - val_loss: 33.9728\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 37.6816 - val_loss: 33.7468\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 37.3525 - val_loss: 33.6110\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.1365 - val_loss: 33.2748\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 36.8810 - val_loss: 33.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.5255 - val_loss: 33.2145\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 36.3618 - val_loss: 32.6618\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.1229 - val_loss: 32.6888\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 36.0483 - val_loss: 32.6651\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 35.5724 - val_loss: 31.8900\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 35.3182 - val_loss: 31.6267\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 35.3379 - val_loss: 31.7616\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 34.8867 - val_loss: 31.5495\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.7502 - val_loss: 31.4409\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.5196 - val_loss: 30.9545\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 34.3166 - val_loss: 30.4063\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 34.0721 - val_loss: 30.3288\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 33.9407 - val_loss: 30.0319\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 33.6822 - val_loss: 30.0748\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 33.7988 - val_loss: 29.7539\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 33.1523 - val_loss: 30.0122\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 33.0373 - val_loss: 30.2412\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 32.9538 - val_loss: 29.7899\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 32.6954 - val_loss: 29.6517\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.3663 - val_loss: 28.9108\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 34.7723\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.7s\n",
      "[CV] learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74 ...\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 592.3980 - val_loss: 502.7538\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 520.7194 - val_loss: 422.5028\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 426.7979 - val_loss: 320.6958\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 315.8472 - val_loss: 217.5816\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 217.7549 - val_loss: 148.4863\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 159.6042 - val_loss: 117.6967\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 134.1750 - val_loss: 104.7813\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 122.3172 - val_loss: 99.3039\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 116.9869 - val_loss: 94.9855\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 111.8501 - val_loss: 90.8191\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 107.0285 - val_loss: 87.0291\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 102.8492 - val_loss: 83.2904\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 98.9340 - val_loss: 80.3157\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 95.2451 - val_loss: 77.3326\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 92.6857 - val_loss: 73.8591\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 88.2855 - val_loss: 71.2421\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 85.2300 - val_loss: 68.6448\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 82.7137 - val_loss: 66.6809\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 79.6978 - val_loss: 63.7376\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 77.0511 - val_loss: 62.7007\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 74.7016 - val_loss: 60.4597\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 72.5019 - val_loss: 59.0114\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 70.6229 - val_loss: 57.0770\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 68.8026 - val_loss: 55.5087\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 66.9397 - val_loss: 54.5621\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 65.3263 - val_loss: 53.0945\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 63.8019 - val_loss: 52.2230\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 62.5385 - val_loss: 50.8901\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 61.1953 - val_loss: 50.1358\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 60.1739 - val_loss: 49.5983\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 59.0757 - val_loss: 49.1731\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 58.3125 - val_loss: 49.8441\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 57.4274 - val_loss: 48.1610\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 56.5183 - val_loss: 46.9851\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 55.7230 - val_loss: 46.7654\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 55.8349 - val_loss: 46.6892\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 54.3240 - val_loss: 46.2058\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 53.6867 - val_loss: 45.9429\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 53.2238 - val_loss: 45.5532\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 52.7977 - val_loss: 44.5325\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 52.1157 - val_loss: 44.3886\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 51.6099 - val_loss: 44.1929\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 51.1239 - val_loss: 43.7862\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 50.7520 - val_loss: 43.1587\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 50.5781 - val_loss: 42.7215\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 88us/sample - loss: 49.9792 - val_loss: 43.1508\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 49.4537 - val_loss: 42.9638\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 49.2697 - val_loss: 42.3150\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 110us/sample - loss: 48.8872 - val_loss: 42.2597\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.8059 - val_loss: 41.8723\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 48.1909 - val_loss: 41.2834\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 47.7596 - val_loss: 41.0031\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 47.4513 - val_loss: 41.1771\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 47.0716 - val_loss: 40.5460\n",
      "Epoch 55/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 46.8193 - val_loss: 40.9620\n",
      "Epoch 56/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 46.3940 - val_loss: 40.8505\n",
      "Epoch 57/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.1132 - val_loss: 40.3715\n",
      "Epoch 58/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 46.3010 - val_loss: 39.8946\n",
      "Epoch 59/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 45.5159 - val_loss: 39.8641\n",
      "Epoch 60/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 45.3833 - val_loss: 38.8915\n",
      "Epoch 61/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 44.8276 - val_loss: 39.1387\n",
      "Epoch 62/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 44.5285 - val_loss: 39.5547\n",
      "Epoch 63/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 44.3117 - val_loss: 38.8557\n",
      "Epoch 64/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 43.9806 - val_loss: 38.9496\n",
      "Epoch 65/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.8261 - val_loss: 38.1568\n",
      "Epoch 66/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.5871 - val_loss: 37.2188\n",
      "Epoch 67/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 43.2441 - val_loss: 37.2589\n",
      "Epoch 68/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 43.0059 - val_loss: 36.9588\n",
      "Epoch 69/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 42.6985 - val_loss: 36.7150\n",
      "Epoch 70/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 42.5666 - val_loss: 36.6747\n",
      "Epoch 71/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 42.0295 - val_loss: 36.8503\n",
      "Epoch 72/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.8416 - val_loss: 36.6233\n",
      "Epoch 73/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.5380 - val_loss: 36.3267\n",
      "Epoch 74/100\n",
      "180/180 [==============================] - ETA: 0s - loss: 66.09 - 0s 105us/sample - loss: 41.1656 - val_loss: 35.7474\n",
      "Epoch 75/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.9222 - val_loss: 35.5857\n",
      "Epoch 76/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 40.7067 - val_loss: 35.4437\n",
      "Epoch 77/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 40.6098 - val_loss: 34.9655\n",
      "Epoch 78/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 40.2814 - val_loss: 34.6066\n",
      "Epoch 79/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 40.4127 - val_loss: 34.1257\n",
      "Epoch 80/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 39.8476 - val_loss: 34.1356\n",
      "Epoch 81/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 39.7857 - val_loss: 33.9402\n",
      "Epoch 82/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 39.3051 - val_loss: 34.2141\n",
      "Epoch 83/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 38.9839 - val_loss: 33.4963\n",
      "Epoch 84/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.6919 - val_loss: 33.6197\n",
      "Epoch 85/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 38.6699 - val_loss: 33.2009\n",
      "Epoch 86/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.4709 - val_loss: 32.7415\n",
      "Epoch 87/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 38.2044 - val_loss: 32.7561\n",
      "Epoch 88/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 38.0442 - val_loss: 32.1823\n",
      "Epoch 89/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 37.6384 - val_loss: 32.3605\n",
      "Epoch 90/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.5341 - val_loss: 32.1018\n",
      "Epoch 91/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.2916 - val_loss: 31.6647\n",
      "Epoch 92/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.1610 - val_loss: 31.4526\n",
      "Epoch 93/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 37.0860 - val_loss: 31.3318\n",
      "Epoch 94/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.6709 - val_loss: 31.1511\n",
      "Epoch 95/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 36.3698 - val_loss: 30.8379\n",
      "Epoch 96/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 36.3253 - val_loss: 30.8661\n",
      "Epoch 97/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 36.2129 - val_loss: 30.3945\n",
      "Epoch 98/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.8963 - val_loss: 30.1982\n",
      "Epoch 99/100\n",
      "180/180 [==============================] - 0s 138us/sample - loss: 35.7549 - val_loss: 29.8075\n",
      "Epoch 100/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 35.5262 - val_loss: 29.7970\n",
      "90/90 [==============================] - 0s 44us/sample - loss: 24.9830\n",
      "[CV]  learning_rate=0.0007814361860439043, n_hidden=1, n_neurons=74, total=   2.6s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 401.3324 - val_loss: 152.8101\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 149us/sample - loss: 316.1091 - val_loss: 350.0138\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 232.2919 - val_loss: 300.3606\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 274.6873 - val_loss: 116.6808\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 83.5501 - val_loss: 74.0282\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 70.9639 - val_loss: 47.8970\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 81.8420 - val_loss: 61.3508\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 53.4513 - val_loss: 49.7415\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 59.2526 - val_loss: 53.6481\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 74.4715 - val_loss: 34.6974\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 39.5069 - val_loss: 32.3495\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 41.2120 - val_loss: 29.7955\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.3899 - val_loss: 26.6992\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 23.3802 - val_loss: 23.8857\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 20.9800 - val_loss: 50.6364\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 43.8013 - val_loss: 23.5134\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 22.2418 - val_loss: 51.4313\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 22.5168 - val_loss: 20.1384\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 41.6578 - val_loss: 31.1802\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 24.0956 - val_loss: 35.2813\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 68.2964 - val_loss: 21.0141\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 35.3392 - val_loss: 22.8068\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 25.8527 - val_loss: 71.7404\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 30.6391 - val_loss: 21.7389\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 30.9430 - val_loss: 23.5060\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 18.3821 - val_loss: 25.7458\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 111us/sample - loss: 23.7420 - val_loss: 20.3766\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 15.0562 - val_loss: 17.8905\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 18.0561 - val_loss: 17.0210\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 19.3781 - val_loss: 22.2817\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 14.8058 - val_loss: 29.4034\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.5927 - val_loss: 18.0460\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 18.2248 - val_loss: 33.9865\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 26.1798 - val_loss: 39.1959\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 27.4611 - val_loss: 17.8562\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 13.3882 - val_loss: 16.1960\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 12.1941 - val_loss: 23.7435\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 21.0953 - val_loss: 20.8620\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 28.5734 - val_loss: 15.3677\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 19.3983 - val_loss: 42.3627\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 17.7948 - val_loss: 24.2534\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 23.4587 - val_loss: 28.7936\n",
      "Epoch 43/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 14.5013 - val_loss: 18.8072\n",
      "Epoch 44/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 12.2576 - val_loss: 14.7037\n",
      "Epoch 45/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 17.3926 - val_loss: 52.3591\n",
      "Epoch 46/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 36.2494 - val_loss: 15.2251\n",
      "Epoch 47/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 14.5282 - val_loss: 15.1863\n",
      "Epoch 48/100\n",
      "180/180 [==============================] - 0s 139us/sample - loss: 16.3266 - val_loss: 19.0651\n",
      "Epoch 49/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 15.9983 - val_loss: 59.5998\n",
      "Epoch 50/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.4807 - val_loss: 73.4764\n",
      "Epoch 51/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 34.2226 - val_loss: 16.3665\n",
      "Epoch 52/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 11.9245 - val_loss: 15.7083\n",
      "Epoch 53/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 28.2946 - val_loss: 44.6941\n",
      "Epoch 54/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.6206 - val_loss: 21.0747\n",
      "90/90 [==============================] - 0s 89us/sample - loss: 32.1550\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.7s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 1s 3ms/sample - loss: 292.9857 - val_loss: 150.5109\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 141.1087 - val_loss: 225.8679\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 223.5075 - val_loss: 310.6685\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 208.9495 - val_loss: 230.4313\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 230.9520 - val_loss: 92.7066\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 53.1258 - val_loss: 56.0980\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 65.1219 - val_loss: 89.4350\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 133us/sample - loss: 75.0332 - val_loss: 67.0958\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.2168 - val_loss: 122.5726\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 57.7645 - val_loss: 83.6184\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 58.5102 - val_loss: 23.8598\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 46.1159 - val_loss: 57.5041\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 44.7079 - val_loss: 34.7924\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 54.1820 - val_loss: 27.9629\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 83us/sample - loss: 24.5912 - val_loss: 21.1775\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 25.0180 - val_loss: 37.5408\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 95.8966 - val_loss: 33.0566\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 30.0557 - val_loss: 26.3700\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 32.2242 - val_loss: 20.4725\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 22.6578 - val_loss: 37.0840\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.6007 - val_loss: 66.5033\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.4159 - val_loss: 32.0167\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 40.5256 - val_loss: 18.6017\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 35.3432 - val_loss: 21.4179\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 21.6221 - val_loss: 18.5820\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 20.6314 - val_loss: 16.6313\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 17.5511 - val_loss: 16.2510\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 19.0236 - val_loss: 35.5965\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 25.3859 - val_loss: 81.9903\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 61.8771 - val_loss: 18.8130\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 18.3361 - val_loss: 16.5186\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 23.2030 - val_loss: 15.9708\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 30.5765 - val_loss: 18.7029\n",
      "Epoch 34/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 21.6315 - val_loss: 54.7517\n",
      "Epoch 35/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 26.1208 - val_loss: 32.7003\n",
      "Epoch 36/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 22.2022 - val_loss: 16.1456\n",
      "Epoch 37/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 56.3112 - val_loss: 20.7513\n",
      "Epoch 38/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 21.7969 - val_loss: 37.9338\n",
      "Epoch 39/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 22.4628 - val_loss: 31.2747\n",
      "Epoch 40/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 27.9086 - val_loss: 17.8938\n",
      "Epoch 41/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 17.2838 - val_loss: 19.0050\n",
      "Epoch 42/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 20.6641 - val_loss: 30.5466\n",
      "90/90 [==============================] - 0s 67us/sample - loss: 35.1924\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.6s\n",
      "[CV] learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78 ....\n",
      "Train on 180 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "180/180 [==============================] - 0s 2ms/sample - loss: 466.2099 - val_loss: 353.2231\n",
      "Epoch 2/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 203.8177 - val_loss: 386.2215\n",
      "Epoch 3/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 344.2270 - val_loss: 94.5998\n",
      "Epoch 4/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 228.4950 - val_loss: 213.3386\n",
      "Epoch 5/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 167.1251 - val_loss: 80.7292\n",
      "Epoch 6/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 85.4755 - val_loss: 51.4002\n",
      "Epoch 7/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 54.0761 - val_loss: 44.7171\n",
      "Epoch 8/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 81.3973 - val_loss: 45.8911\n",
      "Epoch 9/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 48.2117 - val_loss: 43.2586\n",
      "Epoch 10/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 56.8398 - val_loss: 37.0028\n",
      "Epoch 11/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 135.4252 - val_loss: 38.1035\n",
      "Epoch 12/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 45.0301 - val_loss: 35.9797\n",
      "Epoch 13/100\n",
      "180/180 [==============================] - 0s 105us/sample - loss: 49.9429 - val_loss: 29.3376\n",
      "Epoch 14/100\n",
      "180/180 [==============================] - 0s 128us/sample - loss: 46.2621 - val_loss: 33.6070\n",
      "Epoch 15/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 37.8622 - val_loss: 35.0535\n",
      "Epoch 16/100\n",
      "180/180 [==============================] - 0s 94us/sample - loss: 42.3775 - val_loss: 31.8466\n",
      "Epoch 17/100\n",
      "180/180 [==============================] - 0s 127us/sample - loss: 50.6726 - val_loss: 24.3019\n",
      "Epoch 18/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 30.8747 - val_loss: 31.7110\n",
      "Epoch 19/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 54.6826 - val_loss: 25.4972\n",
      "Epoch 20/100\n",
      "180/180 [==============================] - 0s 122us/sample - loss: 41.6633 - val_loss: 29.1782\n",
      "Epoch 21/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 26.0553 - val_loss: 21.0221\n",
      "Epoch 22/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 31.1049 - val_loss: 20.7500\n",
      "Epoch 23/100\n",
      "180/180 [==============================] - 0s 144us/sample - loss: 36.4823 - val_loss: 20.3649\n",
      "Epoch 24/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 31.6510 - val_loss: 20.7281\n",
      "Epoch 25/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 24.3760 - val_loss: 23.0579\n",
      "Epoch 26/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 49.7480 - val_loss: 26.4147\n",
      "Epoch 27/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 46.0535 - val_loss: 108.8371\n",
      "Epoch 28/100\n",
      "180/180 [==============================] - 0s 116us/sample - loss: 61.6098 - val_loss: 27.1616\n",
      "Epoch 29/100\n",
      "180/180 [==============================] - 0s 100us/sample - loss: 37.4466 - val_loss: 21.0188\n",
      "Epoch 30/100\n",
      "180/180 [==============================] - 0s 117us/sample - loss: 30.7879 - val_loss: 20.4835\n",
      "Epoch 31/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 27.4040 - val_loss: 36.1873\n",
      "Epoch 32/100\n",
      "180/180 [==============================] - 0s 89us/sample - loss: 41.2496 - val_loss: 40.1566\n",
      "Epoch 33/100\n",
      "180/180 [==============================] - 0s 111us/sample - loss: 34.7782 - val_loss: 35.5394\n",
      "90/90 [==============================] - 0s 77us/sample - loss: 32.0864\n",
      "[CV]  learning_rate=0.023013121253611973, n_hidden=1, n_neurons=78, total=   1.2s\n",
      "Train on 270 samples, validate on 134 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   59.1s finished\n",
      "C:\\Users\\richard.stansbury\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 1s 2ms/sample - loss: 583.8328 - val_loss: 523.5317\n",
      "Epoch 2/100\n",
      "270/270 [==============================] - 0s 96us/sample - loss: 528.9890 - val_loss: 438.3452\n",
      "Epoch 3/100\n",
      "270/270 [==============================] - 0s 100us/sample - loss: 389.1581 - val_loss: 218.2884\n",
      "Epoch 4/100\n",
      "270/270 [==============================] - 0s 100us/sample - loss: 163.0669 - val_loss: 108.1025\n",
      "Epoch 5/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 116.8943 - val_loss: 100.6449\n",
      "Epoch 6/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 105.3471 - val_loss: 84.6953\n",
      "Epoch 7/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 94.8330 - val_loss: 76.5121\n",
      "Epoch 8/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 86.7094 - val_loss: 69.2287\n",
      "Epoch 9/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 78.3921 - val_loss: 62.6716\n",
      "Epoch 10/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 71.4048 - val_loss: 57.4610\n",
      "Epoch 11/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 66.3688 - val_loss: 57.6062\n",
      "Epoch 12/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 61.9316 - val_loss: 51.3060\n",
      "Epoch 13/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 57.6299 - val_loss: 47.7231\n",
      "Epoch 14/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 53.6423 - val_loss: 45.9876\n",
      "Epoch 15/100\n",
      "270/270 [==============================] - 0s 140us/sample - loss: 50.9503 - val_loss: 50.3333\n",
      "Epoch 16/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 49.9339 - val_loss: 41.9181\n",
      "Epoch 17/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 47.0548 - val_loss: 40.9085\n",
      "Epoch 18/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 45.7341 - val_loss: 39.7258\n",
      "Epoch 19/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 44.2892 - val_loss: 38.9552\n",
      "Epoch 20/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 42.5633 - val_loss: 37.8126\n",
      "Epoch 21/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 41.6202 - val_loss: 36.8565\n",
      "Epoch 22/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 40.0614 - val_loss: 36.5405\n",
      "Epoch 23/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 39.0148 - val_loss: 49.3174\n",
      "Epoch 24/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 39.2908 - val_loss: 34.1498\n",
      "Epoch 25/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 36.8674 - val_loss: 33.2054\n",
      "Epoch 26/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 36.0461 - val_loss: 32.6074\n",
      "Epoch 27/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 34.7237 - val_loss: 32.2217\n",
      "Epoch 28/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 34.1929 - val_loss: 30.7640\n",
      "Epoch 29/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 34.0165 - val_loss: 30.7008\n",
      "Epoch 30/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 32.6834 - val_loss: 30.4055\n",
      "Epoch 31/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 31.3121 - val_loss: 29.9757\n",
      "Epoch 32/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 30.6342 - val_loss: 27.7685\n",
      "Epoch 33/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 30.1653 - val_loss: 27.0044\n",
      "Epoch 34/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 29.1440 - val_loss: 26.7361\n",
      "Epoch 35/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 29.1482 - val_loss: 25.8612\n",
      "Epoch 36/100\n",
      "270/270 [==============================] - 0s 114us/sample - loss: 27.9134 - val_loss: 25.6054\n",
      "Epoch 37/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 27.0945 - val_loss: 24.7323\n",
      "Epoch 38/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 26.9274 - val_loss: 24.1887\n",
      "Epoch 39/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 26.2959 - val_loss: 23.7360\n",
      "Epoch 40/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 25.5603 - val_loss: 23.6031\n",
      "Epoch 41/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 25.3374 - val_loss: 24.5273\n",
      "Epoch 42/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 24.6759 - val_loss: 23.8642\n",
      "Epoch 43/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 24.2926 - val_loss: 23.0048\n",
      "Epoch 44/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 24.1109 - val_loss: 21.9097\n",
      "Epoch 45/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 23.8854 - val_loss: 21.2632\n",
      "Epoch 46/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 23.1595 - val_loss: 22.3246\n",
      "Epoch 47/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 23.5614 - val_loss: 21.9164\n",
      "Epoch 48/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 22.8337 - val_loss: 20.9294\n",
      "Epoch 49/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 22.8185 - val_loss: 19.9112\n",
      "Epoch 50/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 22.8430 - val_loss: 20.0842\n",
      "Epoch 51/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 21.9388 - val_loss: 19.5658\n",
      "Epoch 52/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 22.1661 - val_loss: 19.1478\n",
      "Epoch 53/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 21.9118 - val_loss: 19.9509\n",
      "Epoch 54/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 21.4996 - val_loss: 19.0666\n",
      "Epoch 55/100\n",
      "270/270 [==============================] - 0s 129us/sample - loss: 21.2490 - val_loss: 18.5016\n",
      "Epoch 56/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 20.7037 - val_loss: 19.1956\n",
      "Epoch 57/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 21.2502 - val_loss: 21.5835\n",
      "Epoch 58/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 20.6418 - val_loss: 18.4912\n",
      "Epoch 59/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 20.4283 - val_loss: 17.8705\n",
      "Epoch 60/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 19.7412 - val_loss: 17.7490\n",
      "Epoch 61/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 20.1408 - val_loss: 17.5890\n",
      "Epoch 62/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 19.8389 - val_loss: 19.1225\n",
      "Epoch 63/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 20.0202 - val_loss: 17.6508\n",
      "Epoch 64/100\n",
      "270/270 [==============================] - 0s 116us/sample - loss: 19.6784 - val_loss: 18.7106\n",
      "Epoch 65/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.1093 - val_loss: 17.1595\n",
      "Epoch 66/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.0598 - val_loss: 17.2840\n",
      "Epoch 67/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.9796 - val_loss: 18.1601\n",
      "Epoch 68/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 19.3309 - val_loss: 17.1377\n",
      "Epoch 69/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2896 - val_loss: 16.7315\n",
      "Epoch 70/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 18.4427 - val_loss: 16.7119\n",
      "Epoch 71/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.8293 - val_loss: 17.4678\n",
      "Epoch 72/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.7546 - val_loss: 16.6315\n",
      "Epoch 73/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 18.2095 - val_loss: 16.4738\n",
      "Epoch 74/100\n",
      "270/270 [==============================] - 0s 107us/sample - loss: 18.0889 - val_loss: 16.6038\n",
      "Epoch 75/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 18.2867 - val_loss: 16.3512\n",
      "Epoch 76/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.0259 - val_loss: 16.6975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.7973 - val_loss: 16.2581\n",
      "Epoch 78/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 17.7507 - val_loss: 24.1572\n",
      "Epoch 79/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 18.7235 - val_loss: 17.0640\n",
      "Epoch 80/100\n",
      "270/270 [==============================] - 0s 122us/sample - loss: 17.7068 - val_loss: 18.8588\n",
      "Epoch 81/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.7348 - val_loss: 16.3200\n",
      "Epoch 82/100\n",
      "270/270 [==============================] - 0s 103us/sample - loss: 17.5287 - val_loss: 15.8408\n",
      "Epoch 83/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.4712 - val_loss: 15.7981\n",
      "Epoch 84/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.5123 - val_loss: 16.0019\n",
      "Epoch 85/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.1369 - val_loss: 16.0562\n",
      "Epoch 86/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.0689 - val_loss: 15.9726\n",
      "Epoch 87/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.3819 - val_loss: 15.8501\n",
      "Epoch 88/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 17.2237 - val_loss: 16.3386\n",
      "Epoch 89/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.2427 - val_loss: 15.7244\n",
      "Epoch 90/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.0856 - val_loss: 16.0268\n",
      "Epoch 91/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 17.1649 - val_loss: 15.8056\n",
      "Epoch 92/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 16.8764 - val_loss: 15.6320\n",
      "Epoch 93/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.5414 - val_loss: 15.4881\n",
      "Epoch 94/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.7811 - val_loss: 15.2772\n",
      "Epoch 95/100\n",
      "270/270 [==============================] - 0s 118us/sample - loss: 16.5557 - val_loss: 15.8493\n",
      "Epoch 96/100\n",
      "270/270 [==============================] - 0s 115us/sample - loss: 16.6232 - val_loss: 15.9881\n",
      "Epoch 97/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.4985 - val_loss: 15.3283\n",
      "Epoch 98/100\n",
      "270/270 [==============================] - 0s 96us/sample - loss: 16.6098 - val_loss: 15.2057\n",
      "Epoch 99/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 16.2506 - val_loss: 19.8862\n",
      "Epoch 100/100\n",
      "270/270 [==============================] - 0s 111us/sample - loss: 17.6560 - val_loss: 15.5610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.00031819783764683556, 'n_hidden': 3, 'n_neurons': 64}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=13):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_hidden': [0,1,2,3],\n",
    "    'n_neurons': np.arange(1,100),\n",
    "    'learning_rate': reciprocal(3e-4,3e-2),\n",
    "}\n",
    "\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "rnd_search = RandomizedSearchCV(model, \n",
    "                                param_dist, \n",
    "                                n_iter=10, \n",
    "                                cv=3, verbose=2, \n",
    "                                error_score='raise-deprecating')\n",
    "print(X_train)\n",
    "\n",
    "rnd_search.fit(X_train, \n",
    "               y_train, \n",
    "               epochs=100,\n",
    "               validation_data=(X_val, y_val),\n",
    "               callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "\n",
    "rnd_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN Demonstration\n",
    "\n",
    "Our final demonstration will use the MNIST image set to demonstrate a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library and Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n",
      "(55000, 28, 28) (5000, 28, 28)\n",
      "(55000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "#(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "print(X_train.shape, X_valid.shape)\n",
    "print(y_train.shape, y_valid.shape)\n",
    "\n",
    "\n",
    "X_mean = X_train.mean(axis=0, keepdims=True)\n",
    "X_std = X_train.std(axis=0, keepdims=True) + 1e-7\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_valid = (X_valid - X_mean) / X_std\n",
    "X_test = (X_test - X_mean) / X_std\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D,\n",
    "                        kernel_size=3, activation='relu', padding=\"SAME\")\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 484s 9ms/sample - loss: 0.2947 - accuracy: 0.9209 - val_loss: 0.0696 - val_accuracy: 0.9830\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 483s 9ms/sample - loss: 0.1164 - accuracy: 0.9733 - val_loss: 0.0578 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 474s 9ms/sample - loss: 0.0920 - accuracy: 0.9786 - val_loss: 0.0525 - val_accuracy: 0.9878\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 472s 9ms/sample - loss: 0.0888 - accuracy: 0.9799 - val_loss: 0.0935 - val_accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 468s 9ms/sample - loss: 0.0741 - accuracy: 0.9828 - val_loss: 0.0600 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 468s 9ms/sample - loss: 0.0745 - accuracy: 0.9837 - val_loss: 0.0582 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 471s 9ms/sample - loss: 0.0704 - accuracy: 0.9847 - val_loss: 0.0488 - val_accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 471s 9ms/sample - loss: 0.0647 - accuracy: 0.9856 - val_loss: 0.0505 - val_accuracy: 0.9884\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 470s 9ms/sample - loss: 0.0567 - accuracy: 0.9865 - val_loss: 0.0531 - val_accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 473s 9ms/sample - loss: 0.0503 - accuracy: 0.9892 - val_loss: 0.0762 - val_accuracy: 0.9870\n",
      "10000/10000 [==============================] - 27s 3ms/sample - loss: 1814.9945 - accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 27s 3ms/sample - loss: 1814.9945 - accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
